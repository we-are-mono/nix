From: Tomaz Zaman <tzaman@zaman.io>
Date: Sat, 24 Jan 2026 02:17:11 +0100
Subject: [PATCH] ASK: Port NXP ASK kernel modifications to Linux 6.12

This patch ports the NXP Advanced Switching Kit (ASK) modifications
to the Linux 6.12 kernel. The ASK provides hardware-accelerated packet
processing for Layerscape platforms including:

- DPAA (Data Path Acceleration Architecture) ethernet driver enhancements
- Frame Manager (FMan) SDK driver modifications
- QBMan (Queue/Buffer Manager) driver updates
- IPsec offload support for both IPv4 and IPv6
- Netfilter QoS marking extensions
- Bridge and network core modifications for fast path

Removed dead code guarded by CONFIG_CPE_NATT which was never defined
in any Kconfig file.

Upstream-Status: Inappropriate [NXP vendor kernel modifications]
Signed-off-by: Tomaz Zaman <tomaz@mono.si>

diff --git a/Makefile b/Makefile
index 66ae67c52da8..a1d4113d3f65 100644
--- a/Makefile
+++ b/Makefile
@@ -130,6 +130,11 @@ export KBUILD_CLIPPY
 
 # Use make M=dir or set the environment variable KBUILD_EXTMOD to specify the
 # directory of external module to build. Setting M= takes precedence.
+
+ifdef SUBDIRS
+  KBUILD_EXTMOD ?= $(SUBDIRS)
+endif
+
 ifeq ("$(origin M)", "command line")
   KBUILD_EXTMOD := $(M)
 endif
diff --git a/arch/arm64/boot/dts/freescale/Makefile b/arch/arm64/boot/dts/freescale/Makefile
index 0bf63f8fff03..699623e36d27 100644
--- a/arch/arm64/boot/dts/freescale/Makefile
+++ b/arch/arm64/boot/dts/freescale/Makefile
@@ -19,7 +19,9 @@ dtb-$(CONFIG_ARCH_LAYERSCAPE) += fsl-ls1028a-rdb-dpdk.dtb
 dtb-$(CONFIG_ARCH_LAYERSCAPE) += fsl-ls1043a-qds.dtb
 dtb-$(CONFIG_ARCH_LAYERSCAPE) += fsl-ls1043a-qds-sdk.dtb
 dtb-$(CONFIG_ARCH_LAYERSCAPE) += fsl-ls1043a-rdb.dtb
+dtb-$(CONFIG_ARCH_LAYERSCAPE) += fsl-ls1043a-rdb-w906x.dtb
 dtb-$(CONFIG_ARCH_LAYERSCAPE) += fsl-ls1043a-rdb-sdk.dtb
+dtb-$(CONFIG_ARCH_LAYERSCAPE) += fsl-ls1043a-rdb-w906x-sdk.dtb
 dtb-$(CONFIG_ARCH_LAYERSCAPE) += fsl-ls1043a-rdb-usdpaa.dtb
 dtb-$(CONFIG_ARCH_LAYERSCAPE) += fsl-ls1043a-tqmls1043a-mbls10xxa.dtb
 dtb-$(CONFIG_ARCH_LAYERSCAPE) += fsl-ls1046a-frwy.dtb
@@ -28,7 +30,9 @@ dtb-$(CONFIG_ARCH_LAYERSCAPE) += fsl-ls1046a-frwy-usdpaa.dtb
 dtb-$(CONFIG_ARCH_LAYERSCAPE) += fsl-ls1046a-qds.dtb
 dtb-$(CONFIG_ARCH_LAYERSCAPE) += fsl-ls1046a-qds-sdk.dtb
 dtb-$(CONFIG_ARCH_LAYERSCAPE) += fsl-ls1046a-rdb.dtb
+dtb-$(CONFIG_ARCH_LAYERSCAPE) += fsl-ls1046a-rdb-w906x.dtb
 dtb-$(CONFIG_ARCH_LAYERSCAPE) += fsl-ls1046a-rdb-sdk.dtb
+dtb-$(CONFIG_ARCH_LAYERSCAPE) += fsl-ls1046a-rdb-w906x-sdk.dtb
 dtb-$(CONFIG_ARCH_LAYERSCAPE) += fsl-ls1046a-rdb-usdpaa.dtb
 dtb-$(CONFIG_ARCH_LAYERSCAPE) += fsl-ls1046a-rdb-shared-mac9-only.dtb
 dtb-$(CONFIG_ARCH_LAYERSCAPE) += fsl-ls1046a-rdb-usdpaa-shared-mac10.dtb
diff --git a/arch/arm64/boot/dts/freescale/fsl-ls1043a-dgw-sdk.dts b/arch/arm64/boot/dts/freescale/fsl-ls1043a-dgw-sdk.dts
new file mode 100755
index 000000000000..0def62e70e35
--- /dev/null
+++ b/arch/arm64/boot/dts/freescale/fsl-ls1043a-dgw-sdk.dts
@@ -0,0 +1,90 @@
+/*
+ * Device Tree Include file for Freescale Layerscape-1043A family SoC.
+ *
+ * Copyright 2014-2015 Freescale Semiconductor, Inc.
+ * Mingkai Hu <Mingkai.hu@freescale.com>
+ * Copyright 2018 NXP
+ *
+ * This file is dual-licensed: you can use it either under the terms
+ * of the GPLv2 or the X11 license, at your option. Note that this dual
+ * licensing only applies to this file, and not this project as a
+ * whole.
+ *
+ *  a) This library is free software; you can redistribute it and/or
+ *     modify it under the terms of the GNU General Public License as
+ *     published by the Free Software Foundation; either version 2 of the
+ *     License, or (at your option) any later version.
+ *
+ *     This library is distributed in the hope that it will be useful,
+ *     but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *     GNU General Public License for more details.
+ *
+ * Or, alternatively,
+ *
+ *  b) Permission is hereby granted, free of charge, to any person
+ *     obtaining a copy of this software and associated documentation
+ *     files (the "Software"), to deal in the Software without
+ *     restriction, including without limitation the rights to use,
+ *     copy, modify, merge, publish, distribute, sublicense, and/or
+ *     sell copies of the Software, and to permit persons to whom the
+ *     Software is furnished to do so, subject to the following
+ *     conditions:
+ *
+ *     The above copyright notice and this permission notice shall be
+ *     included in all copies or substantial portions of the Software.
+ *
+ *     THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ *     EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES
+ *     OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ *     NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ *     HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
+ *     WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ *     FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ *     OTHER DEALINGS IN THE SOFTWARE.
+ */
+
+#include "fsl-ls1043a-dgw.dts"
+#include "qoriq-qman-portals-sdk.dtsi"
+#include "qoriq-bman-portals-sdk.dtsi"
+
+&bman_fbpr {
+	compatible = "fsl,bman-fbpr";
+	alloc-ranges = <0 0 0x10000 0>;
+};
+&qman_fqd {
+	compatible = "fsl,qman-fqd";
+	alloc-ranges = <0 0 0x10000 0>;
+};
+&qman_pfdr {
+	compatible = "fsl,qman-pfdr";
+	alloc-ranges = <0 0 0x10000 0>;
+};
+
+&soc {
+/delete-property/ dma-coherent;
+
+#include "qoriq-dpaa-eth.dtsi"
+#include "qoriq-fman3-0-6oh.dtsi"
+
+pcie@3400000 {
+	/delete-property/ iommu-map;
+	dma-coherent;
+};
+
+pcie@3500000 {
+	/delete-property/ iommu-map;
+	dma-coherent;
+};
+
+pcie@3600000 {
+	/delete-property/ iommu-map;
+	dma-coherent;
+};
+
+/delete-node/ iommu@9000000;
+};
+
+&fman0 {
+	compatible = "fsl,fman", "simple-bus";
+};
diff --git a/arch/arm64/boot/dts/freescale/fsl-ls1043a-dgw.dts b/arch/arm64/boot/dts/freescale/fsl-ls1043a-dgw.dts
new file mode 100755
index 000000000000..940bece8638d
--- /dev/null
+++ b/arch/arm64/boot/dts/freescale/fsl-ls1043a-dgw.dts
@@ -0,0 +1,292 @@
+/*
+ * Device Tree Include file for Freescale Layerscape-1043A family SoC.
+ *
+ * Copyright 2014-2015, Freescale Semiconductor
+ *
+ * Mingkai Hu <Mingkai.hu@freescale.com>
+ * Copyright 2018 NXP
+ *
+ * This file is dual-licensed: you can use it either under the terms
+ * of the GPLv2 or the X11 license, at your option. Note that this dual
+ * licensing only applies to this file, and not this project as a
+ * whole.
+ *
+ *  a) This library is free software; you can redistribute it and/or
+ *     modify it under the terms of the GNU General Public License as
+ *     published by the Free Software Foundation; either version 2 of the
+ *     License, or (at your option) any later version.
+ *
+ *     This library is distributed in the hope that it will be useful,
+ *     but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *     GNU General Public License for more details.
+ *
+ * Or, alternatively,
+ *
+ *  b) Permission is hereby granted, free of charge, to any person
+ *     obtaining a copy of this software and associated documentation
+ *     files (the "Software"), to deal in the Software without
+ *     restriction, including without limitation the rights to use,
+ *     copy, modify, merge, publish, distribute, sublicense, and/or
+ *     sell copies of the Software, and to permit persons to whom the
+ *     Software is furnished to do so, subject to the following
+ *     conditions:
+ *
+ *     The above copyright notice and this permission notice shall be
+ *     included in all copies or substantial portions of the Software.
+ *
+ *     THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ *     EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES
+ *     OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ *     NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ *     HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
+ *     WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ *     FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ *     OTHER DEALINGS IN THE SOFTWARE.
+ */
+
+/dts-v1/;
+#include "fsl-ls1043a.dtsi"
+
+/ {
+	model = "LS1043A DGW Board";
+	compatible = "fsl,ls1043a-dgw", "fsl,ls1043a";
+
+	aliases {
+		crypto = &crypto;
+	};
+};
+
+&i2c0 {
+	status = "okay";
+
+	pmic@08 {
+		compatible = "nxp,34vr500";
+		reg = <0x8>;
+	};
+	pca9546@21 {
+		compatible = "nxp,pca9546";
+		reg = <0x21>;
+	};
+	ina220@40 {
+		compatible = "ti,ina220";
+		reg = <0x40>;
+		shunt-resistor = <1000>;
+	};
+	adt7461a@4c {
+		compatible = "adi,adt7461";
+		reg = <0x4c>;
+	};
+	rtc@51 {
+		compatible = "nxp,pcf2127";
+		reg = <0x51>;
+	};
+	eeprom@52 {
+		compatible = "at24,24c04";
+		reg = <0x52>;
+	};
+	eeprom@53 {
+		compatible = "at24,24c04";
+		reg = <0x53>;
+	};
+	pca9554@77 {
+		compatible = "nxp,pca9554";
+		reg = <0x77>;
+        #address-cells = <1>;
+        #size-cells = <0>;
+
+	    i2c@3 {
+              #address-cells = <1>;
+              #size-cells = <0>;
+		      reg = <0x3>;
+
+			  eeprom@50 {
+				      compatible = "at24,24c04";
+				      reg = <0x50>;
+			   };
+		};
+
+	 };	
+};
+
+&ifc {
+	status = "okay";
+	#address-cells = <2>;
+	#size-cells = <1>;
+/* NAND Flash on board 128MB */
+	ranges = <0x0 0x0 0x0 0x7e800000 0x00010000>;
+
+
+		nand@0,0 {
+			compatible = "fsl,ifc-nand";
+			nand-ecc-mode = "none";
+			#address-cells = <1>;
+			#size-cells = <1>;
+            reg = <0x0 0x0 0x10000>;
+		
+/* this partitions nodes are not in previous current sdk may be moved to u-boot ,adding with reference to previos sdk */
+             partition@0 {
+				/* This location must not be altered  */
+				/* 1MB for u-boot Bootloader Image */
+				reg = <0x0 0x00100000>;
+				label = "NAND U-Boot Image";
+				read-only;
+			};
+
+			partition@100000 {
+				/* 128KB for u-boot environment */
+				reg = <0x00100000 0x00020000>;
+				label = "NAND U-Boot Env";
+				read-only;
+			};
+
+			partition@120000 {
+				/* 256KB for u-boot environment */
+				reg = <0x00120000 0x00040000>;
+				label = "FMAN / QE ucode";
+				read-only;
+			};
+
+			partition@160000 {
+				/* 48MB for FIT Image */
+				reg = <0x00160000 0x03000000>;
+				label = "NAND FIT Image";
+				read-only;
+			};
+
+			partition@3160000 {
+				/* 20MB for FIT Image */
+				reg = <0x03160000 0x04EA0000>;
+				label = "NAND User Space";
+			};
+		};
+};
+
+
+&dspi0 {
+	bus-num = <0>;
+	status = "okay";
+
+
+	slic@0 {
+		compatible = "microsemi,zl88801";
+		reg = <0>;
+		spi-max-frequency = <2000000>;
+	};
+
+
+};
+
+&duart0 {
+	status = "okay";
+};
+
+&duart1 {
+	status = "okay";
+};
+
+#include "fsl-ls1043-post.dtsi"
+
+&fman0 {
+	ethernet@e0000 {
+		phy-handle = <&qsgmii_phy1>;
+		phy-connection-type = "qsgmii";
+        status = "okay";
+	};
+
+	ethernet@e2000 {
+		phy-handle = <&qsgmii_phy2>;
+       	phy-connection-type = "qsgmii";
+        status = "okay";
+	};
+
+	ethernet@e4000 {
+		fixed-link = <1 1 1000 0 0>;
+		phy-connection-type = "rgmii";
+        status = "okay";
+	};
+
+	ethernet@e6000 {
+		phy-handle = <&rgmii_phy2>;
+		phy-connection-type = "rgmii";
+	};
+
+	ethernet@e8000 {
+		phy-handle = <&qsgmii_phy3>;
+		phy-connection-type = "qsgmii";
+        status = "okay";
+	};
+
+	ethernet@ea000 {
+		phy-handle = <&qsgmii_phy4>;
+  		phy-connection-type = "qsgmii";
+        status = "okay";
+	};
+
+    ethernet@f0000 { /* DTSEC9/10GEC1 */
+		fixed-link = <1 1 10000 0 0>;
+		phy-connection-type = "xgmii";
+		status = "okay";
+	};
+	dpa-fman0-oh@2 {
+                compatible = "fsl,dpa-oh";
+                /* <OH Rx error, OH Rx default> */
+                fsl,qman-frame-queues-oh = <0x60 1 0x61 1>;
+                fsl,fman-oh-port = <&fman0_oh_0x3>;
+        };
+	dpa-fman0-oh@3 {
+                compatible = "fsl,dpa-oh";
+                /* <OH Rx error, OH Rx default> */
+                fsl,qman-frame-queues-oh = <0x62 1 0x63 1>;
+                fsl,fman-oh-port = <&fman0_oh_0x4>;
+        };
+
+	mdio@fc000 {
+		rgmii_phy1: ethernet-phy@1 {
+			reg = <0x1>;
+		};
+		rgmii_phy2: ethernet-phy@2 {
+			reg = <0x2>;
+		};
+		qsgmii_phy1: ethernet-phy@3 {
+			reg = <0x4>;
+		};
+		qsgmii_phy2: ethernet-phy@4 {
+			reg = <0x5>;
+		};
+		qsgmii_phy3: ethernet-phy@5 {
+			reg = <0x6>;
+		};
+		qsgmii_phy4: ethernet-phy@6 {
+			reg = <0x7>;
+		};
+	};
+
+	mdio@fd000 {
+	};
+};
+
+&uqe {
+	ucc_hdlc: ucc@2000 {
+		compatible = "fsl,ucc_hdlc";
+		rx-clock-name = "clk8";
+		tx-clock-name = "clk9";
+		fsl,rx-sync-clock = "rsync_pin";
+		fsl,tx-sync-clock = "tsync_pin";
+		fsl,tx-timeslot = <0xfffffffe>;
+		fsl,rx-timeslot = <0xfffffffe>;
+		fsl,tdm-framer-type = "e1";
+		fsl,tdm-mode = "normal";
+		fsl,tdm-id = <0>;
+		fsl,siram-entry-id = <0>;
+		fsl,tdm-interface;
+	};
+
+	ucc_serial: ucc@2200 {
+		device_type = "serial";
+		compatible = "ucc_uart";
+		port-number = <0>;
+		rx-clock-name = "brg2";
+		tx-clock-name = "brg2";
+	};
+};
diff --git a/arch/arm64/boot/dts/freescale/fsl-ls1043a-rdb-w906x-sdk.dts b/arch/arm64/boot/dts/freescale/fsl-ls1043a-rdb-w906x-sdk.dts
new file mode 100644
index 000000000000..908d7fd6bc7b
--- /dev/null
+++ b/arch/arm64/boot/dts/freescale/fsl-ls1043a-rdb-w906x-sdk.dts
@@ -0,0 +1,262 @@
+/*
+ * Device Tree Include file for Freescale Layerscape-1043A family SoC.
+ *
+ * Copyright 2014-2015 Freescale Semiconductor, Inc.
+ *
+ * Mingkai Hu <Mingkai.hu@freescale.com>
+ *
+ * This file is dual-licensed: you can use it either under the terms
+ * of the GPLv2 or the X11 license, at your option. Note that this dual
+ * licensing only applies to this file, and not this project as a
+ * whole.
+ *
+ *  a) This library is free software; you can redistribute it and/or
+ *     modify it under the terms of the GNU General Public License as
+ *     published by the Free Software Foundation; either version 2 of the
+ *     License, or (at your option) any later version.
+ *
+ *     This library is distributed in the hope that it will be useful,
+ *     but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *     GNU General Public License for more details.
+ *
+ * Or, alternatively,
+ *
+ *  b) Permission is hereby granted, free of charge, to any person
+ *     obtaining a copy of this software and associated documentation
+ *     files (the "Software"), to deal in the Software without
+ *     restriction, including without limitation the rights to use,
+ *     copy, modify, merge, publish, distribute, sublicense, and/or
+ *     sell copies of the Software, and to permit persons to whom the
+ *     Software is furnished to do so, subject to the following
+ *     conditions:
+ *
+ *     The above copyright notice and this permission notice shall be
+ *     included in all copies or substantial portions of the Software.
+ *
+ *     THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ *     EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES
+ *     OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ *     NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ *     HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
+ *     WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ *     FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ *     OTHER DEALINGS IN THE SOFTWARE.
+ */
+
+#include "fsl-ls1043a-rdb-w906x.dts"
+#include "qoriq-qman-portals-sdk.dtsi"
+#include "qoriq-bman-portals-sdk.dtsi"
+
+&bman_fbpr {
+	compatible = "fsl,bman-fbpr";
+	alloc-ranges = <0 0 0x10000 0>;
+};
+&qman_fqd {
+	compatible = "fsl,qman-fqd";
+	alloc-ranges = <0 0 0x10000 0>;
+};
+&qman_pfdr {
+	compatible = "fsl,qman-pfdr";
+	alloc-ranges = <0 0 0x10000 0>;
+};
+
+&soc {
+/delete-property/ dma-coherent;
+
+#include "qoriq-dpaa-eth.dtsi"
+#include "qoriq-fman3-0-6oh.dtsi"
+
+pcie@3400000 {
+	/delete-property/ iommu-map;
+	dma-coherent;
+};
+
+pcie@3500000 {
+	/delete-property/ iommu-map;
+	dma-coherent;
+};
+
+pcie@3600000 {
+	/delete-property/ iommu-map;
+	dma-coherent;
+};
+
+/delete-node/ iommu@9000000;
+};
+
+&fman0 {
+	compatible = "fsl,fman", "simple-bus";
+};
+
+&clockgen {
+	dma-coherent;
+};
+
+&scfg {
+	dma-coherent;
+};
+
+&crypto {
+	dma-coherent;
+};
+
+&dcfg {
+	dma-coherent;
+};
+
+&ifc {
+	dma-coherent;
+};
+
+&qspi {
+	dma-coherent;
+};
+
+&esdhc {
+	dma-coherent;
+};
+
+&ddr {
+	dma-coherent;
+};
+
+&tmu {
+	dma-coherent;
+};
+
+&qman {
+	dma-coherent;
+};
+
+&bman {
+	dma-coherent;
+};
+
+&bportals {
+	dma-coherent;
+};
+
+&qportals {
+	dma-coherent;
+};
+
+&dspi0 {
+	dma-coherent;
+};
+
+&dspi1 {
+	dma-coherent;
+};
+
+&i2c0 {
+	dma-coherent;
+};
+
+&i2c1 {
+	dma-coherent;
+};
+
+&i2c2 {
+	dma-coherent;
+};
+
+&i2c3 {
+	dma-coherent;
+};
+
+&duart0 {
+	dma-coherent;
+};
+
+&duart1 {
+	dma-coherent;
+};
+
+&duart2 {
+	dma-coherent;
+};
+
+&duart3 {
+	dma-coherent;
+};
+
+&gpio1 {
+	dma-coherent;
+};
+
+&gpio2 {
+	dma-coherent;
+};
+
+&gpio3 {
+	dma-coherent;
+};
+
+&gpio4 {
+	dma-coherent;
+};
+
+&lpuart0 {
+	dma-coherent;
+};
+
+&lpuart1 {
+	dma-coherent;
+};
+
+&lpuart2 {
+	dma-coherent;
+};
+
+&lpuart3 {
+	dma-coherent;
+};
+
+&lpuart4 {
+	dma-coherent;
+};
+
+&lpuart5 {
+	dma-coherent;
+};
+
+&ftm_alarm0 {
+	dma-coherent;
+};
+
+&wdog0 {
+	dma-coherent;
+};
+
+&edma0 {
+	dma-coherent;
+};
+
+&qdma {
+	dma-coherent;
+};
+
+&msi1 {
+	dma-coherent;
+};
+
+&msi2 {
+	dma-coherent;
+};
+
+&msi3 {
+	dma-coherent;
+};
+
+&fman0 {
+	dma-coherent;
+};
+
+&ptp_timer0 {
+	dma-coherent;
+};
+
+&fsldpaa {
+	dma-coherent;
+};
diff --git a/arch/arm64/boot/dts/freescale/fsl-ls1043a-rdb-w906x.dts b/arch/arm64/boot/dts/freescale/fsl-ls1043a-rdb-w906x.dts
new file mode 100644
index 000000000000..851ea335aac4
--- /dev/null
+++ b/arch/arm64/boot/dts/freescale/fsl-ls1043a-rdb-w906x.dts
@@ -0,0 +1,235 @@
+// SPDX-License-Identifier: (GPL-2.0+ OR MIT)
+/*
+ * Device Tree Include file for Freescale Layerscape-1043A family SoC.
+ *
+ * Copyright 2014-2015 Freescale Semiconductor, Inc.
+ * Copyright 2018 NXP
+ *
+ * Mingkai Hu <Mingkai.hu@freescale.com>
+ */
+
+/dts-v1/;
+#include "fsl-ls1043a-w906x.dtsi"
+
+/ {
+	model = "LS1043A RDB Board";
+	compatible = "fsl,ls1043a-rdb", "fsl,ls1043a";
+
+	aliases {
+		serial0 = &duart0;
+		serial1 = &duart1;
+		serial2 = &duart2;
+		serial3 = &duart3;
+	};
+
+	chosen {
+		stdout-path = "serial0:115200n8";
+	};
+};
+
+&i2c0 {
+	status = "okay";
+	ina220@40 {
+		compatible = "ti,ina220";
+		reg = <0x40>;
+		shunt-resistor = <1000>;
+	};
+	adt7461a@4c {
+		compatible = "adi,adt7461";
+		reg = <0x4c>;
+	};
+	eeprom@52 {
+		compatible = "atmel,24c512";
+		reg = <0x52>;
+	};
+	eeprom@53 {
+		compatible = "atmel,24c512";
+		reg = <0x53>;
+	};
+	rtc@68 {
+		compatible = "pericom,pt7c4338";
+		reg = <0x68>;
+	};
+	rtc@51 {
+		compatible = "nxp,pcf85263";
+		reg = <0x51>;
+	};
+};
+
+&ifc {
+	status = "okay";
+	#address-cells = <2>;
+	#size-cells = <1>;
+	/* NOR, NAND Flashes and FPGA on board */
+	ranges = <0x0 0x0 0x0 0x60000000 0x08000000
+		  0x1 0x0 0x0 0x7e800000 0x00010000
+		  0x2 0x0 0x0 0x7fb00000 0x00000100>;
+
+		nor@0,0 {
+			compatible = "cfi-flash";
+			#address-cells = <1>;
+			#size-cells = <1>;
+			reg = <0x0 0x0 0x8000000>;
+			big-endian;
+			bank-width = <2>;
+			device-width = <1>;
+		};
+
+		nand@1,0 {
+			compatible = "fsl,ifc-nand";
+			#address-cells = <1>;
+			#size-cells = <1>;
+			reg = <0x1 0x0 0x10000>;
+		};
+
+		cpld: board-control@2,0 {
+			compatible = "fsl,ls1043ardb-cpld";
+			reg = <0x2 0x0 0x0000100>;
+		};
+};
+
+&dspi0 {
+	bus-num = <0>;
+	status = "okay";
+
+	flash@0 {
+		#address-cells = <1>;
+		#size-cells = <1>;
+		compatible = "n25q128a13", "jedec,spi-nor";  /* 16MB */
+		reg = <0>;
+		spi-max-frequency = <1000000>; /* input clock */
+	};
+
+	slic@2 {
+		compatible = "maxim,ds26522";
+		reg = <2>;
+		spi-max-frequency = <2000000>;
+		fsl,spi-cs-sck-delay = <100>;
+		fsl,spi-sck-cs-delay = <50>;
+	};
+
+	slic@3 {
+		compatible = "maxim,ds26522";
+		reg = <3>;
+		spi-max-frequency = <2000000>;
+		fsl,spi-cs-sck-delay = <100>;
+		fsl,spi-sck-cs-delay = <50>;
+	};
+};
+
+&uqe {
+	ucc_hdlc: ucc@2000 {
+		compatible = "fsl,ucc-hdlc";
+		rx-clock-name = "clk8";
+		tx-clock-name = "clk9";
+		fsl,rx-sync-clock = "rsync_pin";
+		fsl,tx-sync-clock = "tsync_pin";
+		fsl,tx-timeslot-mask = <0xfffffffe>;
+		fsl,rx-timeslot-mask = <0xfffffffe>;
+		fsl,tdm-framer-type = "e1";
+		fsl,tdm-id = <0>;
+		fsl,siram-entry-id = <0>;
+		fsl,tdm-interface;
+	};
+};
+
+&duart0 {
+	status = "okay";
+};
+
+&duart1 {
+	status = "okay";
+};
+
+#include "fsl-ls1043-post.dtsi"
+
+&fman0 {
+	ethernet@e0000 {
+		phy-handle = <&qsgmii_phy1>;
+		phy-connection-type = "qsgmii";
+	};
+
+	ethernet@e2000 {
+		phy-handle = <&qsgmii_phy2>;
+		phy-connection-type = "qsgmii";
+	};
+
+	ethernet@e4000 {
+		phy-handle = <&rgmii_phy1>;
+		phy-connection-type = "rgmii-id";
+	};
+
+	ethernet@e6000 {
+		phy-handle = <&rgmii_phy2>;
+		phy-connection-type = "rgmii-id";
+	};
+
+	ethernet@e8000 {
+		phy-handle = <&qsgmii_phy3>;
+		phy-connection-type = "qsgmii";
+	};
+
+	ethernet@ea000 {
+		phy-handle = <&qsgmii_phy4>;
+		phy-connection-type = "qsgmii";
+	};
+
+	ethernet@f0000 { /* 10GEC1 */
+		phy-handle = <&aqr105_phy>;
+		phy-connection-type = "xgmii";
+	};
+	dpa-fman0-oh@2 {
+		compatible = "fsl,dpa-oh";
+		/* <OH Rx error, OH Rx default> */
+		fsl,qman-frame-queues-oh = <0x60 1 0x61 1>;
+		fsl,fman-oh-port = <&fman0_oh_0x3>;
+    };
+	dpa-fman0-oh@3 {
+		compatible = "fsl,dpa-oh";
+		/* <OH Rx error, OH Rx default> */
+		fsl,qman-frame-queues-oh = <0x62 1 0x63 1>;
+		fsl,fman-oh-port = <&fman0_oh_0x4>;
+	};
+
+	mdio@fc000 {
+		rgmii_phy1: ethernet-phy@1 {
+			reg = <0x1>;
+		};
+
+		rgmii_phy2: ethernet-phy@2 {
+			reg = <0x2>;
+		};
+
+		qsgmii_phy1: ethernet-phy@4 {
+			reg = <0x4>;
+		};
+
+		qsgmii_phy2: ethernet-phy@5 {
+			reg = <0x5>;
+		};
+
+		qsgmii_phy3: ethernet-phy@6 {
+			reg = <0x6>;
+		};
+
+		qsgmii_phy4: ethernet-phy@7 {
+			reg = <0x7>;
+		};
+	};
+
+	mdio@fd000 {
+		aqr105_phy: ethernet-phy@1 {
+			compatible = "ethernet-phy-ieee802.3-c45";
+			interrupts = <0 132 4>;
+			reg = <0x1>;
+		};
+	};
+};
+
+&usb0 {
+	status = "okay";
+};
+
+&usb1 {
+	status = "okay";
+};
diff --git a/arch/arm64/boot/dts/freescale/fsl-ls1043a-rdb.dts b/arch/arm64/boot/dts/freescale/fsl-ls1043a-rdb.dts
index c4532c809f0a..49a549d1b055 100644
--- a/arch/arm64/boot/dts/freescale/fsl-ls1043a-rdb.dts
+++ b/arch/arm64/boot/dts/freescale/fsl-ls1043a-rdb.dts
@@ -188,6 +188,18 @@ ethernet@f0000 { /* 10GEC1 */
 		phy-handle = <&aqr105_phy>;
 		phy-connection-type = "xgmii";
 	};
+	dpa-fman0-oh@2 {
+		compatible = "fsl,dpa-oh";
+		/* <OH Rx error, OH Rx default> */
+		fsl,qman-frame-queues-oh = <0x60 1 0x61 1>;
+		fsl,fman-oh-port = <&fman0_oh_0x3>;
+    };
+	dpa-fman0-oh@3 {
+		compatible = "fsl,dpa-oh";
+		/* <OH Rx error, OH Rx default> */
+		fsl,qman-frame-queues-oh = <0x62 1 0x63 1>;
+		fsl,fman-oh-port = <&fman0_oh_0x4>;
+	};
 
 	mdio@fc000 {
 		rgmii_phy1: ethernet-phy@1 {
diff --git a/arch/arm64/boot/dts/freescale/fsl-ls1043a-rgw-sdk.dts b/arch/arm64/boot/dts/freescale/fsl-ls1043a-rgw-sdk.dts
new file mode 100755
index 000000000000..b6ff1dfd8e40
--- /dev/null
+++ b/arch/arm64/boot/dts/freescale/fsl-ls1043a-rgw-sdk.dts
@@ -0,0 +1,91 @@
+
+ /*
+ * Device Tree Include file for Freescale Layerscape-1043A family SoC.
+ *
+ * Copyright 2014-2015 Freescale Semiconductor, Inc.
+ * Mingkai Hu <Mingkai.hu@freescale.com>
+ * Copyright 2018 NXP
+ *
+ * This file is dual-licensed: you can use it either under the terms
+ * of the GPLv2 or the X11 license, at your option. Note that this dual
+ * licensing only applies to this file, and not this project as a
+ * whole.
+ *
+ *  a) This library is free software; you can redistribute it and/or
+ *     modify it under the terms of the GNU General Public License as
+ *     published by the Free Software Foundation; either version 2 of the
+ *     License, or (at your option) any later version.
+ *
+ *     This library is distributed in the hope that it will be useful,
+ *     but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *     GNU General Public License for more details.
+ *
+ * Or, alternatively,
+ *
+ *  b) Permission is hereby granted, free of charge, to any person
+ *     obtaining a copy of this software and associated documentation
+ *     files (the "Software"), to deal in the Software without
+ *     restriction, including without limitation the rights to use,
+ *     copy, modify, merge, publish, distribute, sublicense, and/or
+ *     sell copies of the Software, and to permit persons to whom the
+ *     Software is furnished to do so, subject to the following
+ *     conditions:
+ *
+ *     The above copyright notice and this permission notice shall be
+ *     included in all copies or substantial portions of the Software.
+ *
+ *     THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ *     EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES
+ *     OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ *     NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ *     HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
+ *     WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ *     FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ *     OTHER DEALINGS IN THE SOFTWARE.
+ */
+
+#include "fsl-ls1043a-rgw.dts"
+#include "qoriq-qman-portals-sdk.dtsi"
+#include "qoriq-bman-portals-sdk.dtsi"
+
+&bman_fbpr {
+	compatible = "fsl,bman-fbpr";
+	alloc-ranges = <0 0 0x10000 0>;
+};
+&qman_fqd {
+	compatible = "fsl,qman-fqd";
+	alloc-ranges = <0 0 0x10000 0>;
+};
+&qman_pfdr {
+	compatible = "fsl,qman-pfdr";
+	alloc-ranges = <0 0 0x10000 0>;
+};
+
+&soc {
+/delete-property/ dma-coherent;
+
+#include "qoriq-dpaa-eth.dtsi"
+#include "qoriq-fman3-0-6oh.dtsi"
+
+pcie@3400000 {
+	/delete-property/ iommu-map;
+	dma-coherent;
+};
+
+pcie@3500000 {
+	/delete-property/ iommu-map;
+	dma-coherent;
+};
+
+pcie@3600000 {
+	/delete-property/ iommu-map;
+	dma-coherent;
+};
+
+/delete-node/ iommu@9000000;
+};
+
+&fman0 {
+	compatible = "fsl,fman", "simple-bus";
+};
diff --git a/arch/arm64/boot/dts/freescale/fsl-ls1043a-rgw.dts b/arch/arm64/boot/dts/freescale/fsl-ls1043a-rgw.dts
new file mode 100644
index 000000000000..0c2c17387777
--- /dev/null
+++ b/arch/arm64/boot/dts/freescale/fsl-ls1043a-rgw.dts
@@ -0,0 +1,291 @@
+/*
+ * Device Tree Include file for Freescale Layerscape-1043A family SoC.
+ *
+ * Copyright 2014-2015, Freescale Semiconductor
+ *
+ * Mingkai Hu <Mingkai.hu@freescale.com>
+ * Copyright 2018 NXP
+ *
+ * This file is dual-licensed: you can use it either under the terms
+ * of the GPLv2 or the X11 license, at your option. Note that this dual
+ * licensing only applies to this file, and not this project as a
+ * whole.
+ *
+ *  a) This library is free software; you can redistribute it and/or
+ *     modify it under the terms of the GNU General Public License as
+ *     published by the Free Software Foundation; either version 2 of the
+ *     License, or (at your option) any later version.
+ *
+ *     This library is distributed in the hope that it will be useful,
+ *     but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *     GNU General Public License for more details.
+ *
+ * Or, alternatively,
+ *
+ *  b) Permission is hereby granted, free of charge, to any person
+ *     obtaining a copy of this software and associated documentation
+ *     files (the "Software"), to deal in the Software without
+ *     restriction, including without limitation the rights to use,
+ *     copy, modify, merge, publish, distribute, sublicense, and/or
+ *     sell copies of the Software, and to permit persons to whom the
+ *     Software is furnished to do so, subject to the following
+ *     conditions:
+ *
+ *     The above copyright notice and this permission notice shall be
+ *     included in all copies or substantial portions of the Software.
+ *
+ *     THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ *     EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES
+ *     OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ *     NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ *     HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
+ *     WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ *     FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ *     OTHER DEALINGS IN THE SOFTWARE.
+ */
+
+/dts-v1/;
+#include "fsl-ls1043a.dtsi"
+
+/ {
+	model = "LS1043A RGW Board";
+	compatible = "fsl,ls1043a-rgw", "fsl,ls1043a";
+
+	aliases {
+		crypto = &crypto;
+	};
+};
+
+&i2c0 {
+	status = "okay";
+
+	pmic@08 {
+		compatible = "nxp,34vr500";
+		reg = <0x8>;
+	};
+	pca9546@21 {
+		compatible = "nxp,pca9546";
+		reg = <0x21>;
+	};
+	ina220@40 {
+		compatible = "ti,ina220";
+		reg = <0x40>;
+		shunt-resistor = <1000>;
+	};
+	adt7461a@4c {
+		compatible = "adi,adt7461";
+		reg = <0x4c>;
+	};
+	rtc@51 {
+		compatible = "nxp,pcf2127";
+		reg = <0x51>;
+	};
+	eeprom@52 {
+		compatible = "at24,24c04";
+		reg = <0x52>;
+	};
+	eeprom@53 {
+		compatible = "at24,24c04";
+		reg = <0x53>;
+	};
+	pca9554@77 {
+		compatible = "nxp,pca9554";
+		reg = <0x77>;
+        #address-cells = <1>;
+        #size-cells = <0>;
+
+	    i2c@3 {
+              #address-cells = <1>;
+              #size-cells = <0>;
+		      reg = <0x3>;
+
+			  eeprom@50 {
+				      compatible = "at24,24c04";
+				      reg = <0x50>;
+			   };
+		};
+
+	 };	
+};
+
+&ifc {
+	status = "okay";
+	#address-cells = <2>;
+	#size-cells = <1>;
+/* NAND Flash on board 128MB */
+	ranges = <0x0 0x0 0x0 0x7e800000 0x00010000>;
+
+
+		nand@0,0 {
+			compatible = "fsl,ifc-nand";
+			#address-cells = <1>;
+			#size-cells = <1>;
+            reg = <0x0 0x0 0x10000>;
+		
+/* this partitions nodes are not in previous current sdk may be moved to u-boot ,adding with reference to previos sdk */
+             partition@0 {
+				/* This location must not be altered  */
+				/* 1MB for u-boot Bootloader Image */
+				reg = <0x0 0x00100000>;
+				label = "NAND U-Boot Image";
+				read-only;
+			};
+
+			partition@100000 {
+				/* 128KB for u-boot environment */
+				reg = <0x00100000 0x00020000>;
+				label = "NAND U-Boot Env";
+				read-only;
+			};
+
+			partition@120000 {
+				/* 256KB for u-boot environment */
+				reg = <0x00120000 0x00040000>;
+				label = "FMAN / QE ucode";
+				read-only;
+			};
+
+			partition@160000 {
+				/* 48MB for FIT Image */
+				reg = <0x00160000 0x03000000>;
+				label = "NAND FIT Image";
+				read-only;
+			};
+
+			partition@3160000 {
+				/* 20MB for FIT Image */
+				reg = <0x03160000 0x04EA0000>;
+				label = "NAND User Space";
+			};
+		};
+};
+
+
+&dspi0 {
+	bus-num = <0>;
+	status = "okay";
+
+
+	slic@0 {
+		compatible = "microsemi,zl88801";
+		reg = <0>;
+		spi-max-frequency = <2000000>;
+	};
+
+
+};
+
+&duart0 {
+	status = "okay";
+};
+
+&duart1 {
+	status = "okay";
+};
+
+#include "fsl-ls1043-post.dtsi"
+
+&fman0 {
+	ethernet@e0000 {
+		phy-handle = <&qsgmii_phy1>;
+		phy-connection-type = "qsgmii";
+        status = "okay";
+	};
+
+	ethernet@e2000 {
+		phy-handle = <&qsgmii_phy2>;
+       	phy-connection-type = "qsgmii";
+        status = "okay";
+	};
+
+	ethernet@e4000 {
+		phy-handle = <&rgmii_phy1>;
+		phy-connection-type = "rgmii";
+        status = "okay";
+	};
+
+	ethernet@e6000 {
+		phy-handle = <&rgmii_phy2>;
+		phy-connection-type = "rgmii";
+	};
+
+	ethernet@e8000 {
+		phy-handle = <&qsgmii_phy3>;
+		phy-connection-type = "qsgmii";
+        status = "okay";
+	};
+
+	ethernet@ea000 {
+		phy-handle = <&qsgmii_phy4>;
+  		phy-connection-type = "qsgmii";
+        status = "okay";
+	};
+
+    ethernet@f0000 { /* DTSEC9/10GEC1 */
+		fixed-link = <1 1 10000 0 0>;
+		phy-connection-type = "xgmii";
+		status = "okay";
+	};
+	dpa-fman0-oh@2 {
+                compatible = "fsl,dpa-oh";
+                /* <OH Rx error, OH Rx default> */
+                fsl,qman-frame-queues-oh = <0x60 1 0x61 1>;
+                fsl,fman-oh-port = <&fman0_oh_0x3>;
+        };
+	dpa-fman0-oh@3 {
+                compatible = "fsl,dpa-oh";
+                /* <OH Rx error, OH Rx default> */
+                fsl,qman-frame-queues-oh = <0x62 1 0x63 1>;
+                fsl,fman-oh-port = <&fman0_oh_0x4>;
+        };
+
+	mdio@fc000 {
+		rgmii_phy1: ethernet-phy@1 {
+			reg = <0x1>;
+		};
+		rgmii_phy2: ethernet-phy@2 {
+			reg = <0x2>;
+		};
+		qsgmii_phy1: ethernet-phy@3 {
+			reg = <0x4>;
+		};
+		qsgmii_phy2: ethernet-phy@4 {
+			reg = <0x5>;
+		};
+		qsgmii_phy3: ethernet-phy@5 {
+			reg = <0x6>;
+		};
+		qsgmii_phy4: ethernet-phy@6 {
+			reg = <0x7>;
+		};
+	};
+
+	mdio@fd000 {
+	};
+};
+
+&uqe {
+	ucc_hdlc: ucc@2000 {
+		compatible = "fsl,ucc_hdlc";
+		rx-clock-name = "clk8";
+		tx-clock-name = "clk9";
+		fsl,rx-sync-clock = "rsync_pin";
+		fsl,tx-sync-clock = "tsync_pin";
+		fsl,tx-timeslot = <0xfffffffe>;
+		fsl,rx-timeslot = <0xfffffffe>;
+		fsl,tdm-framer-type = "e1";
+		fsl,tdm-mode = "normal";
+		fsl,tdm-id = <0>;
+		fsl,siram-entry-id = <0>;
+		fsl,tdm-interface;
+	};
+
+	ucc_serial: ucc@2200 {
+		device_type = "serial";
+		compatible = "ucc_uart";
+		port-number = <0>;
+		rx-clock-name = "brg2";
+		tx-clock-name = "brg2";
+	};
+};
diff --git a/arch/arm64/boot/dts/freescale/fsl-ls1043a-w906x.dtsi b/arch/arm64/boot/dts/freescale/fsl-ls1043a-w906x.dtsi
new file mode 100644
index 000000000000..3df92f7304fb
--- /dev/null
+++ b/arch/arm64/boot/dts/freescale/fsl-ls1043a-w906x.dtsi
@@ -0,0 +1,1028 @@
+// SPDX-License-Identifier: (GPL-2.0+ OR MIT)
+/*
+ * Device Tree Include file for Freescale Layerscape-1043A family SoC.
+ *
+ * Copyright 2014-2015 Freescale Semiconductor, Inc.
+ * Copyright 2018 NXP
+ *
+ * Mingkai Hu <Mingkai.hu@freescale.com>
+ */
+
+#include <dt-bindings/thermal/thermal.h>
+#include <dt-bindings/interrupt-controller/arm-gic.h>
+
+/ {
+	compatible = "fsl,ls1043a";
+	interrupt-parent = <&gic>;
+	#address-cells = <2>;
+	#size-cells = <2>;
+
+	aliases {
+		crypto = &crypto;
+		fman0 = &fman0;
+		ethernet0 = &enet0;
+		ethernet1 = &enet1;
+		ethernet2 = &enet2;
+		ethernet3 = &enet3;
+		ethernet4 = &enet4;
+		ethernet5 = &enet5;
+		ethernet6 = &enet6;
+		rtc1 = &ftm_alarm0;
+	};
+
+	cpus {
+		#address-cells = <1>;
+		#size-cells = <0>;
+
+		/*
+		 * We expect the enable-method for cpu's to be "psci", but this
+		 * is dependent on the SoC FW, which will fill this in.
+		 *
+		 * Currently supported enable-method is psci v0.2
+		 */
+		cooling_map0: cpu0: cpu@0 {
+			device_type = "cpu";
+			compatible = "arm,cortex-a53";
+			reg = <0x0>;
+			clocks = <&clockgen 1 0>;
+			next-level-cache = <&l2>;
+			cpu-idle-states = <&CPU_PH20>;
+			#cooling-cells = <2>;
+		};
+
+		cpu1: cpu@1 {
+			device_type = "cpu";
+			compatible = "arm,cortex-a53";
+			reg = <0x1>;
+			clocks = <&clockgen 1 0>;
+			next-level-cache = <&l2>;
+			cpu-idle-states = <&CPU_PH20>;
+			#cooling-cells = <2>;
+		};
+
+		cpu2: cpu@2 {
+			device_type = "cpu";
+			compatible = "arm,cortex-a53";
+			reg = <0x2>;
+			clocks = <&clockgen 1 0>;
+			next-level-cache = <&l2>;
+			cpu-idle-states = <&CPU_PH20>;
+			#cooling-cells = <2>;
+		};
+
+		cpu3: cpu@3 {
+			device_type = "cpu";
+			compatible = "arm,cortex-a53";
+			reg = <0x3>;
+			clocks = <&clockgen 1 0>;
+			next-level-cache = <&l2>;
+			cpu-idle-states = <&CPU_PH20>;
+			#cooling-cells = <2>;
+		};
+
+		fman0-extended-args {
+			cell-index = <0>;
+			compatible = "fsl,fman-extended-args";
+			total-fifo-size = <0x37700>;
+
+			fman0_oh1-extended-args {
+				cell-index = <1>;
+				compatible = "fsl,fman-port-op-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+			};
+
+			fman0_oh2-extended-args {
+				cell-index = <2>;
+				compatible = "fsl,fman-port-op-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+			};
+			fman0_oh3-extended-args {
+				cell-index = <3>;
+				compatible = "fsl,fman-port-op-extended-args";
+				fifo-size = <0x900 0x0>;
+				buffer-layout = <96 64>;
+			};
+
+			fman0_rx0-extended-args {
+				cell-index = <0>;
+				compatible = "fsl,fman-port-1g-rx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+				vsp-window = <2 0>;
+			};
+			fman0_tx0-extended-args {
+				cell-index = <0>;
+				compatible = "fsl,fman-port-1g-tx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+			};
+			fman0_rx1-extended-args {
+				cell-index = <1>;
+				compatible = "fsl,fman-port-1g-rx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+				vsp-window = <2 0>;
+			};
+			fman0_tx1-extended-args {
+				cell-index = <1>;
+				compatible = "fsl,fman-port-1g-tx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+			};
+			fman0_rx2-extended-args {
+				cell-index = <2>;
+				compatible = "fsl,fman-port-1g-rx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+				vsp-window = <2 0>;
+			};
+			fman0_tx2-extended-args {
+				cell-index = <2>;
+				compatible = "fsl,fman-port-1g-tx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+			};
+			fman0_rx3-extended-args {
+				cell-index = <3>;
+				compatible = "fsl,fman-port-1g-rx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+				vsp-window = <2 0>;
+			};
+			fman0_tx3-extended-args {
+				cell-index = <3>;
+				compatible = "fsl,fman-port-1g-tx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+			};
+			fman0_rx4-extended-args {
+				cell-index = <4>;
+				compatible = "fsl,fman-port-1g-rx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+				vsp-window = <2 0>;
+			};
+			fman0_tx4-extended-args {
+				cell-index = <4>;
+				compatible = "fsl,fman-port-1g-tx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+			};
+			fman0_rx5-extended-args {
+				cell-index = <5>;
+				compatible = "fsl,fman-port-1g-rx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+				vsp-window = <2 0>;
+			};
+			fman0_tx5-extended-args {
+				cell-index = <5>;
+				compatible = "fsl,fman-port-1g-tx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+			};
+
+			fman0_rx6-extended-args {
+				cell-index = <0>;
+				compatible = "fsl,fman-port-10g-rx-extended-args";
+				fifo-size = <0x6000 0x0>;
+				buffer-layout = <96 64>;
+				vsp-window = <2 0>;
+			};
+			fman0_tx6-extended-args {
+				cell-index = <0>;
+				compatible = "fsl,fman-port-10g-tx-extended-args";
+				fifo-size = <0x4000 0x0>;
+				buffer-layout = <96 64>;
+			};
+		};
+
+
+		l2: l2-cache {
+			compatible = "cache";
+		};
+	};
+
+	idle-states {
+		/*
+		 * PSCI node is not added default, U-boot will add missing
+		 * parts if it determines to use PSCI.
+		 */
+		entry-method = "psci";
+
+		CPU_PH20: cpu-ph20 {
+			compatible = "arm,idle-state";
+			idle-state-name = "PH20";
+			arm,psci-suspend-param = <0x0>;
+			entry-latency-us = <1000>;
+			exit-latency-us = <1000>;
+			min-residency-us = <3000>;
+		};
+	};
+
+	memory@80000000 {
+		device_type = "memory";
+		reg = <0x0 0x80000000 0x0 0x80000000>,
+		      <0x8 0x80000000 0x1 0x80000000>;
+		      /* DRAM space 1, size: 2GiB DRAM */
+	};
+
+	reserved-memory {
+		#address-cells = <2>;
+		#size-cells = <2>;
+		ranges;
+
+		bootmem0: bootmem0@a0000000 {
+			reg = <0x0 0xa0000000 0x0 0x04000000>, /* 64MB reserved */
+			      <0x0 0xa4000000 0x0 0x06000000>; /* 96MB reserved */
+		};
+  
+		bootmem1: bootmem1@aa000000 {
+			reg = <0x0 0xaa000000 0x0 0x04000000>, /* 64MB reserved */
+			      <0x0 0xae000000 0x0 0x06000000>; /* 96MB reserved */
+		};
+
+		bman_fbpr: bman-fbpr {
+			compatible = "shared-dma-pool";
+			size = <0 0x1000000>;
+			alignment = <0 0x1000000>;
+			no-map;
+		};
+
+		qman_fqd: qman-fqd {
+			compatible = "shared-dma-pool";
+			size = <0 0x800000>;
+			alignment = <0 0x800000>;
+			no-map;
+		};
+
+		qman_pfdr: qman-pfdr {
+			compatible = "shared-dma-pool";
+			size = <0 0x2000000>;
+			alignment = <0 0x2000000>;
+			no-map;
+		};
+	};
+
+	sysclk: sysclk {
+		compatible = "fixed-clock";
+		#clock-cells = <0>;
+		clock-frequency = <100000000>;
+		clock-output-names = "sysclk";
+	};
+
+	reboot {
+		compatible ="syscon-reboot";
+		regmap = <&dcfg>;
+		offset = <0xb0>;
+		mask = <0x02>;
+	};
+
+	timer {
+		compatible = "arm,armv8-timer";
+		interrupts = <1 13 0xf08>, /* Physical Secure PPI */
+			     <1 14 0xf08>, /* Physical Non-Secure PPI */
+			     <1 11 0xf08>, /* Virtual PPI */
+			     <1 10 0xf08>; /* Hypervisor PPI */
+		fsl,erratum-a008585;
+	};
+
+	pmu {
+		compatible = "arm,armv8-pmuv3";
+		interrupts = <0 106 0x4>,
+			     <0 107 0x4>,
+			     <0 95 0x4>,
+			     <0 97 0x4>;
+		interrupt-affinity = <&cpu0>,
+				     <&cpu1>,
+				     <&cpu2>,
+				     <&cpu3>;
+	};
+
+	gic: interrupt-controller@1400000 {
+		compatible = "arm,gic-400";
+		#interrupt-cells = <3>;
+		interrupt-controller;
+		reg = <0x0 0x1401000 0 0x1000>, /* GICD */
+		      <0x0 0x1402000 0 0x2000>, /* GICC */
+		      <0x0 0x1404000 0 0x2000>, /* GICH */
+		      <0x0 0x1406000 0 0x2000>; /* GICV */
+		interrupts = <1 9 0xf08>;
+	};
+
+	soc: soc {
+		compatible = "simple-bus";
+		#address-cells = <2>;
+		#size-cells = <2>;
+		ranges;
+		dma-ranges = <0x0 0x0 0x0 0x0 0x10000 0x00000000>;
+		dma-coherent;
+
+		clockgen: clocking@1ee1000 {
+			compatible = "fsl,ls1043a-clockgen";
+			reg = <0x0 0x1ee1000 0x0 0x1000>;
+			#clock-cells = <2>;
+			clocks = <&sysclk>;
+		};
+
+		smmu: iommu@9000000 {
+			compatible = "arm,mmu-500";
+			reg = <0 0x9000000 0 0x400000>;
+			dma-coherent;
+			stream-match-mask = <0x7f00>;
+			#global-interrupts = <2>;
+			#iommu-cells = <1>;
+			interrupts = <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 143 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>;
+		};
+
+		scfg: scfg@1570000 {
+			compatible = "fsl,ls1043a-scfg", "syscon";
+			reg = <0x0 0x1570000 0x0 0x10000>;
+			big-endian;
+		};
+
+		crypto: crypto@1700000 {
+			compatible = "fsl,sec-v5.4", "fsl,sec-v5.0",
+				     "fsl,sec-v4.0";
+			fsl,sec-era = <3>;
+			#address-cells = <1>;
+			#size-cells = <1>;
+			ranges = <0x0 0x00 0x1700000 0x100000>;
+			reg = <0x00 0x1700000 0x0 0x100000>;
+			interrupts = <0 75 0x4>;
+
+			sec_jr0: jr@10000 {
+				compatible = "fsl,sec-v5.4-job-ring",
+					     "fsl,sec-v5.0-job-ring",
+					     "fsl,sec-v4.0-job-ring";
+				reg	   = <0x10000 0x10000>;
+				interrupts = <0 71 0x4>;
+			};
+
+			sec_jr1: jr@20000 {
+				compatible = "fsl,sec-v5.4-job-ring",
+					     "fsl,sec-v5.0-job-ring",
+					     "fsl,sec-v4.0-job-ring";
+				reg	   = <0x20000 0x10000>;
+				interrupts = <0 72 0x4>;
+			};
+
+			sec_jr2: jr@30000 {
+				compatible = "fsl,sec-v5.4-job-ring",
+					     "fsl,sec-v5.0-job-ring",
+					     "fsl,sec-v4.0-job-ring";
+				reg	   = <0x30000 0x10000>;
+				interrupts = <0 73 0x4>;
+			};
+
+			sec_jr3: jr@40000 {
+				compatible = "fsl,sec-v5.4-job-ring",
+					     "fsl,sec-v5.0-job-ring",
+					     "fsl,sec-v4.0-job-ring";
+				reg	   = <0x40000 0x10000>;
+				interrupts = <0 74 0x4>;
+			};
+		};
+
+		dcfg: dcfg@1ee0000 {
+			compatible = "fsl,ls1043a-dcfg", "syscon";
+			reg = <0x0 0x1ee0000 0x0 0x1000>;
+			big-endian;
+		};
+
+		ifc: ifc@1530000 {
+			compatible = "fsl,ifc", "simple-bus";
+			reg = <0x0 0x1530000 0x0 0x10000>;
+			interrupts = <0 43 0x4>;
+		};
+
+		qspi: spi@1550000 {
+			compatible = "fsl,ls1043a-qspi", "fsl,ls1021a-qspi";
+			#address-cells = <1>;
+			#size-cells = <0>;
+			reg = <0x0 0x1550000 0x0 0x10000>,
+				<0x0 0x40000000 0x0 0x4000000>;
+			reg-names = "QuadSPI", "QuadSPI-memory";
+			interrupts = <0 99 0x4>;
+			clock-names = "qspi_en", "qspi";
+			clocks = <&clockgen 4 0>, <&clockgen 4 0>;
+			status = "disabled";
+		};
+
+		esdhc: esdhc@1560000 {
+			compatible = "fsl,ls1043a-esdhc", "fsl,esdhc";
+			reg = <0x0 0x1560000 0x0 0x10000>;
+			interrupts = <0 62 0x4>;
+			clock-frequency = <0>;
+			voltage-ranges = <1800 1800 3300 3300>;
+			sdhci,auto-cmd12;
+			big-endian;
+			bus-width = <4>;
+		};
+
+		ddr: memory-controller@1080000 {
+			compatible = "fsl,qoriq-memory-controller";
+			reg = <0x0 0x1080000 0x0 0x1000>;
+			interrupts = <0 144 0x4>;
+			big-endian;
+		};
+
+		tmu: tmu@1f00000 {
+			compatible = "fsl,qoriq-tmu";
+			reg = <0x0 0x1f00000 0x0 0x10000>;
+			interrupts = <0 33 0x4>;
+			fsl,tmu-range = <0xb0000 0x9002a 0x6004c 0x30062>;
+			fsl,tmu-calibration = <0x00000000 0x00000026
+					       0x00000001 0x0000002d
+					       0x00000002 0x00000032
+					       0x00000003 0x00000039
+					       0x00000004 0x0000003f
+					       0x00000005 0x00000046
+					       0x00000006 0x0000004d
+					       0x00000007 0x00000054
+					       0x00000008 0x0000005a
+					       0x00000009 0x00000061
+					       0x0000000a 0x0000006a
+					       0x0000000b 0x00000071
+
+					       0x00010000 0x00000025
+					       0x00010001 0x0000002c
+					       0x00010002 0x00000035
+					       0x00010003 0x0000003d
+					       0x00010004 0x00000045
+					       0x00010005 0x0000004e
+					       0x00010006 0x00000057
+					       0x00010007 0x00000061
+					       0x00010008 0x0000006b
+					       0x00010009 0x00000076
+
+					       0x00020000 0x00000029
+					       0x00020001 0x00000033
+					       0x00020002 0x0000003d
+					       0x00020003 0x00000049
+					       0x00020004 0x00000056
+					       0x00020005 0x00000061
+					       0x00020006 0x0000006d
+
+					       0x00030000 0x00000021
+					       0x00030001 0x0000002a
+					       0x00030002 0x0000003c
+					       0x00030003 0x0000004e>;
+			#thermal-sensor-cells = <1>;
+		};
+
+		qman: qman@1880000 {
+			compatible = "fsl,qman";
+			reg = <0x0 0x1880000 0x0 0x10000>;
+			interrupts = <GIC_SPI 45 IRQ_TYPE_LEVEL_HIGH>;
+			memory-region = <&qman_fqd &qman_pfdr>;
+		};
+
+		bman: bman@1890000 {
+			compatible = "fsl,bman";
+			reg = <0x0 0x1890000 0x0 0x10000>;
+			interrupts = <GIC_SPI 45 IRQ_TYPE_LEVEL_HIGH>;
+			memory-region = <&bman_fbpr>;
+		};
+
+		bportals: bman-portals@508000000 {
+			ranges = <0x0 0x5 0x08000000 0x8000000>;
+		};
+
+		qportals: qman-portals@500000000 {
+			ranges = <0x0 0x5 0x00000000 0x8000000>;
+		};
+
+		dspi0: spi@2100000 {
+			compatible = "fsl,ls1043a-dspi", "fsl,ls1021a-v1.0-dspi";
+			#address-cells = <1>;
+			#size-cells = <0>;
+			reg = <0x0 0x2100000 0x0 0x10000>;
+			interrupts = <0 64 0x4>;
+			clock-names = "dspi";
+			clocks = <&clockgen 4 0>;
+			spi-num-chipselects = <5>;
+			big-endian;
+			status = "disabled";
+		};
+
+		dspi1: spi@2110000 {
+			compatible = "fsl,ls1043a-dspi", "fsl,ls1021a-v1.0-dspi";
+			#address-cells = <1>;
+			#size-cells = <0>;
+			reg = <0x0 0x2110000 0x0 0x10000>;
+			interrupts = <0 65 0x4>;
+			clock-names = "dspi";
+			clocks = <&clockgen 4 0>;
+			spi-num-chipselects = <5>;
+			big-endian;
+			status = "disabled";
+		};
+
+		i2c0: i2c@2180000 {
+			compatible = "fsl,vf610-i2c", "fsl,ls1043a-vf610-i2c";
+			#address-cells = <1>;
+			#size-cells = <0>;
+			reg = <0x0 0x2180000 0x0 0x10000>;
+			interrupts = <0 56 0x4>;
+			clock-names = "i2c";
+			clocks = <&clockgen 4 0>;
+			dmas = <&edma0 1 39>,
+			       <&edma0 1 38>;
+			dma-names = "tx", "rx";
+			scl-gpios = <&gpio4 12 0>;
+			status = "disabled";
+		};
+
+		i2c1: i2c@2190000 {
+			compatible = "fsl,vf610-i2c";
+			#address-cells = <1>;
+			#size-cells = <0>;
+			reg = <0x0 0x2190000 0x0 0x10000>;
+			interrupts = <0 57 0x4>;
+			clock-names = "i2c";
+			clocks = <&clockgen 4 0>;
+			status = "disabled";
+		};
+
+		i2c2: i2c@21a0000 {
+			compatible = "fsl,vf610-i2c";
+			#address-cells = <1>;
+			#size-cells = <0>;
+			reg = <0x0 0x21a0000 0x0 0x10000>;
+			interrupts = <0 58 0x4>;
+			clock-names = "i2c";
+			clocks = <&clockgen 4 0>;
+			status = "disabled";
+		};
+
+		i2c3: i2c@21b0000 {
+			compatible = "fsl,vf610-i2c";
+			#address-cells = <1>;
+			#size-cells = <0>;
+			reg = <0x0 0x21b0000 0x0 0x10000>;
+			interrupts = <0 59 0x4>;
+			clock-names = "i2c";
+			clocks = <&clockgen 4 0>;
+			status = "disabled";
+		};
+
+		duart0: serial@21c0500 {
+			compatible = "fsl,ns16550", "ns16550a";
+			reg = <0x00 0x21c0500 0x0 0x100>;
+			interrupts = <0 54 0x4>;
+			clocks = <&clockgen 4 0>;
+		};
+
+		duart1: serial@21c0600 {
+			compatible = "fsl,ns16550", "ns16550a";
+			reg = <0x00 0x21c0600 0x0 0x100>;
+			interrupts = <0 54 0x4>;
+			clocks = <&clockgen 4 0>;
+		};
+
+		duart2: serial@21d0500 {
+			compatible = "fsl,ns16550", "ns16550a";
+			reg = <0x0 0x21d0500 0x0 0x100>;
+			interrupts = <0 55 0x4>;
+			clocks = <&clockgen 4 0>;
+		};
+
+		duart3: serial@21d0600 {
+			compatible = "fsl,ns16550", "ns16550a";
+			reg = <0x0 0x21d0600 0x0 0x100>;
+			interrupts = <0 55 0x4>;
+			clocks = <&clockgen 4 0>;
+		};
+
+		gpio1: gpio@2300000 {
+			compatible = "fsl,ls1043a-gpio", "fsl,qoriq-gpio";
+			reg = <0x0 0x2300000 0x0 0x10000>;
+			interrupts = <0 66 0x4>;
+			gpio-controller;
+			#gpio-cells = <2>;
+			interrupt-controller;
+			#interrupt-cells = <2>;
+		};
+
+		gpio2: gpio@2310000 {
+			compatible = "fsl,ls1043a-gpio", "fsl,qoriq-gpio";
+			reg = <0x0 0x2310000 0x0 0x10000>;
+			interrupts = <0 67 0x4>;
+			gpio-controller;
+			#gpio-cells = <2>;
+			interrupt-controller;
+			#interrupt-cells = <2>;
+		};
+
+		gpio3: gpio@2320000 {
+			compatible = "fsl,ls1043a-gpio", "fsl,qoriq-gpio";
+			reg = <0x0 0x2320000 0x0 0x10000>;
+			interrupts = <0 68 0x4>;
+			gpio-controller;
+			#gpio-cells = <2>;
+			interrupt-controller;
+			#interrupt-cells = <2>;
+		};
+
+		gpio4: gpio@2330000 {
+			compatible = "fsl,ls1043a-gpio", "fsl,qoriq-gpio";
+			reg = <0x0 0x2330000 0x0 0x10000>;
+			interrupts = <0 134 0x4>;
+			gpio-controller;
+			#gpio-cells = <2>;
+			interrupt-controller;
+			#interrupt-cells = <2>;
+		};
+
+		uqe: uqe@2400000 {
+			#address-cells = <1>;
+			#size-cells = <1>;
+			device_type = "qe";
+			compatible = "fsl,qe", "simple-bus";
+			ranges = <0x0 0x0 0x2400000 0x40000>;
+			reg = <0x0 0x2400000 0x0 0x480>;
+			brg-frequency = <100000000>;
+			bus-frequency = <200000000>;
+
+			fsl,qe-num-riscs = <1>;
+			fsl,qe-num-snums = <28>;
+
+			qeic: qeic@80 {
+				compatible = "fsl,qe-ic";
+				reg = <0x80 0x80>;
+				#address-cells = <0>;
+				interrupt-controller;
+				#interrupt-cells = <1>;
+				interrupts = <0 77 0x04 0 77 0x04>;
+			};
+
+			si1: si@700 {
+				#address-cells = <1>;
+				#size-cells = <0>;
+				compatible = "fsl,ls1043-qe-si",
+						"fsl,t1040-qe-si";
+				reg = <0x700 0x80>;
+			};
+
+			siram1: siram@1000 {
+				#address-cells = <1>;
+				#size-cells = <1>;
+				compatible = "fsl,ls1043-qe-siram",
+						"fsl,t1040-qe-siram";
+				reg = <0x1000 0x800>;
+			};
+
+			ucc@2000 {
+				cell-index = <1>;
+				reg = <0x2000 0x200>;
+				interrupts = <32>;
+				interrupt-parent = <&qeic>;
+			};
+
+			ucc@2200 {
+				cell-index = <3>;
+				reg = <0x2200 0x200>;
+				interrupts = <34>;
+				interrupt-parent = <&qeic>;
+			};
+
+			muram@10000 {
+				#address-cells = <1>;
+				#size-cells = <1>;
+				compatible = "fsl,qe-muram", "fsl,cpm-muram";
+				ranges = <0x0 0x10000 0x6000>;
+
+				data-only@0 {
+					compatible = "fsl,qe-muram-data",
+					"fsl,cpm-muram-data";
+					reg = <0x0 0x6000>;
+				};
+			};
+		};
+
+		lpuart0: serial@2950000 {
+			compatible = "fsl,ls1021a-lpuart";
+			reg = <0x0 0x2950000 0x0 0x1000>;
+			interrupts = <0 48 0x4>;
+			clocks = <&clockgen 0 0>;
+			clock-names = "ipg";
+			status = "disabled";
+		};
+
+		lpuart1: serial@2960000 {
+			compatible = "fsl,ls1021a-lpuart";
+			reg = <0x0 0x2960000 0x0 0x1000>;
+			interrupts = <0 49 0x4>;
+			clocks = <&clockgen 4 0>;
+			clock-names = "ipg";
+			status = "disabled";
+		};
+
+		lpuart2: serial@2970000 {
+			compatible = "fsl,ls1021a-lpuart";
+			reg = <0x0 0x2970000 0x0 0x1000>;
+			interrupts = <0 50 0x4>;
+			clocks = <&clockgen 4 0>;
+			clock-names = "ipg";
+			status = "disabled";
+		};
+
+		lpuart3: serial@2980000 {
+			compatible = "fsl,ls1021a-lpuart";
+			reg = <0x0 0x2980000 0x0 0x1000>;
+			interrupts = <0 51 0x4>;
+			clocks = <&clockgen 4 0>;
+			clock-names = "ipg";
+			status = "disabled";
+		};
+
+		lpuart4: serial@2990000 {
+			compatible = "fsl,ls1021a-lpuart";
+			reg = <0x0 0x2990000 0x0 0x1000>;
+			interrupts = <0 52 0x4>;
+			clocks = <&clockgen 4 0>;
+			clock-names = "ipg";
+			status = "disabled";
+		};
+
+		lpuart5: serial@29a0000 {
+			compatible = "fsl,ls1021a-lpuart";
+			reg = <0x0 0x29a0000 0x0 0x1000>;
+			interrupts = <0 53 0x4>;
+			clocks = <&clockgen 4 0>;
+			clock-names = "ipg";
+			status = "disabled";
+		};
+
+		wdog0: wdog@2ad0000 {
+			compatible = "fsl,ls1043a-wdt", "fsl,imx21-wdt";
+			reg = <0x0 0x2ad0000 0x0 0x10000>;
+			interrupts = <0 83 0x4>;
+			clocks = <&clockgen 4 0>;
+			clock-names = "wdog";
+			big-endian;
+		};
+
+		edma0: edma@2c00000 {
+			#dma-cells = <2>;
+			compatible = "fsl,vf610-edma";
+			reg = <0x0 0x2c00000 0x0 0x10000>,
+			      <0x0 0x2c10000 0x0 0x10000>,
+			      <0x0 0x2c20000 0x0 0x10000>;
+			interrupts = <0 103 0x4>,
+				     <0 103 0x4>;
+			interrupt-names = "edma-tx", "edma-err";
+			dma-channels = <32>;
+			big-endian;
+			clock-names = "dmamux0", "dmamux1";
+			clocks = <&clockgen 4 0>,
+				 <&clockgen 4 0>;
+		};
+
+		aux_bus: aux_bus {
+			#address-cells = <2>;
+			#size-cells = <2>;
+			compatible = "simple-bus";
+			ranges;
+			dma-ranges = <0x0 0x0 0x0 0x0 0x100 0x00000000>;
+
+			usb0: usb3@2f00000 {
+				compatible = "fsl,ls1043a-dwc3", "snps,dwc3";
+				reg = <0x0 0x2f00000 0x0 0x10000>;
+				interrupts = <0 60 0x4>;
+				dr_mode = "host";
+				snps,quirk-frame-length-adjustment = <0x20>;
+				snps,dis_rxdet_inp3_quirk;
+				usb3-lpm-capable;
+				snps,dis-u1u2-when-u3-quirk;
+				snps,incr-burst-type-adjustment = <1>, <4>, <8>, <16>;
+				snps,host-vbus-glitches;
+				configure-gfladj;
+				dma-coherent;
+				status = "disabled";
+			};
+
+			usb1: usb3@3000000 {
+				compatible = "fsl,ls1043a-dwc3", "snps,dwc3";
+				reg = <0x0 0x3000000 0x0 0x10000>;
+				interrupts = <0 61 0x4>;
+				dr_mode = "host";
+				snps,quirk-frame-length-adjustment = <0x20>;
+				snps,dis_rxdet_inp3_quirk;
+				usb3-lpm-capable;
+				snps,dis-u1u2-when-u3-quirk;
+				snps,incr-burst-type-adjustment = <1>, <4>, <8>, <16>;
+				snps,host-vbus-glitches;
+				configure-gfladj;
+				dma-coherent;
+				status = "disabled";
+			};
+
+			usb2: usb3@3100000 {
+				compatible = "fsl,ls1043a-dwc3", "snps,dwc3";
+				reg = <0x0 0x3100000 0x0 0x10000>;
+				interrupts = <0 63 0x4>;
+				dr_mode = "host";
+				snps,quirk-frame-length-adjustment = <0x20>;
+				snps,dis_rxdet_inp3_quirk;
+				usb3-lpm-capable;
+				snps,dis-u1u2-when-u3-quirk;
+				snps,incr-burst-type-adjustment = <1>, <4>, <8>, <16>;
+				snps,host-vbus-glitches;
+				configure-gfladj;
+				dma-coherent;
+				status = "disabled";
+			};
+
+			sata: sata@3200000 {
+				compatible = "fsl,ls1043a-ahci";
+				reg = <0x0 0x3200000 0x0 0x10000>,
+					<0x0 0x20140520 0x0 0x4>;
+				reg-names = "ahci", "sata-ecc";
+				interrupts = <0 69 0x4>;
+				clocks = <&clockgen 4 0>;
+			};
+		};
+
+		msi1: msi-controller1@1571000 {
+			compatible = "fsl,ls1043a-msi";
+			reg = <0x0 0x1571000 0x0 0x8>;
+			msi-controller;
+			interrupts = <0 116 0x4>;
+		};
+
+		msi2: msi-controller2@1572000 {
+			compatible = "fsl,ls1043a-msi";
+			reg = <0x0 0x1572000 0x0 0x8>;
+			msi-controller;
+			interrupts = <0 126 0x4>;
+		};
+
+		msi3: msi-controller3@1573000 {
+			compatible = "fsl,ls1043a-msi";
+			reg = <0x0 0x1573000 0x0 0x8>;
+			msi-controller;
+			interrupts = <0 160 0x4>;
+		};
+
+		pcie@3400000 {
+			compatible = "fsl,ls1043a-pcie";
+			reg = <0x00 0x03400000 0x0 0x00100000   /* controller registers */
+			       0x40 0x00000000 0x0 0x00002000>; /* configuration space */
+			reg-names = "regs", "config";
+			interrupts = <0 117 0x4>, /* PME interrupt */
+				     <0 118 0x4>; /* aer interrupt */
+			interrupt-names = "pme", "aer";
+			#address-cells = <3>;
+			#size-cells = <2>;
+			device_type = "pci";
+			iommu-map = <0 &smmu 0 1>;	/* update by bootloader */
+			num-viewport = <6>;
+			bus-range = <0x0 0xff>;
+			ranges = <0x81000000 0x0 0x00000000 0x40 0x00010000 0x0 0x00010000   /* downstream I/O */
+				  0x82000000 0x0 0x40000000 0x40 0x40000000 0x0 0x40000000>; /* non-prefetchable memory */
+			msi-parent = <&msi1>, <&msi2>, <&msi3>;
+			#interrupt-cells = <1>;
+			interrupt-map-mask = <0 0 0 7>;
+			interrupt-map = <0000 0 0 1 &gic 0 110 0x4>,
+					<0000 0 0 2 &gic 0 111 0x4>,
+					<0000 0 0 3 &gic 0 112 0x4>,
+					<0000 0 0 4 &gic 0 113 0x4>;
+			status = "disabled";
+		};
+
+		pcie@3500000 {
+			compatible = "fsl,ls1043a-pcie";
+			reg = <0x00 0x03500000 0x0 0x00100000   /* controller registers */
+			       0x48 0x00000000 0x0 0x00002000>; /* configuration space */
+			reg-names = "regs", "config";
+			interrupts = <0 127 0x4>,
+				     <0 128 0x4>;
+			interrupt-names = "pme", "aer";
+			#address-cells = <3>;
+			#size-cells = <2>;
+			device_type = "pci";
+			iommu-map = <0 &smmu 0 1>;	/* update by bootloader */
+			num-viewport = <6>;
+			bus-range = <0x0 0xff>;
+			ranges = <0x81000000 0x0 0x00000000 0x48 0x00010000 0x0 0x00010000   /* downstream I/O */
+				  0x82000000 0x0 0x40000000 0x48 0x40000000 0x0 0x40000000>; /* non-prefetchable memory */
+			msi-parent = <&msi1>, <&msi2>, <&msi3>;
+			#interrupt-cells = <1>;
+			interrupt-map-mask = <0 0 0 7>;
+			interrupt-map = <0000 0 0 1 &gic 0 120  0x4>,
+					<0000 0 0 2 &gic 0 121 0x4>,
+					<0000 0 0 3 &gic 0 122 0x4>,
+					<0000 0 0 4 &gic 0 123 0x4>;
+			status = "disabled";
+		};
+
+		pcie@3600000 {
+			compatible = "fsl,ls1043a-pcie";
+			reg = <0x00 0x03600000 0x0 0x00100000   /* controller registers */
+			       0x50 0x00000000 0x0 0x00002000>; /* configuration space */
+			reg-names = "regs", "config";
+			interrupts = <0 161 0x4>,
+				     <0 162 0x4>;
+			interrupt-names = "pme", "aer";
+			#address-cells = <3>;
+			#size-cells = <2>;
+			device_type = "pci";
+			iommu-map = <0 &smmu 0 1>;	/* update by bootloader */
+			num-viewport = <6>;
+			bus-range = <0x0 0xff>;
+			ranges = <0x81000000 0x0 0x00000000 0x50 0x00010000 0x0 0x00010000   /* downstream I/O */
+				  0x82000000 0x0 0x40000000 0x50 0x40000000 0x0 0x40000000>; /* non-prefetchable memory */
+			msi-parent = <&msi1>, <&msi2>, <&msi3>;
+			#interrupt-cells = <1>;
+			interrupt-map-mask = <0 0 0 7>;
+			interrupt-map = <0000 0 0 1 &gic 0 154 0x4>,
+					<0000 0 0 2 &gic 0 155 0x4>,
+					<0000 0 0 3 &gic 0 156 0x4>,
+					<0000 0 0 4 &gic 0 157 0x4>;
+			status = "disabled";
+		};
+
+		qdma: dma-controller@8380000 {
+			compatible = "fsl,ls1021a-qdma", "fsl,ls1043a-qdma";
+			reg = <0x0 0x8380000 0x0 0x1000>, /* Controller regs */
+			      <0x0 0x8390000 0x0 0x10000>, /* Status regs */
+			      <0x0 0x83a0000 0x0 0x40000>; /* Block regs */
+			interrupts = <GIC_SPI 153 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 39 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 40 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 41 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 42 IRQ_TYPE_LEVEL_HIGH>;
+			interrupt-names = "qdma-error", "qdma-queue0",
+				"qdma-queue1", "qdma-queue2", "qdma-queue3";
+			dma-channels = <8>;
+			block-number = <1>;
+			block-offset = <0x10000>;
+			fsl,dma-queues = <2>;
+			status-sizes = <64>;
+			queue-sizes = <64 64>;
+			big-endian;
+		};
+
+		rcpm: rcpm@1ee2140 {
+			compatible = "fsl,ls1043a-rcpm", "fsl,qoriq-rcpm-2.1+";
+			reg = <0x0 0x1ee2140 0x0 0x4>;
+			#fsl,rcpm-wakeup-cells = <1>;
+		};
+
+		ftm_alarm0: timer@29d0000 {
+			compatible = "fsl,ls1043a-ftm-alarm";
+			reg = <0x0 0x29d0000 0x0 0x10000>;
+			fsl,rcpm-wakeup = <&rcpm 0x20000>;
+			interrupts = <0 86 0x4>;
+			big-endian;
+		};
+	};
+
+	firmware {
+		optee {
+			compatible = "linaro,optee-tz";
+			method = "smc";
+		};
+	};
+
+};
+
+#include "qoriq-qman-portals.dtsi"
+#include "qoriq-bman-portals.dtsi"
diff --git a/arch/arm64/boot/dts/freescale/fsl-ls1043a.dtsi b/arch/arm64/boot/dts/freescale/fsl-ls1043a.dtsi
index dbf684afc7e1..72fd24193916 100644
--- a/arch/arm64/boot/dts/freescale/fsl-ls1043a.dtsi
+++ b/arch/arm64/boot/dts/freescale/fsl-ls1043a.dtsi
@@ -82,6 +82,126 @@ cpu3: cpu@3 {
 			#cooling-cells = <2>;
 		};
 
+		fman0-extended-args {
+			cell-index = <0>;
+			compatible = "fsl,fman-extended-args";
+			total-fifo-size = <0x37700>;
+
+			fman0_oh1-extended-args {
+				cell-index = <1>;
+				compatible = "fsl,fman-port-op-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+			};
+
+			fman0_oh2-extended-args {
+				cell-index = <2>;
+				compatible = "fsl,fman-port-op-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+			};
+			fman0_oh3-extended-args {
+				cell-index = <3>;
+				compatible = "fsl,fman-port-op-extended-args";
+				fifo-size = <0x900 0x0>;
+				buffer-layout = <96 64>;
+			};
+
+			fman0_rx0-extended-args {
+				cell-index = <0>;
+				compatible = "fsl,fman-port-1g-rx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+				vsp-window = <2 0>;
+			};
+			fman0_tx0-extended-args {
+				cell-index = <0>;
+				compatible = "fsl,fman-port-1g-tx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+			};
+			fman0_rx1-extended-args {
+				cell-index = <1>;
+				compatible = "fsl,fman-port-1g-rx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+				vsp-window = <2 0>;
+			};
+			fman0_tx1-extended-args {
+				cell-index = <1>;
+				compatible = "fsl,fman-port-1g-tx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+			};
+			fman0_rx2-extended-args {
+				cell-index = <2>;
+				compatible = "fsl,fman-port-1g-rx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+				vsp-window = <2 0>;
+			};
+			fman0_tx2-extended-args {
+				cell-index = <2>;
+				compatible = "fsl,fman-port-1g-tx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+			};
+			fman0_rx3-extended-args {
+				cell-index = <3>;
+				compatible = "fsl,fman-port-1g-rx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+				vsp-window = <2 0>;
+			};
+			fman0_tx3-extended-args {
+				cell-index = <3>;
+				compatible = "fsl,fman-port-1g-tx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+			};
+			fman0_rx4-extended-args {
+				cell-index = <4>;
+				compatible = "fsl,fman-port-1g-rx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+				vsp-window = <2 0>;
+			};
+			fman0_tx4-extended-args {
+				cell-index = <4>;
+				compatible = "fsl,fman-port-1g-tx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+			};
+			fman0_rx5-extended-args {
+				cell-index = <5>;
+				compatible = "fsl,fman-port-1g-rx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+				vsp-window = <2 0>;
+			};
+			fman0_tx5-extended-args {
+				cell-index = <5>;
+				compatible = "fsl,fman-port-1g-tx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+			};
+
+			fman0_rx6-extended-args {
+				cell-index = <0>;
+				compatible = "fsl,fman-port-10g-rx-extended-args";
+				fifo-size = <0x6000 0x0>;
+				buffer-layout = <96 64>;
+				vsp-window = <2 0>;
+			};
+			fman0_tx6-extended-args {
+				cell-index = <0>;
+				compatible = "fsl,fman-port-10g-tx-extended-args";
+				fifo-size = <0x4000 0x0>;
+				buffer-layout = <96 64>;
+			};
+		};
+
+
 		l2: l2-cache {
 			compatible = "cache";
 			cache-level = <2>;
@@ -126,8 +246,8 @@ bman_fbpr: bman-fbpr {
 
 		qman_fqd: qman-fqd {
 			compatible = "shared-dma-pool";
-			size = <0 0x400000>;
-			alignment = <0 0x400000>;
+			size = <0 0x800000>;
+			alignment = <0 0x800000>;
 			no-map;
 		};
 
diff --git a/arch/arm64/boot/dts/freescale/fsl-ls1046a-rdb-w906x-sdk.dts b/arch/arm64/boot/dts/freescale/fsl-ls1046a-rdb-w906x-sdk.dts
new file mode 100644
index 000000000000..5c47686b46b7
--- /dev/null
+++ b/arch/arm64/boot/dts/freescale/fsl-ls1046a-rdb-w906x-sdk.dts
@@ -0,0 +1,273 @@
+/*
+ * Device Tree Include file for Freescale Layerscape-1046A family SoC.
+ *
+ * Copyright 2014-2015 Freescale Semiconductor, Inc.
+ *
+ * Mingkai Hu <Mingkai.hu@freescale.com>
+ *
+ * This file is dual-licensed: you can use it either under the terms
+ * of the GPLv2 or the X11 license, at your option. Note that this dual
+ * licensing only applies to this file, and not this project as a
+ * whole.
+ *
+ *  a) This library is free software; you can redistribute it and/or
+ *     modify it under the terms of the GNU General Public License as
+ *     published by the Free Software Foundation; either version 2 of the
+ *     License, or (at your option) any later version.
+ *
+ *     This library is distributed in the hope that it will be useful,
+ *     but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *     MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *     GNU General Public License for more details.
+ *
+ * Or, alternatively,
+ *
+ *  b) Permission is hereby granted, free of charge, to any person
+ *     obtaining a copy of this software and associated documentation
+ *     files (the "Software"), to deal in the Software without
+ *     restriction, including without limitation the rights to use,
+ *     copy, modify, merge, publish, distribute, sublicense, and/or
+ *     sell copies of the Software, and to permit persons to whom the
+ *     Software is furnished to do so, subject to the following
+ *     conditions:
+ *
+ *     The above copyright notice and this permission notice shall be
+ *     included in all copies or substantial portions of the Software.
+ *
+ *     THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ *     EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES
+ *     OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ *     NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ *     HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
+ *     WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ *     FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ *     OTHER DEALINGS IN THE SOFTWARE.
+ */
+
+#include "fsl-ls1046a-rdb-w906x.dts"
+#include "qoriq-qman-portals-sdk.dtsi"
+#include "qoriq-bman-portals-sdk.dtsi"
+
+&bman_fbpr {
+	compatible = "fsl,bman-fbpr";
+	alloc-ranges = <0 0 0x10000 0>;
+};
+&qman_fqd {
+	compatible = "fsl,qman-fqd";
+	alloc-ranges = <0 0 0x10000 0>;
+};
+&qman_pfdr {
+	compatible = "fsl,qman-pfdr";
+	alloc-ranges = <0 0 0x10000 0>;
+};
+
+&soc {
+/delete-property/ dma-coherent;
+
+#include "qoriq-dpaa-eth.dtsi"
+#include "qoriq-fman3-0-6oh.dtsi"
+
+pcie@3400000 {
+	/delete-property/ iommu-map;
+};
+
+pcie@3500000 {
+	/delete-property/ iommu-map;
+};
+
+pcie@3600000 {
+	/delete-property/ iommu-map;
+};
+
+/delete-node/ iommu@9000000;
+};
+
+&fsldpaa {
+	ethernet@0 {
+		status = "disabled";
+	};
+	ethernet@1 {
+		status = "disabled";
+	};
+	ethernet@9 {
+		compatible = "fsl,dpa-ethernet";
+		fsl,fman-mac = <&enet7>;
+		dma-coherent;
+	};
+};
+
+&fman0 {
+	compatible = "fsl,fman", "simple-bus";
+};
+
+&clockgen {
+	dma-coherent;
+};
+
+&scfg {
+	dma-coherent;
+};
+
+&crypto {
+	dma-coherent;
+};
+
+&dcfg {
+	dma-coherent;
+};
+
+&ifc {
+	dma-coherent;
+};
+
+&qspi {
+	dma-coherent;
+};
+
+&esdhc {
+	dma-coherent;
+};
+
+&ddr {
+	dma-coherent;
+};
+
+&tmu {
+	dma-coherent;
+};
+
+&qman {
+	dma-coherent;
+};
+
+&bman {
+	dma-coherent;
+};
+
+&bportals {
+	dma-coherent;
+};
+
+&qportals {
+	dma-coherent;
+};
+
+&dspi {
+	dma-coherent;
+};
+
+&i2c0 {
+	dma-coherent;
+};
+
+&i2c1 {
+	dma-coherent;
+};
+
+&i2c2 {
+	dma-coherent;
+};
+
+&i2c3 {
+	dma-coherent;
+};
+
+&duart0 {
+	dma-coherent;
+};
+
+&duart1 {
+	dma-coherent;
+};
+
+&duart2 {
+	dma-coherent;
+};
+
+&duart3 {
+	dma-coherent;
+};
+
+&gpio0 {
+	dma-coherent;
+};
+
+&gpio1 {
+	dma-coherent;
+};
+
+&gpio2 {
+	dma-coherent;
+};
+
+&gpio3 {
+	dma-coherent;
+};
+
+&lpuart0 {
+	dma-coherent;
+};
+
+&lpuart1 {
+	dma-coherent;
+};
+
+&lpuart2 {
+	dma-coherent;
+};
+
+&lpuart3 {
+	dma-coherent;
+};
+
+&lpuart4 {
+	dma-coherent;
+};
+
+&lpuart5 {
+	dma-coherent;
+};
+
+&ftm_alarm0 {
+	dma-coherent;
+};
+
+&wdog0 {
+	dma-coherent;
+};
+
+&edma0 {
+	dma-coherent;
+};
+
+&sata {
+	dma-coherent;
+};
+
+&qdma {
+	dma-coherent;
+};
+
+&msi1 {
+	dma-coherent;
+};
+
+&msi2 {
+	dma-coherent;
+};
+
+&msi3 {
+	dma-coherent;
+};
+
+&fman0 {
+	dma-coherent;
+};
+
+&ptp_timer0 {
+	dma-coherent;
+};
+
+&fsldpaa {
+	dma-coherent;
+};
diff --git a/arch/arm64/boot/dts/freescale/fsl-ls1046a-rdb-w906x.dts b/arch/arm64/boot/dts/freescale/fsl-ls1046a-rdb-w906x.dts
new file mode 100644
index 000000000000..af45a8def081
--- /dev/null
+++ b/arch/arm64/boot/dts/freescale/fsl-ls1046a-rdb-w906x.dts
@@ -0,0 +1,203 @@
+// SPDX-License-Identifier: (GPL-2.0+ OR MIT)
+/*
+ * Device Tree Include file for Freescale Layerscape-1046A family SoC.
+ *
+ * Copyright 2016 Freescale Semiconductor, Inc.
+ * Copyright 2019 NXP
+ *
+ * Mingkai Hu <mingkai.hu@nxp.com>
+ */
+
+/dts-v1/;
+
+#include "fsl-ls1046a-w906x.dtsi"
+
+/ {
+	model = "LS1046A RDB Board";
+	compatible = "fsl,ls1046a-rdb", "fsl,ls1046a";
+
+	aliases {
+		serial0 = &duart0;
+		serial1 = &duart1;
+		serial2 = &duart2;
+		serial3 = &duart3;
+	};
+
+	chosen {
+		stdout-path = "serial0:115200n8";
+	};
+};
+
+&duart0 {
+	status = "okay";
+};
+
+&duart1 {
+	status = "okay";
+};
+
+&esdhc {
+	mmc-hs200-1_8v;
+	sd-uhs-sdr104;
+	sd-uhs-sdr50;
+	sd-uhs-sdr25;
+	sd-uhs-sdr12;
+};
+
+&usb1 {
+	dr_mode = "otg";
+};
+
+&i2c0 {
+	status = "okay";
+
+	ina220@40 {
+		compatible = "ti,ina220";
+		reg = <0x40>;
+		shunt-resistor = <1000>;
+	};
+
+	temp-sensor@4c {
+		compatible = "adi,adt7461";
+		reg = <0x4c>;
+	};
+
+	eeprom@52 {
+		compatible = "atmel,24c512";
+		reg = <0x52>;
+	};
+
+	eeprom@53 {
+		compatible = "atmel,24c512";
+		reg = <0x53>;
+	};
+};
+
+&i2c3 {
+	status = "okay";
+
+	rtc@51 {
+		compatible = "nxp,pcf2129";
+		reg = <0x51>;
+	};
+};
+
+&ifc {
+	#address-cells = <2>;
+	#size-cells = <1>;
+	/* NAND Flashe and CPLD on board */
+	ranges = <0x0 0x0 0x0 0x7e800000 0x00010000
+		  0x2 0x0 0x0 0x7fb00000 0x00000100>;
+	status = "okay";
+
+	nand@0,0 {
+		compatible = "fsl,ifc-nand";
+		#address-cells = <1>;
+		#size-cells = <1>;
+		reg = <0x0 0x0 0x10000>;
+	};
+
+	cpld: board-control@2,0 {
+		compatible = "fsl,ls1046ardb-cpld";
+		reg = <0x2 0x0 0x0000100>;
+	};
+};
+
+&qspi {
+	status = "okay";
+
+	s25fs512s0: flash@0 {
+		compatible = "jedec,spi-nor";
+		#address-cells = <1>;
+		#size-cells = <1>;
+		spi-max-frequency = <50000000>;
+		m25p,fast-read;
+		spi-rx-bus-width = <1>;
+		spi-tx-bus-width = <1>;
+		reg = <0>;
+	};
+
+	s25fs512s: flash@1 {
+		compatible = "jedec,spi-nor";
+		#address-cells = <1>;
+		#size-cells = <1>;
+		spi-max-frequency = <50000000>;
+		m25p,fast-read;
+		spi-rx-bus-width = <1>;
+		spi-tx-bus-width = <1>;
+		reg = <1>;
+	};
+};
+
+#include "fsl-ls1046-post.dtsi"
+
+&fman0 {
+	ethernet@e4000 {
+		phy-handle = <&rgmii_phy1>;
+		phy-connection-type = "rgmii-id";
+	};
+
+	ethernet@e6000 {
+		phy-handle = <&rgmii_phy2>;
+		phy-connection-type = "rgmii-id";
+	};
+
+	ethernet@e8000 {
+		phy-handle = <&sgmii_phy1>;
+		phy-connection-type = "sgmii";
+	};
+
+	ethernet@ea000 {
+		phy-handle = <&sgmii_phy2>;
+		phy-connection-type = "sgmii";
+	};
+
+	ethernet@f0000 { /* 10GEC1 */
+		phy-handle = <&aqr106_phy>;
+		phy-connection-type = "xgmii";
+	};
+
+	ethernet@f2000 { /* 10GEC2 */
+		fixed-link = <0 1 1000 0 0>;
+		phy-connection-type = "xgmii";
+	};
+
+	dpa-fman0-oh@2 {
+		compatible = "fsl,dpa-oh";
+		/* <OH Rx error, OH Rx default> */
+		fsl,qman-frame-queues-oh = <0x60 1 0x61 1>;
+		fsl,fman-oh-port = <&fman0_oh_0x3>;
+	};
+	dpa-fman0-oh@3 {
+		compatible = "fsl,dpa-oh";
+		/* <OH Rx error, OH Rx default> */
+		fsl,qman-frame-queues-oh = <0x62 1 0x63 1>;
+		fsl,fman-oh-port = <&fman0_oh_0x4>;
+	};
+
+	mdio@fc000 {
+		rgmii_phy1: ethernet-phy@1 {
+			reg = <0x1>;
+		};
+
+		rgmii_phy2: ethernet-phy@2 {
+			reg = <0x2>;
+		};
+
+		sgmii_phy1: ethernet-phy@3 {
+			reg = <0x3>;
+		};
+
+		sgmii_phy2: ethernet-phy@4 {
+			reg = <0x4>;
+		};
+	};
+
+	mdio@fd000 {
+		aqr106_phy: ethernet-phy@0 {
+			compatible = "ethernet-phy-ieee802.3-c45";
+			interrupts = <0 131 4>;
+			reg = <0x0>;
+		};
+	};
+};
diff --git a/arch/arm64/boot/dts/freescale/fsl-ls1046a-rdb.dts b/arch/arm64/boot/dts/freescale/fsl-ls1046a-rdb.dts
index 032abe0a11a4..2d642609f01c 100644
--- a/arch/arm64/boot/dts/freescale/fsl-ls1046a-rdb.dts
+++ b/arch/arm64/boot/dts/freescale/fsl-ls1046a-rdb.dts
@@ -104,6 +104,7 @@ s25fs512s0: flash@0 {
 		#address-cells = <1>;
 		#size-cells = <1>;
 		spi-max-frequency = <50000000>;
+		m25p,fast-read;
 		spi-rx-bus-width = <1>;
 		spi-tx-bus-width = <1>;
 		reg = <0>;
@@ -114,6 +115,7 @@ s25fs512s1: flash@1 {
 		#address-cells = <1>;
 		#size-cells = <1>;
 		spi-max-frequency = <50000000>;
+		m25p,fast-read;
 		spi-rx-bus-width = <1>;
 		spi-tx-bus-width = <1>;
 		reg = <1>;
@@ -157,6 +159,19 @@ ethernet@f2000 { /* 10GEC2 */
 		managed = "in-band-status";
 	};
 
+	dpa-fman0-oh@2 {
+		compatible = "fsl,dpa-oh";
+		/* <OH Rx error, OH Rx default> */
+		fsl,qman-frame-queues-oh = <0x60 1 0x61 1>;
+		fsl,fman-oh-port = <&fman0_oh_0x3>;
+	};
+	dpa-fman0-oh@3 {
+		compatible = "fsl,dpa-oh";
+		/* <OH Rx error, OH Rx default> */
+		fsl,qman-frame-queues-oh = <0x62 1 0x63 1>;
+		fsl,fman-oh-port = <&fman0_oh_0x4>;
+	};
+
 	mdio@fc000 {
 		rgmii_phy1: ethernet-phy@1 {
 			reg = <0x1>;
diff --git a/arch/arm64/boot/dts/freescale/fsl-ls1046a-w906x.dtsi b/arch/arm64/boot/dts/freescale/fsl-ls1046a-w906x.dtsi
new file mode 100644
index 000000000000..6ca59b7e5d49
--- /dev/null
+++ b/arch/arm64/boot/dts/freescale/fsl-ls1046a-w906x.dtsi
@@ -0,0 +1,1002 @@
+// SPDX-License-Identifier: (GPL-2.0+ OR MIT)
+/*
+ * Device Tree Include file for Freescale Layerscape-1046A family SoC.
+ *
+ * Copyright 2016 Freescale Semiconductor, Inc.
+ * Copyright 2018 NXP
+ *
+ * Mingkai Hu <mingkai.hu@nxp.com>
+ */
+
+#include <dt-bindings/interrupt-controller/arm-gic.h>
+#include <dt-bindings/thermal/thermal.h>
+
+/ {
+	compatible = "fsl,ls1046a";
+	interrupt-parent = <&gic>;
+	#address-cells = <2>;
+	#size-cells = <2>;
+
+	aliases {
+		crypto = &crypto;
+		fman0 = &fman0;
+		ethernet0 = &enet0;
+		ethernet1 = &enet1;
+		ethernet2 = &enet2;
+		ethernet3 = &enet3;
+		ethernet4 = &enet4;
+		ethernet5 = &enet5;
+		ethernet6 = &enet6;
+		ethernet7 = &enet7;
+		rtc1 = &ftm_alarm0;
+	};
+
+	cpus {
+		#address-cells = <1>;
+		#size-cells = <0>;
+
+		cooling_map0: cpu0: cpu@0 {
+			device_type = "cpu";
+			compatible = "arm,cortex-a72";
+			reg = <0x0>;
+			clocks = <&clockgen 1 0>;
+			next-level-cache = <&l2>;
+			cpu-idle-states = <&CPU_PH20>;
+			#cooling-cells = <2>;
+		};
+
+		cpu1: cpu@1 {
+			device_type = "cpu";
+			compatible = "arm,cortex-a72";
+			reg = <0x1>;
+			clocks = <&clockgen 1 0>;
+			next-level-cache = <&l2>;
+			cpu-idle-states = <&CPU_PH20>;
+			#cooling-cells = <2>;
+		};
+
+		cpu2: cpu@2 {
+			device_type = "cpu";
+			compatible = "arm,cortex-a72";
+			reg = <0x2>;
+			clocks = <&clockgen 1 0>;
+			next-level-cache = <&l2>;
+			cpu-idle-states = <&CPU_PH20>;
+			#cooling-cells = <2>;
+		};
+
+		cpu3: cpu@3 {
+			device_type = "cpu";
+			compatible = "arm,cortex-a72";
+			reg = <0x3>;
+			clocks = <&clockgen 1 0>;
+			next-level-cache = <&l2>;
+			cpu-idle-states = <&CPU_PH20>;
+			#cooling-cells = <2>;
+		};
+
+		l2: l2-cache {
+			compatible = "cache";
+		};
+		fman0-extended-args {
+			cell-index = <0>;
+			compatible = "fsl,fman-extended-args";
+			total-fifo-size = <0x3E500>;
+
+			fman0_oh1-extended-args {
+				cell-index = <1>;
+				compatible = "fsl,fman-port-op-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+			};
+
+			fman0_oh2-extended-args {
+				cell-index = <2>;
+				compatible = "fsl,fman-port-op-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+			};
+			fman0_oh3-extended-args {
+				cell-index = <3>;
+				compatible = "fsl,fman-port-op-extended-args";
+				fifo-size = <0x900 0x0>;
+				buffer-layout = <96 64>;
+			};
+
+			fman0_rx0-extended-args {
+				cell-index = <0>;
+				compatible = "fsl,fman-port-1g-rx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+				vsp-window = <2 0>;
+			};
+			fman0_tx0-extended-args {
+				cell-index = <0>;
+				compatible = "fsl,fman-port-1g-tx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+			};
+			fman0_rx1-extended-args {
+				cell-index = <1>;
+				compatible = "fsl,fman-port-1g-rx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+				vsp-window = <2 0>;
+			};
+			fman0_tx1-extended-args {
+				cell-index = <1>;
+				compatible = "fsl,fman-port-1g-tx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+			};
+			fman0_rx2-extended-args {
+				cell-index = <2>;
+				compatible = "fsl,fman-port-1g-rx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+				vsp-window = <2 0>;
+			};
+			fman0_tx2-extended-args {
+				cell-index = <2>;
+				compatible = "fsl,fman-port-1g-tx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+			};
+			fman0_rx3-extended-args {
+				cell-index = <3>;
+				compatible = "fsl,fman-port-1g-rx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+				vsp-window = <2 0>;
+			};
+			fman0_tx3-extended-args {
+				cell-index = <3>;
+				compatible = "fsl,fman-port-1g-tx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+			};
+			fman0_rx4-extended-args {
+				cell-index = <4>;
+				compatible = "fsl,fman-port-1g-rx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+				vsp-window = <2 0>;
+			};
+			fman0_tx4-extended-args {
+				cell-index = <4>;
+				compatible = "fsl,fman-port-1g-tx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+			};
+			fman0_rx5-extended-args {
+				cell-index = <5>;
+				compatible = "fsl,fman-port-1g-rx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+				vsp-window = <2 0>;
+			};
+			fman0_tx5-extended-args {
+				cell-index = <5>;
+				compatible = "fsl,fman-port-1g-tx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+			};
+
+			fman0_rx6-extended-args {
+				cell-index = <0>;
+				compatible = "fsl,fman-port-10g-rx-extended-args";
+				fifo-size = <0x6000 0x0>;
+				buffer-layout = <96 64>;
+				vsp-window = <2 0>;
+			};
+			fman0_tx6-extended-args {
+				cell-index = <0>;
+				compatible = "fsl,fman-port-10g-tx-extended-args";
+				fifo-size = <0x4000 0x0>;
+				buffer-layout = <96 64>;
+			};
+			fman0_rx7-extended-args {
+				cell-index = <1>;
+				compatible = "fsl,fman-port-10g-rx-extended-args";
+				fifo-size = <0x6000 0x0>;
+				buffer-layout = <96 64>;
+				vsp-window = <2 0>;
+			};
+			fman0_tx7-extended-args {
+				cell-index = <1>;
+				compatible = "fsl,fman-port-10g-tx-extended-args";
+				fifo-size = <0x4000 0x0>;
+				buffer-layout = <96 64>;
+			};
+
+		};
+	};
+
+	idle-states {
+		/*
+		 * PSCI node is not added default, U-boot will add missing
+		 * parts if it determines to use PSCI.
+		 */
+		entry-method = "psci";
+
+		CPU_PH20: cpu-ph20 {
+			compatible = "arm,idle-state";
+			idle-state-name = "PH20";
+			arm,psci-suspend-param = <0x0>;
+			entry-latency-us = <1000>;
+			exit-latency-us = <1000>;
+			min-residency-us = <3000>;
+		};
+	};
+
+	memory@80000000 {
+		device_type = "memory";
+		/* Real size will be filled by bootloader */
+		reg = <0x0 0x80000000 0x0 0x80000000>,
+              <0x8 0x80000000 0x1 0x80000000>;
+	};
+
+	sysclk: sysclk {
+		compatible = "fixed-clock";
+		#clock-cells = <0>;
+		clock-frequency = <100000000>;
+		clock-output-names = "sysclk";
+	};
+
+	bootmem0: bootmem0@a0000000 {
+		reg = <0x0 0xa0000000 0x0 0x04000000>, /* 64MB reserved */
+		      <0x0 0xa4000000 0x0 0x06000000>; /* 96MB reserved */
+	};
+  
+	bootmem1: bootmem1@aa000000 {
+		reg = <0x0 0xaa000000 0x0 0x04000000>, /* 64MB reserved */
+		      <0x0 0xae000000 0x0 0x06000000>; /* 96MB reserved */
+	};
+
+
+	reboot {
+		compatible ="syscon-reboot";
+		regmap = <&dcfg>;
+		offset = <0xb0>;
+		mask = <0x02>;
+	};
+
+	timer {
+		compatible = "arm,armv8-timer";
+		interrupts = <GIC_PPI 13 (GIC_CPU_MASK_RAW(0xf) |
+					  IRQ_TYPE_LEVEL_LOW)>,
+			     <GIC_PPI 14 (GIC_CPU_MASK_RAW(0xf) |
+					  IRQ_TYPE_LEVEL_LOW)>,
+			     <GIC_PPI 11 (GIC_CPU_MASK_RAW(0xf) |
+					  IRQ_TYPE_LEVEL_LOW)>,
+			     <GIC_PPI 10 (GIC_CPU_MASK_RAW(0xf) |
+					  IRQ_TYPE_LEVEL_LOW)>;
+	};
+
+	pmu {
+		compatible = "arm,cortex-a72-pmu";
+		interrupts = <GIC_SPI 106 IRQ_TYPE_LEVEL_HIGH>,
+			     <GIC_SPI 107 IRQ_TYPE_LEVEL_HIGH>,
+			     <GIC_SPI 95 IRQ_TYPE_LEVEL_HIGH>,
+			     <GIC_SPI 97 IRQ_TYPE_LEVEL_HIGH>;
+		interrupt-affinity = <&cpu0>,
+				     <&cpu1>,
+				     <&cpu2>,
+				     <&cpu3>;
+	};
+
+	gic: interrupt-controller@1400000 {
+		compatible = "arm,gic-400";
+		#interrupt-cells = <3>;
+		interrupt-controller;
+		reg = <0x0 0x1410000 0 0x10000>, /* GICD */
+		      <0x0 0x1420000 0 0x20000>, /* GICC */
+		      <0x0 0x1440000 0 0x20000>, /* GICH */
+		      <0x0 0x1460000 0 0x20000>; /* GICV */
+		interrupts = <GIC_PPI 9 (GIC_CPU_MASK_RAW(0xf) |
+					 IRQ_TYPE_LEVEL_LOW)>;
+	};
+
+	soc: soc {
+		compatible = "simple-bus";
+		#address-cells = <2>;
+		#size-cells = <2>;
+		ranges;
+		dma-ranges = <0x0 0x0 0x0 0x0 0x10000 0x00000000>;
+		dma-coherent;
+
+		ddr: memory-controller@1080000 {
+			compatible = "fsl,qoriq-memory-controller";
+			reg = <0x0 0x1080000 0x0 0x1000>;
+			interrupts = <GIC_SPI 144 IRQ_TYPE_LEVEL_HIGH>;
+			big-endian;
+		};
+
+		ifc: ifc@1530000 {
+			compatible = "fsl,ifc", "simple-bus";
+			reg = <0x0 0x1530000 0x0 0x10000>;
+			interrupts = <GIC_SPI 43 IRQ_TYPE_LEVEL_HIGH>;
+			status = "disabled";
+		};
+
+		qspi: spi@1550000 {
+			compatible = "fsl,ls1021a-qspi","fsl,ls1-qspi";
+			#address-cells = <1>;
+			#size-cells = <0>;
+			reg = <0x0 0x1550000 0x0 0x10000>,
+				<0x0 0x40000000 0x0 0x10000000>;
+			reg-names = "QuadSPI", "QuadSPI-memory";
+			interrupts = <GIC_SPI 99 IRQ_TYPE_LEVEL_HIGH>;
+			clock-names = "qspi_en", "qspi";
+			clocks = <&clockgen 4 1>, <&clockgen 4 1>;
+			status = "disabled";
+		};
+
+		esdhc: esdhc@1560000 {
+			compatible = "fsl,ls1046a-esdhc", "fsl,esdhc";
+			reg = <0x0 0x1560000 0x0 0x10000>;
+			interrupts = <GIC_SPI 62 IRQ_TYPE_LEVEL_HIGH>;
+			clocks = <&clockgen 2 1>;
+			voltage-ranges = <1800 1800 3300 3300>;
+			sdhci,auto-cmd12;
+			big-endian;
+			bus-width = <4>;
+		};
+
+		smmu: iommu@9000000 {
+			compatible = "arm,mmu-500";
+			reg = <0 0x9000000 0 0x400000>;
+			dma-coherent;
+			stream-match-mask = <0x7f00>;
+			#global-interrupts = <2>;
+			#iommu-cells = <1>;
+			interrupts = <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 143 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 142 IRQ_TYPE_LEVEL_HIGH>;
+		};
+
+		scfg: scfg@1570000 {
+			compatible = "fsl,ls1046a-scfg", "syscon";
+			reg = <0x0 0x1570000 0x0 0x10000>;
+			big-endian;
+		};
+
+		crypto: crypto@1700000 {
+			compatible = "fsl,sec-v5.4", "fsl,sec-v5.0",
+				     "fsl,sec-v4.0";
+			fsl,sec-era = <8>;
+			#address-cells = <1>;
+			#size-cells = <1>;
+			ranges = <0x0 0x00 0x1700000 0x100000>;
+			reg = <0x00 0x1700000 0x0 0x100000>;
+			interrupts = <GIC_SPI 75 IRQ_TYPE_LEVEL_HIGH>;
+
+			sec_jr0: jr@10000 {
+				compatible = "fsl,sec-v5.4-job-ring",
+					     "fsl,sec-v5.0-job-ring",
+					     "fsl,sec-v4.0-job-ring";
+				reg	   = <0x10000 0x10000>;
+				interrupts = <GIC_SPI 71 IRQ_TYPE_LEVEL_HIGH>;
+			};
+
+			sec_jr1: jr@20000 {
+				compatible = "fsl,sec-v5.4-job-ring",
+					     "fsl,sec-v5.0-job-ring",
+					     "fsl,sec-v4.0-job-ring";
+				reg	   = <0x20000 0x10000>;
+				interrupts = <GIC_SPI 72 IRQ_TYPE_LEVEL_HIGH>;
+			};
+
+			sec_jr2: jr@30000 {
+				compatible = "fsl,sec-v5.4-job-ring",
+					     "fsl,sec-v5.0-job-ring",
+					     "fsl,sec-v4.0-job-ring";
+				reg	   = <0x30000 0x10000>;
+				interrupts = <GIC_SPI 73 IRQ_TYPE_LEVEL_HIGH>;
+			};
+
+			sec_jr3: jr@40000 {
+				compatible = "fsl,sec-v5.4-job-ring",
+					     "fsl,sec-v5.0-job-ring",
+					     "fsl,sec-v4.0-job-ring";
+				reg	   = <0x40000 0x10000>;
+				interrupts = <GIC_SPI 74 IRQ_TYPE_LEVEL_HIGH>;
+			};
+		};
+
+		qman: qman@1880000 {
+			compatible = "fsl,qman";
+			reg = <0x0 0x1880000 0x0 0x10000>;
+			interrupts = <GIC_SPI 45 IRQ_TYPE_LEVEL_HIGH>;
+			memory-region = <&qman_fqd &qman_pfdr>;
+
+		};
+
+		bman: bman@1890000 {
+			compatible = "fsl,bman";
+			reg = <0x0 0x1890000 0x0 0x10000>;
+			interrupts = <GIC_SPI 45 IRQ_TYPE_LEVEL_HIGH>;
+			memory-region = <&bman_fbpr>;
+
+		};
+
+		qportals: qman-portals@500000000 {
+			ranges = <0x0 0x5 0x00000000 0x8000000>;
+		};
+
+		bportals: bman-portals@508000000 {
+			ranges = <0x0 0x5 0x08000000 0x8000000>;
+		};
+
+		dcfg: dcfg@1ee0000 {
+			compatible = "fsl,ls1046a-dcfg", "syscon";
+			reg = <0x0 0x1ee0000 0x0 0x1000>;
+			big-endian;
+		};
+
+		clockgen: clocking@1ee1000 {
+			compatible = "fsl,ls1046a-clockgen";
+			reg = <0x0 0x1ee1000 0x0 0x1000>;
+			#clock-cells = <2>;
+			clocks = <&sysclk>;
+		};
+
+		tmu: tmu@1f00000 {
+			compatible = "fsl,qoriq-tmu";
+			reg = <0x0 0x1f00000 0x0 0x10000>;
+			interrupts = <0 33 0x4>;
+			fsl,tmu-range = <0xb0000 0x9002a 0x6004c 0x30062>;
+			fsl,tmu-calibration =
+				/* Calibration data group 1 */
+				<0x00000000 0x00000026
+				0x00000001 0x0000002d
+				0x00000002 0x00000032
+				0x00000003 0x00000039
+				0x00000004 0x0000003f
+				0x00000005 0x00000046
+				0x00000006 0x0000004d
+				0x00000007 0x00000054
+				0x00000008 0x0000005a
+				0x00000009 0x00000061
+				0x0000000a 0x0000006a
+				0x0000000b 0x00000071
+				/* Calibration data group 2 */
+				0x00010000 0x00000025
+				0x00010001 0x0000002c
+				0x00010002 0x00000035
+				0x00010003 0x0000003d
+				0x00010004 0x00000045
+				0x00010005 0x0000004e
+				0x00010006 0x00000057
+				0x00010007 0x00000061
+				0x00010008 0x0000006b
+				0x00010009 0x00000076
+				/* Calibration data group 3 */
+				0x00020000 0x00000029
+				0x00020001 0x00000033
+				0x00020002 0x0000003d
+				0x00020003 0x00000049
+				0x00020004 0x00000056
+				0x00020005 0x00000061
+				0x00020006 0x0000006d
+				/* Calibration data group 4 */
+				0x00030000 0x00000021
+				0x00030001 0x0000002a
+				0x00030002 0x0000003c
+				0x00030003 0x0000004e>;
+			big-endian;
+			#thermal-sensor-cells = <1>;
+		};
+
+		dspi: spi@2100000 {
+			compatible = "fsl,ls1021a-v1.0-dspi";
+			#address-cells = <1>;
+			#size-cells = <0>;
+			reg = <0x0 0x2100000 0x0 0x10000>;
+			interrupts = <GIC_SPI 64 IRQ_TYPE_LEVEL_HIGH>;
+			clock-names = "dspi";
+			clocks = <&clockgen 4 1>;
+			spi-num-chipselects = <5>;
+			big-endian;
+			status = "disabled";
+		};
+
+		i2c0: i2c@2180000 {
+			compatible = "fsl,vf610-i2c", "fsl,ls1046a-vf610-i2c";
+			#address-cells = <1>;
+			#size-cells = <0>;
+			reg = <0x0 0x2180000 0x0 0x10000>;
+			interrupts = <GIC_SPI 56 IRQ_TYPE_LEVEL_HIGH>;
+			clocks = <&clockgen 4 1>;
+			dmas = <&edma0 1 39>,
+			       <&edma0 1 38>;
+			dma-names = "tx", "rx";
+			scl-gpios = <&gpio3 12 0>;
+			status = "disabled";
+		};
+
+		i2c1: i2c@2190000 {
+			compatible = "fsl,vf610-i2c";
+			#address-cells = <1>;
+			#size-cells = <0>;
+			reg = <0x0 0x2190000 0x0 0x10000>;
+			interrupts = <GIC_SPI 57 IRQ_TYPE_LEVEL_HIGH>;
+			clocks = <&clockgen 4 1>;
+			status = "disabled";
+		};
+
+		i2c2: i2c@21a0000 {
+			compatible = "fsl,vf610-i2c";
+			#address-cells = <1>;
+			#size-cells = <0>;
+			reg = <0x0 0x21a0000 0x0 0x10000>;
+			interrupts = <GIC_SPI 58 IRQ_TYPE_LEVEL_HIGH>;
+			clocks = <&clockgen 4 1>;
+			status = "disabled";
+		};
+
+		i2c3: i2c@21b0000 {
+			compatible = "fsl,vf610-i2c", "fsl,ls1046a-vf610-i2c";
+			#address-cells = <1>;
+			#size-cells = <0>;
+			reg = <0x0 0x21b0000 0x0 0x10000>;
+			interrupts = <GIC_SPI 59 IRQ_TYPE_LEVEL_HIGH>;
+			clocks = <&clockgen 4 1>;
+			scl-gpios = <&gpio3 12 0>;
+			status = "disabled";
+		};
+
+		duart0: serial@21c0500 {
+			compatible = "fsl,ns16550", "ns16550a";
+			reg = <0x00 0x21c0500 0x0 0x100>;
+			interrupts = <GIC_SPI 54 IRQ_TYPE_LEVEL_HIGH>;
+			clocks = <&clockgen 4 1>;
+			status = "disabled";
+		};
+
+		duart1: serial@21c0600 {
+			compatible = "fsl,ns16550", "ns16550a";
+			reg = <0x00 0x21c0600 0x0 0x100>;
+			interrupts = <GIC_SPI 54 IRQ_TYPE_LEVEL_HIGH>;
+			clocks = <&clockgen 4 1>;
+			status = "disabled";
+		};
+
+		duart2: serial@21d0500 {
+			compatible = "fsl,ns16550", "ns16550a";
+			reg = <0x0 0x21d0500 0x0 0x100>;
+			interrupts = <GIC_SPI 55 IRQ_TYPE_LEVEL_HIGH>;
+			clocks = <&clockgen 4 1>;
+			status = "disabled";
+		};
+
+		duart3: serial@21d0600 {
+			compatible = "fsl,ns16550", "ns16550a";
+			reg = <0x0 0x21d0600 0x0 0x100>;
+			interrupts = <GIC_SPI 55 IRQ_TYPE_LEVEL_HIGH>;
+			clocks = <&clockgen 4 1>;
+			status = "disabled";
+		};
+
+		gpio0: gpio@2300000 {
+			compatible = "fsl,qoriq-gpio";
+			reg = <0x0 0x2300000 0x0 0x10000>;
+			interrupts = <GIC_SPI 66 IRQ_TYPE_LEVEL_HIGH>;
+			gpio-controller;
+			#gpio-cells = <2>;
+			interrupt-controller;
+			#interrupt-cells = <2>;
+		};
+
+		gpio1: gpio@2310000 {
+			compatible = "fsl,qoriq-gpio";
+			reg = <0x0 0x2310000 0x0 0x10000>;
+			interrupts = <GIC_SPI 67 IRQ_TYPE_LEVEL_HIGH>;
+			gpio-controller;
+			#gpio-cells = <2>;
+			interrupt-controller;
+			#interrupt-cells = <2>;
+		};
+
+		gpio2: gpio@2320000 {
+			compatible = "fsl,qoriq-gpio";
+			reg = <0x0 0x2320000 0x0 0x10000>;
+			interrupts = <GIC_SPI 68 IRQ_TYPE_LEVEL_HIGH>;
+			gpio-controller;
+			#gpio-cells = <2>;
+			interrupt-controller;
+			#interrupt-cells = <2>;
+		};
+
+		gpio3: gpio@2330000 {
+			compatible = "fsl,qoriq-gpio";
+			reg = <0x0 0x2330000 0x0 0x10000>;
+			interrupts = <GIC_SPI 134 IRQ_TYPE_LEVEL_HIGH>;
+			gpio-controller;
+			#gpio-cells = <2>;
+			interrupt-controller;
+			#interrupt-cells = <2>;
+		};
+
+		lpuart0: serial@2950000 {
+			compatible = "fsl,ls1021a-lpuart";
+			reg = <0x0 0x2950000 0x0 0x1000>;
+			interrupts = <GIC_SPI 48 IRQ_TYPE_LEVEL_HIGH>;
+			clocks = <&clockgen 4 0>;
+			clock-names = "ipg";
+			status = "disabled";
+		};
+
+		lpuart1: serial@2960000 {
+			compatible = "fsl,ls1021a-lpuart";
+			reg = <0x0 0x2960000 0x0 0x1000>;
+			interrupts = <GIC_SPI 49 IRQ_TYPE_LEVEL_HIGH>;
+			clocks = <&clockgen 4 1>;
+			clock-names = "ipg";
+			status = "disabled";
+		};
+
+		lpuart2: serial@2970000 {
+			compatible = "fsl,ls1021a-lpuart";
+			reg = <0x0 0x2970000 0x0 0x1000>;
+			interrupts = <GIC_SPI 50 IRQ_TYPE_LEVEL_HIGH>;
+			clocks = <&clockgen 4 1>;
+			clock-names = "ipg";
+			status = "disabled";
+		};
+
+		lpuart3: serial@2980000 {
+			compatible = "fsl,ls1021a-lpuart";
+			reg = <0x0 0x2980000 0x0 0x1000>;
+			interrupts = <GIC_SPI 51 IRQ_TYPE_LEVEL_HIGH>;
+			clocks = <&clockgen 4 1>;
+			clock-names = "ipg";
+			status = "disabled";
+		};
+
+		lpuart4: serial@2990000 {
+			compatible = "fsl,ls1021a-lpuart";
+			reg = <0x0 0x2990000 0x0 0x1000>;
+			interrupts = <GIC_SPI 52 IRQ_TYPE_LEVEL_HIGH>;
+			clocks = <&clockgen 4 1>;
+			clock-names = "ipg";
+			status = "disabled";
+		};
+
+		lpuart5: serial@29a0000 {
+			compatible = "fsl,ls1021a-lpuart";
+			reg = <0x0 0x29a0000 0x0 0x1000>;
+			interrupts = <GIC_SPI 53 IRQ_TYPE_LEVEL_HIGH>;
+			clocks = <&clockgen 4 1>;
+			clock-names = "ipg";
+			status = "disabled";
+		};
+
+		wdog0: watchdog@2ad0000 {
+			compatible = "fsl,imx21-wdt";
+			reg = <0x0 0x2ad0000 0x0 0x10000>;
+			interrupts = <GIC_SPI 83 IRQ_TYPE_LEVEL_HIGH>;
+			clocks = <&clockgen 4 1>;
+			big-endian;
+		};
+
+		edma0: edma@2c00000 {
+			#dma-cells = <2>;
+			compatible = "fsl,vf610-edma";
+			reg = <0x0 0x2c00000 0x0 0x10000>,
+			      <0x0 0x2c10000 0x0 0x10000>,
+			      <0x0 0x2c20000 0x0 0x10000>;
+			interrupts = <GIC_SPI 103 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 103 IRQ_TYPE_LEVEL_HIGH>;
+			interrupt-names = "edma-tx", "edma-err";
+			dma-channels = <32>;
+			big-endian;
+			clock-names = "dmamux0", "dmamux1";
+			clocks = <&clockgen 4 1>,
+				 <&clockgen 4 1>;
+		};
+
+		aux_bus: aux_bus {
+			#address-cells = <2>;
+			#size-cells = <2>;
+			compatible = "simple-bus";
+			ranges;
+			dma-ranges = <0x0 0x0 0x0 0x0 0x100 0x00000000>;
+
+			usb0: usb@2f00000 {
+				compatible = "fsl,ls1046a-dwc3", "snps,dwc3";
+				reg = <0x0 0x2f00000 0x0 0x10000>;
+				interrupts = <GIC_SPI 60 IRQ_TYPE_LEVEL_HIGH>;
+				dr_mode = "host";
+				snps,quirk-frame-length-adjustment = <0x20>;
+				snps,dis_rxdet_inp3_quirk;
+				snps,incr-burst-type-adjustment = <1>, <4>, <8>, <16>;
+				usb3-lpm-capable;
+				snps,dis-u1u2-when-u3-quirk;
+				snps,host-vbus-glitches;
+				dma-coherent;
+			};
+
+			usb1: usb@3000000 {
+				compatible = "fsl,ls1046a-dwc3", "snps,dwc3";
+				reg = <0x0 0x3000000 0x0 0x10000>;
+				interrupts = <GIC_SPI 61 IRQ_TYPE_LEVEL_HIGH>;
+				dr_mode = "host";
+				snps,quirk-frame-length-adjustment = <0x20>;
+				snps,dis_rxdet_inp3_quirk;
+				snps,incr-burst-type-adjustment = <1>, <4>, <8>, <16>;
+				usb3-lpm-capable;
+				snps,dis-u1u2-when-u3-quirk;
+				snps,host-vbus-glitches;
+				dma-coherent;
+			};
+
+			usb2: usb@3100000 {
+				compatible = "fsl,ls1046a-dwc3", "snps,dwc3";
+				reg = <0x0 0x3100000 0x0 0x10000>;
+				interrupts = <GIC_SPI 63 IRQ_TYPE_LEVEL_HIGH>;
+				dr_mode = "host";
+				snps,quirk-frame-length-adjustment = <0x20>;
+				snps,dis_rxdet_inp3_quirk;
+				snps,incr-burst-type-adjustment = <1>, <4>, <8>, <16>;
+				usb3-lpm-capable;
+				snps,dis-u1u2-when-u3-quirk;
+				snps,host-vbus-glitches;
+				dma-coherent;
+			};
+
+			sata: sata@3200000 {
+				compatible = "fsl,ls1046a-ahci";
+				reg = <0x0 0x3200000 0x0 0x10000>,
+					<0x0 0x20140520 0x0 0x4>;
+				reg-names = "ahci", "sata-ecc";
+				interrupts = <GIC_SPI 69 IRQ_TYPE_LEVEL_HIGH>;
+				clocks = <&clockgen 4 1>;
+			};
+		};
+
+		msi1: msi-controller@1580000 {
+			compatible = "fsl,ls1046a-msi";
+			msi-controller;
+			reg = <0x0 0x1580000 0x0 0x10000>;
+			interrupts = <GIC_SPI 116 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 111 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 112 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 113 IRQ_TYPE_LEVEL_HIGH>;
+		};
+
+		msi2: msi-controller@1590000 {
+			compatible = "fsl,ls1046a-msi";
+			msi-controller;
+			reg = <0x0 0x1590000 0x0 0x10000>;
+			interrupts = <GIC_SPI 126 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 121 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 122 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 123 IRQ_TYPE_LEVEL_HIGH>;
+		};
+
+		msi3: msi-controller@15a0000 {
+			compatible = "fsl,ls1046a-msi";
+			msi-controller;
+			reg = <0x0 0x15a0000 0x0 0x10000>;
+			interrupts = <GIC_SPI 160 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 155 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 156 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 157 IRQ_TYPE_LEVEL_HIGH>;
+		};
+
+		pcie@3400000 {
+			compatible = "fsl,ls1046a-pcie";
+			reg = <0x00 0x03400000 0x0 0x00100000   /* controller registers */
+			       0x40 0x00000000 0x0 0x00002000>; /* configuration space */
+			reg-names = "regs", "config";
+			interrupts = <GIC_SPI 118 IRQ_TYPE_LEVEL_HIGH>, /* controller interrupt */
+				     <GIC_SPI 117 IRQ_TYPE_LEVEL_HIGH>; /* PME interrupt */
+			interrupt-names = "aer", "pme";
+			#address-cells = <3>;
+			#size-cells = <2>;
+			device_type = "pci";
+			dma-coherent;
+			iommu-map = <0 &smmu 0 1>;	/* update by bootloader */
+			num-viewport = <8>;
+			bus-range = <0x0 0xff>;
+			ranges = <0x81000000 0x0 0x00000000 0x40 0x00010000 0x0 0x00010000   /* downstream I/O */
+				  0x82000000 0x0 0x40000000 0x40 0x40000000 0x0 0x40000000>; /* non-prefetchable memory */
+			msi-parent = <&msi1>, <&msi2>, <&msi3>;
+			#interrupt-cells = <1>;
+			interrupt-map-mask = <0 0 0 7>;
+			interrupt-map = <0000 0 0 1 &gic GIC_SPI 110 IRQ_TYPE_LEVEL_HIGH>,
+					<0000 0 0 2 &gic GIC_SPI 110 IRQ_TYPE_LEVEL_HIGH>,
+					<0000 0 0 3 &gic GIC_SPI 110 IRQ_TYPE_LEVEL_HIGH>,
+					<0000 0 0 4 &gic GIC_SPI 110 IRQ_TYPE_LEVEL_HIGH>;
+			status = "disabled";
+		};
+
+		pcie_ep@3400000 {
+			compatible = "fsl,ls1046a-pcie-ep","fsl,ls-pcie-ep";
+			reg = <0x00 0x03400000 0x0 0x00100000
+				0x40 0x00000000 0x8 0x00000000>;
+			reg-names = "regs", "addr_space";
+			num-ib-windows = <6>;
+			num-ob-windows = <8>;
+			status = "disabled";
+		};
+
+		pcie@3500000 {
+			compatible = "fsl,ls1046a-pcie";
+			reg = <0x00 0x03500000 0x0 0x00100000   /* controller registers */
+			       0x48 0x00000000 0x0 0x00002000>; /* configuration space */
+			reg-names = "regs", "config";
+			interrupts = <GIC_SPI 128 IRQ_TYPE_LEVEL_HIGH>, /* controller interrupt */
+				     <GIC_SPI 127 IRQ_TYPE_LEVEL_HIGH>; /* PME interrupt */
+			interrupt-names = "aer", "pme";
+			#address-cells = <3>;
+			#size-cells = <2>;
+			device_type = "pci";
+			dma-coherent;
+			iommu-map = <0 &smmu 0 1>;	/* update by bootloader */
+			num-viewport = <8>;
+			bus-range = <0x0 0xff>;
+			ranges = <0x81000000 0x0 0x00000000 0x48 0x00010000 0x0 0x00010000   /* downstream I/O */
+				  0x82000000 0x0 0x40000000 0x48 0x40000000 0x0 0x40000000>; /* non-prefetchable memory */
+			msi-parent = <&msi2>, <&msi3>, <&msi1>;
+			#interrupt-cells = <1>;
+			interrupt-map-mask = <0 0 0 7>;
+			interrupt-map = <0000 0 0 1 &gic GIC_SPI 120 IRQ_TYPE_LEVEL_HIGH>,
+					<0000 0 0 2 &gic GIC_SPI 120 IRQ_TYPE_LEVEL_HIGH>,
+					<0000 0 0 3 &gic GIC_SPI 120 IRQ_TYPE_LEVEL_HIGH>,
+					<0000 0 0 4 &gic GIC_SPI 120 IRQ_TYPE_LEVEL_HIGH>;
+			status = "disabled";
+		};
+
+		pcie_ep@3500000 {
+			compatible = "fsl,ls1046a-pcie-ep","fsl,ls-pcie-ep";
+			reg = <0x00 0x03500000 0x0 0x00100000
+				0x48 0x00000000 0x8 0x00000000>;
+			reg-names = "regs", "addr_space";
+			num-ib-windows = <6>;
+			num-ob-windows = <8>;
+			status = "disabled";
+		};
+
+		pcie@3600000 {
+			compatible = "fsl,ls1046a-pcie";
+			reg = <0x00 0x03600000 0x0 0x00100000   /* controller registers */
+			       0x50 0x00000000 0x0 0x00002000>; /* configuration space */
+			reg-names = "regs", "config";
+			interrupts = <GIC_SPI 162 IRQ_TYPE_LEVEL_HIGH>, /* controller interrupt */
+				     <GIC_SPI 161 IRQ_TYPE_LEVEL_HIGH>; /* PME interrupt */
+			interrupt-names = "aer", "pme";
+			#address-cells = <3>;
+			#size-cells = <2>;
+			device_type = "pci";
+			dma-coherent;
+			iommu-map = <0 &smmu 0 1>;	/* update by bootloader */
+			num-viewport = <8>;
+			bus-range = <0x0 0xff>;
+			ranges = <0x81000000 0x0 0x00000000 0x50 0x00010000 0x0 0x00010000   /* downstream I/O */
+				  0x82000000 0x0 0x40000000 0x50 0x40000000 0x0 0x40000000>; /* non-prefetchable memory */
+			msi-parent = <&msi3>, <&msi1>, <&msi2>;
+			#interrupt-cells = <1>;
+			interrupt-map-mask = <0 0 0 7>;
+			interrupt-map = <0000 0 0 1 &gic GIC_SPI 154 IRQ_TYPE_LEVEL_HIGH>,
+					<0000 0 0 2 &gic GIC_SPI 154 IRQ_TYPE_LEVEL_HIGH>,
+					<0000 0 0 3 &gic GIC_SPI 154 IRQ_TYPE_LEVEL_HIGH>,
+					<0000 0 0 4 &gic GIC_SPI 154 IRQ_TYPE_LEVEL_HIGH>;
+			status = "disabled";
+		};
+
+		pcie_ep@3600000 {
+			compatible = "fsl,ls1046a-pcie-ep", "fsl,ls-pcie-ep";
+			reg = <0x00 0x03600000 0x0 0x00100000
+				0x50 0x00000000 0x8 0x00000000>;
+			reg-names = "regs", "addr_space";
+			num-ib-windows = <6>;
+			num-ob-windows = <8>;
+			status = "disabled";
+		};
+
+		qdma: dma-controller@8380000 {
+			compatible = "fsl,ls1046a-qdma", "fsl,ls1021a-qdma";
+			reg = <0x0 0x8380000 0x0 0x1000>, /* Controller regs */
+			      <0x0 0x8390000 0x0 0x10000>, /* Status regs */
+			      <0x0 0x83a0000 0x0 0x40000>; /* Block regs */
+			interrupts = <GIC_SPI 153 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 39 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 40 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 41 IRQ_TYPE_LEVEL_HIGH>,
+				     <GIC_SPI 42 IRQ_TYPE_LEVEL_HIGH>;
+			interrupt-names = "qdma-error", "qdma-queue0",
+				"qdma-queue1", "qdma-queue2", "qdma-queue3";
+			dma-channels = <8>;
+			block-number = <1>;
+			block-offset = <0x10000>;
+			fsl,dma-queues = <2>;
+			status-sizes = <64>;
+			queue-sizes = <64 64>;
+			big-endian;
+		};
+
+		rcpm: rcpm@1ee208c {
+			compatible = "fsl,ls1046a-rcpm", "fsl,qoriq-rcpm-2.1+";
+			reg = <0x0 0x1ee2140 0x0 0x4>;
+			#fsl,rcpm-wakeup-cells = <1>;
+		};
+
+		ftm_alarm0: timer@29d0000 {
+			compatible = "fsl,ls1046a-ftm-alarm";
+			reg = <0x0 0x29d0000 0x0 0x10000>;
+			fsl,rcpm-wakeup = <&rcpm 0x20000>;
+			interrupts = <GIC_SPI 86 IRQ_TYPE_LEVEL_HIGH>;
+			big-endian;
+		};
+	};
+
+	reserved-memory {
+		#address-cells = <2>;
+		#size-cells = <2>;
+		ranges;
+
+		bman_fbpr: bman-fbpr {
+			compatible = "shared-dma-pool";
+			size = <0 0x1000000>;
+			alignment = <0 0x1000000>;
+			no-map;
+		};
+
+		qman_fqd: qman-fqd {
+			compatible = "shared-dma-pool";
+			size = <0 0x800000>;
+			alignment = <0 0x800000>;
+			no-map;
+		};
+
+		qman_pfdr: qman-pfdr {
+			compatible = "shared-dma-pool";
+			size = <0 0x2000000>;
+			alignment = <0 0x2000000>;
+			no-map;
+		};
+	};
+
+	firmware {
+		optee {
+			compatible = "linaro,optee-tz";
+			method = "smc";
+		};
+	};
+};
+
+#include "qoriq-qman-portals.dtsi"
+#include "qoriq-bman-portals.dtsi"
diff --git a/arch/arm64/boot/dts/freescale/fsl-ls1046a.dtsi b/arch/arm64/boot/dts/freescale/fsl-ls1046a.dtsi
index 9fc64fb225b1..fdae51b2373b 100644
--- a/arch/arm64/boot/dts/freescale/fsl-ls1046a.dtsi
+++ b/arch/arm64/boot/dts/freescale/fsl-ls1046a.dtsi
@@ -85,6 +85,138 @@ l2: l2-cache {
 			cache-level = <2>;
 			cache-unified;
 		};
+		fman0-extended-args {
+			cell-index = <0>;
+			compatible = "fsl,fman-extended-args";
+			total-fifo-size = <0x3E500>;
+
+			fman0_oh1-extended-args {
+				cell-index = <1>;
+				compatible = "fsl,fman-port-op-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+			};
+
+			fman0_oh2-extended-args {
+				cell-index = <2>;
+				compatible = "fsl,fman-port-op-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+			};
+			fman0_oh3-extended-args {
+				cell-index = <3>;
+				compatible = "fsl,fman-port-op-extended-args";
+				fifo-size = <0x900 0x0>;
+				buffer-layout = <96 64>;
+			};
+
+			fman0_rx0-extended-args {
+				cell-index = <0>;
+				compatible = "fsl,fman-port-1g-rx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+				vsp-window = <2 0>;
+			};
+			fman0_tx0-extended-args {
+				cell-index = <0>;
+				compatible = "fsl,fman-port-1g-tx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+			};
+			fman0_rx1-extended-args {
+				cell-index = <1>;
+				compatible = "fsl,fman-port-1g-rx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+				vsp-window = <2 0>;
+			};
+			fman0_tx1-extended-args {
+				cell-index = <1>;
+				compatible = "fsl,fman-port-1g-tx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+			};
+			fman0_rx2-extended-args {
+				cell-index = <2>;
+				compatible = "fsl,fman-port-1g-rx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+				vsp-window = <2 0>;
+			};
+			fman0_tx2-extended-args {
+				cell-index = <2>;
+				compatible = "fsl,fman-port-1g-tx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+			};
+			fman0_rx3-extended-args {
+				cell-index = <3>;
+				compatible = "fsl,fman-port-1g-rx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+				vsp-window = <2 0>;
+			};
+			fman0_tx3-extended-args {
+				cell-index = <3>;
+				compatible = "fsl,fman-port-1g-tx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+			};
+			fman0_rx4-extended-args {
+				cell-index = <4>;
+				compatible = "fsl,fman-port-1g-rx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+				vsp-window = <2 0>;
+			};
+			fman0_tx4-extended-args {
+				cell-index = <4>;
+				compatible = "fsl,fman-port-1g-tx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+			};
+			fman0_rx5-extended-args {
+				cell-index = <5>;
+				compatible = "fsl,fman-port-1g-rx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+				vsp-window = <2 0>;
+			};
+			fman0_tx5-extended-args {
+				cell-index = <5>;
+				compatible = "fsl,fman-port-1g-tx-extended-args";
+				fifo-size = <0x3200 0x0>;
+				buffer-layout = <96 64>;
+			};
+
+			fman0_rx6-extended-args {
+				cell-index = <0>;
+				compatible = "fsl,fman-port-10g-rx-extended-args";
+				fifo-size = <0x6000 0x0>;
+				buffer-layout = <96 64>;
+				vsp-window = <2 0>;
+			};
+			fman0_tx6-extended-args {
+				cell-index = <0>;
+				compatible = "fsl,fman-port-10g-tx-extended-args";
+				fifo-size = <0x4000 0x0>;
+				buffer-layout = <96 64>;
+			};
+			fman0_rx7-extended-args {
+				cell-index = <1>;
+				compatible = "fsl,fman-port-10g-rx-extended-args";
+				fifo-size = <0x6000 0x0>;
+				buffer-layout = <96 64>;
+				vsp-window = <2 0>;
+			};
+			fman0_tx7-extended-args {
+				cell-index = <1>;
+				compatible = "fsl,fman-port-10g-tx-extended-args";
+				fifo-size = <0x4000 0x0>;
+				buffer-layout = <96 64>;
+			};
+
+		};
 	};
 
 	idle-states {
@@ -295,7 +427,7 @@ ifc: memory-controller@1530000 {
 		};
 
 		qspi: spi@1550000 {
-			compatible = "fsl,ls1021a-qspi";
+			compatible = "fsl,ls1021a-qspi","fsl,ls1-qspi";
 			#address-cells = <1>;
 			#size-cells = <0>;
 			reg = <0x0 0x1550000 0x0 0x10000>,
diff --git a/drivers/crypto/caam/pdb.h b/drivers/crypto/caam/pdb.h
index 4b1bcf53f7ac..1669e0d267e3 100644
--- a/drivers/crypto/caam/pdb.h
+++ b/drivers/crypto/caam/pdb.h
@@ -145,7 +145,7 @@ struct ipsec_encap_pdb {
 	u32 spi;
 	u32 ip_hdr_len;
 	u32 ip_hdr[];
-};
+}__attribute__((packed));
 
 /**
  * ipsec_decap_cbc - PDB part for IPsec CBC decapsulation
@@ -153,7 +153,7 @@ struct ipsec_encap_pdb {
  */
 struct ipsec_decap_cbc {
 	u32 rsvd[2];
-};
+}__attribute__((packed));
 
 /**
  * ipsec_decap_ctr - PDB part for IPsec CTR decapsulation
@@ -163,7 +163,7 @@ struct ipsec_decap_cbc {
 struct ipsec_decap_ctr {
 	u8 ctr_nonce[4];
 	u32 ctr_initial;
-};
+}__attribute__((packed));
 
 /**
  * ipsec_decap_ccm - PDB part for IPsec CCM decapsulation
@@ -177,7 +177,7 @@ struct ipsec_decap_ctr {
 struct ipsec_decap_ccm {
 	u8 salt[4];
 	u32 ccm_opt;
-};
+}__attribute__((packed));
 
 /**
  * ipsec_decap_gcm - PDB part for IPsec GCN decapsulation
@@ -187,7 +187,7 @@ struct ipsec_decap_ccm {
 struct ipsec_decap_gcm {
 	u8 salt[4];
 	u32 resvd;
-};
+}__attribute__((packed));
 
 /**
  * ipsec_decap_pdb - PDB for IPsec decapsulation
@@ -211,7 +211,7 @@ struct ipsec_decap_pdb {
 	u32 seq_num_ext_hi;
 	u32 seq_num;
 	__be32 anti_replay[4];
-};
+}__attribute__((packed));
 
 /*
  * IPSec ESP Datapath Protocol Override Register (DPOVRD)
diff --git a/drivers/net/ethernet/freescale/enetc/enetc.h b/drivers/net/ethernet/freescale/enetc/enetc.h
index 70f1c59434c3..c81d22a11df7 100644
--- a/drivers/net/ethernet/freescale/enetc/enetc.h
+++ b/drivers/net/ethernet/freescale/enetc/enetc.h
@@ -741,7 +741,7 @@ static inline void enetc4_clear_flower_list(struct enetc_si *si)
 }
 #endif
 
-#if IS_ENABLED(CONFIG_TSN)
+#if IS_ENABLED(CONFIG_TSN) && IS_ENABLED(CONFIG_FSL_ENETC_QOS)
 
 void enetc_tsn_pf_init(struct net_device *netdev, struct pci_dev *pdev);
 void enetc_tsn_pf_deinit(struct net_device *netdev);
diff --git a/drivers/net/ethernet/freescale/sdk_dpaa/Kconfig b/drivers/net/ethernet/freescale/sdk_dpaa/Kconfig
index bb6693e2d702..a14b325f2b4b 100644
--- a/drivers/net/ethernet/freescale/sdk_dpaa/Kconfig
+++ b/drivers/net/ethernet/freescale/sdk_dpaa/Kconfig
@@ -114,8 +114,10 @@ config FSL_DPAA_ETH_REFILL_THRESHOLD
 	default "80"
 	help
 	  The DPAA-Ethernet driver will start replenishing buffer pools whose count
-	  falls below this threshold per CPU. This must be related to DPAA_ETH_MAX_BUF_COUNT.
-	  One needn't normally modify this value unless one has very specific performance reasons.
+	  falls below (buffer pool config count - this threshold)(for ethernet buffer case
+	  config count is DPAA_ETH_MAX_BUF_COUNT). This parameter can also useful for other
+	  buffer pools(vsp is using it). One needn't normally modify this value unless one
+	  has very specific performance reasons.
 
 config FSL_DPAA_CS_THRESHOLD_1G
 	hex "Egress congestion threshold on 1G ports"
diff --git a/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_eth.c b/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_eth.c
index 010b47239ccc..69ce5b9fb6f9 100644
--- a/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_eth.c
+++ b/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_eth.c
@@ -300,7 +300,7 @@ static void _dpa_tx_error(struct net_device		*net_dev,
 	struct sk_buff *skb;
 
 	if (netif_msg_hw(priv) && net_ratelimit())
-		netdev_warn(net_dev, "FD status = 0x%08x\n",
+		netdev_warn(net_dev, "  _dpa_tx_error :FD status = 0x%08x\n",
 				fd->status & FM_FD_STAT_TX_ERRORS);
 #ifdef CONFIG_FSL_DPAA_HOOKS
 	if (dpaa_eth_hooks.tx_error &&
@@ -347,10 +347,16 @@ void __hot _dpa_process_parse_results(const fm_prs_result_t *parse_results,
 				      bool dcl4c_valid)
 {
 	if (dcl4c_valid && fd->status & FM_FD_STAT_L4CV) {
-		/* The parser has run and performed L4 checksum validation.
-		 * We know there were no parser errors (and implicitly no
-		 * L4 csum error), otherwise we wouldn't be here.
+		/* FM_FD_STAT_L4CV only indicates validation was ATTEMPTED.
+		 * We must also verify parse_results->cksum == 0xFFFF to
+		 * confirm the checksum actually PASSED.
 		 */
+		if (parse_results->cksum != DPA_CSUM_VALID) {
+			/* Checksum validation failed - use software checksum */
+			skb->ip_summed = CHECKSUM_NONE;
+			*use_gro = false;
+			return;
+		}
 		skb->ip_summed = CHECKSUM_UNNECESSARY;
 
 		/* Don't go through GRO for certain types of traffic that
@@ -446,11 +452,13 @@ priv_rx_error_dqrr(struct qman_portal		*portal,
 
 	percpu_priv = raw_cpu_ptr(priv->percpu_priv);
 	count_ptr = raw_cpu_ptr(priv->percpu_count);
-
+#ifndef CONFIG_FSL_ASK_QMAN_PORTAL_NAPI
 	if (dpaa_eth_napi_schedule(percpu_priv, portal))
 		return qman_cb_dqrr_stop;
+#endif
 
-	if (unlikely(dpaa_eth_refill_bpools(priv->dpa_bp, count_ptr)))
+	if (unlikely(dpaa_eth_refill_bpools(priv->dpa_bp, count_ptr,
+			CONFIG_FSL_DPAA_ETH_REFILL_THRESHOLD)))
 		/* Unable to refill the buffer pool due to insufficient
 		 * system memory. Just release the frame back into the pool,
 		 * otherwise we'll soon end up with an empty buffer pool.
@@ -483,13 +491,15 @@ priv_rx_default_dqrr(struct qman_portal		*portal,
 	/* IRQ handler, non-migratable; safe to use raw_cpu_ptr here */
 	percpu_priv = raw_cpu_ptr(priv->percpu_priv);
 	count_ptr = raw_cpu_ptr(priv->percpu_count);
-
+#ifndef CONFIG_FSL_ASK_QMAN_PORTAL_NAPI
 	if (unlikely(dpaa_eth_napi_schedule(percpu_priv, portal)))
 		return qman_cb_dqrr_stop;
+#endif
 
 	/* Vale of plenty: make sure we didn't run out of buffers */
 
-	if (unlikely(dpaa_eth_refill_bpools(dpa_bp, count_ptr)))
+	if (unlikely(dpaa_eth_refill_bpools(dpa_bp, count_ptr,
+			CONFIG_FSL_DPAA_ETH_REFILL_THRESHOLD)))
 		/* Unable to refill the buffer pool due to insufficient
 		 * system memory. Just release the frame back into the pool,
 		 * otherwise we'll soon end up with an empty buffer pool.
@@ -515,9 +525,10 @@ priv_tx_conf_error_dqrr(struct qman_portal		*portal,
 	priv = netdev_priv(net_dev);
 
 	percpu_priv = raw_cpu_ptr(priv->percpu_priv);
-
+#ifndef CONFIG_FSL_ASK_QMAN_PORTAL_NAPI
 	if (dpaa_eth_napi_schedule(percpu_priv, portal))
 		return qman_cb_dqrr_stop;
+#endif
 
 	_dpa_tx_error(net_dev, priv, percpu_priv, &dq->fd, fq->fqid);
 
@@ -541,10 +552,10 @@ priv_tx_conf_default_dqrr(struct qman_portal		*portal,
 
 	/* Non-migratable context, safe to use raw_cpu_ptr */
 	percpu_priv = raw_cpu_ptr(priv->percpu_priv);
-
+#ifndef CONFIG_FSL_ASK_QMAN_PORTAL_NAPI
 	if (dpaa_eth_napi_schedule(percpu_priv, portal))
 		return qman_cb_dqrr_stop;
-
+#endif
 	_dpa_tx_conf(net_dev, priv, percpu_priv, &dq->fd, fq->fqid);
 
 	return qman_cb_dqrr_consume;
@@ -691,6 +702,7 @@ static const struct net_device_ops dpa_private_ops = {
 	.ndo_poll_controller = dpaa_eth_poll_controller,
 #endif
 	.ndo_set_features = dpa_set_features,
+	.ndo_fix_features = dpa_fix_features,
 };
 
 static int dpa_private_napi_add(struct net_device *net_dev)
@@ -766,6 +778,11 @@ static int dpa_private_netdev_init(struct net_device *net_dev)
 	net_dev->hw_features |= NETIF_F_IP_CSUM | NETIF_F_IPV6_CSUM |
 				NETIF_F_RXCSUM;
 	net_dev->lltx               = true;
+#if 0 // commenting as of now , and skipping linearize in case of ipsec_offload
+	// to handle fraglist in case of ipsec instead of linearize at linux
+	// Issue is that data pointer is not getting freed after xmit/SEC engine processing if linux is linearizing
+	net_dev->features   |=  NETIF_F_FRAGLIST;
+#endif // 0
 
 	/* Advertise S/G and HIGHDMA support for private interfaces */
 	net_dev->hw_features |= NETIF_F_SG | NETIF_F_HIGHDMA;
@@ -892,7 +909,8 @@ static void dpa_priv_bp_seed(struct net_device *net_dev)
 		 */
 		int *count_ptr = per_cpu_ptr(priv->percpu_count, i);
 
-		dpaa_eth_refill_bpools(dpa_bp, count_ptr);
+		dpaa_eth_refill_bpools(dpa_bp, count_ptr,
+			CONFIG_FSL_DPAA_ETH_REFILL_THRESHOLD);
 	}
 }
 
@@ -1005,9 +1023,12 @@ dpaa_eth_priv_probe(struct platform_device *_of_dev)
 
 	if (err < 0)
 		goto fq_probe_failed;
-
 	/* bp init */
-
+#ifndef EXCLUDE_FMAN_IPR_OFFLOAD
+	printk("%s::bpid %d, count %d ", __FUNCTION__,
+			dpa_bp->bpid, dpa_bp->config_count);
+	printk("adj count %d\n", dpa_bp->config_count);
+#endif
 	err = dpa_priv_bp_create(net_dev, dpa_bp, count);
 
 	if (err < 0)
@@ -1111,6 +1132,8 @@ dpaa_eth_priv_probe(struct platform_device *_of_dev)
 	device_set_wakeup_capable(dev, true);
 #endif
 
+	priv->ifinfo = NULL;
+
 	pr_info("fsl_dpa: Probed interface %s\n", net_dev->name);
 
 	return 0;
diff --git a/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_eth.h b/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_eth.h
index 7109d33419bd..0685667b42b2 100644
--- a/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_eth.h
+++ b/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_eth.h
@@ -37,6 +37,7 @@
 #include <linux/fsl_qman.h>	/* struct qman_fq */
 
 #include "fm_ext.h"
+#include "fm_ehash.h"
 #include "dpaa_eth_trace.h"
 
 extern int dpa_rx_extra_headroom;
@@ -92,7 +93,10 @@ static inline void DPA_BUG_ON(bool cond)
 /* The raw buffer size must be cacheline aligned.
  * Normally we use 2K buffers.
  */
-#define DPA_BP_RAW_SIZE		2048
+/* As 1518 byte packets are received in scatter gather buffers from DPAA, 
+and these buffers are used by WIFI which requires contiguous buffers. So
+increased buffer size from 2048 to 2176, to accomodate them in contiguous fd */
+#define DPA_BP_RAW_SIZE		2176
 #else
 /* For jumbo frame optimizations, use buffers large enough to accommodate
  * 9.6K frames, FD maximum offset, skb sh_info overhead and some extra
@@ -198,6 +202,7 @@ static inline void DPA_BUG_ON(bool cond)
 #endif
 
 #define DPAA_ETH_RX_QUEUES	128
+#define DPAA_IP_VERSION_4  4
 
 /* Convenience macros for storing/retrieving the skb back-pointers. They must
  * accommodate both recycling and confirmation paths - i.e. cases when the buf
@@ -335,12 +340,16 @@ struct dpa_percpu_priv_s {
 	u64 tx_frag_skbuffs;
 	/* number of S/G frames received */
 	u64 rx_sg;
-
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) && defined(CONFIG_CPE_FAST_PATH)
+	u64 tx_caam_enc;
+	u64 tx_caam_dec;
+#endif
 	struct rtnl_link_stats64 stats;
 	struct dpa_rx_errors rx_errors;
 	struct dpa_ern_cnt ern_cnt;
 };
 
+
 struct dpa_priv_s {
 	struct dpa_percpu_priv_s	__percpu *percpu_priv;
 	struct dpa_bp *dpa_bp;
@@ -412,9 +421,13 @@ struct dpa_priv_s {
 	int loop_id;
 	int loop_to;
 #endif
-#ifdef CONFIG_FSL_DPAA_CEETM
+#if defined(CONFIG_FSL_DPAA_CEETM) || defined(CONFIG_CPE_FAST_PATH)
 	bool ceetm_en; /* CEETM QoS enabled */
+#ifdef CONFIG_CPE_FAST_PATH
+	void *qm_ctx;  /* CEETM context */
+#endif
 #endif
+	void *ifinfo;
 };
 
 struct fm_port_fqs {
@@ -429,7 +442,7 @@ struct fm_port_fqs {
 extern struct net_device *dpa_loop_netdevs[20];
 #endif
 
-int dpaa_eth_refill_bpools(struct dpa_bp *dpa_bp, int *count_ptr);
+int dpaa_eth_refill_bpools(struct dpa_bp *dpa_bp, int *count_ptr, int threshold);
 void __hot _dpa_rx(struct net_device *net_dev,
 		struct qman_portal *portal,
 		const struct dpa_priv_s *priv,
diff --git a/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_eth_ceetm.c b/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_eth_ceetm.c
index f947264bf54d..05cf73183818 100644
--- a/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_eth_ceetm.c
+++ b/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_eth_ceetm.c
@@ -148,6 +148,7 @@ static void ceetm_ern(struct qman_portal *portal, struct qman_fq *fq,
 	struct ceetm_class *cls;
 	struct sk_buff *skb;
 
+	printk("%s::\n", __FUNCTION__);
 	ceetm_fq = container_of(fq, struct ceetm_fq, fq);
 	net_dev = ceetm_fq->net_dev;
 	dpa_priv = netdev_priv(net_dev);
diff --git a/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_eth_common.c b/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_eth_common.c
index 515dfb68ed5f..610b84c8718d 100644
--- a/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_eth_common.c
+++ b/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_eth_common.c
@@ -166,6 +166,7 @@ int __cold dpa_start(struct net_device *net_dev)
 	}
 
 	netif_tx_start_all_queues(net_dev);
+	dpa_update_eth_if(priv);
 
 	return 0;
 
@@ -186,6 +187,8 @@ int __cold dpa_stop(struct net_device *net_dev)
 	priv = netdev_priv(net_dev);
 	mac_dev = priv->mac_dev;
 
+	dpa_update_eth_if(priv);
+
 	netif_tx_stop_all_queues(net_dev);
 	/* Allow the Fman (Tx) port to process in-flight frames before we
 	 * try switching it off.
@@ -297,6 +300,20 @@ int dpa_set_features(struct net_device *dev, netdev_features_t features)
 }
 EXPORT_SYMBOL(dpa_set_features);
 
+netdev_features_t dpa_fix_features(struct net_device *dev,
+				   netdev_features_t features)
+{
+	netdev_features_t unsupported_features = 0;
+
+	/* We don't support enabling Rx csum through ethtool yet */
+	unsupported_features |= NETIF_F_RXCSUM;
+
+	features &= ~unsupported_features;
+
+	return features;
+}
+EXPORT_SYMBOL(dpa_fix_features);
+
 #ifdef CONFIG_FSL_DPAA_TS
 u64 dpa_get_timestamp_ns(const struct dpa_priv_s *priv, enum port_type rx_tx,
 			const void *data)
@@ -588,6 +605,16 @@ void dpa_set_rx_mode(struct net_device *net_dev)
 					   "mac_dev->set_promisc() = %d\n",
 					   _errno);
 	}
+	if (!!(net_dev->flags & IFF_ALLMULTI) != priv->mac_dev->allmulti) {
+		priv->mac_dev->allmulti = !priv->mac_dev->allmulti;
+		_errno = priv->mac_dev->set_allmulti(
+				priv->mac_dev->get_mac_handle(priv->mac_dev),
+				priv->mac_dev->allmulti);
+		if (unlikely(_errno < 0) && netif_msg_drv(priv))
+			netdev_err(net_dev,
+					   "mac_dev->set_allmulti() = %d\n",
+					   _errno);
+	}
 
 	_errno = priv->mac_dev->set_multi(net_dev, priv->mac_dev);
 	if (unlikely(_errno < 0) && netif_msg_drv(priv))
@@ -608,6 +635,7 @@ void dpa_set_buffers_layout(struct mac_device *mac_dev,
 	layout[RX].time_stamp = true;
 #endif
 	fm_port_get_buff_layout_ext_params(mac_dev->port_dev[RX], &params);
+	printk("*********%s(%d) internal buffer offset %d\n",__FUNCTION__,__LINE__, params.manip_extra_space);
 	layout[RX].manip_extra_space = params.manip_extra_space;
 	/* a value of zero for data alignment means "don't care", so align to
 	 * a non-zero value to prevent FMD from using its own default
@@ -718,7 +746,7 @@ void dpa_bp_drain(struct dpa_bp *bp)
 }
 EXPORT_SYMBOL(dpa_bp_drain);
 
-static void __cold __attribute__((nonnull))
+void __cold __attribute__((nonnull))
 _dpa_bp_free(struct dpa_bp *dpa_bp)
 {
 	struct dpa_bp *bp = dpa_bpid2pool(dpa_bp->bpid);
@@ -739,6 +767,7 @@ _dpa_bp_free(struct dpa_bp *dpa_bp)
 	dpa_bp_array[bp->bpid] = NULL;
 	bman_free_pool(bp->pool);
 }
+EXPORT_SYMBOL(_dpa_bp_free);
 
 void __cold __attribute__((nonnull))
 dpa_bp_free(struct dpa_priv_s *priv)
@@ -1543,8 +1572,9 @@ void dpa_release_sgt(struct qm_sg_entry *sgt)
 }
 EXPORT_SYMBOL(dpa_release_sgt);
 
-void __attribute__((nonnull))
-dpa_fd_release(const struct net_device *net_dev, const struct qm_fd *fd)
+// net_dev is not used internally, so commenting non null check
+//void __attribute__((nonnull))
+void dpa_fd_release(const struct net_device *net_dev, const struct qm_fd *fd)
 {
 	struct qm_sg_entry	*sgt;
 	struct dpa_bp		*dpa_bp;
@@ -1600,6 +1630,66 @@ dpa_fd_release(const struct net_device *net_dev, const struct qm_fd *fd)
 }
 EXPORT_SYMBOL(dpa_fd_release);
 
+// SGT fraglist to be freed
+//void __attribute__((nonnull))
+void sgt_fraglist_fd_release(const struct net_device *net_dev, const struct qm_fd *fd)
+{
+   struct qm_sg_entry  *sgt;
+   struct dpa_bp       *dpa_bp;
+   struct bm_buffer    bmb;
+   struct sk_buff *skb;
+   dma_addr_t      addr;
+   void            *vaddr;
+   int ii = 0;
+
+   bmb.opaque = 0;
+
+   if (!qm_fd_addr(fd))
+   {
+       printk("%s(%d) NULL addr in fd\n",__FUNCTION__,__LINE__);
+       return;
+   }
+
+
+   char *tmp = (char *) fd;
+   printk("%s(%d) FD info : \t",__FUNCTION__,__LINE__);
+   printk("%0x %0x %0x %0x %0x %0x %0x %0x %0x %0x %0x %0x %0x %0x %0x %0x\n",
+   tmp[0],tmp[1],tmp[2],tmp[3],tmp[4],tmp[5],tmp[6],tmp[7],tmp[8],tmp[9],tmp[10],tmp[11],tmp[12],tmp[13],tmp[14],tmp[15]);
+   bm_buffer_set64(&bmb, qm_fd_addr(fd));
+   dpa_bp = dpa_bpid2pool(fd->bpid);
+   DPA_BUG_ON(!dpa_bp);
+
+   if (fd->format == qm_fd_sg) {
+       vaddr = phys_to_virt(qm_fd_addr(fd));
+       sgt = vaddr;
+
+       printk("%s(%d) addr %lx , size %d, buff pool id %x, fd %p\t",
+           __FUNCTION__,__LINE__,qm_fd_addr(fd), dpa_bp->size, bmb.bpid, fd);
+       printk("bpid: %d, netdev name %s, vaddr %lx, fd offset %d\n",
+           fd->bpid,net_dev->name, vaddr, dpa_fd_offset(fd));
+
+       while (!qm_sg_entry_get_final(&sgt[ii]))
+           ii++;
+       addr = qm_sg_addr(&sgt[ii+1]);
+       printk("%s(%d) ii %d, old-skb %p \n",__FUNCTION__, __LINE__,ii,(void *)addr);
+       if (addr) // free the old skb
+       {
+           skb =  (struct sk_buff *)(addr);
+           kfree_skb(skb);
+       }
+       addr = 0;
+       qm_sg_entry_set64(&sgt[ii+1], addr);
+
+       dma_unmap_single(dpa_bp->dev, qm_fd_addr(fd), (ii+1)*sizeof(struct qm_sg_entry),
+                DMA_BIDIRECTIONAL);
+
+   }
+
+   while (bman_release(dpa_bp->pool, &bmb, 1, 0))
+       cpu_relax();
+}
+EXPORT_SYMBOL(sgt_fraglist_fd_release);
+
 void count_ern(struct dpa_percpu_priv_s *percpu_priv,
 		      const struct qm_mr_entry *msg)
 {
@@ -1735,7 +1825,7 @@ int dpa_enable_tx_csum(struct dpa_priv_s *priv,
 }
 EXPORT_SYMBOL(dpa_enable_tx_csum);
 
-#ifdef CONFIG_FSL_DPAA_CEETM
+#if defined(CONFIG_FSL_DPAA_CEETM) || defined(CONFIG_CPE_FAST_PATH)
 void dpa_enable_ceetm(struct net_device *dev)
 {
 	struct dpa_priv_s *priv = netdev_priv(dev);
@@ -1750,3 +1840,36 @@ void dpa_disable_ceetm(struct net_device *dev)
 }
 EXPORT_SYMBOL(dpa_disable_ceetm);
 #endif
+
+void dpa_set_eth_ifinfo(struct dpa_priv_s *priv, void* ifinfo)
+{
+	if(!priv)
+		return;
+	priv->ifinfo = ifinfo;
+	return;
+}
+EXPORT_SYMBOL(dpa_set_eth_ifinfo);
+
+
+void dpa_reset_eth_ifinfo(struct dpa_priv_s *priv)
+{
+	if(!priv)
+		return;
+	priv->ifinfo = NULL;
+	return;
+}
+EXPORT_SYMBOL(dpa_reset_eth_ifinfo);
+
+int dpa_update_eth_if(struct dpa_priv_s *priv)
+{
+	unsigned int port_status;
+	if(!priv->ifinfo || !priv->net_dev)
+		return 1;
+	port_status = test_bit(__LINK_STATE_START,
+							&priv->net_dev->state);
+		/* Synch tx port here */
+		((struct en_ehash_ifportinfo*)(priv->ifinfo))->txpinfo.port_info = ntohl(port_status);
+
+		return 0;
+}
+EXPORT_SYMBOL(dpa_update_eth_if);
diff --git a/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_eth_common.h b/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_eth_common.h
index f46c243ff1b8..9bd7f1e2a43c 100644
--- a/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_eth_common.h
+++ b/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_eth_common.h
@@ -97,6 +97,21 @@ typedef enum dpaa_eth_hook_result (*dpaa_eth_egress_hook_t)(
 typedef enum dpaa_eth_hook_result (*dpaa_eth_confirm_hook_t)(
 		struct net_device *net_dev, const struct qm_fd *fd, u32 fqid);
 
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+typedef struct qman_fq *(*cdx_get_ipsec_fq_hook_t)(u32 handle);
+int dpa_register_ipsec_fq_handler(cdx_get_ipsec_fq_hook_t hookfn);
+int dpaa_submit_inb_pkt_to_SEC(struct sk_buff *skb, uint16_t sagd);
+ __hot void dpaa_submit_outb_pkt_to_SEC(struct sk_buff *skb, struct net_device *net_dev, struct dpa_bp *dpa_bp);
+
+#endif
+
+#ifdef CONFIG_CPE_FAST_PATH
+typedef struct qman_fq *(*cdx_get_ceetm_egressfq)(void *, uint32_t chnl_id, uint32_t queue, uint32_t ff);
+typedef struct qman_fq *(*cdx_get_ceetm_dscp_fq)(void *, uint8_t dscp);
+int dpa_register_ceetm_get_egress_fq(cdx_get_ceetm_egressfq egress_fq_func, cdx_get_ceetm_dscp_fq dscp_fq_func);
+#endif
+
+
 /* used in napi related functions */
 extern u16 qman_portal_max;
 
@@ -136,6 +151,12 @@ void fsl_dpaa_eth_set_hooks(struct dpaa_eth_hooks_s *hooks);
 extern struct dpaa_eth_hooks_s dpaa_eth_hooks;
 #endif
 
+#ifndef EXCLUDE_FMAN_IPR_OFFLOAD
+typedef int (*dpaa_eth_bpool_replenish_hook_t)(
+				struct net_device *net_dev, u32 bpid);
+void register_dpaa_eth_bpool_replenish_hook(dpaa_eth_bpool_replenish_hook_t func);
+#endif
+
 int dpa_netdev_init(struct net_device *net_dev,
 		    const uint8_t *mac_addr,
 		    uint16_t tx_timeout);
@@ -147,6 +168,8 @@ dpa_get_stats64(struct net_device *net_dev,
 		struct rtnl_link_stats64 *stats);
 int dpa_ndo_init(struct net_device *net_dev);
 int dpa_set_features(struct net_device *dev, netdev_features_t features);
+netdev_features_t dpa_fix_features(struct net_device *dev,
+				   netdev_features_t features);
 #ifdef CONFIG_FSL_DPAA_TS
 u64 dpa_get_timestamp_ns(const struct dpa_priv_s *priv,
 			enum port_type rx_tx, const void *data);
@@ -170,6 +193,8 @@ struct dpa_bp *dpa_bpid2pool(int bpid);
 void dpa_bpid2pool_map(int bpid, struct dpa_bp *dpa_bp);
 bool dpa_bpid2pool_use(int bpid);
 void dpa_bp_drain(struct dpa_bp *bp);
+void __cold __attribute__((nonnull))
+_dpa_bp_free(struct dpa_bp *dpa_bp);
 #ifdef CONFIG_FMAN_PFC
 u16 dpa_select_queue(struct net_device *net_dev, struct sk_buff *skb,
 		     struct net_device *sb_dev,
@@ -201,13 +226,14 @@ void dpaa_eth_init_ports(struct mac_device *mac_dev,
 		struct device *dev);
 void dpa_release_sgt(struct qm_sg_entry *sgt);
 void dpa_release_sgt_by_bpid(struct qm_sg_entry *sgt);
-void __attribute__((nonnull))
+//void __attribute__((nonnull))
+void
 dpa_fd_release(const struct net_device *net_dev, const struct qm_fd *fd);
 void count_ern(struct dpa_percpu_priv_s *percpu_priv,
 		      const struct qm_mr_entry *msg);
 int dpa_enable_tx_csum(struct dpa_priv_s *priv,
 	struct sk_buff *skb, struct qm_fd *fd, char *parse_results);
-#ifdef CONFIG_FSL_DPAA_CEETM
+#if defined(CONFIG_FSL_DPAA_CEETM) || defined(CONFIG_CPE_FAST_PATH)
 void dpa_enable_ceetm(struct net_device *dev);
 void dpa_disable_ceetm(struct net_device *dev);
 #endif
@@ -222,5 +248,15 @@ int dpa_proxy_set_mac_address(struct proxy_device *proxy_dev,
 			  struct net_device *net_dev);
 int dpa_proxy_set_rx_mode(struct proxy_device *proxy_dev,
 		      struct net_device *net_dev);
+void dpa_set_eth_ifinfo(struct dpa_priv_s *priv, void* ifinfo);
+void dpa_reset_eth_ifinfo(struct dpa_priv_s *priv);
+int dpa_update_eth_if(struct dpa_priv_s *priv);
+struct sk_buff *__hot contig_fd_to_skb(const struct dpa_priv_s *priv,
+				       const struct qm_fd *fd,
+				       bool *use_gro, bool dcl4c_valid);
+struct sk_buff *__hot sg_fd_to_skb(const struct dpa_priv_s *priv,
+				   const struct qm_fd *fd, bool *use_gro,
+				   int *count_ptr, bool dcl4c_valid);
+
 
 #endif /* __DPAA_ETH_COMMON_H */
diff --git a/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_eth_sg.c b/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_eth_sg.c
index 4164644d3268..8a139b2666e5 100644
--- a/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_eth_sg.c
+++ b/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_eth_sg.c
@@ -52,6 +52,55 @@
 #endif
 #ifdef CONFIG_FSL_DPAA_CEETM
 #include "dpaa_eth_ceetm.h"
+#endif
+#if defined(CONFIG_IP_NF_CONNTRACK_MARK) || defined(CONFIG_NF_CONNTRACK_MARK)
+#include "net/netfilter/nf_conntrack.h"
+#endif // CONFIG_IP_NF_CONNTRACK_MARK ||  CONFIG_NF_CONNTRACK_MARK
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+#include <uapi/linux/if_ether.h>
+#include <uapi/linux/ppp_defs.h>
+#include <uapi/linux/if_pppox.h>
+#include <net/xfrm.h>
+#endif
+
+#define DPAA_EXTRA_BUF_SIZE_4_SKB SMP_CACHE_BYTES + DPA_MAX_FD_OFFSET + \
+		sizeof(struct skb_shared_info) +  128 
+
+#ifndef EXCLUDE_FMAN_IPR_OFFLOAD
+//added for IPR offload to FMAN
+static dpaa_eth_bpool_replenish_hook_t dpaa_eth_bpool_replenish_hook;
+#endif
+
+/* registered function to get ceetm Fqs */
+#ifdef CONFIG_CPE_FAST_PATH
+static cdx_get_ceetm_egressfq ceetm_fqget_func;
+static cdx_get_ceetm_dscp_fq ceetm_dscp_fqget_func;
+/* This function registers two cdx functions, which are to get the egress fq. 
+   One is based on channel and classqueue and another one is based on dscp. */
+int dpa_register_ceetm_get_egress_fq(cdx_get_ceetm_egressfq egress_fq_func, cdx_get_ceetm_dscp_fq dscp_fq_func)
+{
+	ceetm_fqget_func = egress_fq_func;
+	ceetm_dscp_fqget_func = dscp_fq_func;
+	return 0;
+}
+EXPORT_SYMBOL(dpa_register_ceetm_get_egress_fq);
+#endif
+
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+cdx_get_ipsec_fq_hook_t cdx_get_ipsec_fq_hookfn;
+
+int dpa_register_ipsec_fq_handler(cdx_get_ipsec_fq_hook_t hookfn)
+{
+       if (cdx_get_ipsec_fq_hookfn) {
+               printk("%s::hook already registered\n", __FUNCTION__);
+               return -1;
+       }
+       cdx_get_ipsec_fq_hookfn = hookfn;
+       return 0;
+}
+
+EXPORT_SYMBOL(dpa_register_ipsec_fq_handler);
+
 #endif
 
 /* DMA map and add a page frag back into the bpool.
@@ -81,6 +130,109 @@ static void dpa_bp_recycle_frag(struct dpa_bp *dpa_bp, unsigned long vaddr,
 	(*count_ptr)++;
 }
 
+// adding a new function which allocates memory for buffers and adds bman pool
+int dpaa_bp_alloc_n_add_buffs(const struct dpa_bp *dpa_bp, uint32_t nbuffs, bool act_skb)
+{
+	struct bm_buffer bmb[8];
+	char *new_buf, *ptr_buf;
+	dma_addr_t addr;
+	int ii,entries_in_bmb,buffs2fill;
+	struct device *dev = dpa_bp->dev;
+	struct sk_buff *skb = NULL, **skbh;
+	uint32_t bufsize;
+
+	if (act_skb)
+		bufsize =  DPAA_EXTRA_BUF_SIZE_4_SKB + dpa_bp->size;
+	else
+		bufsize =  SMP_CACHE_BYTES + dpa_bp->size + DPA_MAX_FD_OFFSET + 128;
+
+	/* aligning to SMP_CACHE_BYTES */
+	bufsize = DPA_SKB_SIZE(bufsize);
+
+	buffs2fill= 0;
+	while (buffs2fill < nbuffs)
+	{
+		memset(bmb, 0, sizeof(struct bm_buffer) * 8);
+
+		if ((nbuffs -   buffs2fill) < 8)
+			entries_in_bmb = (nbuffs - buffs2fill);
+		else
+			entries_in_bmb = 8;
+		for (ii= 0; ii<entries_in_bmb; ii++) {
+			ptr_buf = (char *)kmalloc(bufsize, GFP_DMA | GFP_ATOMIC);
+
+			if (unlikely(!ptr_buf))
+			{
+				pr_err("%s(%d) ii %d,  buffs2fill %d kmalloc failed \n",
+						__FUNCTION__,__LINE__,ii, buffs2fill);
+				goto handle_fail;
+			}
+
+			new_buf = ptr_buf;
+			if (act_skb)
+			{
+				/* We'll prepend the skb back-pointer; can't use the DPA
+				 * priv space, because FMan will overwrite it (from offset 0)
+				 * if it ends up being the second, third, etc. fragment
+				 * in a S/G frame.
+				 *
+				 * We only need enough space to store a pointer, but allocate
+				 * an entire cacheline for performance reasons.
+				 */
+				skb = build_skb(ptr_buf, 0);
+				if (unlikely(!skb)) {
+					pr_err("%s(%d) ii %d , buffs2fill %d build_skb failed \n",
+							__FUNCTION__,__LINE__, ii, buffs2fill);
+					kfree(new_buf);
+					goto handle_fail;
+				}
+				ptr_buf = PTR_ALIGN(ptr_buf, SMP_CACHE_BYTES) + SMP_CACHE_BYTES;
+				skb_reserve(skb, (ptr_buf-new_buf));
+				DPA_WRITE_SKB_PTR(skb, skbh, ptr_buf, -1);
+			}
+			else
+				ptr_buf = PTR_ALIGN(ptr_buf /*+ SMP_CACHE_BYTES */, SMP_CACHE_BYTES);
+
+			addr = dma_map_single(dev, ptr_buf, dpa_bp->size, DMA_BIDIRECTIONAL);
+			if (unlikely(dma_mapping_error(dev, addr)))
+			{
+				pr_err("%s(%d) ii %d buffs2fill %d dma_mapping_error failed \n",
+						__FUNCTION__,__LINE__,ii,buffs2fill);
+				if (act_skb)
+				{
+					kfree_skb(skb);
+				}
+				kfree(new_buf);
+				goto handle_fail;
+			}
+			bm_buffer_set64(&bmb[ii], addr);
+
+			bmb[ii].bpid = cpu_to_be16(dpa_bp->bpid & 0xff);
+		}
+		while (unlikely(bman_release(dpa_bp->pool, bmb, entries_in_bmb, 0)))
+			cpu_relax();
+		buffs2fill+= entries_in_bmb;
+		/*     printk("%s(%d) adrsses %lx %lx %lx %lx %lx %lx %lx %lx\n",
+			   __FUNCTION__,__LINE__,bm_buffer_get64(&bmb[0]),bm_buffer_get64(&bmb[1]),
+			   bm_buffer_get64(&bmb[2]),bm_buffer_get64(&bmb[3]),bm_buffer_get64(&bmb[4]),
+			   bm_buffer_get64(&bmb[5]),bm_buffer_get64(&bmb[6]),bm_buffer_get64(&bmb[7])); */
+	}
+	/* printk("%s(%d) buff allocation and bman release success buffs2fill %d\n",
+	   __FUNCTION__,__LINE__,buffs2fill); */
+	return 0;
+
+handle_fail:
+	if (ii)
+	{
+		while (unlikely(bman_release(dpa_bp->pool, bmb, ii, 0)))
+			cpu_relax();
+	}
+	return ii+buffs2fill;
+
+}
+EXPORT_SYMBOL(dpaa_bp_alloc_n_add_buffs);
+
+
 static int _dpa_bp_add_8_bufs(const struct dpa_bp *dpa_bp)
 {
 	void *new_buf, *fman_buf;
@@ -182,12 +334,13 @@ static int _dpa_bp_add_8_bufs(const struct dpa_bp *dpa_bp)
 /* Add buffers/(pages) for Rx processing whenever bpool count falls below
  * REFILL_THRESHOLD.
  */
-int dpaa_eth_refill_bpools(struct dpa_bp *dpa_bp, int *countptr)
+int dpaa_eth_refill_bpools(struct dpa_bp *dpa_bp, int *countptr, int threshold)
 {
 	int count = *countptr;
 	int new_bufs;
+	int percpu_buf_cfg_count = dpa_bp->config_count;
 
-	if (unlikely(count < CONFIG_FSL_DPAA_ETH_REFILL_THRESHOLD)) {
+	if (unlikely(count <= (percpu_buf_cfg_count - threshold))) {
 		do {
 			new_bufs = _dpa_bp_add_8_bufs(dpa_bp);
 			if (unlikely(!new_bufs)) {
@@ -198,10 +351,10 @@ int dpaa_eth_refill_bpools(struct dpa_bp *dpa_bp, int *countptr)
 				break;
 			}
 			count += new_bufs;
-		} while (count < CONFIG_FSL_DPAA_ETH_MAX_BUF_COUNT);
+		} while (count < percpu_buf_cfg_count);
 
 		*countptr = count;
-		if (unlikely(count < CONFIG_FSL_DPAA_ETH_MAX_BUF_COUNT))
+		if (unlikely(count < percpu_buf_cfg_count))
 			return -ENOMEM;
 	}
 
@@ -365,7 +518,7 @@ EXPORT_SYMBOL(dpa_buf_is_recyclable);
  * We are guaranteed there is enough room at the end of the data buffer to
  * accommodate the shared info area of the skb.
  */
-static struct sk_buff *__hot contig_fd_to_skb(const struct dpa_priv_s *priv,
+struct sk_buff *__hot contig_fd_to_skb(const struct dpa_priv_s *priv,
 					      const struct qm_fd *fd,
 					      bool *use_gro, bool dcl4c_valid)
 {
@@ -417,14 +570,14 @@ static struct sk_buff *__hot contig_fd_to_skb(const struct dpa_priv_s *priv,
 
 	return skb;
 }
-
+EXPORT_SYMBOL(contig_fd_to_skb);
 
 /* Build an skb with the data of the first S/G entry in the linear portion and
  * the rest of the frame as skb fragments.
  *
  * The page fragment holding the S/G Table is recycled here.
  */
-static struct sk_buff *__hot sg_fd_to_skb(const struct dpa_priv_s *priv,
+struct sk_buff *__hot sg_fd_to_skb(const struct dpa_priv_s *priv,
 					  const struct qm_fd *fd, bool *use_gro,
 					  int *count_ptr, bool dcl4c_valid)
 {
@@ -444,7 +597,8 @@ static struct sk_buff *__hot sg_fd_to_skb(const struct dpa_priv_s *priv,
 	vaddr = phys_to_virt(addr);
 	DPA_BUG_ON(!IS_ALIGNED((unsigned long)vaddr, SMP_CACHE_BYTES));
 
-	dpa_bp = priv->dpa_bp;
+/*	dpa_bp = priv->dpa_bp; */
+	dpa_bp =  dpa_bpid2pool(fd->bpid);
 	/* Iterate through the SGT entries and add data buffers to the skb */
 	sgt = vaddr + fd_off;
 	for (i = 0; i < DPA_SGT_MAX_ENTRIES; i++) {
@@ -452,9 +606,9 @@ static struct sk_buff *__hot sg_fd_to_skb(const struct dpa_priv_s *priv,
 		DPA_BUG_ON(qm_sg_entry_get_ext(&sgt[i]));
 
 		/* We use a single global Rx pool */
-		DPA_BUG_ON(dpa_bp !=
+/*		DPA_BUG_ON(dpa_bp !=
 			   dpa_bpid2pool(qm_sg_entry_get_bpid(&sgt[i])));
-
+*/
 		sg_addr = qm_sg_addr(&sgt[i]);
 		sg_vaddr = phys_to_virt(sg_addr);
 		DPA_BUG_ON(!IS_ALIGNED((unsigned long)sg_vaddr,
@@ -537,6 +691,7 @@ static struct sk_buff *__hot sg_fd_to_skb(const struct dpa_priv_s *priv,
 	dpa_bp_recycle_frag(dpa_bp, (unsigned long)vaddr, count_ptr);
 	return skb;
 }
+EXPORT_SYMBOL(sg_fd_to_skb);
 
 #ifdef CONFIG_FSL_DPAA_DBG_LOOP
 static inline int dpa_skb_loop(const struct dpa_priv_s *priv,
@@ -554,6 +709,14 @@ static inline int dpa_skb_loop(const struct dpa_priv_s *priv,
 }
 #endif
 
+#ifndef EXCLUDE_FMAN_IPR_OFFLOAD
+void register_dpaa_eth_bpool_replenish_hook(dpaa_eth_bpool_replenish_hook_t func)
+{
+	dpaa_eth_bpool_replenish_hook = func;
+}
+EXPORT_SYMBOL(register_dpaa_eth_bpool_replenish_hook);
+#endif
+
 void __hot _dpa_rx(struct net_device *net_dev,
 		struct qman_portal *portal,
 		const struct dpa_priv_s *priv,
@@ -573,7 +736,7 @@ void __hot _dpa_rx(struct net_device *net_dev,
 
 	if (unlikely(fd_status & FM_FD_STAT_RX_ERRORS) != 0) {
 		if (netif_msg_hw(priv) && net_ratelimit())
-			netdev_warn(net_dev, "FD status = 0x%08x\n",
+			netdev_warn(net_dev, "_dpa_rx FD status = 0x%08x\n",
 					fd_status & FM_FD_STAT_RX_ERRORS);
 
 		percpu_stats->rx_errors++;
@@ -589,6 +752,31 @@ void __hot _dpa_rx(struct net_device *net_dev,
 
 	/* The only FD types that we may receive are contig and S/G */
 	DPA_BUG_ON((fd->format != qm_fd_contig) && (fd->format != qm_fd_sg));
+#if 0
+        {
+                char *ptr;
+                uint32_t ii;
+
+                ptr = ((char *)phys_to_virt(addr) + 0x0);
+                for (ii  = 0; ii < 0x70; ii++) {
+                        if ((ii % 16) == 0)
+                                printk("\n%02x ", *(ptr + ii));
+                        else
+                                printk("%02x ", *(ptr + ii));
+                }
+                printk("\n");
+        }
+	{
+		uint32_t ccbase;
+		uint64_t hashval;
+		//get ccbase 
+		ccbase  = *((uint32_t *)((char *)phys_to_virt(addr) + 0x18));
+                printk("%s::ccbase %08x, fqid 0x%x\n", __FUNCTION__, cpu_to_be32(ccbase), fqid);
+		hashval  = *((uint64_t *)((char *)phys_to_virt(addr) + 0x48));
+                printk("%s::hashval %lx\n", __FUNCTION__, cpu_to_be64(hashval));
+	 		
+	}
+#endif
 
 	if (likely(fd->format == qm_fd_contig)) {
 #ifdef CONFIG_FSL_DPAA_HOOKS
@@ -599,6 +787,15 @@ void __hot _dpa_rx(struct net_device *net_dev,
 			/* won't count the rx bytes in */
 			return;
 		}
+#endif
+#ifndef EXCLUDE_FMAN_IPR_OFFLOAD
+		if (dpaa_eth_bpool_replenish_hook) {
+			if (dpaa_eth_bpool_replenish_hook(net_dev, fd->bpid)) {
+				//could not replenish buffer, drop packet ??
+				printk("%s::could not replenish buffer to pool\n",
+						__FUNCTION__);
+			}
+		}
 #endif
 		skb = contig_fd_to_skb(priv, fd, &use_gro, dcl4c_valid);
 	} else {
@@ -645,6 +842,7 @@ void __hot _dpa_rx(struct net_device *net_dev,
 _release_frame:
 	dpa_fd_release(net_dev, fd);
 }
+EXPORT_SYMBOL(_dpa_rx);
 
 int __hot skb_to_contig_fd(struct dpa_priv_s *priv,
 			   struct sk_buff *skb, struct qm_fd *fd,
@@ -746,7 +944,7 @@ EXPORT_SYMBOL(skb_to_contig_fd);
  * - SG fragments that aren't mod 16 bytes in size (except for the last
  *   fragment)
  */
-static bool a050385_check_skb(struct sk_buff *skb, struct dpa_priv_s *priv)
+bool a050385_check_skb(struct sk_buff *skb, struct dpa_priv_s *priv)
 {
 	skb_frag_t *frag;
 	int i, nr_frags;
@@ -808,12 +1006,13 @@ static bool a050385_check_skb(struct sk_buff *skb, struct dpa_priv_s *priv)
 
 	return false;
 }
+EXPORT_SYMBOL(a050385_check_skb);
 
 /* Realign the skb by copying its contents at the start of a newly allocated
  * page. Build a new skb around the new buffer and release the old one.
  * A performance drop should be expected.
  */
-static struct sk_buff *a050385_realign_skb(struct sk_buff *skb,
+struct sk_buff *a050385_realign_skb(struct sk_buff *skb,
 					   struct dpa_priv_s *priv)
 {
 	int trans_offset = skb_transport_offset(skb);
@@ -882,8 +1081,213 @@ static struct sk_buff *a050385_realign_skb(struct sk_buff *skb,
 	put_page(npage);
 	return NULL;
 }
+EXPORT_SYMBOL(a050385_realign_skb);
 #endif
 
+struct dpa_bp *sg_bpool_g;
+EXPORT_SYMBOL(sg_bpool_g);
+
+struct dpa_bp *skb_2bfreed_bpool_g; //if no recyclable skbs exist in skb fraglist, those should be freed back, SEC engine will add to this bman pool
+EXPORT_SYMBOL(skb_2bfreed_bpool_g);
+
+struct device* dpa_get_bp_device(void)
+{
+	if (skb_2bfreed_bpool_g)
+		return skb_2bfreed_bpool_g->dev;
+	else
+		return NULL;
+}
+
+/* 
+ *This functions unmaps all the mapped skb sg so far and stored in sgt.  
+*/
+static void dma_unmap_skb_sg_addrs(struct device *dev, struct sk_buff *skb,
+			struct qm_sg_entry *sgt, int skb_list_frags)
+{
+	dma_addr_t addr;
+	struct sk_buff *list_skb;
+	struct sk_buff *cur_skb;
+	const enum dma_data_direction dma_dir = DMA_TO_DEVICE;
+	int sgt_idx = 0;
+	int nr_frags = 0;
+
+
+	for (cur_skb = skb, list_skb = skb_shinfo(skb)->frag_list; 
+		(sgt_idx < skb_list_frags) && (cur_skb); )
+	{
+		addr = qm_sg_addr(&sgt[sgt_idx]);
+		dma_unmap_single(dev, addr, qm_sg_entry_get_len(&sgt[sgt_idx]), dma_dir);
+		sgt_idx++;
+
+		nr_frags = skb_shinfo(cur_skb)->nr_frags;
+		while(nr_frags)
+		{
+			addr = qm_sg_addr(&sgt[sgt_idx]);
+			dma_unmap_page(dev, addr, qm_sg_entry_get_len(&sgt[sgt_idx]), dma_dir);
+			nr_frags--;
+			sgt_idx++;
+		}
+		cur_skb = list_skb;
+		if (list_skb)
+			list_skb = list_skb->next;
+	}
+
+	return;
+}
+
+/*
+ * This inline function updates the sgt entry parameters.
+ */
+static inline void prepare_qm_sg_entry(struct qm_sg_entry *sgt, int sgt_idx, 
+					unsigned int len, dma_addr_t addr)
+{
+	qm_sg_entry_set_ext(&sgt[sgt_idx], 0);
+	qm_sg_entry_set_final(&sgt[sgt_idx], 0);
+	/* fill the first entry with skb details */
+	qm_sg_entry_set_bpid(&sgt[sgt_idx], 0xff);
+	/* set the offset and addr pointers such that
+	   in next alloc, that addr should point to skb*/
+	qm_sg_entry_set_offset(&sgt[sgt_idx],0);
+	qm_sg_entry_set_len(&sgt[sgt_idx], len);
+	qm_sg_entry_set64(&sgt[sgt_idx], addr);
+
+	return;
+}
+
+int __hot skb_fraglist_to_sg_fd(struct device *dev, struct net_device *net_dev , struct sk_buff *skb, struct qm_fd *fd, u32 fd_cmd)
+{
+	dma_addr_t addr, sg_addr;
+	struct sk_buff *list_skb;
+	struct sk_buff *cur_skb;
+	int  sgt_size;
+	int err;
+	struct qm_sg_entry *sgt;
+	struct bm_buffer bmb;
+	int sgt_index = 0, nr_frags = 0;
+	const enum dma_data_direction dma_dir = DMA_TO_DEVICE;
+	int dma_map_size;
+	skb_frag_t *frag;
+
+	// calculate the number of fragments
+	// check if any of skb is not recyclable
+	nr_frags = 1 + skb_shinfo(skb)->nr_frags;
+	skb_walk_frags(skb, list_skb)
+	{
+		nr_frags += 1 + skb_shinfo(list_skb)->nr_frags;
+	}
+
+	/* The below condition covers nr_frags + 1(This is to store skb address in opaque variable at the end.)*/
+	if (nr_frags > (DPA_SGT_MAX_ENTRIES))
+	{
+		/* TODO linearize */
+		pr_err("%s()::%d number of skb frags %d crossed the MAX SGT entries%d", __func__, __LINE__, nr_frags, DPA_SGT_MAX_ENTRIES);
+		return -1;
+	}
+
+	fd->format = qm_fd_sg;
+	/* allocate an SG buffer from SG BMAN POOL
+	   if any entries in skb_2bfreed_bpool_g, acquire and free skb and use the SG buffer */
+	if (bman_acquire(skb_2bfreed_bpool_g->pool, &bmb, 1, 0) == 1)
+	{
+		sgt =  (struct qm_sg_entry *)phys_to_virt(bmb.addr);
+		while (!qm_sg_entry_get_final(&sgt[sgt_index]))
+			sgt_index++;
+		addr = sgt[sgt_index+1].opaque;
+		if (addr) /* free the old skb */
+		{
+			list_skb =  (struct sk_buff *)(addr);
+			kfree_skb(list_skb);
+		}
+		sgt[sgt_index+1].opaque = 0; /* set to 0*/
+	}
+	else if (bman_acquire(sg_bpool_g->pool, &bmb, 1, 0) == 1)
+	{
+		sgt =  (struct qm_sg_entry *)phys_to_virt(bmb.addr);
+	} 
+	else
+	{
+		printk("%s(%d) bman_acquire of SG bman buffer failed\n",
+				__FUNCTION__,__LINE__);
+		return -1;
+	}
+
+
+	/* net_crit_ratelimited("%s(%d) nr_frags %d, MAX frags %d \n", __FUNCTION__,__LINE__,nr_frags,DPA_SGT_MAX_ENTRIES);*/
+	/* After nr_frags, in next index of sgt array storing skb address in opaque. So doing memset for (nr_frags+1).*/
+	sgt_size = sizeof(struct qm_sg_entry) * (nr_frags + 1);
+
+
+	/* memset to 0s of size sgt_size*/
+	memset(sgt, 0, sgt_size);
+
+	
+
+	sgt_index = 0;
+	for (cur_skb = skb, list_skb = skb_shinfo(skb)->frag_list; cur_skb;)
+	{
+		dma_map_size = skb_headlen(cur_skb);
+		addr = dma_map_single(dev, cur_skb->data, dma_map_size, dma_dir);
+		if (unlikely(dma_mapping_error(dev, addr))) {
+			if (net_ratelimit())
+				netdev_err(net_dev, "skb_fraglist_to_sg_fd : 2.DMA mappping error");
+			err = -EINVAL;
+			dma_unmap_skb_sg_addrs(dev, skb, sgt, sgt_index);
+			bman_release(sg_bpool_g->pool, &bmb, 1, 0);
+			return -1;
+		}
+		prepare_qm_sg_entry(sgt, sgt_index, dma_map_size, addr);
+		sgt_index++;
+		
+		nr_frags = skb_shinfo(cur_skb)->nr_frags;
+		frag = skb_shinfo(cur_skb)->frags;
+		while(nr_frags)
+		{
+			addr = skb_frag_dma_map(dev, frag, 0, skb_frag_size(frag), dma_dir);
+			if (unlikely(dma_mapping_error(dev, addr))) {
+				if (net_ratelimit())
+					netdev_err(net_dev, "skb_fraglist_to_sg_fd : 2.DMA mappping error");
+				dma_unmap_skb_sg_addrs(dev, skb, sgt, sgt_index);
+				err = -EINVAL;
+				bman_release(sg_bpool_g->pool, &bmb, 1, 0);
+				return -1;
+			}
+			prepare_qm_sg_entry(sgt, sgt_index, skb_frag_size(frag), addr);
+			frag++;
+			nr_frags--;
+			sgt_index++;
+		}
+		cur_skb = list_skb;
+		if (list_skb)
+			list_skb = list_skb->next;
+	}
+
+	qm_sg_entry_set_final(&sgt[sgt_index-1], 1);
+
+	addr = (dma_addr_t) (skb);
+	sgt[sgt_index].opaque = addr;
+
+	sg_addr = dma_map_single(dev, sgt, sgt_size, dma_dir);
+	if (unlikely(dma_mapping_error(dev, sg_addr))) {
+		/*if (netif_msg_tx_err(priv) && net_ratelimit())*/
+		dma_unmap_skb_sg_addrs(dev, skb, sgt, sgt_index);
+		if (net_ratelimit())
+			netdev_err(net_dev, "skb_fraglist_to_sg_fd : 2.DMA mappping error");
+		err = -EINVAL;
+		bman_release(sg_bpool_g->pool, &bmb, 1, 0);
+		return -1;
+	}
+	qm_fd_addr_set64(fd, sg_addr);
+	fd->bpid = skb_2bfreed_bpool_g->bpid; /*sg_bpool_g->bpid;*/
+	fd->cmd = fd_cmd;
+	fd->length20 = skb->len;
+	fd->offset = 0;
+
+	/*net_crit_ratelimited("%s(%d) sgt_index %d, addr %p \n",__FUNCTION__, __LINE__,sgt_index,(void *)(sgt[sgt_index].opaque)); */
+	/* percpu_priv->tx_returned++; */
+	return 0;
+}
+
+EXPORT_SYMBOL(skb_fraglist_to_sg_fd);
 int __hot skb_to_sg_fd(struct dpa_priv_s *priv,
 		       struct sk_buff *skb, struct qm_fd *fd)
 {
@@ -1030,9 +1434,532 @@ int __hot skb_to_sg_fd(struct dpa_priv_s *priv,
 }
 EXPORT_SYMBOL(skb_to_sg_fd);
 
-int __hot dpa_tx(struct sk_buff *skb, struct net_device *net_dev)
+#define EMAC_QUEUENUM_MASK 0xff
+
+#ifdef CONFIG_CPE_FAST_PATH
+static int pfe_eth_get_queuenum( struct sk_buff *skb )
+{
+
+#if defined(CONFIG_IP_NF_CONNTRACK_MARK) || defined(CONFIG_NF_CONNTRACK_MARK)
+	/* Use conntrack mark (if conntrack exists) */
+	if (skb->_nfct) {
+		enum ip_conntrack_info cinfo;
+		struct nf_conn *ct;
+
+		ct = nf_ct_get(skb, &cinfo);
+		if (ct) {
+			u_int64_t markval;
+
+			markval = ct->qosconnmark;
+			if (cinfo >= IP_CT_IS_REPLY) {
+				if (markval & ((uint64_t)1 << 63))
+					markval >>= 32;
+               else
+					markval = 0;
+			}
+			markval &= 0x7fffffff;
+			return markval;
+
+		}
+	}
+#endif
+	/* use  packet mark (if any) */
+	if (skb->mark) {
+		return (skb->mark & EMAC_QUEUENUM_MASK);
+	}
+	/* These are packets through control path, assign highest priority */
+	return (QOS_DEFAULT_QUEUE);
+}
+#endif /*endif for CONFIG_CPE_FAST_PATH */
+
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+unsigned int ipsec_offload_pkt_cnt;
+void print_ipsec_offload_pkt_count(void)
+{
+	printk("%s:: Ipsec offload slow path packet count = %d\n",__func__,ipsec_offload_pkt_cnt);
+	ipsec_offload_pkt_cnt = 0;
+}
+EXPORT_SYMBOL(print_ipsec_offload_pkt_count);
+#endif
+
+#ifdef CONFIG_XFRM
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+
+#define ETH_HDR_SIZE            14
+#define VLAN_HDR_SIZE           4
+#define PPPOE_HDR_SIZE          8
+#define ETHHDR_MACEND_OFFSET    12
+
+#define DPOVRD_ENABLE		0x80000000
+
+unsigned char* dpa_get_skb_nh(struct sk_buff* skb, unsigned short *l3_proto, unsigned short* l3_offset)
+{
+	unsigned short type_id;
+	unsigned short offset = ETH_HDR_SIZE;
+	type_id = *((unsigned short*) (skb->data + offset - 2));
+	while (1)
+	{
+		switch (type_id)
+		{
+			case htons(ETH_P_PPP_SES):
+				offset += PPPOE_HDR_SIZE;
+				type_id = *(unsigned short*)(skb->data + offset - 2);
+
+				if (type_id == htons(PPP_IP))
+					type_id = ntohs(ETH_P_IP);
+				else if (type_id == htons(PPP_IPV6))
+					type_id = ntohs(ETH_P_IPV6);
+				break;
+			case htons(ETH_P_8021Q):
+				offset += VLAN_HDR_SIZE;
+				type_id = *(unsigned short*) (skb->data + offset - 2);
+				break;
+			case htons(ETH_P_IP):
+			case htons(ETH_P_IPV6):
+				*l3_proto = type_id;
+				*l3_offset = offset;
+				return (skb->data + offset);
+			default:
+				*l3_proto = type_id;
+				*l3_offset = offset;
+				return NULL;
+		}
+	}
+}
+
+ __hot void dpaa_submit_outb_pkt_to_SEC(struct sk_buff *skb, struct net_device *net_dev, struct dpa_bp *dpa_bp)
+{
+	struct xfrm_state *x;
+	struct qman_fq *egress_fq = NULL;
+	struct qm_fd		 fd;
+	int err = 0,ii;
+	int new_ethhdr_end, old_ethhdr_end;
+	unsigned short l3_proto, l3_offset;
+	unsigned char* skb_nh ;
+	struct sec_path *sp;
+	unsigned int dpovrd = 0;
+
+	sp = skb_sec_path(skb);
+
+	if ((cdx_get_ipsec_fq_hookfn) && (sp) && (sp->len))
+	{
+		x = sp->xvec[0];
+
+		egress_fq = cdx_get_ipsec_fq_hookfn(x->handle);
+
+		/* when a packet is submitting to SEC engine,
+		use the below code */
+		if (!egress_fq)
+		{
+			printk("%s(%d) egress frame queue not found \n",
+			__FUNCTION__, __LINE__);
+			goto sec_submit_failed;	
+		}
+
+		/*
+		* For packets with L2 headers other than ethernet header, L2 headers are
+		* stripped off and only ethernet header is maintained. These L2 headers
+		* will be added again in offline port classification table entry
+		* after SEC processing.
+		*/
+
+		skb_nh = dpa_get_skb_nh(skb, &l3_proto, &l3_offset);
+
+		if (skb_nh)
+		{
+			if(l3_offset != ETH_HDR_SIZE)
+			{
+				new_ethhdr_end = l3_offset - 2  ; /*l3 offset - protocol(2bytes) */
+				old_ethhdr_end = ETHHDR_MACEND_OFFSET ;
+				while(old_ethhdr_end >= 0)
+					skb->data[new_ethhdr_end--] = skb->data[old_ethhdr_end--];
+
+				*((unsigned short*) (skb->data + l3_offset - 2) ) = l3_proto;
+				skb->data = skb->data + l3_offset - ETH_HDR_SIZE;
+				skb->len = skb->len - l3_offset + ETH_HDR_SIZE;
+			}
+			if ((*skb_nh >> 4) == IPVERSION) /* Extracting ip version from network header */
+			{
+				dpovrd = IPPROTO_IPIP; /* ESP trailer NH type. Here traffic is IPv4 */
+			}
+			else
+			{
+				dpovrd = IPPROTO_IPV6; /* ESP trailer NH type. Here traffic is IPv4 */
+			}
+			dpovrd |= DPOVRD_ENABLE; /* OVRD enable */
+		}
+
+
+		err =  skb_fraglist_to_sg_fd(dpa_bp->dev, net_dev, skb, &fd, dpovrd);
+		if (unlikely(err < 0))
+		{
+			printk("%s(%d) skb_fraglist_to_sg_fd \n",__FUNCTION__,__LINE__);
+			goto sec_submit_failed;
+		}
+
+
+		for (ii = 0; ii < 100000; ii++) {
+			err = qman_enqueue(egress_fq, &fd, 0);
+			if (err != -EBUSY)
+				break;
+		}
+
+		if (unlikely(err < 0)) {
+			struct bm_buffer bmb;
+			dma_addr_t addr;
+
+			printk("%s(%d) dpa_xmit failed\n",__FUNCTION__,__LINE__);
+			/* put the buffer back to sg pool */
+			addr = qm_fd_addr(&fd);
+			bm_buffer_set64(&bmb, addr);
+			while (bman_release(sg_bpool_g->pool, &bmb, 1, 0))
+				cpu_relax();
+			/* release skb and retuen */
+			goto sec_submit_failed;
+		}
+
+		/* sucessful transmit to CAAM */
+		netif_trans_update(net_dev);
+		ipsec_offload_pkt_cnt++;
+		return;
+	}
+sec_submit_failed:
+	dev_kfree_skb(skb);
+	return;
+
+}
+
+EXPORT_SYMBOL(dpaa_submit_outb_pkt_to_SEC);
+
+/**
+ * dpa_add_dummy_eth_hdr - Add dummy Ethernet header space to SKB
+ * @skb_in: Pointer to SKB pointer (may be reallocated)
+ * @priv_headroom: Private headroom to reserve (not used, for API compatibility)
+ * @hdroom_realloc: Set to 1 if headroom was reallocated
+ *
+ * This function ensures there is space for an Ethernet header in the SKB
+ * headroom for cellular interfaces that don't have a MAC header.
+ * Returns 0 on success, negative on failure.
+ */
+int dpa_add_dummy_eth_hdr(struct sk_buff **skb_in, int priv_headroom,
+			  unsigned char *hdroom_realloc)
+{
+	struct sk_buff *skb = *skb_in;
+	struct ethhdr *eth;
+	__be16 proto;
+	int headroom_needed = ETH_HLEN + priv_headroom;
+	int ipv;
+
+	/* Check if we have enough headroom */
+	if (skb_headroom(skb) < headroom_needed) {
+		struct sk_buff *new_skb;
+
+		new_skb = skb_realloc_headroom(skb, headroom_needed);
+		if (!new_skb)
+			return -ENOMEM;
+
+		dev_kfree_skb(skb);
+		*skb_in = new_skb;
+		skb = new_skb;
+		*hdroom_realloc = 1;
+	}
+
+	/* Determine IP version from first byte of packet */
+	ipv = (skb->data[0] >> 4) & 0xf;
+
+	/* Set protocol based on IP version */
+	if (ipv == 6)
+		proto = htons(ETH_P_IPV6);
+	else
+		proto = htons(ETH_P_IP);
+
+	/* Push ethernet header space */
+	eth = (struct ethhdr *)skb_push(skb, ETH_HLEN);
+
+	/* Initialize with dummy MAC addresses (will be overwritten later) */
+	memset(eth->h_dest, 0, ETH_ALEN);
+	memset(eth->h_source, 0, ETH_ALEN);
+	eth->h_proto = proto;
+
+	/* Reset SKB pointers - caller will adjust data/len */
+	skb_pull(skb, ETH_HLEN);
+
+	return 0;
+}
+EXPORT_SYMBOL(dpa_add_dummy_eth_hdr);
+
+#ifdef UNIT_TEST
+unsigned char temp_ethhdr[16];
+#endif
+/* This function is invoked from xfrm_input.c to submit IPSEC packets
+   to SEC engine, if the corresponding SA is programmed in ucode
+*/
+int dpaa_submit_inb_pkt_to_SEC(struct sk_buff *skb, uint16_t sagd)
+{
+	struct qman_fq *sec_fq = NULL;
+	struct dpa_priv_s	*priv = NULL;
+	struct dpa_percpu_priv_s *percpu_priv = NULL;
+	struct qm_fd		 fd;
+	int err, ii, ret;
+	uint8_t tmp_len = 0, data[ETH_HLEN],ipvsn;
+	struct net_device *netdev;
+	struct device* dev;
+	unsigned char hdroom_realloced = 0;
+#ifdef UNIT_TEST
+	unsigned short dev_type = skb->dev->type;
+#endif
+	struct net_device *real_dev = NULL;
+
+	if (cdx_get_ipsec_fq_hookfn)
+	{
+		/*net_crit_ratelimited("%s(%d) x->handle %d, skb->data %p, machdr %p\n",
+		  __FUNCTION__,__LINE__, sagd,skb->data, skb_mac_header(skb)); */
+		/* Get the SEC FQID corresponding to sagd */
+		sec_fq = cdx_get_ipsec_fq_hookfn(sagd);
+
+		/*if no SEC FQID found, return non-zero to return pkt to linux*/
+		if (!sec_fq || !(skb->dev))
+		{
+			return -1; /* give packet to linux */
+		}
+#ifdef UNIT_TEST
+		{
+			skb->dev->type = ARPHRD_NONE;
+			skb->mac_len = 0;
+		}
+#endif
+		if (skb->dev->type == ARPHRD_ETHER) 
+		{
+			/* Get the corresponding physical device info, if the skb->dev corresponds to vlan*/
+			real_dev = is_vlan_dev(skb->dev) ? vlan_dev_real_dev(skb->dev) : skb->dev;
+			priv = netdev_priv(real_dev);
+			/* SEC shared descriptor designed to take packet including MAC hdr */
+			/* modify skb->data to point to MAC hdr */
+			tmp_len = (skb->data - skb_mac_header(skb));
+			skb->len += tmp_len;
+			skb->data = skb_mac_header(skb);
+		}
+		else if (skb->dev->type == ARPHRD_PPP)
+		{
+			/* Get the corresponding physica device info */
+			netdev = __dev_get_by_index(dev_net(skb->dev), skb->iif_index);
+			if (!netdev)
+			{
+				return -1;
+			}
+			priv = netdev_priv(netdev);
+			/* observation in case of PPPoE skb_mac_header is pointing to IP header*/
+			/* get the IP version*/
+			/*printk("%s(%d), MAC header ptr: \n",
+			  __FUNCTION__,__LINE__);
+			  display_buf_data(&skb->head[skb->mac_header] ,16);*/
+			ipvsn = ((skb->head[skb->mac_header]) & 0xf0) >> 4;
+			/*printk(KERN_INFO "iif_dev :%s, ifindex %d, ipvsn %d\n", netdev->name, netdev->ifindex, ipvsn);*/
+			/* SEC shared descriptor designed to take packet including MAC hdr */
+			/* modify skb->data to point to MAC hdr */
+			tmp_len = (skb->data - skb_mac_header(skb) + ETH_HLEN);
+			skb->len += tmp_len;
+			skb->data = skb_mac_header(skb) - ETH_HLEN;
+			/* Copy MAC hdr to the skb->data */
+			/* have a backup data in case of failure */
+			memcpy(data, skb->data, ETH_HLEN);
+			/* copying 8 bytes and then 4 bytes from the backup , as there is overlap*/
+			memcpy(skb->data, skb->data-PPPOE_SES_HLEN, PPPOE_SES_HLEN);
+			memcpy(skb->data+PPPOE_SES_HLEN, data, 4);
+			/* setting IPv4/IPv6 ethernet protocol value */
+			if (ipvsn == DPAA_IP_VERSION_4)
+			{
+				skb->data[12] = 0x08;
+				skb->data[13] = 0x00;
+			}
+			else /* IP v6 */
+			{
+				skb->data[12] = 0x86;
+				skb->data[13] = 0xdd;
+			}
+			/*printk("%s(%d), modified header : \n",
+			  __FUNCTION__,__LINE__);
+			  display_buf_data(skb->data,16);*/
+		}
+
+		if (skb->dev->wifi_offload_dev)
+		{
+			dev = dpa_get_bp_device();
+			netdev = skb->dev;
+			/* Following code is added for cellular interfaces */
+			/* FIX :May be we can check for device type as ARPHRD_NONE */
+			if (skb->mac_len == 0)
+			{
+				tmp_len = (skb->data - skb_network_header(skb));
+				skb->len += tmp_len;
+				skb->data = skb_network_header(skb);
+#ifdef UNIT_TEST
+				memcpy(temp_ethhdr, (skb->data - ETH_HLEN), 12);
+#endif
+				/* Add mac_header */
+				ret = dpa_add_dummy_eth_hdr(&skb, 0, &hdroom_realloced);
+				if (ret < 0)
+					return -1;
+
+				skb->data -= ETH_HLEN;
+				skb->len += ETH_HLEN;
+				tmp_len += ETH_HLEN;
+#ifdef UNIT_TEST
+				memcpy(skb->data ,temp_ethhdr,12);
+				skb->dev->type = dev_type;
+				skb->mac_len = ETH_HLEN;
+#endif
+			}
+		}
+		else
+		{
+			if (!priv)
+				return -1;
+			dev = priv->dpa_bp->dev;
+			netdev = priv->net_dev;
+		}
+		/*FIXME: skb->dev->type other than ARPHRD_ETHER and ARPHRD_PPP priv is uninitialized. Here else case should add to address it. */
+		/*net_crit_ratelimited("%s(%d) x->handle %d, skb->data %p, machdr %p, len %d, skb->dev %p\n",
+			__FUNCTION__,__LINE__, sagd, skb->data, skb_mac_header(skb),skb->len, skb->dev); */
+		err =  skb_fraglist_to_sg_fd(dev, netdev, skb, &fd, 0);
+		if (unlikely(err < 0))
+		{
+			printk("%s(%d) skb_fraglist_to_sg_fd failed\n",
+					__FUNCTION__,__LINE__);
+			if (skb->dev->type == ARPHRD_PPP)
+				memcpy(skb->data, data, ETH_HLEN);
+
+			skb->len -= tmp_len;
+			skb->data += tmp_len;
+			return -1; /* give packet to linux */
+		}
+
+		for (ii = 0; ii < 100000; ii++) {
+			err = qman_enqueue(sec_fq, &fd, 0);
+			if (err != -EBUSY)
+				break;
+		}
+
+		if (unlikely(err < 0)) {
+			struct bm_buffer bmb;
+			dma_addr_t addr;
+
+			printk("%s(%d) qman_enqueue failed\n",
+					__FUNCTION__,__LINE__);
+			/* put the buffer back to sg pool */
+			addr = qm_fd_addr(&fd);
+			bm_buffer_set64(&bmb, addr);
+			while (bman_release(sg_bpool_g->pool, &bmb, 1, 0))
+				cpu_relax();
+			return -1; /* give packet to linux */
+		}
+		if (priv)
+		{
+			percpu_priv = raw_cpu_ptr(priv->percpu_priv);
+			percpu_priv->tx_caam_dec++;
+		}
+	}
+	return 0;
+}
+#endif
+#endif
+
+#ifdef CONFIG_CPE_FAST_PATH
+#define CHANNEL_BIT_POSITION 24
+
+int cpe_fp_tx(struct sk_buff *skb, struct net_device *net_dev)
 {
 	struct dpa_priv_s	*priv;
+	struct dpa_percpu_priv_s *percpu_priv;
+	int channel_id;
+	int queuenum;
+	int markval,ff=0;
+	struct qman_fq *egress_fq, *conf_fq;
+	uint8_t get_ceetm_cm_egress_fq;
+	uint8_t dscp;
+	unsigned char* skb_nh ;
+	uint16_t l3_proto = 0, l3_offset = 0;
+
+	priv = netdev_priv(net_dev);
+#ifdef CONFIG_XFRM
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	if(skb->ipsec_offload) {
+		dpaa_submit_outb_pkt_to_SEC(skb, net_dev, priv->dpa_bp);
+		percpu_priv = raw_cpu_ptr(priv->percpu_priv);
+		percpu_priv->tx_caam_enc++;
+		return NETDEV_TX_OK;
+	}
+#endif
+#endif
+	if (priv->ceetm_en) {
+		/* markval also using to know qosconnmark is present for this packet. */
+		/* If markval is 0 assuming qosconnmark is not present for this packet(connection). */
+		markval = pfe_eth_get_queuenum(skb);
+		queuenum = markval & 0xf;
+		channel_id = (markval >> CHANNEL_BIT_POSITION) & 0xf;
+		egress_fq = NULL;
+		get_ceetm_cm_egress_fq = 1; /* This becomes 0 when qosconnark(markval is 0) is not present or 
+						can't find egress fq for dscp */
+		/* markval is 0 means qosconnmark is not configured, so getting dscp from skb. */
+		/* using dscp get the egress fq. */
+		if (!markval) {
+			skb_nh = dpa_get_skb_nh(skb, &l3_proto, &l3_offset);
+			if (skb_nh)
+			{
+				/* skb_nh is non NULL means either it is pointing to ipv4 or ipv6 header only */
+				if (l3_proto ==  htons(ETH_P_IP))
+				{
+					/* Getting the DSCP value from IPv4 header*/
+					dscp = (((struct iphdr *)skb_nh)->tos) >> 2; /* tos 8 bit size, DSCP 6 bit value, shifting 2 bits right to get actual DSCP value*/
+				}
+				else
+				{
+					 /* Getting the DSCP value from IPv6 header*/
+					dscp = ((((struct ipv6hdr *)skb_nh)->priority) << 2) /* priority is 4 bit size, shifting 2 bits left to give space for flow_lbl[0] 2 bits */
+						+ ((((struct ipv6hdr *)skb_nh)->flow_lbl[0]) >> 6); /* flow_lbl[0] is 8 bit size, DSCP 2 bits are here, so shifting 6 bits right*/
+				}
+				egress_fq = ceetm_dscp_fqget_func(priv->qm_ctx, dscp);
+				if (egress_fq)
+					get_ceetm_cm_egress_fq = 0;
+			}
+		}
+		if (get_ceetm_cm_egress_fq)
+		{
+			if (ceetm_fqget_func) {
+				egress_fq = ceetm_fqget_func(priv->qm_ctx, 
+					channel_id,queuenum,ff);
+			}
+			if (!egress_fq) {
+				printk(KERN_CRIT "%s::unable to get ceetm fq, mark %08x registered func %p"
+						"dropping packet\n",
+						__FUNCTION__, markval , ceetm_fqget_func);
+				dev_kfree_skb(skb);
+				return NETDEV_TX_OK;
+			}
+		}
+	}  else
+	{
+		queuenum = dpa_get_queue_mapping(skb);
+		if (unlikely(queuenum >= DPAA_ETH_TX_QUEUES))
+			queuenum = queuenum % DPAA_ETH_TX_QUEUES;
+		egress_fq = priv->egress_fqs[queuenum];
+	}
+	conf_fq = priv->conf_fqs[queuenum  & (DPAA_ETH_TX_QUEUES-1)];
+	return dpa_tx_extended(skb, net_dev, egress_fq, conf_fq);
+}
+#endif
+
+static inline void skb_reset_truesize(struct sk_buff *skb, unsigned int size)
+{
+	size -= SKB_DATA_ALIGN(sizeof(struct skb_shared_info));
+	skb->truesize = SKB_TRUESIZE(size);
+
+	return;
+}
+
+int __hot dpa_tx(struct sk_buff *skb, struct net_device *net_dev)
+{
+	struct dpa_priv_s       *priv;
 	int queue_mapping = dpa_get_queue_mapping(skb);
 	struct qman_fq *egress_fq, *conf_fq;
 
@@ -1044,6 +1971,10 @@ int __hot dpa_tx(struct sk_buff *skb, struct net_device *net_dev)
 		return NETDEV_TX_OK;
 #endif
 
+#ifdef CONFIG_CPE_FAST_PATH
+	return cpe_fp_tx(skb, net_dev);
+#endif
+
 	priv = netdev_priv(net_dev);
 
 #ifdef CONFIG_FSL_DPAA_CEETM
@@ -1114,6 +2045,7 @@ int __hot dpa_tx_extended(struct sk_buff *skb, struct net_device *net_dev,
 	skb_shinfo(skb)->tx_flags |= SKBTX_IN_PROGRESS;
 #endif /* CONFIG_FSL_DPAA_TS */
 
+
 	/* MAX_SKB_FRAGS is larger than our DPA_SGT_MAX_ENTRIES; make sure
 	 * we don't feed FMan with more fragments than it supports.
 	 * Btw, we're using the first sgt entry to store the linear part of
@@ -1212,13 +2144,18 @@ int __hot dpa_tx_extended(struct sk_buff *skb, struct net_device *net_dev,
 		 * but we need the skb to look as if returned by build_skb().
 		 * We need to manually adjust the tailptr as well.
 		 */
+		/* skb_reset_truesize() resets the skb truesize, to avoid 
+		 * skb truesize gets increment continuously when the same 
+		 * skb used for next fragments.
+		 */
+		skb_reset_truesize(skb, SMP_CACHE_BYTES + DPA_SKB_SIZE(priv->dpa_bp->size) +
+				SKB_DATA_ALIGN(sizeof(struct skb_shared_info)));
 		skb->data = skb->head + offset;
 		skb_reset_tail_pointer(skb);
 
 		(*countptr)++;
 		percpu_priv->tx_returned++;
 	}
-
 	if (unlikely(dpa_xmit(priv, percpu_stats, &fd, egress_fq, conf_fq) < 0))
 		goto xmit_failed;
 
diff --git a/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_ethtool.c b/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_ethtool.c
index eeb19fc2c92d..a15d31c7bf7b 100644
--- a/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_ethtool.c
+++ b/drivers/net/ethernet/freescale/sdk_dpaa/dpaa_ethtool.c
@@ -55,6 +55,10 @@ static const char dpa_stats_percpu[][ETH_GSTRING_LEN] = {
 	"tx packets",
 	"tx recycled",
 	"tx confirm",
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) && defined(CONFIG_CPE_FAST_PATH)
+	"tx toenc",
+	"tx todec",
+#endif
 	"tx S/G",
 	"rx S/G",
 	"tx error",
@@ -387,6 +391,13 @@ static void copy_stats(struct dpa_percpu_priv_s *percpu_priv, int num_cpus,
 	data[crr_stat * num_stat_values + crr_cpu] = percpu_priv->tx_confirm;
 	data[crr_stat++ * num_stat_values + num_cpus] += percpu_priv->tx_confirm;
 
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) && defined(CONFIG_CPE_FAST_PATH)
+	data[crr_stat * num_stat_values + crr_cpu] = percpu_priv->tx_caam_enc;
+	data[crr_stat++ * num_stat_values + num_cpus] += percpu_priv->tx_caam_enc;
+
+	data[crr_stat * num_stat_values + crr_cpu] = percpu_priv->tx_caam_dec;
+	data[crr_stat++ * num_stat_values + num_cpus] += percpu_priv->tx_caam_dec;
+#endif
 	data[crr_stat * num_stat_values + crr_cpu] = percpu_priv->tx_frag_skbuffs;
 	data[crr_stat++ * num_stat_values + num_cpus] += percpu_priv->tx_frag_skbuffs;
 
diff --git a/drivers/net/ethernet/freescale/sdk_dpaa/mac-api.c b/drivers/net/ethernet/freescale/sdk_dpaa/mac-api.c
index 2215016d9fa8..73ecec1f9d5a 100644
--- a/drivers/net/ethernet/freescale/sdk_dpaa/mac-api.c
+++ b/drivers/net/ethernet/freescale/sdk_dpaa/mac-api.c
@@ -636,6 +636,7 @@ static void setup_memac(struct mac_device *mac_dev)
 	mac_dev->stop		= stop;
 	mac_dev->set_promisc	= fm_mac_set_promiscuous;
 	mac_dev->change_addr    = fm_mac_modify_mac_addr;
+	mac_dev->set_allmulti	= fm_mac_set_allmulti;
 	mac_dev->set_multi      = set_multi;
 	mac_dev->uninit		= uninit;
 	mac_dev->get_mac_handle		= get_mac_handle;
diff --git a/drivers/net/ethernet/freescale/sdk_dpaa/mac.h b/drivers/net/ethernet/freescale/sdk_dpaa/mac.h
index 38509644c826..de5ffc0ab9c5 100644
--- a/drivers/net/ethernet/freescale/sdk_dpaa/mac.h
+++ b/drivers/net/ethernet/freescale/sdk_dpaa/mac.h
@@ -47,6 +47,7 @@ struct mac_device {
 	void __iomem		*vaddr;
 	uint8_t			 addr[ETH_ALEN];
 	bool			 promisc;
+	bool			 allmulti;
 
 	struct fm		*fm_dev;
 	struct fm_port		*port_dev[2];
@@ -78,6 +79,7 @@ struct mac_device {
 	int (*start)(struct mac_device *mac_dev);
 	int (*stop)(struct mac_device *mac_dev);
 	int (*set_promisc)(struct fm_mac_dev *fm_mac_dev, bool enable);
+	int (*set_allmulti)(struct fm_mac_dev *fm_mac_dev, bool enable);
 	int (*change_addr)(struct fm_mac_dev *fm_mac_dev, const uint8_t *addr);
 	int (*set_multi)(struct net_device *net_dev,
 			 struct mac_device *mac_dev);
diff --git a/drivers/net/ethernet/freescale/sdk_dpaa/offline_port.c b/drivers/net/ethernet/freescale/sdk_dpaa/offline_port.c
index 000caf70e00e..46bab80830f1 100644
--- a/drivers/net/ethernet/freescale/sdk_dpaa/offline_port.c
+++ b/drivers/net/ethernet/freescale/sdk_dpaa/offline_port.c
@@ -50,6 +50,7 @@
 #include <linux/of_platform.h>
 #include <linux/platform_device.h>
 #include <linux/fsl_qman.h>
+#include <linux/fsl_oh_port.h>
 
 #include "offline_port.h"
 #include "dpaa_eth.h"
@@ -65,6 +66,7 @@ MODULE_LICENSE("Dual BSD/GPL");
 MODULE_AUTHOR("Bogdan Hamciuc <bogdan.hamciuc@freescale.com>");
 MODULE_DESCRIPTION(OH_MOD_DESCRIPTION);
 
+static struct fman_offline_port_info offline_port_info[MAX_FMANS][MAX_OFFLINE_PORTS];
 
 static const struct of_device_id oh_port_match_table[] = {
 	{
@@ -232,6 +234,33 @@ static int __cold oh_free_pcd_fqids(struct device *dev, uint32_t base_fqid)
 	return 0;
 }
 
+
+int oh_port_driver_get_port_info(struct fman_offline_port_info *info)
+{
+	uint32_t ii;
+	uint32_t fman_idx;
+	uint32_t port_idx;
+	struct fman_offline_port_info *port_info;
+
+	if (sscanf(info->port_name, "dpa-fman%d-oh@%d", &fman_idx, &port_idx) != 2) {
+		printk("%s::invalid name %s\n", __FUNCTION__, info->port_name);
+		return (-EINVAL);
+	}
+
+	port_info = &offline_port_info[fman_idx][0];
+	for (ii = 0; ii < MAX_OFFLINE_PORTS; ii++) {
+		if (strcmp(&info->port_name[0], &port_info->port_name[0]) == 0) {
+			memcpy(info, port_info, sizeof(struct fman_offline_port_info));
+			return 0;
+		}
+		port_info++;
+	}
+	return (-ENOENT);
+}
+
+EXPORT_SYMBOL(oh_port_driver_get_port_info);
+
+
 static void oh_set_buffer_layout(struct fm_port *port,
 				 struct dpa_buffer_layout_s *layout)
 {
@@ -737,6 +766,30 @@ oh_port_probe(struct platform_device *_of_dev)
 		goto return_kfree;
 
 	dev_info(dpa_oh_dev, "OH port %s enabled.\n", oh_node->full_name);
+	{
+		uint32_t fman_idx;
+		uint32_t port_idx;
+		struct fman_offline_port_info *info;
+		char *devname;
+
+		printk("devname %s\n", dev_name(dpa_oh_dev));
+		devname = strstr(dev_name(dpa_oh_dev), "dpa-fman");
+		if (devname) {
+			if (sscanf(devname, "dpa-fman%d-oh@%d", &fman_idx, &port_idx) == 2) {
+				info = &offline_port_info[fman_idx][port_idx - 1];
+				strcpy(&info->port_name[0], devname);
+				info->channel_id = channel_id;
+				//info->err_fqid = oh_config->default_fqid;
+				//info->default_fqid = oh_config->error_fqid;
+				info->default_fqid = oh_config->default_fqid;
+				info->err_fqid = oh_config->error_fqid;
+				printk("%s::found OH port %s, fman %d, port %d\n", __FUNCTION__,
+						&info->port_name[0], fman_idx, port_idx);
+			}
+		} else {
+			printk("strstr failed on str %s\n", dev_name(dpa_oh_dev));
+		}
+	}
 
 	/* print of all referenced & created queues */
 	dump_oh_config(dpa_oh_dev, oh_config);
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Kconfig b/drivers/net/ethernet/freescale/sdk_fman/Kconfig
index 3a6d1810b525..f977e4526f27 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/Kconfig
+++ b/drivers/net/ethernet/freescale/sdk_fman/Kconfig
@@ -25,6 +25,18 @@ config FSL_SDK_FMAN_RTC_API
 		it is selected for RTC (1588 timer). Neither of them
 		were not able to be used together.
 
+config DBG_UCODE_INFRA
+	bool "debug infra support for microcode"
+	default n
+	help
+	  Enable/disable debug infra support for microcode.
+
+config DMAR_TEST
+	bool "DMA read test in microcode"
+	default n
+	help
+	  Enable DMA read test in microcode.
+
 config FSL_FM_MAX_FRAME_SIZE
 	int "Maximum L2 frame size"
 	range 64 9600
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/HC/hc.c b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/HC/hc.c
index 80fb535231b9..459e5872374f 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/HC/hc.c
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/HC/hc.c
@@ -67,6 +67,14 @@
 #define HC_HCOR_ACTION_REG_IP_FRAG_SCRATCH_POOL_CMD_SHIFT       24
 #define HC_HCOR_ACTION_REG_IP_FRAG_SCRATCH_POOL_BPID            16
 
+
+#ifdef CONFIG_DBG_UCODE_INFRA
+#define HC_HCOR_OPCODE_DBG_UCODE_CMD  0x1e
+#ifdef CONFIG_DMAR_TEST
+#define HC_HCOR_OPCDOE_DMA_READ_TEST 0x1f
+#endif //CONFIG_DMAR_TEST
+#endif // CONFIG_DBG_UCODE_INFRA
+
 #define HC_HCOR_GBL                         0x20000000
 
 #define HC_HCOR_KG_SCHEME_COUNTER           0x00000400
@@ -79,6 +87,9 @@
 #define SIZE_OF_HC_FRAME_PROFILE_CNT        (sizeof(t_HcFrame)-sizeof(t_FmPcdPlcrProfileRegs)+sizeof(uint32_t))
 #define SIZE_OF_HC_FRAME_READ_OR_CC_DYNAMIC 16
 
+
+#define SIZE_OF_HC_FRAME_READ_DBG_UCODE_CMD 64 //jyos
+
 #define HC_CMD_POOL_SIZE                    (INTG_MAX_NUM_OF_CORES)
 
 #define BUILD_FD(len)                     \
@@ -113,6 +124,11 @@ typedef struct t_HcFrame {
         volatile uint32_t                       clsPlanEntries[CLS_PLAN_NUM_PER_GRP];
         t_FmPcdCcCapwapReassmTimeoutParams      ccCapwapReassmTimeout;
         t_FmPcdCcReassmTimeoutParams            ccReassmTimeout;
+#ifdef CONFIG_DMAR_TEST
+	volatile uint8_t			data[64];
+#else
+	volatile uint8_t			data[48];
+#endif //CONFIG_DMAR_TEST
     } hcSpecificData;
 } t_HcFrame;
 
@@ -1195,6 +1211,97 @@ t_Error FmHcPcdCcDoDynamicChange(t_Handle h_FmHc, uint32_t oldAdAddrOffset, uint
     return E_OK;
 }
 
+t_Error FmHcPcdCcDoDynamicChangeWithAging(t_Handle h_FmHc,
+                                          uint32_t oldAdAddrOffset,
+                                          uint32_t newAdAddrOffset,
+                                          e_ModifyState modifyState,
+                                          uint16_t keyIndex)
+{
+    t_FmHc                  *p_FmHc = (t_FmHc*)h_FmHc;
+    t_HcFrame               *p_HcFrame;
+    t_DpaaFD                fmFd;
+    t_Error                 err = E_OK;
+    uint32_t                seqNum;
+
+    SANITY_CHECK_RETURN_ERROR(p_FmHc, E_INVALID_HANDLE);
+
+    p_HcFrame = GetBuf(p_FmHc, &seqNum);
+    if (!p_HcFrame)
+        RETURN_ERROR(MINOR, E_NO_MEMORY, ("HC Frame object"));
+    memset(p_HcFrame, 0, sizeof(t_HcFrame));
+
+    p_HcFrame->opcode     = (uint32_t)(HC_HCOR_GBL | HC_HCOR_OPCODE_CC_UPDATE_WITH_AGING);
+    p_HcFrame->actionReg  = newAdAddrOffset;
+    p_HcFrame->actionReg |= 0xc0000000;
+    p_HcFrame->extraReg   = oldAdAddrOffset;
+
+    switch (modifyState)
+    {
+        case e_MODIFY_STATE_ADD:
+            p_HcFrame->extraReg |= HC_HCOR_EXTRA_REG_CC_AGING_ADD;
+            break;
+
+        case e_MODIFY_STATE_REMOVE:
+            p_HcFrame->extraReg |= HC_HCOR_EXTRA_REG_CC_AGING_REMOVE;
+            p_HcFrame->extraReg |= ((keyIndex << HC_HCOR_EXTRA_REG_CC_REMOVE_INDX_SHIFT) & HC_HCOR_EXTRA_REG_CC_REMOVE_INDX_MASK);
+            break;
+
+        case e_MODIFY_STATE_CHANGE:
+            p_HcFrame->extraReg &= ~HC_HCOR_EXTRA_REG_CC_AGING_CHANGE_MASK;
+            break;
+    }
+
+    p_HcFrame->commandSequence = seqNum;
+
+    BUILD_FD(SIZE_OF_HC_FRAME_READ_OR_CC_DYNAMIC);
+
+    err = EnQFrm(p_FmHc, &fmFd, seqNum);
+
+    PutBuf(p_FmHc, p_HcFrame, seqNum);
+
+    if (err != E_OK)
+        RETURN_ERROR(MAJOR, err, NO_MSG);
+
+    return E_OK;
+}
+
+t_Error FmHcPcdCcResetAgingMask(t_Handle h_FmHc, uint32_t adAddrOffset, uint32_t newAgeMask, uint32_t *p_OldAgeMask)
+{
+    t_FmHc                  *p_FmHc = (t_FmHc*)h_FmHc;
+    t_HcFrame               *p_HcFrame;
+    t_DpaaFD                fmFd;
+    t_Error                 err = E_OK;
+    uint32_t                seqNum;
+
+    SANITY_CHECK_RETURN_ERROR(p_FmHc, E_INVALID_HANDLE);
+
+    p_HcFrame = GetBuf(p_FmHc, &seqNum);
+    if (!p_HcFrame)
+        RETURN_ERROR(MINOR, E_NO_MEMORY, ("HC Frame object"));
+    memset(p_HcFrame, 0, sizeof(t_HcFrame));
+
+    p_HcFrame->opcode     = (uint32_t)(HC_HCOR_GBL | HC_HCOR_OPCODE_CC_AGE_MASK);
+    p_HcFrame->actionReg  = adAddrOffset;
+    p_HcFrame->extraReg   = newAgeMask;
+    p_HcFrame->commandSequence = seqNum;
+
+    BUILD_FD(SIZE_OF_HC_FRAME_READ_OR_CC_DYNAMIC);
+
+    err = EnQFrm(p_FmHc, &fmFd, seqNum);
+
+    /* On command completion the FMC writes to HCER the 'aging-mask' field
+       before it was updated by this command. This way the user may identify
+       which bits were cleared by FMC before setting them. */
+    *p_OldAgeMask = p_HcFrame->extraReg;
+
+    PutBuf(p_FmHc, p_HcFrame, seqNum);
+
+    if (err != E_OK)
+        RETURN_ERROR(MAJOR, err, NO_MSG);
+
+    return E_OK;
+}
+
 t_Error FmHcPcdSync(t_Handle h_FmHc)
 {
     t_FmHc                  *p_FmHc = (t_FmHc*)h_FmHc;
@@ -1250,3 +1357,116 @@ bool FmIsHcUsageAllowed(t_Handle h_FmHc)
 
 	return p_FmHc->usageAllowed;
 }
+
+#ifdef CONFIG_DBG_UCODE_INFRA
+t_Error FmHcPcdDbgUcodeHCmd(t_Handle h_FmHc,
+			   uint32_t muram_offset,
+			   uint8_t  *data,
+			   uint8_t	size)
+{
+    t_FmHc                  *p_FmHc = (t_FmHc*)h_FmHc;
+    t_HcFrame               *p_HcFrame;
+    t_DpaaFD                fmFd;
+    t_Error                 err = E_OK;
+    uint32_t                seqNum, ii;
+    uint8_t		   *hc_data;
+
+
+    SANITY_CHECK_RETURN_ERROR(p_FmHc, E_INVALID_HANDLE);
+
+    p_HcFrame = GetBuf(p_FmHc, &seqNum);
+    if (!p_HcFrame)
+        RETURN_ERROR(MINOR, E_NO_MEMORY, ("HC Frame object"));
+    memset(p_HcFrame, 0, sizeof(t_HcFrame));
+
+    p_HcFrame->opcode     = (uint32_t)(HC_HCOR_GBL | HC_HCOR_OPCODE_DBG_UCODE_CMD);
+    p_HcFrame->actionReg = muram_offset;
+    p_HcFrame->extraReg =  size;
+    hc_data = (uint8_t *)p_HcFrame->hcSpecificData.data;
+    for (ii=0; ii<size; ii++)
+	hc_data[ii] =  data[ii];
+
+    BUILD_FD(SIZE_OF_HC_FRAME_READ_DBG_UCODE_CMD);
+
+    err = EnQFrm(p_FmHc, &fmFd, seqNum);
+
+    PutBuf(p_FmHc, p_HcFrame, seqNum);
+    if (err != E_OK)
+        RETURN_ERROR(MAJOR, err, NO_MSG);
+
+    return E_OK;
+}
+
+t_Error FmHcPcdDbgUcodeTest(t_Handle h_FmHc,
+			uint32_t opcode,
+			uint32_t *data,
+			uint16_t data_size)
+{
+    t_FmHc                  *p_FmHc = (t_FmHc*)h_FmHc;
+    t_HcFrame               *p_HcFrame;
+    t_DpaaFD                fmFd;
+    t_Error                 err = E_OK;
+    uint32_t                seqNum;
+
+    SANITY_CHECK_RETURN_ERROR(p_FmHc, E_INVALID_HANDLE);
+
+    p_HcFrame = GetBuf(p_FmHc, &seqNum);
+    if (!p_HcFrame)
+	RETURN_ERROR(MINOR, E_NO_MEMORY, ("HC Frame object"));
+    memset(p_HcFrame, 0, sizeof(t_HcFrame));
+
+    p_HcFrame->opcode	  = opcode;
+    p_HcFrame->actionReg  = *data;
+    p_HcFrame->extraReg = data_size;
+
+    BUILD_FD(SIZE_OF_HC_FRAME_READ_DBG_UCODE_CMD);
+
+    err = EnQFrm(p_FmHc, &fmFd, seqNum);
+
+    PutBuf(p_FmHc, p_HcFrame, seqNum);
+
+    if (err != E_OK)
+	RETURN_ERROR(MAJOR, err, NO_MSG);
+
+    return E_OK;
+}
+#ifdef CONFIG_DMAR_TEST
+
+t_Error FmHcPcdDMAreadTest(t_Handle h_FmHc, uint32_t muram_addr_offset,
+									 uint8_t *ptr, uint8_t size)
+{
+    t_FmHc                  *p_FmHc = (t_FmHc*)h_FmHc;
+    t_HcFrame               *p_HcFrame;
+    uint8_t					*data;
+    t_DpaaFD                fmFd;
+    t_Error                 err = E_OK;
+    uint32_t                seqNum, ii;
+
+    SANITY_CHECK_RETURN_ERROR(p_FmHc, E_INVALID_HANDLE);
+
+    p_HcFrame = GetBuf(p_FmHc, &seqNum);
+    if (!p_HcFrame)
+	RETURN_ERROR(MINOR, E_NO_MEMORY, ("HC Frame object"));
+    memset(p_HcFrame, 0, sizeof(t_HcFrame));
+
+    p_HcFrame->opcode	  = HC_HCOR_OPCDOE_DMA_READ_TEST;
+    p_HcFrame->actionReg  = muram_addr_offset;
+    p_HcFrame->extraReg = size;
+    data = p_HcFrame->hcSpecificData.data;
+    memcpy(data, ptr, size);
+
+    BUILD_FD(SIZE_OF_HC_FRAME_READ_DBG_UCODE_CMD+16);
+
+    err = EnQFrm(p_FmHc, &fmFd, seqNum);
+
+    PutBuf(p_FmHc, p_HcFrame, seqNum);
+
+    if (err != E_OK)
+	RETURN_ERROR(MAJOR, err, NO_MSG);
+
+    return E_OK;
+}
+
+#endif //CONFIG_DMAR_TEST
+
+#endif // CONFIG_DBG_UCODE_INFRA
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/MAC/fm_mac.c b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/MAC/fm_mac.c
index 5ef579872a3b..ce7b97605c7c 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/MAC/fm_mac.c
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/MAC/fm_mac.c
@@ -579,6 +579,20 @@ t_Error FM_MAC_SetPromiscuous (t_Handle h_FmMac, bool newVal)
 
 /* ......................................................................... */
 
+t_Error FM_MAC_SetAllMulti (t_Handle h_FmMac, bool newVal)
+{
+    t_FmMacControllerDriver *p_FmMacControllerDriver = (t_FmMacControllerDriver *)h_FmMac;
+
+    SANITY_CHECK_RETURN_ERROR(p_FmMacControllerDriver, E_INVALID_HANDLE);
+
+    if (p_FmMacControllerDriver->f_FM_MAC_SetAllMulti)
+        return p_FmMacControllerDriver->f_FM_MAC_SetAllMulti(h_FmMac, newVal);
+
+    RETURN_ERROR(MINOR, E_NOT_SUPPORTED, NO_MSG);
+}
+
+/* ......................................................................... */
+
 t_Error FM_MAC_AdjustLink(t_Handle h_FmMac, e_EnetSpeed speed, bool fullDuplex)
 {
     t_FmMacControllerDriver *p_FmMacControllerDriver = (t_FmMacControllerDriver *)h_FmMac;
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/MAC/fm_mac.h b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/MAC/fm_mac.h
index 19ee0e90ab6b..d859fbbcad62 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/MAC/fm_mac.h
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/MAC/fm_mac.h
@@ -112,6 +112,7 @@ typedef struct {
     t_Error (*f_FM_MAC_RemovelExactMatchMacAddr) (t_Handle h_FmMac, t_EnetAddr *p_EnetAddr);
 
     t_Error (*f_FM_MAC_SetPromiscuous) (t_Handle h_FmMac, bool newVal);
+    t_Error (*f_FM_MAC_SetAllMulti) (t_Handle h_FmMac, bool newVal);
     t_Error (*f_FM_MAC_AdjustLink)     (t_Handle h_FmMac, e_EnetSpeed speed, bool fullDuplex);
     t_Error (*f_FM_MAC_RestartAutoneg) (t_Handle h_FmMac);
 
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/MAC/memac.c b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/MAC/memac.c
index 863b2ad6fb2e..45b446d8d3bb 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/MAC/memac.c
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/MAC/memac.c
@@ -1053,6 +1053,63 @@ static t_Error MemacFree(t_Handle h_Memac)
 
 /* ......................................................................... */
 
+static t_Error MemacSetAllMulti(t_Handle h_Memac, bool newVal)
+{
+    t_Memac             *p_Memac = (t_Memac *)h_Memac;
+    uint32_t            ii;
+    char                *pChar;
+    char                EthAddr[6];
+
+    SANITY_CHECK_RETURN_ERROR(p_Memac, E_NULL_POINTER);
+    SANITY_CHECK_RETURN_ERROR(!p_Memac->p_MemacDriverParam, E_INVALID_STATE);
+
+    /* For IPv4 Multicast packet first 3 bytes of dst mac remains the same.
+       so generating hash by varying remaining 3 bytes,which maps to 3 bits
+       in hash register.
+       Similarly for IPv6 multicast packet, first 2 bytes of multicast packet
+       remains the same, so generating hash by varying remaining 4 bytes,
+       which maps to 4 bits in hash register*/
+
+    pChar = EthAddr;
+    pChar[0] = 0x01;
+    pChar[1] = 0x00;
+    pChar[2] = 0x5e;
+    for(ii=0;ii<=7;ii++)
+    {
+        pChar[3] = ii>>2 & 1;
+        pChar[4] = ii>>1 & 1;
+        pChar[5] = ii>>0 & 1;
+        if(newVal)
+        {
+            MemacAddHashMacAddress(h_Memac, (t_EnetAddr *)EthAddr);
+        }
+        else
+        {
+            MemacDelHashMacAddress(h_Memac,(t_EnetAddr *)EthAddr);
+        }
+    }
+    pChar[0] = 0x33;
+    pChar[1] = 0x33;
+    for(ii=0;ii<=15;ii++)
+    {
+        pChar[2] = ii>>3 & 1;
+        pChar[3] = ii>>2 & 1;
+        pChar[4] = ii>>1 & 1;
+        pChar[5] = ii>>0 & 1;
+        if(newVal)
+        {
+            MemacAddHashMacAddress(h_Memac, (t_EnetAddr *)EthAddr);
+        }
+        else
+        {
+            MemacDelHashMacAddress(h_Memac, (t_EnetAddr *)EthAddr);
+        }
+    }
+    return E_OK;
+}
+
+/* ......................................................................... */
+
 static void InitFmMacControllerDriver(t_FmMacControllerDriver *p_FmMacControllerDriver)
 {
     p_FmMacControllerDriver->f_FM_MAC_Init                      = MemacInit;
@@ -1077,6 +1134,7 @@ static void InitFmMacControllerDriver(t_FmMacControllerDriver *p_FmMacController
     p_FmMacControllerDriver->f_FM_MAC_Disable1588TimeStamp      = NULL;
 
     p_FmMacControllerDriver->f_FM_MAC_SetPromiscuous            = MemacSetPromiscuous;
+    p_FmMacControllerDriver->f_FM_MAC_SetAllMulti               = MemacSetAllMulti;
     p_FmMacControllerDriver->f_FM_MAC_AdjustLink                = MemacAdjustLink;
     p_FmMacControllerDriver->f_FM_MAC_RestartAutoneg            = NULL;
 
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/Makefile b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/Makefile
index 6eedcf9de5fb..bcb4567cd5bb 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/Makefile
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/Makefile
@@ -12,4 +12,9 @@ ccflags-y += -I$(NCSW_FM_INC)
 
 obj-y		+= fsl-ncsw-Pcd.o
 
-fsl-ncsw-Pcd-objs	:= fman_kg.o fman_prs.o fm_cc.o fm_kg.o fm_pcd.o fm_plcr.o fm_prs.o fm_manip.o fm_replic.o
+fsl-ncsw-Pcd-objs	:= fman_kg.o fman_prs.o fm_cc.o fm_kg.o fm_pcd.o fm_plcr.o fm_prs.o fm_manip.o fm_replic.o fm_ehash.o
+
+## To enable debug printing, set the env var FMAN_DEBUG to define the debug symbols
+## For example:
+##	setenv FMAN_DEBUG '-DFM_CC_MURAM_DEBUG=1'
+ccflags-y += $(FMAN_DEBUG)
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_cc.c b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_cc.c
index b8d600fa6f25..7969d92992a6 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_cc.c
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_cc.c
@@ -51,7 +51,17 @@
 #include "fm_hc.h"
 #include "fm_cc.h"
 #include "crc64.h"
-
+#include "fm_cc_dbg.h"
+#include "fm_ehash.h"
+
+//#define FM_EHASH_DEBUG 1
+#ifdef USE_ENHANCED_EHASH
+extern t_Handle ExternalHashTableSet(t_Handle h_FmPcd, t_FmPcdHashTableParams *p_Param);
+extern t_Error ExternalHashTableAddKey(t_Handle h_HashTbl, uint8_t keySize,
+                                       t_FmPcdCcKeyParams *p_KeyParams);
+extern t_Error ExternalHashTableModifyMissNextEngine(t_Handle h_HashTbl,
+                                       t_FmPcdCcNextEngineParams *p_FmPcdCcNextEngineParams);
+#endif
 /****************************************/
 /*       static functions               */
 /****************************************/
@@ -274,7 +284,7 @@ static void FillAdOfTypeContLookup(t_Handle h_Ad,
     t_AdOfTypeContLookup *p_AdContLookup = (t_AdOfTypeContLookup *)h_Ad;
     t_Handle h_TmpAd;
     t_FmPcd *p_FmPcd = (t_FmPcd*)h_FmPcd;
-    uint32_t tmpReg32;
+    uint32_t tmpReg32, agingMask;
     t_Handle p_AdNewPtr = NULL;
 
     UNUSED(h_Manip);
@@ -339,6 +349,28 @@ static void FillAdOfTypeContLookup(t_Handle h_Ad,
     /* if (p_AdNewPtr = NULL) --> Done. (case (3)) */
     if (p_AdNewPtr)
     {
+#if (DPAA_VERSION >= 11)
+        if (p_Node->externalHash) {
+            tmpReg32 = 0;
+            tmpReg32 |= FM_PCD_AD_CONT_LOOKUP_TYPE;
+            if (p_Node->extHashInfo.allocateBuffer)
+                tmpReg32 |= FM_PCD_AD_FE_ENTER_ALLOCATE;
+            WRITE_UINT32(p_AdContLookup->ccAdBase, tmpReg32);
+
+            tmpReg32 = 0;
+            WRITE_UINT32(p_AdContLookup->matchTblPtr, tmpReg32);
+
+            tmpReg32 = 0;
+            tmpReg32 |= p_Node->parseCode;
+            WRITE_UINT32(p_AdContLookup->pcAndOffsets, tmpReg32);
+
+            tmpReg32 = 0;
+            tmpReg32 |=
+                    (uint32_t)(XX_VirtToPhys(p_Node->extHashInfo.p_FE) - p_FmPcd->physicalMuramBase);
+            WRITE_UINT32(p_AdContLookup->gmask, tmpReg32);
+
+        } else {
+#endif /* (DPAA_VERSION >= 11) */
         /* cases (1) & (2) */
         tmpReg32 = 0;
         tmpReg32 |= FM_PCD_AD_CONT_LOOKUP_TYPE;
@@ -364,8 +396,19 @@ static void FillAdOfTypeContLookup(t_Handle h_Ad,
         tmpReg32 |= p_Node->parseCode;
         WRITE_UINT32(p_AdContLookup->pcAndOffsets, tmpReg32);
 
-        MemCpy8((void*)&p_AdContLookup->gmask, p_Node->p_GlblMask,
-                    CC_GLBL_MASK_SIZE);
+            if (p_Node->agingSupport)
+            {
+                /* Building a mask of 1-s for all node's keys */
+                agingMask = CC_BUILD_AGING_MASK(p_Node->numOfKeys);
+                memcpy((void*)&p_AdContLookup->gmask, &agingMask,
+                            CC_AGING_MASK_SIZE);
+            }
+            else
+                MemCpy8((void*)&p_AdContLookup->gmask, p_Node->p_GlblMask,
+                            CC_GLBL_MASK_SIZE);
+#if (DPAA_VERSION >= 11)
+        }
+#endif /* (DPAA_VERSION >= 11) */
     }
 }
 
@@ -845,6 +888,7 @@ static t_Error BuildNewAd(t_Handle h_Ad,
     p_FmPcdCcNodeTmp->h_AdTable =
             p_FmPcdModifyCcKeyAdditionalParams->p_AdTableNew;
 
+    p_FmPcdCcNodeTmp->agingSupport = p_CcNode->agingSupport;
     p_FmPcdCcNodeTmp->lclMask = p_CcNode->lclMask;
     p_FmPcdCcNodeTmp->parseCode = p_CcNode->parseCode;
     p_FmPcdCcNodeTmp->offset = p_CcNode->offset;
@@ -889,7 +933,8 @@ static t_Error BuildNewAd(t_Handle h_Ad,
 static t_Error DynamicChangeHc(
         t_Handle h_FmPcd, t_List *h_OldPointersLst, t_List *h_NewPointersLst,
         t_FmPcdModifyCcKeyAdditionalParams *p_AdditionalParams,
-        bool useShadowStructs)
+        bool useShadowStructs,
+        e_ModifyState modifyState)
 {
     t_List *p_PosOld, *p_PosNew;
     uint32_t oldAdAddrOffset, newAdAddrOffset;
@@ -934,7 +979,17 @@ static t_Error DynamicChangeHc(
             }
 
             /* Invoke host command to copy from new AD to old AD */
-            err = FmHcPcdCcDoDynamicChange(((t_FmPcd *)h_FmPcd)->h_Hc,
+	    display_pcd_cc_hc((t_FmPcd *)h_FmPcd, oldAdAddrOffset,
+			newAdAddrOffset);
+            if ((!p_AdditionalParams->tree) &&
+                    (((t_FmPcdCcNode *)(p_AdditionalParams->h_CurrentNode))->agingSupport))
+                err = FmHcPcdCcDoDynamicChangeWithAging(((t_FmPcd *)h_FmPcd)->h_Hc,
+                        oldAdAddrOffset,
+                        newAdAddrOffset,
+                        modifyState,
+                        p_AdditionalParams->savedKeyIndex);
+            else
+                err = FmHcPcdCcDoDynamicChange(((t_FmPcd *)h_FmPcd)->h_Hc,
                                            oldAdAddrOffset, newAdAddrOffset);
             if (err)
             {
@@ -982,7 +1037,8 @@ static t_Error DoDynamicChange(
 
         /* Invoke host-command to copy from the new Ad to existing Ads */
         err = DynamicChangeHc(h_FmPcd, h_OldPointersLst, h_NewPointersLst,
-                              p_AdditionalParams, useShadowStructs);
+                              p_AdditionalParams, useShadowStructs,
+                              p_AdditionalParams->modifyState);
         if (err)
             RETURN_ERROR(MAJOR, err, NO_MSG);
 
@@ -1023,7 +1079,8 @@ static t_Error DoDynamicChange(
 
 			/* HC to copy from the new Ad (old updated structures) to current Ad (uses shadow structures) */
 			err = DynamicChangeHc(h_FmPcd, h_OldPointersLst, h_NewPointersLst,
-								  p_AdditionalParams, useShadowStructs);
+                                  p_AdditionalParams, useShadowStructs,
+                                  e_MODIFY_STATE_CHANGE);
 			if (err)
 				RETURN_ERROR(MAJOR, err, NO_MSG);
 		}
@@ -1038,6 +1095,7 @@ static t_Error DoDynamicChange(
     return E_OK;
 }
 
+#ifndef USE_ENHANCED_EHASH
 static t_Error CcUpdateParam(
         t_Handle h_FmPcd, t_Handle h_PcdParams, t_Handle h_FmPort,
         t_FmPcdCcKeyAndNextEngineParams *p_CcKeyAndNextEngineParams,
@@ -1052,6 +1110,9 @@ static t_Error CcUpdateParam(
 
     level++;
 
+    printk("%s::p_CcKeyAndNextEngineParams %p, numOfEntries %d\n", __FUNCTION__,
+			p_CcKeyAndNextEngineParams, numOfEntries);
+
     if (p_CcTree->h_IpReassemblyManip)
     {
         err = FmPcdManipUpdate(h_FmPcd, h_PcdParams, h_FmPort,
@@ -1079,13 +1140,22 @@ static t_Error CcUpdateParam(
             else
                 h_Ad = PTR_MOVE(h_Ad, FM_PCD_CC_AD_ENTRY_SIZE);
 
+	    printk("%s::.nextEngineParams %p\n", __FUNCTION__,
+			&p_CcKeyAndNextEngineParams[i].nextEngineParams);
             if (p_CcKeyAndNextEngineParams[i].nextEngineParams.nextEngine
                     == e_FM_PCD_CC)
             {
                 p_CcNode =
                         p_CcKeyAndNextEngineParams[i].nextEngineParams.params.ccParams.h_CcNode;
+		printk("%s::next engine is CC, node %p\n", __FUNCTION__, p_CcNode);
                 ASSERT_COND(p_CcNode);
 
+#if (DPAA_VERSION >= 11)
+		printk("%s::p_CcNode->externalHash %d\n", __FUNCTION__,
+				p_CcNode->externalHash);
+                if (p_CcNode->externalHash)
+                    FmPortSetFESupport(h_FmPort);
+#endif /* (DPAA_VERSION >= 11) */
                 if (p_CcKeyAndNextEngineParams[i].nextEngineParams.h_Manip)
                 {
                     err =
@@ -1114,6 +1184,9 @@ static t_Error CcUpdateParam(
             }
             else
             {
+		printk("%s::next engine is %d, h_manip %p\n", __FUNCTION__,		
+			p_CcKeyAndNextEngineParams[i].nextEngineParams.nextEngine,
+                	p_CcKeyAndNextEngineParams[i].nextEngineParams.h_Manip);
                 if (p_CcKeyAndNextEngineParams[i].nextEngineParams.h_Manip)
                 {
                     err =
@@ -1132,6 +1205,20 @@ static t_Error CcUpdateParam(
 
     return E_OK;
 }
+#else
+static t_Error CcUpdateParam(
+        t_Handle h_FmPcd, t_Handle h_PcdParams, t_Handle h_FmPort,
+        t_FmPcdCcKeyAndNextEngineParams *p_CcKeyAndNextEngineParams,
+        uint16_t numOfEntries, t_Handle h_Ad, bool validate, uint16_t level,
+        t_Handle h_FmTree, bool modify)
+{
+#if (DPAA_VERSION >= 11)
+  //  FmPortSetFESupport(h_FmPort);
+    return E_OK;
+#endif /* (DPAA_VERSION >= 11) */
+
+}
+#endif
 
 static ccPrivateInfo_t IcDefineCode(t_FmPcdCcNodeParams *p_CcNodeParam)
 {
@@ -1232,6 +1319,13 @@ static void DeleteNode(t_FmPcdCcNode *p_CcNode)
         p_CcNode->h_TmpAd = NULL;
     }
 
+    if (p_CcNode->h_TmpAd)
+    {
+        FM_MURAM_FreeMem(FmPcdGetMuramHandle(p_CcNode->h_FmPcd),
+                         p_CcNode->h_TmpAd);
+        p_CcNode->h_TmpAd = NULL;
+    }
+
     if (p_CcNode->h_StatsFLRs)
     {
         FM_MURAM_FreeMem(FmPcdGetMuramHandle(p_CcNode->h_FmPcd),
@@ -1247,7 +1341,8 @@ static void DeleteNode(t_FmPcdCcNode *p_CcNode)
 
     /* Restore the original counters pointer instead of the mutual pointer (mutual to all hash buckets) */
     if (p_CcNode->isHashBucket
-            && (p_CcNode->statisticsMode != e_FM_PCD_CC_STATS_MODE_NONE))
+            && (p_CcNode->statisticsMode != e_FM_PCD_CC_STATS_MODE_NONE) &&
+            p_CcNode->keyAndNextEngineParams[p_CcNode->numOfKeys].p_StatsObj)
         p_CcNode->keyAndNextEngineParams[p_CcNode->numOfKeys].p_StatsObj->h_StatsCounters =
                 p_CcNode->h_PrivMissStatsCounters;
 
@@ -1605,14 +1700,18 @@ t_Error ValidateNextEngineParams(
             if (relativeSchemeId == FM_PCD_KG_NUM_OF_SCHEMES)
                 RETURN_ERROR(MAJOR, E_NOT_IN_RANGE, NO_MSG);
             if (!FmPcdKgIsSchemeValidSw(
-                    p_FmPcdCcNextEngineParams->params.kgParams.h_DirectScheme))
+                    p_FmPcdCcNextEngineParams->params.kgParams.h_DirectScheme)) 
                 RETURN_ERROR(MAJOR, E_INVALID_STATE,
                              ("not valid schemeIndex in KG next engine param"));
+	    
+#if 0
+	    //we need to allow any scheme to be part of the KG next engine param
             if (!KgIsSchemeAlwaysDirect(h_FmPcd, relativeSchemeId))
                 RETURN_ERROR(
                         MAJOR,
                         E_INVALID_STATE,
                         ("CC Node may point only to a scheme that is always direct."));
+#endif
             break;
 
         case (e_FM_PCD_PLCR):
@@ -1664,7 +1763,8 @@ t_Error ValidateNextEngineParams(
 static uint8_t GetGenParseCode(e_FmPcdExtractFrom src,
                                uint32_t offset, bool glblMask,
                                uint8_t *parseArrayOffset, bool fromIc,
-                               ccPrivateInfo_t icCode)
+                               ccPrivateInfo_t icCode,
+                               bool aging)
 {
     if (!fromIc)
     {
@@ -1694,7 +1794,10 @@ static uint8_t GetGenParseCode(e_FmPcdExtractFrom src,
         {
             case (CC_PRIVATE_INFO_IC_KEY_EXACT_MATCH):
                 *parseArrayOffset = 0x50;
-                return CC_PC_GENERIC_IC_GMASK;
+                if (aging)
+                    return CC_PC_GENERIC_IC_AGING_MASK;
+                else
+                    return CC_PC_GENERIC_IC_GMASK;
 
             case (CC_PRIVATE_INFO_IC_HASH_EXACT_MATCH):
                 *parseArrayOffset = 0x48;
@@ -3454,6 +3557,7 @@ static t_FmPcdModifyCcKeyAdditionalParams * ModifyNodeCommonPart(
 
     p_FmPcdModifyCcKeyAdditionalParams->h_CurrentNode = h_FmPcdCcNodeOrTree;
     p_FmPcdModifyCcKeyAdditionalParams->savedKeyIndex = keyIndex;
+    p_FmPcdModifyCcKeyAdditionalParams->modifyState = modifyState;
 
     while (i < numOfKeys)
     {
@@ -4057,6 +4161,7 @@ static t_Error ModifyNextEngineParamNode(
         RETURN_ERROR(MAJOR, err, NO_MSG);
     }
 
+    display_cc_node(p_CcNode, __FUNCTION__);
     err = DoDynamicChange(p_FmPcd, &h_OldPointersLst, &h_NewPointersLst,
                           p_ModifyKeyParams, FALSE);
 
@@ -4483,7 +4588,7 @@ static t_Error MatchTableSet(t_Handle h_FmPcd, t_FmPcdCcNode *p_CcNode,
             p_CcNode->parseCode = GetGenParseCode(
                     p_CcNodeParam->extractCcParams.extractNonHdr.src,
                     p_CcNode->offset, glblMask, &p_CcNode->prsArrayOffset,
-                    fromIc, icCode);
+                    fromIc, icCode, p_CcNode->agingSupport);
 
             if (p_CcNode->parseCode == CC_PC_GENERIC_IC_HASH_INDEXED)
             {
@@ -4497,6 +4602,7 @@ static t_Error MatchTableSet(t_Handle h_FmPcd, t_FmPcdCcNode *p_CcNode,
                 }
             }
             if ((p_CcNode->parseCode == CC_PC_GENERIC_IC_GMASK)
+                    || (p_CcNode->parseCode == CC_PC_GENERIC_IC_AGING_MASK)
                     || (p_CcNode->parseCode == CC_PC_GENERIC_IC_HASH_INDEXED))
             {
                 p_CcNode->offset += p_CcNode->prsArrayOffset;
@@ -4526,6 +4632,9 @@ static t_Error MatchTableSet(t_Handle h_FmPcd, t_FmPcdCcNode *p_CcNode,
     if (p_CcNodeParam->keysParams.keySize != p_CcNode->sizeOfExtraction)
     {
         DeleteNode(p_CcNode);
+	printk("keySize %d, sizeOfExtraction %d\n",
+		p_CcNodeParam->keysParams.keySize,  
+		p_CcNode->sizeOfExtraction);
         RETURN_ERROR(MAJOR, E_INVALID_VALUE,
                      ("keySize has to be equal to sizeOfExtraction"));
     }
@@ -4839,127 +4948,1158 @@ static t_Error MatchTableSet(t_Handle h_FmPcd, t_FmPcdCcNode *p_CcNode,
 
     return E_OK;
 }
-/************************** End of static functions **************************/
-
-/*****************************************************************************/
-/*              Inter-module API routines                                    */
-/*****************************************************************************/
 
-t_CcNodeInformation* FindNodeInfoInReleventLst(t_List *p_List, t_Handle h_Info,
-                                               t_Handle h_Spinlock)
+#ifndef USE_ENHANCED_EHASH
+static t_Handle InternalHashTableSet(t_Handle h_FmPcd, t_FmPcdHashTableParams *p_Param)
 {
-    t_CcNodeInformation *p_CcInformation;
-    t_List *p_Pos;
-    uint32_t intFlags;
+    t_FmPcdCcNode *p_CcNodeHashTbl;
+    t_FmPcdCcNodeParams *p_IndxHashCcNodeParam, *p_ExactMatchCcNodeParam;
+    t_FmPcdCcNode *p_CcNode;
+    t_Handle h_MissStatsCounters = NULL;
+    t_FmPcdCcKeyParams *p_HashKeyParams;
+    int i;
+    uint16_t numOfSets, numOfWays, countMask, onesCount = 0;
+    bool statsEnForMiss = FALSE;
+    t_Error err;
 
-    intFlags = XX_LockIntrSpinlock(h_Spinlock);
+    p_ExactMatchCcNodeParam = (t_FmPcdCcNodeParams*)XX_Malloc(
+            sizeof(t_FmPcdCcNodeParams));
+    if (!p_ExactMatchCcNodeParam)
+    {
+        REPORT_ERROR(MAJOR, E_NO_MEMORY, ("p_ExactMatchCcNodeParam"));
+        return NULL;
+    }
+    memset(p_ExactMatchCcNodeParam, 0, sizeof(t_FmPcdCcNodeParams));
 
-    for (p_Pos = LIST_FIRST(p_List); p_Pos != (p_List);
-            p_Pos = LIST_NEXT(p_Pos))
+    p_IndxHashCcNodeParam = (t_FmPcdCcNodeParams*)XX_Malloc(
+            sizeof(t_FmPcdCcNodeParams));
+    if (!p_IndxHashCcNodeParam)
     {
-        p_CcInformation = CC_NODE_F_OBJECT(p_Pos);
+        XX_Free(p_ExactMatchCcNodeParam);
+        REPORT_ERROR(MAJOR, E_NO_MEMORY, ("p_IndxHashCcNodeParam"));
+        return NULL;
+    }
+    memset(p_IndxHashCcNodeParam, 0, sizeof(t_FmPcdCcNodeParams));
 
-        ASSERT_COND(p_CcInformation->h_CcNode);
+    /* Calculate number of sets and number of ways of the hash table */
+    countMask = (uint16_t)(p_Param->hashResMask >> 4);
+    while (countMask)
+    {
+        onesCount++;
+        countMask = (uint16_t)(countMask >> 1);
+    }
 
-        if (p_CcInformation->h_CcNode == h_Info)
+    numOfSets = (uint16_t)(1 << onesCount);
+    numOfWays = (uint16_t)DIV_CEIL(p_Param->maxNumOfKeys, numOfSets);
+
+    if (p_Param->maxNumOfKeys % numOfSets)
+        DBG(INFO, ("'maxNumOfKeys' is not a multiple of hash number of ways, so number of ways will be rounded up"));
+
+    if ((p_Param->agingSupport) && (numOfWays > 31))
+    {
+        XX_Free(p_ExactMatchCcNodeParam);
+        REPORT_ERROR(MAJOR, E_INVALID_VALUE,
+                     ("Aging supported enabled and %d keys requested per hash bucket. Aging cannot be supported when more then 31 keys", numOfWays));
+        return NULL;
+    }
+
+    if ((p_Param->statisticsMode == e_FM_PCD_CC_STATS_MODE_FRAME)
+            || (p_Param->statisticsMode == e_FM_PCD_CC_STATS_MODE_BYTE_AND_FRAME))
+    {
+        /* Allocating a statistics counters table that will be used by all
+         'miss' entries of the hash table */
+        h_MissStatsCounters = (t_Handle)FM_MURAM_AllocMem(
+                FmPcdGetMuramHandle(h_FmPcd), 2 * FM_PCD_CC_STATS_COUNTER_SIZE,
+                FM_PCD_CC_AD_TABLE_ALIGN);
+        if (!h_MissStatsCounters)
         {
-            XX_UnlockIntrSpinlock(h_Spinlock, intFlags);
-            return p_CcInformation;
+            REPORT_ERROR(MAJOR, E_NO_MEMORY, ("MURAM allocation for statistics table for hash miss"));
+            XX_Free(p_IndxHashCcNodeParam);
+            XX_Free(p_ExactMatchCcNodeParam);
+            return NULL;
         }
+        memset(h_MissStatsCounters, 0, (2 * FM_PCD_CC_STATS_COUNTER_SIZE));
+
+        /* Always enable statistics for 'miss', so that a statistics AD will be
+         initialized from the start. We'll store the requested 'statistics enable'
+         value and it will be used when statistics are read by the user. */
+        statsEnForMiss = p_Param->ccNextEngineParamsForMiss.statisticsEn;
+        p_Param->ccNextEngineParamsForMiss.statisticsEn = TRUE;
     }
 
-    XX_UnlockIntrSpinlock(h_Spinlock, intFlags);
+    /* Building exact-match node params, will be used to create the hash buckets */
+    p_ExactMatchCcNodeParam->extractCcParams.type = e_FM_PCD_EXTRACT_NON_HDR;
 
-    return NULL;
-}
+    p_ExactMatchCcNodeParam->extractCcParams.extractNonHdr.src =
+            e_FM_PCD_EXTRACT_FROM_KEY;
+    p_ExactMatchCcNodeParam->extractCcParams.extractNonHdr.action =
+            e_FM_PCD_ACTION_EXACT_MATCH;
+    p_ExactMatchCcNodeParam->extractCcParams.extractNonHdr.offset = 0;
+    p_ExactMatchCcNodeParam->extractCcParams.extractNonHdr.size =
+            p_Param->matchKeySize;
 
-void EnqueueNodeInfoToRelevantLst(t_List *p_List, t_CcNodeInformation *p_CcInfo,
-                                  t_Handle h_Spinlock)
-{
-    t_CcNodeInformation *p_CcInformation;
-    uint32_t intFlags = 0;
+    p_ExactMatchCcNodeParam->keysParams.maxNumOfKeys = numOfWays;
+    p_ExactMatchCcNodeParam->keysParams.maskSupport = FALSE;
+    p_ExactMatchCcNodeParam->keysParams.statisticsMode =
+            p_Param->statisticsMode;
+    p_ExactMatchCcNodeParam->keysParams.numOfKeys = 0;
+    p_ExactMatchCcNodeParam->keysParams.keySize = p_Param->matchKeySize;
+    p_ExactMatchCcNodeParam->keysParams.ccNextEngineParamsForMiss =
+            p_Param->ccNextEngineParamsForMiss;
 
-    p_CcInformation = (t_CcNodeInformation *)XX_Malloc(
-            sizeof(t_CcNodeInformation));
+    p_HashKeyParams = p_IndxHashCcNodeParam->keysParams.keyParams;
 
-    if (p_CcInformation)
+    for (i = 0; i < numOfSets; i++)
     {
-        memset(p_CcInformation, 0, sizeof(t_CcNodeInformation));
-        memcpy(p_CcInformation, p_CcInfo, sizeof(t_CcNodeInformation));
-        INIT_LIST(&p_CcInformation->node);
+        /* Each exact-match node will be marked as a 'bucket' and provided with
+           a pointer to statistics counters, to be used for 'miss' entry
+           statistics */
+        p_CcNode = (t_FmPcdCcNode *)XX_Malloc(sizeof(t_FmPcdCcNode));
+        if (!p_CcNode)
+            break;
+        memset(p_CcNode, 0, sizeof(t_FmPcdCcNode));
 
-        if (h_Spinlock)
-            intFlags = XX_LockIntrSpinlock(h_Spinlock);
+        p_CcNode->isHashBucket = TRUE;
+        p_CcNode->agingSupport = p_Param->agingSupport;
+        p_CcNode->h_MissStatsCounters = h_MissStatsCounters;
 
-        LIST_AddToTail(&p_CcInformation->node, p_List);
+        err = MatchTableSet(h_FmPcd, p_CcNode, p_ExactMatchCcNodeParam);
+        if (err)
+            break;
 
-        if (h_Spinlock)
-            XX_UnlockIntrSpinlock(h_Spinlock, intFlags);
+        p_HashKeyParams[i].ccNextEngineParams.nextEngine = e_FM_PCD_CC;
+        p_HashKeyParams[i].ccNextEngineParams.statisticsEn = FALSE;
+        p_HashKeyParams[i].ccNextEngineParams.params.ccParams.h_CcNode =
+                p_CcNode;
     }
-    else
-        REPORT_ERROR(MAJOR, E_NO_MEMORY, ("CC Node Information"));
-}
 
-void DequeueNodeInfoFromRelevantLst(t_List *p_List, t_Handle h_Info,
-                                    t_Handle h_Spinlock)
-{
-    t_CcNodeInformation *p_CcInformation = NULL;
-    uint32_t intFlags = 0;
-    t_List *p_Pos;
+    if (i < numOfSets)
+    {
+        for (i = i - 1; i >= 0; i--)
+            FM_PCD_MatchTableDelete(
+                    p_HashKeyParams[i].ccNextEngineParams.params.ccParams.h_CcNode);
 
-    if (h_Spinlock)
-        intFlags = XX_LockIntrSpinlock(h_Spinlock);
+        FM_MURAM_FreeMem(FmPcdGetMuramHandle(h_FmPcd), h_MissStatsCounters);
 
-    if (LIST_IsEmpty(p_List))
-    {
-        XX_RestoreAllIntr(intFlags);
-        return;
+        REPORT_ERROR(MAJOR, E_NULL_POINTER, NO_MSG);
+        XX_Free(p_IndxHashCcNodeParam);
+        XX_Free(p_ExactMatchCcNodeParam);
+        return NULL;
     }
 
-    for (p_Pos = LIST_FIRST(p_List); p_Pos != (p_List);
-            p_Pos = LIST_NEXT(p_Pos))
-    {
-        p_CcInformation = CC_NODE_F_OBJECT(p_Pos);
-        ASSERT_COND(p_CcInformation);
-        ASSERT_COND(p_CcInformation->h_CcNode);
-        if (p_CcInformation->h_CcNode == h_Info)
-            break;
-    }
+    /* Creating indexed-hash CC node */
+    p_IndxHashCcNodeParam->extractCcParams.type = e_FM_PCD_EXTRACT_NON_HDR;
+    p_IndxHashCcNodeParam->extractCcParams.extractNonHdr.src =
+            e_FM_PCD_EXTRACT_FROM_HASH;
+    p_IndxHashCcNodeParam->extractCcParams.extractNonHdr.action =
+            e_FM_PCD_ACTION_INDEXED_LOOKUP;
+    p_IndxHashCcNodeParam->extractCcParams.extractNonHdr.icIndxMask =
+            p_Param->hashResMask;
+    p_IndxHashCcNodeParam->extractCcParams.extractNonHdr.offset =
+            p_Param->hashShift;
+    p_IndxHashCcNodeParam->extractCcParams.extractNonHdr.size = 2;
 
-    if (p_CcInformation)
+    p_IndxHashCcNodeParam->keysParams.maxNumOfKeys = numOfSets;
+    p_IndxHashCcNodeParam->keysParams.maskSupport = FALSE;
+    p_IndxHashCcNodeParam->keysParams.statisticsMode =
+            e_FM_PCD_CC_STATS_MODE_NONE;
+    /* Number of keys of this node is number of sets of the hash */
+    p_IndxHashCcNodeParam->keysParams.numOfKeys = numOfSets;
+    p_IndxHashCcNodeParam->keysParams.keySize = 2;
+
+    p_CcNodeHashTbl = FM_PCD_MatchTableSet(h_FmPcd, p_IndxHashCcNodeParam);
+
+    if (p_CcNodeHashTbl)
     {
-        LIST_DelAndInit(&p_CcInformation->node);
-        XX_Free(p_CcInformation);
+        /* Storing the allocated counters for buckets 'miss' in the hash table,
+         and if statistics for miss were enabled. */
+        p_CcNodeHashTbl->h_MissStatsCounters = h_MissStatsCounters;
+        p_CcNodeHashTbl->statsEnForMiss = statsEnForMiss;
     }
 
-    if (h_Spinlock)
-        XX_UnlockIntrSpinlock(h_Spinlock, intFlags);
+    XX_Free(p_IndxHashCcNodeParam);
+    XX_Free(p_ExactMatchCcNodeParam);
+
+    return p_CcNodeHashTbl;
 }
 
-void NextStepAd(t_Handle h_Ad, t_FmPcdCcStatsParams *p_FmPcdCcStatsParams,
-                t_FmPcdCcNextEngineParams *p_FmPcdCcNextEngineParams,
-                t_FmPcd *p_FmPcd)
+static t_Error InternalHashTableDelete(t_FmPcdCcNode *p_HashTbl)
 {
-    switch (p_FmPcdCcNextEngineParams->nextEngine)
-    {
-        case (e_FM_PCD_KG):
-        case (e_FM_PCD_PLCR):
-        case (e_FM_PCD_DONE):
-            /* if NIA is not CC, create a "result" type AD */
-            FillAdOfTypeResult(h_Ad, p_FmPcdCcStatsParams, p_FmPcd,
-                               p_FmPcdCcNextEngineParams);
-            break;
-        case (e_FM_PCD_FR):
-            if (p_FmPcdCcNextEngineParams->params.frParams.h_FrmReplic)
-            {
-                FillAdOfTypeContLookup(
-                        h_Ad, p_FmPcdCcStatsParams, p_FmPcd,
-                        p_FmPcdCcNextEngineParams->params.ccParams.h_CcNode,
-                        p_FmPcdCcNextEngineParams->h_Manip,
-                        p_FmPcdCcNextEngineParams->params.frParams.h_FrmReplic);
-                FrmReplicGroupUpdateOwner(
-                        p_FmPcdCcNextEngineParams->params.frParams.h_FrmReplic,
-                        TRUE/* add */);
+    t_Handle h_FmPcd;
+    t_Handle *p_HashBuckets, h_MissStatsCounters;
+    uint16_t i, numOfBuckets;
+    t_Error err;
+
+    /* Store all hash buckets before the hash is freed */
+    numOfBuckets = p_HashTbl->numOfKeys;
+
+    p_HashBuckets = (t_Handle *)XX_Malloc(numOfBuckets * sizeof(t_Handle));
+    if (!p_HashBuckets)
+        RETURN_ERROR(MAJOR, E_NO_MEMORY, NO_MSG);
+
+    for (i = 0; i < numOfBuckets; i++)
+        p_HashBuckets[i] =
+                p_HashTbl->keyAndNextEngineParams[i].nextEngineParams.params.ccParams.h_CcNode;
+
+    h_FmPcd = p_HashTbl->h_FmPcd;
+    h_MissStatsCounters = p_HashTbl->h_MissStatsCounters;
+
+    /* Free the hash */
+    err = FM_PCD_MatchTableDelete(p_HashTbl);
+
+    /* Free each hash bucket */
+    for (i = 0; i < numOfBuckets; i++)
+        err |= FM_PCD_MatchTableDelete(p_HashBuckets[i]);
+
+    XX_Free(p_HashBuckets);
+
+    /* Free statistics counters for 'miss', if these were allocated */
+    if (h_MissStatsCounters)
+        FM_MURAM_FreeMem(FmPcdGetMuramHandle(h_FmPcd), h_MissStatsCounters);
+
+    if (err)
+        RETURN_ERROR(MAJOR, err, NO_MSG);
+
+    return E_OK;
+}
+
+static t_Error InternalHashTableAddKey(t_Handle h_HashTbl, uint8_t keySize,
+                                       t_FmPcdCcKeyParams *p_KeyParams)
+{
+    t_FmPcdCcNode *p_HashTbl = (t_FmPcdCcNode *)h_HashTbl;
+    t_Handle h_HashBucket;
+    uint8_t bucketIndex;
+    uint16_t lastIndex;
+    t_Error err;
+
+    SANITY_CHECK_RETURN_ERROR(p_HashTbl, E_INVALID_HANDLE);
+    SANITY_CHECK_RETURN_ERROR(p_KeyParams, E_NULL_POINTER);
+    SANITY_CHECK_RETURN_ERROR(p_KeyParams->p_Key, E_NULL_POINTER);
+
+    err = FM_PCD_MatchTableGetIndexedHashBucket(p_HashTbl, keySize,
+                                                p_KeyParams->p_Key,
+                                                0,
+                                                &h_HashBucket, &bucketIndex,
+                                                &lastIndex);
+    if (err)
+        RETURN_ERROR(MAJOR, err, NO_MSG);
+
+    return FM_PCD_MatchTableAddKey(h_HashBucket, FM_PCD_LAST_KEY_INDEX, keySize,
+                                   p_KeyParams);
+}
+
+/**
+ * Removes a specified key from Internal Hash Table
+ *
+ * @param[in] h_HashTbl Handle to hash table where to remove the key
+ * @param[in] keySize The size of Key to be removed
+ * @param[in] p_Key Pointer to key to be removed
+ *
+ * @return E_OK on success; Error code otherwise.
+ */
+static t_Error InternalHashTableRemoveKey(t_Handle h_HashTbl, uint8_t keySize,
+                                          uint8_t *p_Key)
+{
+    t_FmPcdCcNode *p_HashTbl = (t_FmPcdCcNode *)h_HashTbl;
+    t_Handle h_HashBucket;
+    uint8_t bucketIndex;
+    uint16_t lastIndex;
+    t_Error err;
+
+    SANITY_CHECK_RETURN_ERROR(p_HashTbl, E_INVALID_HANDLE);
+    SANITY_CHECK_RETURN_ERROR(p_Key, E_NULL_POINTER);
+
+    err = FM_PCD_MatchTableGetIndexedHashBucket(p_HashTbl, keySize, p_Key,
+                                                0,
+                                                &h_HashBucket, &bucketIndex,
+                                                &lastIndex);
+    if (err)
+        RETURN_ERROR(MAJOR, err, NO_MSG);
+
+    return FM_PCD_MatchTableFindNRemoveKey(h_HashBucket, keySize, p_Key, NULL);
+}
+
+static t_Error InternalHashTableModifyNextEngine(t_Handle h_HashTbl, uint8_t keySize, uint8_t *p_Key,
+                                                 t_FmPcdCcNextEngineParams *p_FmPcdCcNextEngineParams)
+{
+    t_FmPcdCcNode *p_HashTbl = (t_FmPcdCcNode *)h_HashTbl;
+    t_Handle h_HashBucket;
+    uint8_t bucketIndex;
+    uint16_t lastIndex;
+    t_Error err;
+
+    SANITY_CHECK_RETURN_ERROR(p_HashTbl, E_INVALID_HANDLE);
+    SANITY_CHECK_RETURN_ERROR(p_Key, E_NULL_POINTER);
+    SANITY_CHECK_RETURN_ERROR(p_FmPcdCcNextEngineParams, E_NULL_POINTER);
+
+    err = FM_PCD_MatchTableGetIndexedHashBucket(p_HashTbl, keySize, p_Key,
+                                                0,
+                                                &h_HashBucket, &bucketIndex,
+                                                &lastIndex);
+    if (err)
+        RETURN_ERROR(MAJOR, err, NO_MSG);
+
+    return FM_PCD_MatchTableFindNModifyNextEngine(h_HashBucket, keySize, p_Key,
+                                                  NULL,
+                                                  p_FmPcdCcNextEngineParams);
+}
+
+static t_Error InternalHashTableModifyMissNextEngine(t_Handle h_HashTbl, t_FmPcdCcNextEngineParams *p_FmPcdCcNextEngineParams)
+{
+    t_FmPcdCcNode *p_HashTbl = (t_FmPcdCcNode *)h_HashTbl;
+    t_Handle h_HashBucket;
+    uint8_t i;
+    bool nullifyMissStats = FALSE;
+    t_Error err;
+
+    SANITY_CHECK_RETURN_ERROR(p_HashTbl, E_INVALID_HANDLE);
+
+    if ((!p_HashTbl->h_MissStatsCounters)
+            && (p_FmPcdCcNextEngineParams->statisticsEn))
+        RETURN_ERROR(
+                MAJOR,
+                E_CONFLICT,
+                ("Statistics are requested for a key, but statistics mode was set"
+                "to 'NONE' upon initialization"));
+
+    if (p_HashTbl->h_MissStatsCounters)
+    {
+        if ((!p_HashTbl->statsEnForMiss)
+                && (p_FmPcdCcNextEngineParams->statisticsEn))
+            nullifyMissStats = TRUE;
+
+        if ((p_HashTbl->statsEnForMiss)
+                && (!p_FmPcdCcNextEngineParams->statisticsEn))
+        {
+            p_HashTbl->statsEnForMiss = FALSE;
+            p_FmPcdCcNextEngineParams->statisticsEn = TRUE;
+        }
+    }
+
+    for (i = 0; i < p_HashTbl->numOfKeys; i++)
+    {
+        h_HashBucket =
+                p_HashTbl->keyAndNextEngineParams[i].nextEngineParams.params.ccParams.h_CcNode;
+
+        err = FM_PCD_MatchTableModifyMissNextEngine(h_HashBucket,
+                                                    p_FmPcdCcNextEngineParams);
+        if (err)
+            RETURN_ERROR(MAJOR, err, NO_MSG);
+    }
+
+    if (nullifyMissStats)
+    {
+        memset(p_HashTbl->h_MissStatsCounters, 0,
+               (2 * FM_PCD_CC_STATS_COUNTER_SIZE));
+        memset(p_HashTbl->h_MissStatsCounters, 0,
+               (2 * FM_PCD_CC_STATS_COUNTER_SIZE));
+        p_HashTbl->statsEnForMiss = TRUE;
+    }
+
+    return E_OK;
+}
+#endif /* USE_ENHANCED_EHASH */
+
+#if (DPAA_VERSION >= 11)
+void get_indexed_hash_bucket(uint8_t key_size,
+	uint8_t *key_ptr,
+	uint8_t crc_shift,
+	uint16_t mask,
+	uint16_t *bucket_index)
+{
+	uint64_t crc64 = 0;
+
+	crc64 = crc64_init();
+	crc64 = crc64_compute(key_ptr, key_size, crc64);
+
+	crc64 >>= ((6 - crc_shift) << 3);
+	*bucket_index = (uint16_t)crc64 & mask;
+}
+
+#ifndef USE_ENHANCED_EHASH
+static int ext_hash_table_create(t_FmPcdHashTableParams *table_params,
+	void *table_handle)
+{
+	uint32_t temp;
+	uint8_t num_of_zeroes = 0;
+	uint32_t bit_counter;
+	int num_dynamic_buckets;
+	uint16_t hash_mask_temp;
+	int i;
+	t_FmPcdCcNodeExtHashInfo *table_struct_ptr;
+
+    SANITY_CHECK_RETURN_ERROR(table_params, E_NULL_POINTER);
+    SANITY_CHECK_RETURN_ERROR(table_handle, E_INVALID_HANDLE);
+
+    table_struct_ptr = &(((t_FmPcdCcNode *)(table_handle))->extHashInfo);
+
+	temp = (uint32_t)table_params->hashResMask;
+#ifdef CONFIG_FMAN_ARM
+	__asm__ ("clz %0,%1\n"
+			: "=r"(num_of_zeroes)
+			: "r"(temp));
+#else
+	__asm__ ("cntlzw %0,%1\n"
+			: "=r"(num_of_zeroes)
+			: "r"(temp));
+#endif
+	table_struct_ptr->hash_size = 32 - num_of_zeroes;
+
+	/* Allocation of the static buckets */
+	table_struct_ptr->table_base_ptr =
+		(t_FmExtHashBucket *)XX_MallocSmart(
+			CC_EXT_HASH_BUCKET_SIZE << (table_struct_ptr->hash_size),
+			table_params->externalHashParams.dataMemId,
+			256);
+	if (!table_struct_ptr->table_base_ptr) {
+		REPORT_ERROR(MAJOR, E_NO_MEMORY, ("malloc failed in function ext_hash_table_create"));
+		XX_FreeSmart(table_struct_ptr);
+		return -ENOMEM;
+	}
+	MemSet64(table_struct_ptr->table_base_ptr,
+			0,
+			CC_EXT_HASH_BUCKET_SIZE << (table_struct_ptr->hash_size));
+
+	table_struct_ptr->key_size = table_params->matchKeySize;
+	if (table_params->matchKeySize < 2) {
+		table_struct_ptr->aligned_key_size = 2;
+		table_struct_ptr->max_ways = 13;
+	} else {
+		if (table_params->matchKeySize < 4) {
+			table_struct_ptr->aligned_key_size = 4;
+			table_struct_ptr->max_ways = 12;
+		} else {
+			if (table_params->matchKeySize < 8) {
+				table_struct_ptr->aligned_key_size = 8;
+				table_struct_ptr->max_ways = 10;
+			} else {
+				if (table_params->matchKeySize < 16) {
+					table_struct_ptr->aligned_key_size = 16;
+					table_struct_ptr->max_ways = 7;
+				} else {
+					if (table_params->matchKeySize < 24) {
+						table_struct_ptr->aligned_key_size = 24;
+						table_struct_ptr->max_ways = 6;
+					} else {
+						if (table_params->matchKeySize < 32) {
+							table_struct_ptr->aligned_key_size = 32;
+							table_struct_ptr->max_ways = 5;
+						} else {
+							if (table_params->matchKeySize < 40) {
+								table_struct_ptr->aligned_key_size = 40;
+								table_struct_ptr->max_ways = 4;
+							} else {
+								if (table_params->matchKeySize < 48) {
+									table_struct_ptr->aligned_key_size = 48;
+									table_struct_ptr->max_ways = 3;
+								} else {
+									if (table_params->matchKeySize < 56) {
+										table_struct_ptr->aligned_key_size = 56;
+										table_struct_ptr->max_ways = 3;
+									} else {
+										REPORT_ERROR(MAJOR, E_NOT_IN_RANGE, ("Key size too big"));
+										XX_FreeSmart(table_struct_ptr->hash_bucket_pool.bucket_pool_base_ptr);
+										XX_FreeSmart(table_struct_ptr->table_base_ptr);
+										XX_FreeSmart(table_struct_ptr);
+										return -EINVAL;
+									}
+								}
+							}
+						}
+					}
+				}
+			}
+		}
+	}
+
+	/* Count number of ones in the mask */
+	hash_mask_temp = table_params->hashResMask;
+	bit_counter = 0;
+	for(i=0; i < 16; i++)
+	{
+		if(hash_mask_temp&0x8000)
+		{
+			bit_counter++;
+		}
+		hash_mask_temp<<=1;
+	}
+
+	/* Calculate the number of static buckets */
+	num_dynamic_buckets = 1 << bit_counter;
+
+	/* Initialize static buckets:
+	 * If no next bucket exists, should point to itself:*/
+	for (i = 0; i < num_dynamic_buckets; i++) {
+		WRITE_UINT32(table_struct_ptr->table_base_ptr[i].next_bucket_addr,
+			(uint32_t)(XX_VirtToPhys(&table_struct_ptr->table_base_ptr[i]) & 0xffffffff));
+	}
+
+	/* Calculate the number of dynamic buckets */
+	num_dynamic_buckets = table_params->maxNumOfKeys/(table_struct_ptr->max_ways) + 1 - num_dynamic_buckets;
+	if(num_dynamic_buckets > 0)
+	{
+
+		/* Allocation of the dynamic buckets */
+		table_struct_ptr->hash_bucket_pool.bucket_pool_base_ptr = XX_MallocSmart(
+			(uint32_t)(CC_EXT_HASH_BUCKET_SIZE * num_dynamic_buckets),
+			table_params->externalHashParams.dataMemId,
+			256);
+		if (!table_struct_ptr->hash_bucket_pool.bucket_pool_base_ptr) {
+			REPORT_ERROR(MAJOR, E_NO_MEMORY, ("malloc failed in function ext_hash_table_create"));
+			XX_FreeSmart(table_struct_ptr->table_base_ptr);
+			XX_FreeSmart(table_struct_ptr);
+			return -ENOMEM;
+		}
+		MemSet64(table_struct_ptr->hash_bucket_pool.bucket_pool_base_ptr,
+			0,
+			(uint32_t)(CC_EXT_HASH_BUCKET_SIZE * num_dynamic_buckets));
+
+		/* Allocation of the dynamic buckets pool management struct */
+		table_struct_ptr->hash_bucket_pool.bucket_stack = XX_MallocSmart(
+			(uint32_t)(num_dynamic_buckets * sizeof(t_FmExtHashBucket*)),
+			table_params->externalHashParams.dataMemId,
+			64);
+		if (!table_struct_ptr->hash_bucket_pool.bucket_stack) {
+			REPORT_ERROR(MAJOR, E_NO_MEMORY, ("malloc failed in function ext_hash_table_create"));
+			XX_FreeSmart(table_struct_ptr->hash_bucket_pool.bucket_pool_base_ptr);
+			XX_FreeSmart(table_struct_ptr->table_base_ptr);
+			XX_FreeSmart(table_struct_ptr);
+			return -ENOMEM;
+		}
+
+		table_struct_ptr->hash_bucket_pool.last_bucket = (uint32_t)(num_dynamic_buckets- 1);
+		for (i = 0; i < num_dynamic_buckets; i++)
+			table_struct_ptr->hash_bucket_pool.bucket_stack[i] = (t_FmExtHashBucket*)
+				(table_struct_ptr->hash_bucket_pool.bucket_pool_base_ptr + (i<<8));
+	}
+	else
+	{
+		/* There is no dynamic buckets needed */
+		num_dynamic_buckets = 0;
+		table_struct_ptr->hash_bucket_pool.bucket_pool_base_ptr = NULL;
+		table_struct_ptr->hash_bucket_pool.bucket_stack = NULL;
+		table_struct_ptr->hash_bucket_pool.last_bucket = -1;
+	}
+	DBG(TRACE, ("ext_hash_table_create() num_dynamic_buckets: %d", num_dynamic_buckets));
+
+	table_struct_ptr->hash_mask = table_params->hashResMask;
+	table_struct_ptr->crc_shift = table_params->hashShift;
+
+	return E_OK;
+}
+
+static void ext_hash_table_delete(void *table_handle)
+{
+	t_FmPcdCcNodeExtHashInfo *table_struct_ptr;
+
+	SANITY_CHECK_RETURN(table_handle, E_INVALID_HANDLE);
+
+    table_struct_ptr = &(((t_FmPcdCcNode *)(table_handle))->extHashInfo);
+
+    if (table_struct_ptr->hash_bucket_pool.bucket_stack)
+        XX_FreeSmart(table_struct_ptr->hash_bucket_pool.bucket_stack);
+
+    if (table_struct_ptr->hash_bucket_pool.bucket_pool_base_ptr)
+    	XX_FreeSmart(table_struct_ptr->hash_bucket_pool.bucket_pool_base_ptr);
+
+    if (table_struct_ptr->table_base_ptr)
+    	XX_FreeSmart(table_struct_ptr->table_base_ptr);
+}
+
+static t_FmExtHashBucket * ext_hash_lookup(void *table_handle,
+	uint8_t *key_ptr,
+	uint16_t *set_index,
+	uint8_t *found_key_index)
+{
+	int not_found = 1;
+	uint8_t i, not_last;
+	uint16_t bucket_index;
+	t_FmExtHashBucket *found_bucket;
+	t_FmPcdCcNodeExtHashInfo *table_struct_ptr;
+
+    SANITY_CHECK_RETURN_VALUE(table_handle, E_INVALID_HANDLE, NULL);
+    SANITY_CHECK_RETURN_VALUE(key_ptr, E_NULL_POINTER, NULL);
+    SANITY_CHECK_RETURN_VALUE(set_index, E_NULL_POINTER, NULL);
+    SANITY_CHECK_RETURN_VALUE(found_key_index, E_NULL_POINTER, NULL);
+
+	table_struct_ptr = &(((t_FmPcdCcNode *)(table_handle))->extHashInfo);
+	/* Check if Hash table was created */
+	SANITY_CHECK_RETURN_VALUE(table_struct_ptr->table_base_ptr, E_NULL_POINTER, NULL);
+
+	get_indexed_hash_bucket(table_struct_ptr->key_size, key_ptr,
+				table_struct_ptr->crc_shift,
+				table_struct_ptr->hash_mask, &bucket_index);
+
+	*set_index = bucket_index;
+	found_bucket = &(table_struct_ptr->table_base_ptr[bucket_index]);
+
+	if (found_bucket->valid_keys == 0)
+	{
+		return NULL;
+	}
+
+	do {
+		for (i = 0; (i < found_bucket->valid_keys) && not_found; i++)
+		{
+			/*check if the current key is valid */
+			if (found_bucket->key_result[(table_struct_ptr->aligned_key_size * i)
+			                             + table_struct_ptr->key_size] == 0)
+			{
+				not_found =
+					memcmp(key_ptr,
+						&found_bucket->key_result[(table_struct_ptr->aligned_key_size) * i],
+						table_struct_ptr->key_size);
+
+				if (!not_found)
+				{
+					*found_key_index = i;
+					return found_bucket;
+				}
+			}
+		}
+		not_last = found_bucket->not_last;
+		found_bucket = (t_FmExtHashBucket *)XX_PhysToVirt((uint64_t)GET_UINT32(found_bucket->next_bucket_addr));
+	} while (not_last);
+	return NULL;
+}
+
+static int ext_hash_add_key(void *table_handle,
+	uint8_t *key_ptr,
+	t_FmExtHashResult *result)
+{
+	uint16_t bucket_index;
+	uint8_t *valid_ptr;
+	t_FmExtHashBucket *new_bucket;
+	t_FmExtHashBucket *bucket, *static_bucket;
+	t_FmExtHashBucketPool *bucket_pool;
+	t_FmPcdCcNodeExtHashInfo *table_struct_ptr;
+
+    SANITY_CHECK_RETURN_ERROR(table_handle, E_INVALID_HANDLE);
+    SANITY_CHECK_RETURN_ERROR(key_ptr, E_NULL_POINTER);
+    SANITY_CHECK_RETURN_ERROR(result, E_NULL_POINTER);
+
+	table_struct_ptr = &(((t_FmPcdCcNode *)(table_handle))->extHashInfo);
+	/* Check if Hash table was created */
+	SANITY_CHECK_RETURN_ERROR(table_struct_ptr->table_base_ptr, E_NULL_POINTER);
+
+    get_indexed_hash_bucket(table_struct_ptr->key_size, key_ptr,
+				table_struct_ptr->crc_shift,
+				table_struct_ptr->hash_mask,
+				&bucket_index);
+	bucket = &(table_struct_ptr->table_base_ptr[bucket_index]);
+
+    DBG(TRACE, ("ext_hash_add_key() bucket_index: 0x%x", bucket_index));
+
+	static_bucket = bucket;
+	if(bucket->prev_last_bucket_ptr)
+	{
+		bucket = (t_FmExtHashBucket *)XX_PhysToVirt(GET_UINT32(bucket->prev_last_bucket_ptr));
+	}
+
+	if (bucket->valid_keys == table_struct_ptr->max_ways)
+	{
+		/* Need to open new bucket */
+		bucket_pool = &(table_struct_ptr->hash_bucket_pool);
+		if(bucket_pool->last_bucket < 0)
+		{
+			REPORT_ERROR(MAJOR, E_NO_MEMORY, ("ext_hash_add_key failed: no more free buckets"));
+			return -ENOMEM;
+		}
+
+		new_bucket = bucket_pool->bucket_stack[bucket_pool->last_bucket];
+		bucket_pool->last_bucket--;
+
+		MemCpy8(&(new_bucket->key_result[0]),
+			key_ptr,
+			table_struct_ptr->key_size);
+
+		valid_ptr = (new_bucket->key_result + table_struct_ptr->key_size);
+
+		/* Write key invalid bit */
+		WRITE_UINT8(valid_ptr, 0x0);
+		/* writing result to the bucket */
+		WRITE_UINT64(
+			new_bucket->key_result[0xE0],
+			result->contex_addr);
+		WRITE_UINT64(
+			new_bucket->key_result[0xE8],
+			result->monitoring_addr);
+		WRITE_UINT8(new_bucket->not_last, 0);
+		new_bucket->valid_keys = 1;
+		WRITE_UINT32(new_bucket->next_bucket_addr, (uint32_t)XX_VirtToPhys((void *)new_bucket));
+		new_bucket->prev_last_bucket_ptr = bucket->next_bucket_addr;
+
+		bucket->next_bucket_addr = new_bucket->next_bucket_addr;
+		WRITE_UINT8(bucket->not_last, 1);
+
+		/* Update static bucket */
+		static_bucket->prev_last_bucket_ptr = new_bucket->next_bucket_addr;
+
+	}
+	else
+	{
+		/* There is still place in the bucket */
+		/* copy key to the bucket */
+		MemCpy8(&(bucket->key_result[(table_struct_ptr->aligned_key_size) * bucket->valid_keys]),
+			key_ptr,
+			table_struct_ptr->key_size);
+		valid_ptr = ((&(bucket->key_result[
+		            (table_struct_ptr->aligned_key_size) * bucket->valid_keys]))
+		             + table_struct_ptr->key_size);
+
+		/* Write key valid bit */
+		WRITE_UINT8(valid_ptr, 0x0);
+		/* writing result to the bucket */
+		WRITE_UINT64(bucket->key_result[0xE0 - (bucket->valid_keys << 4)],
+			result->contex_addr);
+		WRITE_UINT64(bucket->key_result[0xE8 - (bucket->valid_keys << 4)],
+			result->monitoring_addr);
+		bucket->valid_keys++;
+	}
+	return E_OK;
+}
+
+/**
+ * Low level routine to remove a specified key from External Hash Table
+ *
+ * @param[in] table_handle Handle to hash table where to remove the key
+ * @param[in] key_ptr Pointer to key to be removed
+ *
+ * @return E_OK on success; Error code otherwise.
+ */
+static int ext_hash_remove_key(void *table_handle, uint8_t *key_ptr)
+{
+	t_FmPcdCcNode *p_HashTbl = (t_FmPcdCcNode *)table_handle;
+	uint16_t set_index;
+	uint8_t *valid_ptr;
+	t_FmExtHashBucket *prev_bucket;
+	t_FmExtHashBucket *static_bucket;
+	t_FmExtHashBucketPool *bucket_pool;
+	t_FmPcdCcNodeExtHashInfo *table_struct_ptr;
+	uint8_t rem_key_index;
+	t_FmExtHashBucket *rem_key_bucket, *last_key_bucket;
+
+	SANITY_CHECK_RETURN_ERROR(table_handle, E_INVALID_HANDLE);
+	SANITY_CHECK_RETURN_ERROR(key_ptr, E_NULL_POINTER);
+
+    table_struct_ptr = &(((t_FmPcdCcNode *)(table_handle))->extHashInfo);
+	/* Check if Hash table was created */
+    SANITY_CHECK_RETURN_ERROR(table_struct_ptr->table_base_ptr, E_NULL_POINTER);
+
+	bucket_pool = &(table_struct_ptr->hash_bucket_pool);
+
+	/* Lookup key in the set */
+	rem_key_bucket = ext_hash_lookup(table_handle, key_ptr, &set_index, &rem_key_index);
+    if (rem_key_bucket == NULL)
+        RETURN_ERROR(MAJOR, E_NOT_FOUND, ("Key was not found in external Hash Table"));
+
+    static_bucket = &(table_struct_ptr->table_base_ptr[set_index]);
+
+    /* When static bucket last/prev ptr is NULL then it is the only one in the set */
+    if (static_bucket->prev_last_bucket_ptr)
+        last_key_bucket = (t_FmExtHashBucket *)XX_PhysToVirt(GET_UINT32(static_bucket->prev_last_bucket_ptr));
+    else
+        last_key_bucket = static_bucket;
+
+    /* Is the last valid key in the set ? */
+    if (rem_key_index == rem_key_bucket->valid_keys - 1 && rem_key_bucket->not_last == 0)
+    {
+		/* Is the only valid key in the last dynamic bucket ? */
+		if (rem_key_bucket->valid_keys == 1 && (rem_key_bucket->prev_last_bucket_ptr))
+		{
+			/* Remove the last dynamic bucket: */
+			prev_bucket = (t_FmExtHashBucket *)(XX_PhysToVirt(GET_UINT32(rem_key_bucket->prev_last_bucket_ptr)));
+			prev_bucket->next_bucket_addr = rem_key_bucket->prev_last_bucket_ptr;
+
+			/* Now previous bucket is the last */
+			WRITE_UINT8(prev_bucket->not_last, 0);
+
+			/* Update the prev_last_bucket_ptr in static bucket: */
+			if (prev_bucket == static_bucket)
+				static_bucket->prev_last_bucket_ptr = 0;
+			else
+				static_bucket->prev_last_bucket_ptr = rem_key_bucket->prev_last_bucket_ptr;
+
+			/* Update bucket pool */
+			bucket_pool->bucket_stack[++bucket_pool->last_bucket] = last_key_bucket;
+		}
+		else
+		{
+			/* Decrement number of valid keys in the bucket */
+			rem_key_bucket->valid_keys--;
+		}
+
+		/* Sync external request */
+	    FmPcdHcSync(p_HashTbl->h_FmPcd);
+    }
+    else
+    {
+        /* Key to remove is not on the last position in its bucket OR bucket is not last */
+		valid_ptr = (uint8_t*)(rem_key_bucket->key_result + table_struct_ptr->aligned_key_size*rem_key_index + table_struct_ptr->key_size);
+		WRITE_UINT8(valid_ptr, 0x01);
+
+		/* Copy table's last key to removed key entry */
+		MemCpy8(&(rem_key_bucket->key_result[(table_struct_ptr->aligned_key_size) * rem_key_index]),
+				&(last_key_bucket->key_result[(table_struct_ptr->aligned_key_size) * (last_key_bucket->valid_keys - 1)]),
+				table_struct_ptr->key_size);
+
+		/* Copy table's last lookup result to removed key result entry */
+		MemCpy8(&(rem_key_bucket->key_result[0xE0 - 0x10 * rem_key_index]),
+				&(last_key_bucket->key_result[0xE0 - 0x10 * (last_key_bucket->valid_keys - 1)]),
+				16);
+
+		/* Reset 'invalidKey' */
+		valid_ptr = (uint8_t*)(rem_key_bucket->key_result + table_struct_ptr->aligned_key_size*rem_key_index + table_struct_ptr->key_size);
+		WRITE_UINT8(valid_ptr, 0x00);
+
+		/* Sync external request */
+		FmPcdHcSync(p_HashTbl->h_FmPcd);
+
+	    /* Relocated key is the only valid key in the last dynamic bucket? */
+		if (last_key_bucket->valid_keys == 1 && (last_key_bucket->prev_last_bucket_ptr) )
+		{
+			/* Remove the last dynamic bucket: */
+			prev_bucket = (t_FmExtHashBucket *)(XX_PhysToVirt(GET_UINT32(last_key_bucket->prev_last_bucket_ptr)));
+			prev_bucket->next_bucket_addr = last_key_bucket->prev_last_bucket_ptr;
+
+			/* Now previous bucket is the last */
+			WRITE_UINT8(prev_bucket->not_last, 0);
+
+			/* Update the prev_last_bucket_ptr in static bucket: */
+			if (prev_bucket == static_bucket)
+				static_bucket->prev_last_bucket_ptr = 0;
+			else
+				static_bucket->prev_last_bucket_ptr = last_key_bucket->prev_last_bucket_ptr;
+
+			/* Update bucket pool */
+			bucket_pool->bucket_stack[++bucket_pool->last_bucket] = last_key_bucket;
+		}
+		else
+		{
+			/* Decrement number of valid keys in the last bucket */
+			last_key_bucket->valid_keys--;
+		}
+
+		/* Sync external request */
+	    FmPcdHcSync(p_HashTbl->h_FmPcd);
+    }
+	return E_OK;
+}
+
+static int ext_hash_get_key_result(void *table_handle,
+	uint8_t *key_ptr,
+	t_FmExtHashResult *result)
+{
+	uint16_t set_index;
+	uint8_t key_index;
+	t_FmExtHashBucket *key_bucket;
+
+    SANITY_CHECK_RETURN_VALUE(table_handle, E_INVALID_HANDLE, E_INVALID_HANDLE);
+    SANITY_CHECK_RETURN_VALUE(key_ptr, E_NULL_POINTER, E_NULL_POINTER);
+    SANITY_CHECK_RETURN_VALUE(result, E_NULL_POINTER, E_NULL_POINTER);
+
+	/* Lookup key in the set */
+	key_bucket = ext_hash_lookup(table_handle, key_ptr, &set_index, &key_index);
+    if (key_bucket == NULL)
+        RETURN_ERROR(MAJOR, E_NOT_FOUND, ("Key was not found in external Hash Table"));
+
+	/* read result from the bucket */
+    result->contex_addr = GET_UINT64(key_bucket->key_result[0xE0 - (key_index << 4)]);
+    result->monitoring_addr = GET_UINT64(key_bucket->key_result[0xE8 - (key_index << 4)]);
+
+    return E_OK;
+}
+
+static int ext_hash_set_key_result(void *table_handle,
+	uint8_t *key_ptr,
+	t_FmExtHashResult *result)
+{
+	uint16_t set_index;
+	uint8_t key_index;
+	t_FmExtHashBucket *key_bucket;
+
+    SANITY_CHECK_RETURN_VALUE(table_handle, E_INVALID_HANDLE, E_INVALID_HANDLE);
+    SANITY_CHECK_RETURN_VALUE(key_ptr, E_NULL_POINTER, E_NULL_POINTER);
+    SANITY_CHECK_RETURN_VALUE(result, E_NULL_POINTER, E_NULL_POINTER);
+
+	/* Lookup key in the set */
+	key_bucket = ext_hash_lookup(table_handle, key_ptr, &set_index, &key_index);
+    if (key_bucket == NULL)
+        RETURN_ERROR(MAJOR, E_NOT_FOUND, ("Key was not found in external Hash Table"));
+
+	/* write result in the bucket */
+    WRITE_UINT64(key_bucket->key_result[0xE0 - (key_index << 4)], result->contex_addr);
+    WRITE_UINT64(key_bucket->key_result[0xE8 - (key_index << 4)], result->monitoring_addr);
+
+    return E_OK;
+}
+
+static void ReleaseFEsContextList(t_FmPcdCcNode *p_CcNodeHashTbl)
+{
+    t_FmPcdCcNodeFEContextObj *p_Obj;
+    uint32_t intFlags;
+
+    intFlags = XX_LockIntrSpinlock(p_CcNodeHashTbl->h_Spinlock);
+    while (!LIST_IsEmpty(&p_CcNodeHashTbl->extHashInfo.usedContextLst))
+    {
+        p_Obj = FM_PCD_FE_CONTEXT_OBJ(p_CcNodeHashTbl->extHashInfo.usedContextLst.p_Next);
+        LIST_DelAndInit(&p_Obj->node);
+        XX_FreeSmart(p_Obj->p_Context);
+        XX_Free(p_Obj);
+    }
+    while (!LIST_IsEmpty(&p_CcNodeHashTbl->extHashInfo.availableContextLst))
+    {
+        p_Obj = FM_PCD_FE_CONTEXT_OBJ(p_CcNodeHashTbl->extHashInfo.availableContextLst.p_Next);
+        LIST_DelAndInit(&p_Obj->node);
+        XX_FreeSmart(p_Obj->p_Context);
+        XX_Free(p_Obj);
+    }
+    XX_UnlockIntrSpinlock(p_CcNodeHashTbl->h_Spinlock, intFlags);
+}
+
+#endif /* USE_ENHANCED_EHASH */
+
+static __inline__ t_FmPcdCcNodeFEContextObj* DequeueFEContextObj(t_FmPcdCcNode *p_CcNodeHashTbl, t_List *p_List)
+{
+    t_FmPcdCcNodeFEContextObj *p_Obj = NULL;
+    uint32_t    intFlags;
+
+    intFlags = XX_LockIntrSpinlock(p_CcNodeHashTbl->h_Spinlock);
+    if (!LIST_IsEmpty(p_List))
+    {
+        p_Obj = FM_PCD_FE_CONTEXT_OBJ(p_List->p_Next);
+        LIST_DelAndInit(&p_Obj->node);
+    }
+    XX_UnlockIntrSpinlock(p_CcNodeHashTbl->h_Spinlock, intFlags);
+
+    return p_Obj;
+}
+
+static __inline__ void EnqueueFEContextObj(t_FmPcdCcNode *p_CcNodeHashTbl, t_List *p_List, t_FmPcdCcNodeFEContextObj *p_Obj)
+{
+    uint32_t   intFlags;
+
+    intFlags = XX_LockIntrSpinlock(p_CcNodeHashTbl->h_Spinlock);
+    LIST_AddToTail(&p_Obj->node, p_List);
+    XX_UnlockIntrSpinlock(p_CcNodeHashTbl->h_Spinlock, intFlags);
+}
+
+#ifndef USE_ENHANCED_EHASH
+static t_Error AllocFEContextObjs(t_FmPcdCcNode *p_CcNodeHashTbl)
+{
+    t_FmPcdCcNodeFEContextObj *p_FeContextObj;
+    uint32_t i;
+
+    ASSERT_COND(p_CcNodeHashTbl);
+
+    INIT_LIST(&p_CcNodeHashTbl->extHashInfo.usedContextLst);
+    INIT_LIST(&p_CcNodeHashTbl->extHashInfo.availableContextLst);
+
+    for (i=0; i<p_CcNodeHashTbl->maxNumOfKeys; i++) {
+        p_FeContextObj = (t_FmPcdCcNodeFEContextObj *)XX_Malloc(sizeof(t_FmPcdCcNodeFEContextObj));
+        if (!p_FeContextObj)
+            RETURN_ERROR(MAJOR, E_NO_MEMORY, ("FM-PCD FE-Context obj!"));
+        memset(p_FeContextObj, 0, sizeof(t_FmPcdCcNodeFEContextObj));
+
+        p_FeContextObj->p_Context = XX_MallocSmart(256, p_CcNodeHashTbl->extHashInfo.dataMemId, 256);
+        if (!p_FeContextObj->p_Context)
+            RETURN_ERROR(MAJOR, E_NO_MEMORY, ("allocation for context"));
+        memset(p_FeContextObj->p_Context, 0, 256);
+
+        EnqueueFEContextObj(p_CcNodeHashTbl, &p_CcNodeHashTbl->extHashInfo.availableContextLst, p_FeContextObj);
+    }
+
+    return E_OK;
+}
+
+static uint8_t* GetFEContext(t_FmPcdCcNode *p_CcNodeHashTbl)
+{
+    t_FmPcdCcNodeFEContextObj *p_Obj;
+
+    ASSERT_COND(p_CcNodeHashTbl);
+    p_Obj = DequeueFEContextObj(p_CcNodeHashTbl, &p_CcNodeHashTbl->extHashInfo.availableContextLst);
+    EnqueueFEContextObj(p_CcNodeHashTbl, &p_CcNodeHashTbl->extHashInfo.usedContextLst, p_Obj);
+    return p_Obj->p_Context;
+}
+
+static void PutFEContext(t_FmPcdCcNode *p_CcNodeHashTbl, uint8_t *p_Context)
+{
+    t_List *p_Pos;
+    uint32_t   intFlags;
+    t_FmPcdCcNodeFEContextObj *p_Obj;
+
+    ASSERT_COND(p_CcNodeHashTbl);
+    ASSERT_COND(p_Context);
+
+    intFlags = XX_LockIntrSpinlock(p_CcNodeHashTbl->h_Spinlock);
+    LIST_FOR_EACH(p_Pos, &p_CcNodeHashTbl->extHashInfo.usedContextLst)
+    {
+        p_Obj = FM_PCD_FE_CONTEXT_OBJ(p_Pos);
+        if (p_Obj->p_Context == p_Context) {
+            LIST_DelAndInit(&p_Obj->node);
+            LIST_AddToTail(&p_Obj->node, &p_CcNodeHashTbl->extHashInfo.availableContextLst);
+            memset(p_Context, 0, sizeof(256));
+            break;
+        }
+    }
+    XX_UnlockIntrSpinlock(p_CcNodeHashTbl->h_Spinlock, intFlags);
+}
+#endif /* USE_ENHANCED_EHASH */
+
+static void ExternalHashResultSetMonitorAddr(t_ExtHashResult *p_Result, uint16_t dataLiodnOffset, uintptr_t monitorAddr)
+{
+	uint64_t tmpReg64;
+
+    tmpReg64 = (uint64_t)(XX_VirtToPhys(UINT_TO_PTR(monitorAddr)));
+    tmpReg64 |= ((uint64_t)(dataLiodnOffset & FM_PCD_FE_T_HASH_LIODN_MASK)
+            << (uint64_t)FM_PCD_FE_T_HASH_LIODN_SHIFT);
+    tmpReg64 |= ((uint64_t)(dataLiodnOffset & FM_PCD_FE_T_HASH_ELIODN_MASK)
+            << (uint64_t)FM_PCD_FE_T_HASH_ELIODN_SHIFT);
+    WRITE_UINT32(p_Result->liodnMonitorAndMonitorPtrHi, (uint32_t)(tmpReg64 >> 32));
+    WRITE_UINT32(p_Result->monitorPtrLow, (uint32_t)tmpReg64);
+}
+
+static t_Error ExternalHashTableModifyMissMonitorAddr(t_Handle h_HashTbl, uintptr_t monitorAddr)
+{
+    t_FmPcdCcNode *p_HashTbl = (t_FmPcdCcNode *)h_HashTbl;
+
+    SANITY_CHECK_RETURN_ERROR(p_HashTbl, E_INVALID_HANDLE);
+
+    /* Free old miss monitor addr if it was automatically allocated by the driver */
+    if (p_HashTbl->extHashInfo.missMonitorAddr && p_HashTbl->extHashInfo.drvAllocMissMonitorAddr)
+        XX_FreeSmart((void*)p_HashTbl->extHashInfo.missMonitorAddr);
+
+    p_HashTbl->extHashInfo.missMonitorAddr = monitorAddr;
+    p_HashTbl->extHashInfo.drvAllocMissMonitorAddr = FALSE;
+
+    ExternalHashResultSetMonitorAddr(p_HashTbl->extHashInfo.p_MissResult, p_HashTbl->extHashInfo.dataLiodnOffset, monitorAddr);
+
+    return E_OK;
+}
+
+#endif /* (DPAA_VERSION >= 11) */
+
+/************************** End of static functions **************************/
+
+/*****************************************************************************/
+/*              Inter-module API routines                                    */
+/*****************************************************************************/
+
+t_CcNodeInformation* FindNodeInfoInReleventLst(t_List *p_List, t_Handle h_Info,
+                                               t_Handle h_Spinlock)
+{
+    t_CcNodeInformation *p_CcInformation;
+    t_List *p_Pos;
+    uint32_t intFlags;
+
+    intFlags = XX_LockIntrSpinlock(h_Spinlock);
+
+    for (p_Pos = LIST_FIRST(p_List); p_Pos != (p_List);
+            p_Pos = LIST_NEXT(p_Pos))
+    {
+        p_CcInformation = CC_NODE_F_OBJECT(p_Pos);
+
+        ASSERT_COND(p_CcInformation->h_CcNode);
+
+        if (p_CcInformation->h_CcNode == h_Info)
+        {
+            XX_UnlockIntrSpinlock(h_Spinlock, intFlags);
+            return p_CcInformation;
+        }
+    }
+
+    XX_UnlockIntrSpinlock(h_Spinlock, intFlags);
+
+    return NULL;
+}
+
+void EnqueueNodeInfoToRelevantLst(t_List *p_List, t_CcNodeInformation *p_CcInfo,
+                                  t_Handle h_Spinlock)
+{
+    t_CcNodeInformation *p_CcInformation;
+    uint32_t intFlags = 0;
+
+    p_CcInformation = (t_CcNodeInformation *)XX_Malloc(
+            sizeof(t_CcNodeInformation));
+
+    if (p_CcInformation)
+    {
+        memset(p_CcInformation, 0, sizeof(t_CcNodeInformation));
+        memcpy(p_CcInformation, p_CcInfo, sizeof(t_CcNodeInformation));
+        INIT_LIST(&p_CcInformation->node);
+
+        if (h_Spinlock)
+            intFlags = XX_LockIntrSpinlock(h_Spinlock);
+
+        LIST_AddToTail(&p_CcInformation->node, p_List);
+
+        if (h_Spinlock)
+            XX_UnlockIntrSpinlock(h_Spinlock, intFlags);
+    }
+    else
+        REPORT_ERROR(MAJOR, E_NO_MEMORY, ("CC Node Information"));
+}
+
+void DequeueNodeInfoFromRelevantLst(t_List *p_List, t_Handle h_Info,
+                                    t_Handle h_Spinlock)
+{
+    t_CcNodeInformation *p_CcInformation = NULL;
+    uint32_t intFlags = 0;
+    t_List *p_Pos;
+
+    if (h_Spinlock)
+        intFlags = XX_LockIntrSpinlock(h_Spinlock);
+
+    if (LIST_IsEmpty(p_List))
+    {
+        XX_RestoreAllIntr(intFlags);
+        return;
+    }
+
+    for (p_Pos = LIST_FIRST(p_List); p_Pos != (p_List);
+            p_Pos = LIST_NEXT(p_Pos))
+    {
+        p_CcInformation = CC_NODE_F_OBJECT(p_Pos);
+        ASSERT_COND(p_CcInformation);
+        ASSERT_COND(p_CcInformation->h_CcNode);
+        if (p_CcInformation->h_CcNode == h_Info)
+            break;
+    }
+
+    if (p_CcInformation)
+    {
+        LIST_DelAndInit(&p_CcInformation->node);
+        XX_Free(p_CcInformation);
+    }
+
+    if (h_Spinlock)
+        XX_UnlockIntrSpinlock(h_Spinlock, intFlags);
+}
+
+void NextStepAd(t_Handle h_Ad, t_FmPcdCcStatsParams *p_FmPcdCcStatsParams,
+                t_FmPcdCcNextEngineParams *p_FmPcdCcNextEngineParams,
+                t_FmPcd *p_FmPcd)
+{
+    switch (p_FmPcdCcNextEngineParams->nextEngine)
+    {
+        case (e_FM_PCD_KG):
+        case (e_FM_PCD_PLCR):
+        case (e_FM_PCD_DONE):
+            /* if NIA is not CC, create a "result" type AD */
+            FillAdOfTypeResult(h_Ad, p_FmPcdCcStatsParams, p_FmPcd,
+                               p_FmPcdCcNextEngineParams);
+            break;
+        case (e_FM_PCD_FR):
+            if (p_FmPcdCcNextEngineParams->params.frParams.h_FrmReplic)
+            {
+                FillAdOfTypeContLookup(
+                        h_Ad, p_FmPcdCcStatsParams, p_FmPcd,
+                        p_FmPcdCcNextEngineParams->params.ccParams.h_CcNode,
+                        p_FmPcdCcNextEngineParams->h_Manip,
+                        p_FmPcdCcNextEngineParams->params.frParams.h_FrmReplic);
+                FrmReplicGroupUpdateOwner(
+                        p_FmPcdCcNextEngineParams->params.frParams.h_FrmReplic,
+                        TRUE/* add */);
             }
             break;
 
@@ -5341,6 +6481,7 @@ t_Error FmPcdCcRemoveKey(t_Handle h_FmPcd, t_Handle h_FmPcdCcNode,
         RETURN_ERROR(MAJOR, err, NO_MSG);
     }
 
+    display_cc_node(p_CcNode, __FUNCTION__);
     err = DoDynamicChange(p_FmPcd, &h_OldPointersLst, &h_NewPointersLst,
                           p_ModifyKeyParams, useShadowStructs);
 
@@ -5432,6 +6573,7 @@ t_Error FmPcdCcModifyKey(t_Handle h_FmPcd, t_Handle h_FmPcdCcNode,
         RETURN_ERROR(MAJOR, err, NO_MSG);
     }
 
+    display_cc_node(p_CcNode, __FUNCTION__);
     err = DoDynamicChange(p_FmPcd, &h_OldPointersLst, &h_NewPointersLst,
                           p_ModifyKeyParams, useShadowStructs);
 
@@ -5489,6 +6631,7 @@ t_Error FmPcdCcModifyMissNextEngineParamNode(
         RETURN_ERROR(MAJOR, err, NO_MSG);
     }
 
+    display_cc_node(p_CcNode, __FUNCTION__);
     err = DoDynamicChange(p_FmPcd, &h_OldPointersLst, &h_NewPointersLst,
                           p_ModifyKeyParams, FALSE);
 
@@ -5598,6 +6741,7 @@ t_Error FmPcdCcAddKey(t_Handle h_FmPcd, t_Handle h_FmPcdCcNode,
         RETURN_ERROR(MAJOR, err, NO_MSG);
     }
 
+    display_cc_node(p_CcNode, __FUNCTION__);
     err = DoDynamicChange(p_FmPcd, &h_OldPointersLst, &h_NewPointersLst,
                           p_ModifyKeyParams, useShadowStructs);
     if (p_CcNode->maxNumOfKeys)
@@ -5691,6 +6835,7 @@ t_Error FmPcdCcModifyKeyAndNextEngine(t_Handle h_FmPcd, t_Handle h_FmPcdCcNode,
         RETURN_ERROR(MAJOR, err, NO_MSG);
     }
 
+    display_cc_node(p_CcNode, __FUNCTION__);
     err = DoDynamicChange(p_FmPcd, &h_OldPointersLst, &h_NewPointersLst,
                           p_ModifyKeyParams, useShadowStructs);
 
@@ -5942,6 +7087,143 @@ void FmPcdCcGetAdTablesThatPointOnReplicGroup(t_Handle h_Node,
 /****************************************/
 /*       API Init unit functions        */
 /****************************************/
+#ifdef USE_ENHANCED_EHASH 
+
+#ifndef EXCLUDE_FMAN_IPR_OFFLOAD
+void set_reassembly_tds(void *handle, uint32_t ipv4_off, uint32_t ipv6_off)
+{
+	struct en_exthash_info *info;
+	struct en_exthash_node *ptr, *ccptr;
+
+	info = (struct en_exthash_info *)handle;
+	ptr = (struct en_exthash_node  *)&info->node;
+	ccptr = info->h_Ad;
+	ptr->ipv4_ad_offset = ipv4_off;
+	ptr->word_2 |= (ipv6_off << 24);
+	WRITE_UINT32(ccptr->word_0, ptr->word_0);
+	WRITE_UINT32(ccptr->word_2, ptr->word_2);
+#ifdef FM_EHASH_DEBUG
+	{
+		uint32_t ii;
+		uint8_t *ptr;
+		ptr = (uint8_t *)ccptr;
+		printk("%s::handle %p Ad %p ccptr %pi v4off %x, v6off %x\n", __F
+				UNCTION__,
+				handle, ptr, ccptr, ipv4_off, ipv6_off);
+		for (ii = 0; ii < 16; ii++)
+			printk("%02x ", *(ptr + ii));
+		printk("\n");
+	}
+#endif
+}
+uint32_t copy_td_to_ccbase(void *handle, t_Handle p_CcTreeTmp, uint32_t *node)
+{
+	struct en_exthash_info *info;
+	struct en_exthash_node *ptr, *ccptr;
+	t_FmPcd *p_FmPcd;
+	uint32_t ii;
+
+	info = (struct en_exthash_info *)handle;
+	ptr = (struct en_exthash_node  *)&info->node;
+	ccptr = (struct en_exthash_node  *)p_CcTreeTmp;
+	WRITE_UINT32(ccptr->word_1, ptr->word_1);
+	WRITE_UINT32(ccptr->table_base_lo, ptr->table_base_lo);
+	WRITE_UINT32(ccptr->word_2,  ptr->word_2);
+	WRITE_UINT32(ccptr->word_0, ptr->word_0);
+#ifdef FM_EHASH_DEBUG
+	{
+		uint8_t *ptr;
+
+		printk("%s::handle %p Ad %p ccptr %p\n", __FUNCTION__,
+			 handle, ptr, p_CcTreeTmp);
+		ptr = (uint8_t *)ccptr;
+		for (ii = 0; ii < 16; ii++)
+			printk("%02x ", *(ptr + ii));
+		printk("\n");
+	}
+#endif
+	//save muram addr for AD in the tree 
+	info->h_Ad = ccptr;
+	p_FmPcd = info->pcd;
+	ii = (uint32_t)(XX_VirtToPhys(p_CcTreeTmp) - 
+			p_FmPcd->physicalMuramBase);
+	*node = ii;
+#ifdef FM_EHASH_DEBUG
+	if (info->ip_reassem_info) 
+	{
+		if (info->ip_reassem_info) { 
+			printk("%s::AD for reassembly %p %x\n",
+				__FUNCTION__, ccptr, ii);
+		} else {
+			printk("%s::AD for non-reassembly %p %x\n",
+				__FUNCTION__, ccptr, ii);
+		}
+		display_ehashtbl_info(info, __FUNCTION__);
+	}
+#endif
+	//return type
+	if (info->ip_reassem_info) 
+		return (info->ip_reassem_info->type);
+	return 0;
+}
+#else
+void copy_td_to_ccbase(void *handle, t_Handle p_CcTreeTmp)
+{
+	struct en_exthash_info *info;
+	struct en_exthash_node *ptr, *ccptr;
+
+	info = (struct en_exthash_info *)handle;
+	ptr = (struct en_exthash_node  *)&info->node;
+	ccptr = (struct en_exthash_node  *)p_CcTreeTmp;
+	WRITE_UINT32(ccptr->word_1, ptr->word_1);
+	WRITE_UINT32(ccptr->table_base_lo, ptr->table_base_lo);
+	WRITE_UINT32(ccptr->word_2,  ptr->word_2);
+	WRITE_UINT32(ccptr->word_0, ptr->word_0);
+#ifdef FM_EHASH_DEBUG
+	{
+		uint32_t ii;
+		uint8_t *ptr;
+
+		printk("%s::handle %p Ad %p ccptr %p\n", __FUNCTION__,
+			 handle, ptr, p_CcTreeTmp);
+		ptr = (uint8_t *)ccptr;
+		for (ii = 0; ii < 16; ii++)
+			printk("%02x ", *(ptr + ii));
+		printk("\n");
+	}
+#endif
+	//save muram addr for AD in the tree 
+	info->h_Ad = ccptr;
+
+#ifndef EXCLUDE_FMAN_IPR_OFFLOAD
+	{
+		uint32_t ii;
+		t_FmPcd *p_FmPcd;
+		p_FmPcd = info->pcd;
+		ii = (uint32_t)(XX_VirtToPhys(p_CcTreeTmp) - 
+			p_FmPcd->physicalMuramBase);
+#ifdef FM_EHASH_DEBUG
+		if (info->ip_reassem_info) 
+		{
+			if (info->ip_reassem_info) { 
+				printk("%s::AD for reassembly %p %x\n",
+					__FUNCTION__, ccptr, ii);
+			} else {
+				printk("%s::AD for non-reassembly %p %x\n",
+					__FUNCTION__, ccptr, ii);
+			}
+			display_ehashtbl_info(info, __FUNCTION__);
+		}
+	}
+#endif
+	//return type
+	if (info->ip_reassem_info) 
+		return (info->ip_reassem_info->type);
+#endif
+	return 0;
+}
+#endif
+#endif //USE_ENHANCED_EHASH
 
 t_Handle FM_PCD_CcRootBuild(t_Handle h_FmPcd,
                             t_FmPcdCcTreeParams *p_PcdGroupsParam)
@@ -5957,8 +7239,14 @@ t_Handle FM_PCD_CcRootBuild(t_Handle h_FmPcd,
     t_NetEnvParams netEnvParams;
     uint8_t lastOne = 0;
     uint32_t requiredAction = 0;
+#ifndef USE_ENHANCED_EHASH 
     t_FmPcdCcNode *p_FmPcdCcNextNode;
     t_CcNodeInformation ccNodeInfo, *p_CcInformation;
+#endif 
+#ifndef EXCLUDE_FMAN_IPR_OFFLOAD
+	uint32_t ipv4_reassly_offset;
+	uint32_t ipv6_reassly_offset;
+#endif
 
     SANITY_CHECK_RETURN_VALUE(h_FmPcd, E_INVALID_HANDLE, NULL);
     SANITY_CHECK_RETURN_VALUE(p_PcdGroupsParam, E_INVALID_HANDLE, NULL);
@@ -5991,6 +7279,7 @@ t_Handle FM_PCD_CcRootBuild(t_Handle h_FmPcd,
     numOfEntries = 0;
     p_FmPcdCcTree->netEnvId = FmPcdGetNetEnvId(p_PcdGroupsParam->h_NetEnv);
 
+    //printk("%s::num groups %d\n", __FUNCTION__, p_PcdGroupsParam->numOfGrps);
     for (i = 0; i < p_PcdGroupsParam->numOfGrps; i++)
     {
         p_FmPcdCcGroupParams = &p_PcdGroupsParam->ccGrpParams[i];
@@ -6103,6 +7392,7 @@ t_Handle FM_PCD_CcRootBuild(t_Handle h_FmPcd,
             k++;
         }
     }
+    //printk("%s::num entries %d\n", __FUNCTION__, numOfEntries);
 
     p_FmPcdCcTree->numOfEntries = (uint8_t)k;
     p_FmPcdCcTree->numOfGrps = p_PcdGroupsParam->numOfGrps;
@@ -6123,7 +7413,15 @@ t_Handle FM_PCD_CcRootBuild(t_Handle h_FmPcd,
             (uint32_t)(FM_PCD_MAX_NUM_OF_CC_GROUPS * FM_PCD_CC_AD_ENTRY_SIZE));
 
     p_CcTreeTmp = UINT_TO_PTR(p_FmPcdCcTree->ccTreeBaseAddr);
-
+#ifdef FM_EHASH_DEBUG
+    printk("%s::cctree root %p baseaddr %p numentries %d\n", __FUNCTION__,
+		p_CcTreeTmp, (void *)p_FmPcdCcTree->ccTreeBaseAddr, numOfEntries);
+
+    printk("%s::cctree root %p baseaddr %p numentries %d muram %x\n", __FUNCTION__,
+	          p_CcTreeTmp, (void *)p_FmPcdCcTree->ccTreeBaseAddr, numOfEntries,
+                (uint32_t)(XX_VirtToPhys(p_FmPcdCcTree->ccTreeBaseAddr) - p_FmPcd->physicalMuramBase)); 
+#endif
+#ifndef USE_ENHANCED_EHASH //jyos following code is crashing in case of EHASH
     for (i = 0; i < numOfEntries; i++)
     {
         p_KeyAndNextEngineParams = p_Params + i;
@@ -6159,10 +7457,175 @@ t_Handle FM_PCD_CcRootBuild(t_Handle h_FmPcd,
                 p_CcInformation->index++;
         }
     }
-
+#else
+    for (i = 0; i < numOfEntries; i++) {
+	struct t_FmPcdCcNextEngineParams *nexteng;
+	
+        p_KeyAndNextEngineParams = p_Params + i;
+	memcpy(&p_FmPcdCcTree->keyAndNextEngineParams[i],
+               p_KeyAndNextEngineParams,
+               sizeof(t_FmPcdCcKeyAndNextEngineParams));
+	nexteng = &p_FmPcdCcTree->keyAndNextEngineParams[i].nextEngineParams;
+
+	if (nexteng->nextEngine == e_FM_PCD_CC)
+	{
+		
+        	t_FmPcdCcNextCcParams *ccParams;       /**< Parameters in case next engine is CC */
+		ccParams = &nexteng->params.ccParams;
+		//printk("e_FM_PCD_CC ccnode handle %p\n", (void *)ccParams->h_CcNode);
+#ifdef EXCLUDE_FMAN_IPR_OFFLOAD
+		copy_td_to_ccbase(ccParams->h_CcNode, p_CcTreeTmp);
+#else
+		{
+			uint32_t node;
+			uint32_t type;
+			type = copy_td_to_ccbase(ccParams->h_CcNode, p_CcTreeTmp, &node);
+#ifdef FM_EHASH_DEBUG
+			printk("e_FM_PCD_CC ccnode handle %p type %d\n", (void *)ccParams->h_CcNode,
+				type);
+#endif
+			switch (type) {
+				case IPV4_REASSM_TABLE:
+					ipv4_reassly_offset = (node & 0xff);
+#ifdef FM_EHASH_DEBUG
+					printk("%s::ipv4_reassly_offset %x\n",
+						__FUNCTION__,
+						ipv4_reassly_offset);
+#endif
+					break;
+				case IPV6_REASSM_TABLE:
+					ipv6_reassly_offset = (node & 0xff);
+#ifdef FM_EHASH_DEBUG
+					printk("%s::ipv6_reassly_offset %x\n",
+						__FUNCTION__,
+						ipv6_reassly_offset);
+#endif
+					break;
+				default:
+					break;
+			}
+		}	
+#endif
+	}
+        p_CcTreeTmp = PTR_MOVE(p_CcTreeTmp, FM_PCD_CC_AD_ENTRY_SIZE);
+#ifdef FM_EHASH_DEBUG
+	printk("%s::entry %d tree %p p_KeyAndNextEngineParams %p p_CcTreeTmp %p\n", __FUNCTION__, 
+		i, p_FmPcdCcTree, &p_FmPcdCcTree->keyAndNextEngineParams[i], p_CcTreeTmp); 
+	
+	printk("nextEngineParams %p requiredAction %08x\n", 
+		nexteng,
+		p_FmPcdCcTree->keyAndNextEngineParams[i].requiredAction);
+	printk("nextEngine %d, statisticsEn %d\n",
+		nexteng->nextEngine, nexteng->statisticsEn);
+	if (nexteng->nextEngine == e_FM_PCD_CC)	{
+		printk("h_CcNode %p\n", nexteng->params.ccParams.h_CcNode);
+	}
+#endif
+    }
+
+#ifndef EXCLUDE_FMAN_IPR_OFFLOAD	
+	//set table indices for ipv4 and ipv6 reassly in other ADs
+	for (i = 0; i < numOfEntries; i++) {
+	struct t_FmPcdCcNextEngineParams *nexteng;
+
+	nexteng = &p_FmPcdCcTree->keyAndNextEngineParams[i].nextEngineParams;
+	if (nexteng->nextEngine == e_FM_PCD_CC) {
+        	t_FmPcdCcNextCcParams *ccParams;       
+		struct en_exthash_info *info;
+        	
+		ccParams = &nexteng->params.ccParams;
+		info = (struct en_exthash_info *)ccParams->h_CcNode;
+		if (info->type != ETHERNET_TABLE)
+			set_reassembly_tds(ccParams->h_CcNode, ipv4_reassly_offset,
+				ipv6_reassly_offset);
+		else
+			set_reassembly_tds(ccParams->h_CcNode, 0xff, 0xff);
+	}
+	}
+#endif
+    for (i = 0; i < numOfEntries; i++)
+    {
+	struct t_FmPcdCcNextEngineParams *nexteng;
+
+        p_KeyAndNextEngineParams = 
+		&p_FmPcdCcTree->keyAndNextEngineParams[i];
+	nexteng = &p_KeyAndNextEngineParams->nextEngineParams;
+	switch(nexteng->nextEngine) {
+		case e_FM_PCD_DONE:
+			{
+        			t_FmPcdCcNextEnqueueParams *enqueueParams;  /**< Parameters in case next engine is BMI */
+				printk("e_FM_PCD_DONE\n");
+				enqueueParams = &nexteng->params.enqueueParams;
+				printk("action %d, overrideFqid %d, newFqid %x(%d), storageid %d\n", 
+					enqueueParams->action,
+					enqueueParams->overrideFqid,
+					enqueueParams->newFqid,
+					enqueueParams->newFqid,
+					enqueueParams->newRelativeStorageProfileId);
+			}
+			break;
+    		case e_FM_PCD_KG:
+			{
+        			t_FmPcdCcNextKgParams *kgParams;       /**< Parameters in case next engine is KG */
+				printk("e_FM_PCD_KG\n");
+				kgParams = &nexteng->params.kgParams;
+				printk("overrideFqid %d, newFqid %x(%d), storageid %d directschhandle %d\n", 
+					kgParams->overrideFqid,
+					kgParams->newFqid,
+					kgParams->newFqid,
+					kgParams->newRelativeStorageProfileId,
+					kgParams->h_DirectScheme);
+			}
+			break;
+    		case e_FM_PCD_CC:
+			{
+        			t_FmPcdCcNextCcParams *ccParams;       /**< Parameters in case next engine is CC */
+				ccParams = &nexteng->params.ccParams;
+				//printk("e_FM_PCD_CC ccnode handle %p\n", (void *)ccParams->h_CcNode);
+				//display_ehashtbl_info(ccParams->h_CcNode, __FUNCTION__);
+			}
+			break;
+    		case e_FM_PCD_PLCR:
+			{
+        			t_FmPcdCcNextPlcrParams *plcrParams;     /**< Parameters in case next engine is PLCR */
+				printk("e_FM_PCD_PLCR\n");
+				plcrParams = &nexteng->params.plcrParams;
+				printk("overrideParams %d, sharedProfile %d, newRelativeProfileId %d, newfqid %x(%d)"
+					"storageid %d\n",
+       		                        plcrParams->overrideParams,
+       		                        plcrParams->sharedProfile,
+                                	plcrParams->newRelativeProfileId,
+                                	plcrParams->newFqid,
+                                	plcrParams->newFqid,
+                                	plcrParams->newRelativeStorageProfileId);
+			}
+			break;
+    		case e_FM_PCD_PRS:
+			printk("e_FM_PCD_PRS\n");
+			break;
+#if (DPAA_VERSION >= 11)
+		case e_FM_PCD_FR: 
+			{
+        			t_FmPcdCcNextFrParams *frParams;       /**< Parameters in case next engine is FR */
+				printk("e_FM_PCD_FR\n");
+				frParams = &nexteng->params.frParams;
+				printk("frhandle handle %d\n", frParams->h_FrmReplic);
+			}
+			break;
+#endif /* (DPAA_VERSION >= 11) */
+		case e_FM_PCD_HASH:
+			printk("e_FM_PCD_HASH\n");
+			break;
+		default:
+			printk("next engine %d\n", nexteng->nextEngine);
+			
+	}
+    }
+#endif
     FmPcdIncNetEnvOwners(h_FmPcd, p_FmPcdCcTree->netEnvId);
     p_CcTreeTmp = UINT_TO_PTR(p_FmPcdCcTree->ccTreeBaseAddr);
 
+#ifndef USE_ENHANCED_EHASH  // jyos following code is crashing in case of EHASH
     if (!FmPcdLockTryLockAll(p_FmPcd))
     {
         FM_PCD_CcRootDelete(p_FmPcdCcTree);
@@ -6193,6 +7656,7 @@ t_Handle FM_PCD_CcRootBuild(t_Handle h_FmPcd,
     }
 
     FmPcdLockUnlockAll(p_FmPcd);
+#endif
     p_FmPcdCcTree->p_Lock = FmPcdAcquireLock(p_FmPcd);
     if (!p_FmPcdCcTree->p_Lock)
     {
@@ -7030,16 +8494,6 @@ t_Error FM_PCD_MatchTableGetIndexedHashBucket(t_Handle h_CcNode,
 
 t_Handle FM_PCD_HashTableSet(t_Handle h_FmPcd, t_FmPcdHashTableParams *p_Param)
 {
-    t_FmPcdCcNode *p_CcNodeHashTbl;
-    t_FmPcdCcNodeParams *p_IndxHashCcNodeParam, *p_ExactMatchCcNodeParam;
-    t_FmPcdCcNode *p_CcNode;
-    t_Handle h_MissStatsCounters = NULL;
-    t_FmPcdCcKeyParams *p_HashKeyParams;
-    int i;
-    uint16_t numOfSets, numOfWays, countMask, onesCount = 0;
-    bool statsEnForMiss = FALSE;
-    t_Error err;
-
     SANITY_CHECK_RETURN_VALUE(h_FmPcd, E_INVALID_HANDLE, NULL);
     SANITY_CHECK_RETURN_VALUE(p_Param, E_NULL_POINTER, NULL);
 
@@ -7064,206 +8518,39 @@ t_Handle FM_PCD_HashTableSet(t_Handle h_FmPcd, t_FmPcdHashTableParams *p_Param)
 
     if (p_Param->statisticsMode == e_FM_PCD_CC_STATS_MODE_RMON)
     {
-        REPORT_ERROR(MAJOR, E_INVALID_VALUE,
-                ("RMON statistics mode is not supported for hash table"));
-        return NULL;
-    }
-
-    p_ExactMatchCcNodeParam = (t_FmPcdCcNodeParams*)XX_Malloc(
-            sizeof(t_FmPcdCcNodeParams));
-    if (!p_ExactMatchCcNodeParam)
-    {
-        REPORT_ERROR(MAJOR, E_NO_MEMORY, ("p_ExactMatchCcNodeParam"));
-        return NULL;
-    }
-    memset(p_ExactMatchCcNodeParam, 0, sizeof(t_FmPcdCcNodeParams));
-
-    p_IndxHashCcNodeParam = (t_FmPcdCcNodeParams*)XX_Malloc(
-            sizeof(t_FmPcdCcNodeParams));
-    if (!p_IndxHashCcNodeParam)
-    {
-        XX_Free(p_ExactMatchCcNodeParam);
-        REPORT_ERROR(MAJOR, E_NO_MEMORY, ("p_IndxHashCcNodeParam"));
-        return NULL;
-    }
-    memset(p_IndxHashCcNodeParam, 0, sizeof(t_FmPcdCcNodeParams));
-
-    /* Calculate number of sets and number of ways of the hash table */
-    countMask = (uint16_t)(p_Param->hashResMask >> 4);
-    while (countMask)
-    {
-        onesCount++;
-        countMask = (uint16_t)(countMask >> 1);
-    }
-
-    numOfSets = (uint16_t)(1 << onesCount);
-    numOfWays = (uint16_t)DIV_CEIL(p_Param->maxNumOfKeys, numOfSets);
-
-    if (p_Param->maxNumOfKeys % numOfSets)
-        DBG(INFO, ("'maxNumOfKeys' is not a multiple of hash number of ways, so number of ways will be rounded up"));
-
-    if ((p_Param->statisticsMode == e_FM_PCD_CC_STATS_MODE_FRAME)
-            || (p_Param->statisticsMode == e_FM_PCD_CC_STATS_MODE_BYTE_AND_FRAME))
-    {
-        /* Allocating a statistics counters table that will be used by all
-         'miss' entries of the hash table */
-        h_MissStatsCounters = (t_Handle)FM_MURAM_AllocMem(
-                FmPcdGetMuramHandle(h_FmPcd), 2 * FM_PCD_CC_STATS_COUNTER_SIZE,
-                FM_PCD_CC_AD_TABLE_ALIGN);
-        if (!h_MissStatsCounters)
-        {
-            REPORT_ERROR(MAJOR, E_NO_MEMORY, ("MURAM allocation for statistics table for hash miss"));
-            XX_Free(p_IndxHashCcNodeParam);
-            XX_Free(p_ExactMatchCcNodeParam);
-            return NULL;
-        }
-        memset(h_MissStatsCounters, 0, (2 * FM_PCD_CC_STATS_COUNTER_SIZE));
-
-        /* Always enable statistics for 'miss', so that a statistics AD will be
-         initialized from the start. We'll store the requested 'statistics enable'
-         value and it will be used when statistics are read by the user. */
-        statsEnForMiss = p_Param->ccNextEngineParamsForMiss.statisticsEn;
-        p_Param->ccNextEngineParamsForMiss.statisticsEn = TRUE;
-    }
-
-    /* Building exact-match node params, will be used to create the hash buckets */
-    p_ExactMatchCcNodeParam->extractCcParams.type = e_FM_PCD_EXTRACT_NON_HDR;
-
-    p_ExactMatchCcNodeParam->extractCcParams.extractNonHdr.src =
-            e_FM_PCD_EXTRACT_FROM_KEY;
-    p_ExactMatchCcNodeParam->extractCcParams.extractNonHdr.action =
-            e_FM_PCD_ACTION_EXACT_MATCH;
-    p_ExactMatchCcNodeParam->extractCcParams.extractNonHdr.offset = 0;
-    p_ExactMatchCcNodeParam->extractCcParams.extractNonHdr.size =
-            p_Param->matchKeySize;
-
-    p_ExactMatchCcNodeParam->keysParams.maxNumOfKeys = numOfWays;
-    p_ExactMatchCcNodeParam->keysParams.maskSupport = FALSE;
-    p_ExactMatchCcNodeParam->keysParams.statisticsMode =
-            p_Param->statisticsMode;
-    p_ExactMatchCcNodeParam->keysParams.numOfKeys = 0;
-    p_ExactMatchCcNodeParam->keysParams.keySize = p_Param->matchKeySize;
-    p_ExactMatchCcNodeParam->keysParams.ccNextEngineParamsForMiss =
-            p_Param->ccNextEngineParamsForMiss;
-
-    p_HashKeyParams = p_IndxHashCcNodeParam->keysParams.keyParams;
-
-    for (i = 0; i < numOfSets; i++)
-    {
-        /* Each exact-match node will be marked as a 'bucket' and provided with
-           a pointer to statistics counters, to be used for 'miss' entry
-           statistics */
-        p_CcNode = (t_FmPcdCcNode *)XX_Malloc(sizeof(t_FmPcdCcNode));
-        if (!p_CcNode)
-            break;
-        memset(p_CcNode, 0, sizeof(t_FmPcdCcNode));
-
-        p_CcNode->isHashBucket = TRUE;
-        p_CcNode->h_MissStatsCounters = h_MissStatsCounters;
-
-        err = MatchTableSet(h_FmPcd, p_CcNode, p_ExactMatchCcNodeParam);
-        if (err)
-            break;
-
-        p_HashKeyParams[i].ccNextEngineParams.nextEngine = e_FM_PCD_CC;
-        p_HashKeyParams[i].ccNextEngineParams.statisticsEn = FALSE;
-        p_HashKeyParams[i].ccNextEngineParams.params.ccParams.h_CcNode =
-                p_CcNode;
-    }
-
-    if (i < numOfSets)
-    {
-        for (i = i - 1; i >= 0; i--)
-            FM_PCD_MatchTableDelete(
-                    p_HashKeyParams[i].ccNextEngineParams.params.ccParams.h_CcNode);
-
-        FM_MURAM_FreeMem(FmPcdGetMuramHandle(h_FmPcd), h_MissStatsCounters);
-
-        REPORT_ERROR(MAJOR, E_NULL_POINTER, NO_MSG);
-        XX_Free(p_IndxHashCcNodeParam);
-        XX_Free(p_ExactMatchCcNodeParam);
-        return NULL;
-    }
-
-    /* Creating indexed-hash CC node */
-    p_IndxHashCcNodeParam->extractCcParams.type = e_FM_PCD_EXTRACT_NON_HDR;
-    p_IndxHashCcNodeParam->extractCcParams.extractNonHdr.src =
-            e_FM_PCD_EXTRACT_FROM_HASH;
-    p_IndxHashCcNodeParam->extractCcParams.extractNonHdr.action =
-            e_FM_PCD_ACTION_INDEXED_LOOKUP;
-    p_IndxHashCcNodeParam->extractCcParams.extractNonHdr.icIndxMask =
-            p_Param->hashResMask;
-    p_IndxHashCcNodeParam->extractCcParams.extractNonHdr.offset =
-            p_Param->hashShift;
-    p_IndxHashCcNodeParam->extractCcParams.extractNonHdr.size = 2;
-
-    p_IndxHashCcNodeParam->keysParams.maxNumOfKeys = numOfSets;
-    p_IndxHashCcNodeParam->keysParams.maskSupport = FALSE;
-    p_IndxHashCcNodeParam->keysParams.statisticsMode =
-            e_FM_PCD_CC_STATS_MODE_NONE;
-    /* Number of keys of this node is number of sets of the hash */
-    p_IndxHashCcNodeParam->keysParams.numOfKeys = numOfSets;
-    p_IndxHashCcNodeParam->keysParams.keySize = 2;
-
-    p_CcNodeHashTbl = FM_PCD_MatchTableSet(h_FmPcd, p_IndxHashCcNodeParam);
-
-    if (p_CcNodeHashTbl)
-    {
-        p_CcNodeHashTbl->kgHashShift = p_Param->kgHashShift;
-
-        /* Storing the allocated counters for buckets 'miss' in the hash table
-         and if statistics for miss were enabled. */
-        p_CcNodeHashTbl->h_MissStatsCounters = h_MissStatsCounters;
-        p_CcNodeHashTbl->statsEnForMiss = statsEnForMiss;
-    }
-
-    XX_Free(p_IndxHashCcNodeParam);
-    XX_Free(p_ExactMatchCcNodeParam);
-
-    return p_CcNodeHashTbl;
-}
-
-t_Error FM_PCD_HashTableDelete(t_Handle h_HashTbl)
-{
-    t_FmPcdCcNode *p_HashTbl = (t_FmPcdCcNode *)h_HashTbl;
-    t_Handle h_FmPcd;
-    t_Handle *p_HashBuckets, h_MissStatsCounters;
-    uint16_t i, numOfBuckets;
-    t_Error err;
-
-    SANITY_CHECK_RETURN_ERROR(p_HashTbl, E_INVALID_HANDLE);
-
-    /* Store all hash buckets before the hash is freed */
-    numOfBuckets = p_HashTbl->numOfKeys;
-
-    p_HashBuckets = (t_Handle *)XX_Malloc(numOfBuckets * sizeof(t_Handle));
-    if (!p_HashBuckets)
-        RETURN_ERROR(MAJOR, E_NO_MEMORY, NO_MSG);
-
-    for (i = 0; i < numOfBuckets; i++)
-        p_HashBuckets[i] =
-                p_HashTbl->keyAndNextEngineParams[i].nextEngineParams.params.ccParams.h_CcNode;
-
-    h_FmPcd = p_HashTbl->h_FmPcd;
-    h_MissStatsCounters = p_HashTbl->h_MissStatsCounters;
-
-    /* Free the hash */
-    err = FM_PCD_MatchTableDelete(p_HashTbl);
-
-    /* Free each hash bucket */
-    for (i = 0; i < numOfBuckets; i++)
-        err |= FM_PCD_MatchTableDelete(p_HashBuckets[i]);
+        REPORT_ERROR(MAJOR, E_INVALID_VALUE,
+                ("RMON statistics mode is not supported for hash table"));
+        return NULL;
+    }
 
-    XX_Free(p_HashBuckets);
+#ifndef USE_ENHANCED_EHASH
+#if (DPAA_VERSION >= 11)
+    if (p_Param->externalHash)
+        return ExternalHashTableSet(h_FmPcd, p_Param);
+    else
+#endif /* (DPAA_VERSION >= 11) */
+        return InternalHashTableSet(h_FmPcd, p_Param);
+#else
+        return ExternalHashTableSet(h_FmPcd, p_Param);
+#endif /* USE_ENHANCED_EHASH */
+}
 
-    /* Free statistics counters for 'miss', if these were allocated */
-    if (h_MissStatsCounters)
-        FM_MURAM_FreeMem(FmPcdGetMuramHandle(h_FmPcd), h_MissStatsCounters);
+t_Error FM_PCD_HashTableDelete(t_Handle h_HashTbl)
+{
+    t_FmPcdCcNode *p_HashTbl = (t_FmPcdCcNode *)h_HashTbl;
 
-    if (err)
-        RETURN_ERROR(MAJOR, err, NO_MSG);
+    SANITY_CHECK_RETURN_ERROR(p_HashTbl, E_INVALID_HANDLE);
 
-    return E_OK;
+#ifndef USE_ENHANCED_EHASH
+#if (DPAA_VERSION >= 11)
+    if (p_HashTbl->externalHash)
+        return ExternalHashTableDelete(p_HashTbl);
+    else
+#endif /* (DPAA_VERSION >= 11) */
+        return InternalHashTableDelete(p_HashTbl);
+#else
+        return -1; /* delete table code not added for USE_ENHANCED_EHASH */
+#endif /* USE_ENHANCED_EHASH */
 }
 
 t_Error FM_PCD_HashTableAddKey(t_Handle h_HashTbl, uint8_t keySize,
@@ -7283,125 +8570,49 @@ t_Error FM_PCD_HashTableAddKey(t_Handle h_HashTbl, uint8_t keySize,
         RETURN_ERROR(MAJOR, E_INVALID_VALUE,
                      ("Keys masks not supported for hash table"));
 
-    err = FM_PCD_MatchTableGetIndexedHashBucket(p_HashTbl, keySize,
-                                                p_KeyParams->p_Key,
-                                                p_HashTbl->kgHashShift,
-                                                &h_HashBucket, &bucketIndex,
-                                                &lastIndex);
-    if (err)
-        RETURN_ERROR(MAJOR, err, NO_MSG);
-
-    return FM_PCD_MatchTableAddKey(h_HashBucket, FM_PCD_LAST_KEY_INDEX, keySize,
-                                   p_KeyParams);
+#ifndef USE_ENHANCED_EHASH
+    return InternalHashTableAddKey(h_HashTbl, keySize, p_KeyParams);
+#else
+    return ExternalHashTableAddKey(h_HashTbl, keySize, p_KeyParams);
+#endif // USE_ENHANCED_EHASH
 }
 
+#ifndef USE_ENHANCED_EHASH
 t_Error FM_PCD_HashTableRemoveKey(t_Handle h_HashTbl, uint8_t keySize,
                                   uint8_t *p_Key)
 {
-    t_FmPcdCcNode *p_HashTbl = (t_FmPcdCcNode *)h_HashTbl;
-    t_Handle h_HashBucket;
-    uint8_t bucketIndex;
-    uint16_t lastIndex;
-    t_Error err;
-
-    SANITY_CHECK_RETURN_ERROR(p_HashTbl, E_INVALID_HANDLE);
+    SANITY_CHECK_RETURN_ERROR(h_HashTbl, E_INVALID_HANDLE);
     SANITY_CHECK_RETURN_ERROR(p_Key, E_NULL_POINTER);
 
-    err = FM_PCD_MatchTableGetIndexedHashBucket(p_HashTbl, keySize, p_Key,
-                                                p_HashTbl->kgHashShift,
-                                                &h_HashBucket, &bucketIndex,
-                                                &lastIndex);
-    if (err)
-        RETURN_ERROR(MAJOR, err, NO_MSG);
-
-    return FM_PCD_MatchTableFindNRemoveKey(h_HashBucket, keySize, p_Key, NULL);
+    return InternalHashTableRemoveKey(h_HashTbl, keySize, p_Key);
 }
 
 t_Error FM_PCD_HashTableModifyNextEngine(
         t_Handle h_HashTbl, uint8_t keySize, uint8_t *p_Key,
         t_FmPcdCcNextEngineParams *p_FmPcdCcNextEngineParams)
 {
-    t_FmPcdCcNode *p_HashTbl = (t_FmPcdCcNode *)h_HashTbl;
-    t_Handle h_HashBucket;
-    uint8_t bucketIndex;
-    uint16_t lastIndex;
-    t_Error err;
-
-    SANITY_CHECK_RETURN_ERROR(p_HashTbl, E_INVALID_HANDLE);
+    SANITY_CHECK_RETURN_ERROR(h_HashTbl, E_INVALID_HANDLE);
     SANITY_CHECK_RETURN_ERROR(p_Key, E_NULL_POINTER);
     SANITY_CHECK_RETURN_ERROR(p_FmPcdCcNextEngineParams, E_NULL_POINTER);
 
-    err = FM_PCD_MatchTableGetIndexedHashBucket(p_HashTbl, keySize, p_Key,
-                                                p_HashTbl->kgHashShift,
-                                                &h_HashBucket, &bucketIndex,
-                                                &lastIndex);
-    if (err)
-        RETURN_ERROR(MAJOR, err, NO_MSG);
-
-    return FM_PCD_MatchTableFindNModifyNextEngine(h_HashBucket, keySize, p_Key,
-                                                  NULL,
-                                                  p_FmPcdCcNextEngineParams);
+    return InternalHashTableModifyNextEngine(h_HashTbl, keySize, p_Key, p_FmPcdCcNextEngineParams);
 }
+#endif // USE_ENHANCED_EHASH
 
 t_Error FM_PCD_HashTableModifyMissNextEngine(
         t_Handle h_HashTbl,
         t_FmPcdCcNextEngineParams *p_FmPcdCcNextEngineParams)
 {
-    t_FmPcdCcNode *p_HashTbl = (t_FmPcdCcNode *)h_HashTbl;
-    t_Handle h_HashBucket;
-    uint8_t i;
-    bool nullifyMissStats = FALSE;
-    t_Error err;
-
+#ifndef USE_ENHANCED_EHASH
     SANITY_CHECK_RETURN_ERROR(h_HashTbl, E_INVALID_HANDLE);
     SANITY_CHECK_RETURN_ERROR(p_FmPcdCcNextEngineParams, E_NULL_POINTER);
 
-    if ((!p_HashTbl->h_MissStatsCounters)
-            && (p_FmPcdCcNextEngineParams->statisticsEn))
-        RETURN_ERROR(
-                MAJOR,
-                E_CONFLICT,
-                ("Statistics are requested for a key, but statistics mode was set"
-                "to 'NONE' upon initialization"));
-
-    if (p_HashTbl->h_MissStatsCounters)
-    {
-        if ((!p_HashTbl->statsEnForMiss)
-                && (p_FmPcdCcNextEngineParams->statisticsEn))
-            nullifyMissStats = TRUE;
-
-        if ((p_HashTbl->statsEnForMiss)
-                && (!p_FmPcdCcNextEngineParams->statisticsEn))
-        {
-            p_HashTbl->statsEnForMiss = FALSE;
-            p_FmPcdCcNextEngineParams->statisticsEn = TRUE;
-        }
-    }
-
-    for (i = 0; i < p_HashTbl->numOfKeys; i++)
-    {
-        h_HashBucket =
-                p_HashTbl->keyAndNextEngineParams[i].nextEngineParams.params.ccParams.h_CcNode;
-
-        err = FM_PCD_MatchTableModifyMissNextEngine(h_HashBucket,
-                                                    p_FmPcdCcNextEngineParams);
-        if (err)
-            RETURN_ERROR(MAJOR, err, NO_MSG);
-    }
-
-    if (nullifyMissStats)
-    {
-        memset(p_HashTbl->h_MissStatsCounters, 0,
-               (2 * FM_PCD_CC_STATS_COUNTER_SIZE));
-        memset(p_HashTbl->h_MissStatsCounters, 0,
-               (2 * FM_PCD_CC_STATS_COUNTER_SIZE));
-        p_HashTbl->statsEnForMiss = TRUE;
-    }
-
-    return E_OK;
+    return InternalHashTableModifyMissNextEngine(h_HashTbl, p_FmPcdCcNextEngineParams);
+#else
+    return ExternalHashTableModifyMissNextEngine(h_HashTbl, p_FmPcdCcNextEngineParams);
+#endif
 }
 
-
 t_Error FM_PCD_HashTableGetMissNextEngine(
         t_Handle h_HashTbl,
         t_FmPcdCcNextEngineParams *p_FmPcdCcNextEngineParams)
@@ -7411,6 +8622,11 @@ t_Error FM_PCD_HashTableGetMissNextEngine(
 
     SANITY_CHECK_RETURN_ERROR(p_HashTbl, E_INVALID_HANDLE);
 
+#ifdef USE_ENHANCED_EHASH
+    if (p_HashTbl->externalHash)
+        return E_NOT_SUPPORTED;
+#endif /* USE_ENHANCED_EHASH */
+
     /* Miss next engine of each bucket was initialized with the next engine of the hash table */
     p_HashBucket =
             p_HashTbl->keyAndNextEngineParams[0].nextEngineParams.params.ccParams.h_CcNode;
@@ -7422,6 +8638,23 @@ t_Error FM_PCD_HashTableGetMissNextEngine(
     return E_OK;
 }
 
+t_Error FM_PCD_HashTableModifyMissMonitorAddr(
+        t_Handle h_HashTbl,
+        uintptr_t monitorAddr)
+{
+    t_FmPcdCcNode *p_HashTbl = (t_FmPcdCcNode *)h_HashTbl;
+
+    SANITY_CHECK_RETURN_ERROR(h_HashTbl, E_INVALID_HANDLE);
+    SANITY_CHECK_RETURN_ERROR(monitorAddr, E_NULL_POINTER);
+
+#if (DPAA_VERSION >= 11)
+    if (p_HashTbl->externalHash)
+        return ExternalHashTableModifyMissMonitorAddr(h_HashTbl, monitorAddr);
+    else
+#endif /* (DPAA_VERSION >= 11) */
+        return E_NOT_SUPPORTED;
+}
+
 t_Error FM_PCD_HashTableFindNGetKeyStatistics(
         t_Handle h_HashTbl, uint8_t keySize, uint8_t *p_Key,
         t_FmPcdCcKeyStatistics *p_KeyStatistics)
@@ -7436,8 +8669,13 @@ t_Error FM_PCD_HashTableFindNGetKeyStatistics(
     SANITY_CHECK_RETURN_ERROR(p_Key, E_NULL_POINTER);
     SANITY_CHECK_RETURN_ERROR(p_KeyStatistics, E_NULL_POINTER);
 
+#ifdef USE_ENHANCED_EHASH
+    if (p_HashTbl->externalHash)
+        return E_NOT_SUPPORTED;
+#endif /* USE_ENHANCED_EHASH */
+
     err = FM_PCD_MatchTableGetIndexedHashBucket(p_HashTbl, keySize, p_Key,
-                                                p_HashTbl->kgHashShift,
+                                                0,
                                                 &h_HashBucket, &bucketIndex,
                                                 &lastIndex);
     if (err)
@@ -7456,6 +8694,11 @@ t_Error FM_PCD_HashTableGetMissStatistics(
     SANITY_CHECK_RETURN_ERROR(p_HashTbl, E_INVALID_HANDLE);
     SANITY_CHECK_RETURN_ERROR(p_MissStatistics, E_NULL_POINTER);
 
+#ifdef USE_ENHANCED_EHASH
+    if (p_HashTbl->externalHash)
+        return E_NOT_SUPPORTED;
+#endif /* USE_ENHANCED_EHASH */
+
     if (!p_HashTbl->statsEnForMiss)
         RETURN_ERROR(MAJOR, E_INVALID_STATE,
                      ("Statistics were not enabled for miss"));
@@ -7465,3 +8708,240 @@ t_Error FM_PCD_HashTableGetMissStatistics(
 
     return FM_PCD_MatchTableGetMissStatistics(h_HashBucket, p_MissStatistics);
 }
+
+static t_Error GetAgingMask(t_Handle h_FmPcd,
+                            t_Handle h_FmPcdCcNode,
+                            uint16_t keyIndex,
+                            bool reset,
+                            uint32_t *p_Mask)
+{
+    t_FmPcd *p_FmPcd = (t_FmPcd *)h_FmPcd;
+    t_FmPcdCcNode *p_CcNode = (t_FmPcdCcNode *)h_FmPcdCcNode;
+    t_FmPcdCcNextEngineParams *p_NextEngineParams = NULL;
+    t_List h_NodesLst;
+    uint32_t newAgingMask, oldAgingMask, adAddrOffset;
+    t_AdOfTypeContLookup *p_AdContLookup;
+    t_Error err;
+
+    INIT_LIST(&h_NodesLst);
+
+    /* Building a list of all action descriptors that point to this node.
+       No sharing on AD with aging, so there should be only one parent. */
+    if (!LIST_IsEmpty(&p_CcNode->ccPrevNodesLst))
+        UpdateAdPtrOfNodesWhichPointsOnCrntMdfNode(p_CcNode, &h_NodesLst,
+                                                   &p_NextEngineParams);
+    ASSERT_COND(LIST_NumOfObjs(&h_NodesLst) == 1);
+
+    adAddrOffset = FmPcdCcGetNodeAddrOffsetFromNodeInfo(p_FmPcd, LIST_FIRST(&h_NodesLst));
+
+    if (reset)
+    {
+        if (keyIndex == FM_PCD_LAST_KEY_INDEX)
+            /* If no specific key index provided the entire aging mask will be reset */
+            newAgingMask = CC_BUILD_AGING_MASK(p_CcNode->numOfKeys);
+        else
+            /* Only the bit that corresponds to the provided index is reset,
+               other bits in the mask will be preserved */
+            newAgingMask = (0x80000000 >> keyIndex);
+
+        err = FmHcPcdCcResetAgingMask(p_FmPcd->h_Hc, adAddrOffset, newAgingMask, &oldAgingMask);
+        if (err)
+            RETURN_ERROR(MAJOR, err, NO_MSG);
+
+        *p_Mask = (oldAgingMask & newAgingMask);
+    }
+    else
+    {
+        p_AdContLookup = (t_AdOfTypeContLookup *)(PTR_MOVE(XX_PhysToVirt(p_FmPcd->physicalMuramBase), adAddrOffset));
+        *p_Mask = GET_UINT32(p_AdContLookup->gmask);
+    }
+
+    ReleaseLst(&h_NodesLst);
+
+    return E_OK;
+}
+
+t_Error FM_PCD_HashTableGetKeyAging(t_Handle h_HashTbl,
+                                    uint8_t *p_Key,
+                                    uint8_t keySize,
+                                    bool reset,
+                                    bool *p_KeyAging)
+{
+    t_FmPcdCcNode *p_HashTbl = (t_FmPcdCcNode *)h_HashTbl;
+    t_FmPcd *p_FmPcd;
+    t_Handle h_HashBucket;
+    uint8_t bucketIndex;
+    uint16_t lastIndex, keyIndex;
+    uint32_t agingMask, keyAgingBit;
+    t_Error err;
+
+    SANITY_CHECK_RETURN_ERROR(p_HashTbl, E_INVALID_HANDLE);
+    SANITY_CHECK_RETURN_ERROR(p_Key, E_NULL_POINTER);
+    SANITY_CHECK_RETURN_ERROR(p_KeyAging, E_NULL_POINTER);
+    p_FmPcd = (t_FmPcd *)p_HashTbl->h_FmPcd;
+    SANITY_CHECK_RETURN_ERROR(p_FmPcd, E_INVALID_HANDLE);
+    SANITY_CHECK_RETURN_ERROR(p_FmPcd->h_Hc, E_INVALID_HANDLE);
+
+#ifdef USE_ENHANCED_EHASH
+    if (p_HashTbl->externalHash)
+        return E_NOT_SUPPORTED;
+#endif /* USE_ENHANCED_EHASH */
+
+    err = FM_PCD_MatchTableGetIndexedHashBucket(p_HashTbl, keySize, p_Key,
+                                                0,
+                                                &h_HashBucket, &bucketIndex,
+                                                &lastIndex);
+    if (err)
+        RETURN_ERROR(MAJOR, err, NO_MSG);
+
+    if (!((t_FmPcdCcNode *)h_HashBucket)->agingSupport)
+        RETURN_ERROR(MAJOR, E_INVALID_STATE, ("Aging support was not enabled for this hash table"));
+
+    if (!FmPcdLockTryLockAll(p_FmPcd))
+    {
+        DBG(TRACE, ("FmPcdLockTryLockAll failed"));
+        return ERROR_CODE(E_BUSY);
+    }
+
+    err = FindKeyIndex(h_HashBucket, keySize, p_Key, NULL, &keyIndex);
+    if (GET_ERROR_TYPE(err) != E_OK)
+    {
+        FmPcdLockUnlockAll(p_FmPcd);
+        RETURN_ERROR(
+                MAJOR,
+                err,
+                ("The received key and mask pair was not found in the match table of the provided node"));
+    }
+
+    err = GetAgingMask(p_FmPcd, h_HashBucket, keyIndex, reset, &agingMask);
+
+    keyAgingBit = (0x80000000 >> keyIndex);
+    *p_KeyAging = ((agingMask & keyAgingBit) ? TRUE : FALSE);
+
+    FmPcdLockUnlockAll(p_FmPcd);
+
+    switch(GET_ERROR_TYPE(err))
+    {
+        case E_OK:
+            return E_OK;
+
+        case E_BUSY:
+            DBG(TRACE, ("E_BUSY error"));
+            return ERROR_CODE(E_BUSY);
+
+        default:
+            RETURN_ERROR(MAJOR, err, NO_MSG);
+    }
+}
+
+t_Error FM_PCD_HashTableGetBucketAging(t_Handle h_HashTbl,
+                                       uint16_t bucketId,
+                                       bool reset,
+                                       uint32_t *p_BucketAgingMask,
+                                       uint8_t *agedKeysArray[31])
+{
+    t_FmPcdCcNode *p_HashTbl = (t_FmPcdCcNode *)h_HashTbl;
+    t_FmPcd *p_FmPcd;
+    t_FmPcdCcNode *p_HashBucket;
+    uint32_t tmpMask, keyIndex = 0, indx = 0;
+    t_Error err;
+
+    SANITY_CHECK_RETURN_ERROR(p_HashTbl, E_INVALID_HANDLE);
+    p_FmPcd = (t_FmPcd *)p_HashTbl->h_FmPcd;
+    SANITY_CHECK_RETURN_ERROR(p_FmPcd, E_INVALID_HANDLE);
+    SANITY_CHECK_RETURN_ERROR(p_FmPcd->h_Hc, E_INVALID_HANDLE);
+
+#ifdef USE_ENHANCED_EHASH
+    if (p_HashTbl->externalHash)
+        return E_NOT_SUPPORTED;
+#endif /* USE_ENHANCED_EHASH */
+
+    p_HashBucket = (t_FmPcdCcNode *)(p_HashTbl->keyAndNextEngineParams[bucketId].nextEngineParams.params.ccParams.h_CcNode);
+
+    if (!p_HashBucket->agingSupport)
+        RETURN_ERROR(MAJOR, E_INVALID_STATE, ("Aging support was not enabled for this hash table"));
+
+    if (!FmPcdLockTryLockAll(p_FmPcd))
+    {
+        DBG(TRACE, ("FmPcdLockTryLockAll failed"));
+        return ERROR_CODE(E_BUSY);
+    }
+
+    err = GetAgingMask(p_FmPcd, p_HashBucket, FM_PCD_LAST_KEY_INDEX, reset, p_BucketAgingMask);
+
+    /* If the user provided a valid pointer, the aged keys will be copied
+       into the provided array of pointers */
+    if ((agedKeysArray) && (*p_BucketAgingMask))
+    {
+        tmpMask = *p_BucketAgingMask;
+
+        while (tmpMask)
+        {
+            /* If a bit is set in the aging mask and it doesn't correspond to miss entry,
+               copy the key into the aged keys array */
+            if ((tmpMask & 0x80000000) && (keyIndex != p_HashBucket->numOfKeys))
+            {
+                memcpy(agedKeysArray[indx], p_HashBucket->keyAndNextEngineParams[keyIndex].key, p_HashBucket->userSizeOfExtraction);
+                indx++;
+            }
+
+            tmpMask = (tmpMask << 1);
+            keyIndex++;
+        }
+    }
+
+    FmPcdLockUnlockAll(p_FmPcd);
+
+    switch(GET_ERROR_TYPE(err))
+    {
+        case E_OK:
+            return E_OK;
+
+        case E_BUSY:
+            DBG(TRACE, ("E_BUSY error"));
+            return ERROR_CODE(E_BUSY);
+
+        default:
+            RETURN_ERROR(MAJOR, err, NO_MSG);
+    }
+}
+
+#if (DPAA_VERSION >= 11)
+/**
+ * FmPcdCcBuildFE - Build/configure a Frame Engine object
+ * @h_FmPcd: Handle to FM PCD
+ * @p_FeParams: FE parameters
+ * @h_FE: Handle to FE object
+ *
+ * Stub implementation - FE configuration for enhanced hash support
+ */
+void FmPcdCcBuildFE(t_Handle h_FmPcd, t_FmPcdFEParams *p_FeParams, t_Handle h_FE)
+{
+    UNUSED(h_FmPcd);
+    UNUSED(p_FeParams);
+    UNUSED(h_FE);
+    /* Stub - FE building for enhanced external hash not implemented */
+}
+
+/**
+ * FmPcdCcBuildContextByFE - Build context using FE parameters
+ * @h_FmPcd: Handle to FM PCD
+ * @p_Context: Context buffer
+ * @offset: Offset in context
+ * @p_FeParams: FE context parameters
+ *
+ * Stub implementation - returns success without action
+ */
+t_Error FmPcdCcBuildContextByFE(t_Handle h_FmPcd,
+                                uint8_t *p_Context,
+                                uint16_t offset,
+                                t_FmPcdFEContextParams *p_FeParams)
+{
+    UNUSED(h_FmPcd);
+    UNUSED(p_Context);
+    UNUSED(offset);
+    UNUSED(p_FeParams);
+    /* Stub - FE context building for enhanced external hash not implemented */
+    return E_OK;
+}
+#endif /* DPAA_VERSION >= 11 */
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_cc.h b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_cc.h
index e3b7016b7f2e..890a9d064305 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_cc.h
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_cc.h
@@ -132,6 +132,43 @@
 #define CC_PC_ILLEGAL                       0xff
 #define CC_SIZE_ILLEGAL                     0
 
+#if (DPAA_VERSION >= 11)
+#define FM_PCD_AD_FE_ENTER_ALLOCATE         0x00800000
+#define FM_PCD_AD_FE_ENTER_OPCODE           0x000000F6
+
+#define FM_PCD_FE_TYPE_MASK           		0x3f000000
+#define FM_PCD_FE_TYPE_HM           		0x01000000
+#define FM_PCD_FE_TYPE_ENQ           		0x02000000
+#define FM_PCD_FE_TYPE_EXIT           		0x03000000
+#define FM_PCD_FE_TYPE_MUX           		0x04000000
+#define FM_PCD_FE_TYPE_TRANSITION      		0x05000000
+#define FM_PCD_FE_TYPE_EXT_HASH      		0x06000000
+
+#define FM_PCD_FE_WS_OFFSET_MASK       		0x0000ffff
+#define FM_PCD_FE_NEXT_FE_ADDR_MASK    		0x00ffffff
+
+#define FM_PCD_FE_T_HM_PAHM         		0x00800000
+
+#define FM_PCD_FE_T_ENQ_MPPN                0x00800000
+#define FM_PCD_FE_T_ENQ_PP         			0x00040000
+#define FM_PCD_FE_T_ENQ_SP         			0x00020000
+#define FM_PCD_FE_T_ENQ_FQID       			0x00010000
+#define FM_PCD_FE_T_ENQ_NIA_MASK   			0x00ffffff
+
+#define FM_PCD_FE_T_EXIT_DEALLOCATE        	0x00800000
+
+#define FM_PCD_FE_T_TRANSITION_DEALLOCATE   0x00800000
+#define FM_PCD_FE_T_TRANSITION_AD_FROM_WS   0x00400000
+
+#define FM_PCD_FE_T_HASH_UPDATE_TS          0x00020000
+#define FM_PCD_FE_T_HASH_UPDATE_STATS       0x00010000
+#define FM_PCD_FE_T_HASH_LIODN_MASK         0x0000003F
+#define FM_PCD_FE_T_HASH_LIODN_SHIFT        56
+#define FM_PCD_FE_T_HASH_ELIODN_MASK        0x000003c0
+#define FM_PCD_FE_T_HASH_ELIODN_SHIFT       38
+
+#endif /* (DPAA_VERSION >= 11) */
+
 #define FM_PCD_CC_KEYS_MATCH_TABLE_ALIGN    16
 #define FM_PCD_CC_AD_TABLE_ALIGN            16
 #define FM_PCD_CC_AD_ENTRY_SIZE             16
@@ -184,6 +221,9 @@ typedef uint32_t ccPrivateInfo_t; /**< private info of CC: */
 #define CC_PRIVATE_INFO_IC_DEQ_FQID_INDEX_LOOKUP   0x10000000
 
 #define CC_BUILD_AGING_MASK(numOfKeys)      ((((1LL << ((numOfKeys) + 1)) - 1)) << (31 - (numOfKeys)))
+
+#define CC_EXT_HASH_BUCKET_SIZE					256
+
 /***********************************************************************/
 /*          Memory map                                                 */
 /***********************************************************************/
@@ -191,6 +231,31 @@ typedef uint32_t ccPrivateInfo_t; /**< private info of CC: */
 #pragma pack(push,1)
 #endif /* defined(__MWERKS__) && ... */
 
+#if (DPAA_VERSION >= 11)
+typedef _Packed struct t_ExtHashFe {
+    volatile uint32_t misc;
+    volatile uint16_t hashMask;
+    volatile uint8_t contextSize;
+    volatile uint8_t hashShift;
+    volatile uint32_t liodnTableAndTablePtrHi;
+    volatile uint32_t tablePtrLow;
+    volatile uint32_t missResultPtr;
+    volatile uint32_t nextFEPtr;
+    volatile uint32_t missNextFEPtr;
+} _PackedType t_ExtHashFe;
+
+typedef struct
+{
+    volatile uint32_t general;
+    volatile uint32_t maskOffset;
+    volatile uint32_t addrHigh;
+    volatile uint32_t addrLow;
+    volatile uint32_t missResultPointer;
+    volatile uint32_t nextFEPointer;
+    volatile uint32_t missNextFEPointer;
+} t_FEOfTypeHash;
+#endif /* (DPAA_VERSION >= 11) */
+
 typedef struct
 {
     volatile uint32_t fqid;
@@ -230,6 +295,32 @@ typedef union
 /*  Driver's internal structures                                       */
 /***********************************************************************/
 
+#pragma pack(push,1)
+typedef struct
+{
+    uint32_t		next_bucket_addr;
+    uint32_t		prev_last_bucket_ptr;
+    uint8_t			not_last;
+    uint8_t			valid_keys;
+    uint16_t		reserved1[0x3];
+    uint8_t			key_result[0xF0];
+} t_FmExtHashBucket;
+
+typedef struct {
+	uint64_t contex_addr;
+	uint64_t monitoring_addr;
+} t_FmExtHashResult;
+
+#pragma pack(pop)
+
+
+typedef struct
+{
+	uint8_t *bucket_pool_base_ptr;
+	int last_bucket;
+	t_FmExtHashBucket **bucket_stack;
+} t_FmExtHashBucketPool;
+
 typedef struct t_FmPcdStatsObj
 {
     t_Handle        h_StatsAd;
@@ -280,6 +371,7 @@ typedef struct
     t_Handle            h_FrmReplicForAdd;
     t_Handle            h_FrmReplicForRmv;
     bool                tree;
+    e_ModifyState   modifyState;
 
     t_FmPcdCcKeyAndNextEngineParams  keyAndNextEngineParams[CC_MAX_NUM_OF_KEYS];
 } t_FmPcdModifyCcKeyAdditionalParams;
@@ -290,6 +382,37 @@ typedef struct
     t_Handle    h_CcNode;
 } t_CcNextEngineInfo;
 
+#if (DPAA_VERSION >= 11)
+typedef struct {
+    uint8_t     *p_Context;
+    t_List      node;
+} t_FmPcdCcNodeFEContextObj;
+#define FM_PCD_FE_CONTEXT_OBJ(ptr)  LIST_OBJECT(ptr, t_FmPcdCcNodeFEContextObj, node)
+
+typedef struct
+{
+    bool                allocateBuffer;
+    t_ExtHashFe         *p_FE;
+    t_Handle            h_MissFE;
+    t_ExtHashResult     *p_MissResult;
+    uint8_t             dataMemId;
+    uint16_t            dataLiodnOffset;
+    uintptr_t           missMonitorAddr;
+    bool                drvAllocMissMonitorAddr;
+    t_List              availableContextLst;
+    t_List              usedContextLst;
+ 
+	t_FmExtHashBucketPool hash_bucket_pool;
+	t_FmExtHashBucket 	*table_base_ptr;
+	uint16_t 			hash_mask;
+	uint8_t 			hash_size;
+	uint8_t 			crc_shift;
+	uint8_t 			key_size;
+	uint8_t 			aligned_key_size;
+	uint8_t 			max_ways;
+} t_FmPcdCcNodeExtHashInfo;
+#endif /* (DPAA_VERSION >= 11) */
+
 typedef struct
 {
     uint16_t            numOfKeys;
@@ -303,6 +426,7 @@ typedef struct
     uint32_t            countersArraySize;
 
     bool                isHashBucket;               /**< Valid for match table node that is a bucket of a hash table only */
+    bool                agingSupport;               /**< Valid for match table node that is a bucket of a hash table only */
     t_Handle            h_MissStatsCounters;        /**< Valid for hash table node and match table that is a bucket;
                                                          Holds the statistics counters allocated by the hash table and
                                                          are shared by all hash table buckets; */
@@ -344,6 +468,12 @@ typedef struct
     uint32_t            shadowAction;
     uint8_t             userSizeOfExtraction;
     uint8_t             userOffset;
+ 
+#if (DPAA_VERSION >= 11)
+    bool                externalHash;
+    t_FmPcdCcNodeExtHashInfo extHashInfo;
+#endif /* (DPAA_VERSION >= 11) */
+
     uint8_t             kgHashShift;            /* used in hash-table */
 
     t_Handle            h_Spinlock;
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_cc_dbg.h b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_cc_dbg.h
new file mode 100644
index 000000000000..2f7e5f302ceb
--- /dev/null
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_cc_dbg.h
@@ -0,0 +1,1378 @@
+// SPDX-License-Identifier: GPL-2.0+
+/*
+ * Copyright 2018 NXP
+ */
+
+
+/******************************************************************************
+ @File          fm_cc_dbg.h
+
+ @Description   FM Coarse Classifier debug
+ *//***************************************************************************/
+
+#include <linux/slab.h>
+#include "fm_pcd_ext.h"
+//enable prints from FMD
+//#define FM_CC_DEBUG 		1
+
+//enable prints from host commands
+#define FM_CC_MURAM_DEBUG 	1
+	
+//table descriptor structure
+struct generic_5_off_ic_gmask {
+	union {
+		struct {
+			uint32_t cc_adbase:24;
+			uint32_t key_length:6;
+			uint32_t type:2;
+		}__attribute__((packed));
+		uint32_t word_0;
+	};
+	union {
+		struct {
+			uint32_t match_table_ptr:23;
+			uint32_t LM:1;
+			uint32_t match_table_entries_num:8;	
+		}__attribute__((packed));
+		uint32_t word_1;
+	};
+	union {	
+		struct {
+			uint32_t op_code:8;
+			uint32_t reserved:8;
+			uint32_t offset:8;
+			uint32_t offset_from_parse_result:8;
+		}__attribute__((packed));
+		uint32_t word_2;
+	};
+	uint32_t age_mask;
+}__attribute__((packed));
+
+//new class result descriptor structure
+struct new_class_res_desc {
+	union {
+		uint32_t word_0;
+		struct {
+			uint32_t fqid:24;
+			uint32_t rspid:6;
+			uint32_t type:2;
+		}__attribute__((packed));
+	};
+	union {
+		uint32_t word_1;
+		struct {
+			uint32_t next_ad_index:16;	
+			uint32_t policer_profile:8;	
+			uint32_t vspe:1;	
+			uint32_t resv:1;	
+			uint32_t nenq:1;	
+			uint32_t cwd:1;	
+			uint32_t nl:1;	
+			uint32_t fwd:1;	
+			uint32_t ebad:1;	
+			uint32_t ebd:1;	
+
+		}__attribute__((packed));
+	};
+	union {
+		uint32_t word_2;
+		struct {
+			uint32_t fpm_nia:24;
+			uint32_t ovom:1;
+			uint32_t no_cspen:1;
+			uint32_t resv_2:1;
+			uint32_t fr:1;
+			uint32_t resv_1:1;
+			uint32_t naden:1;
+			uint32_t stats_en:1;
+			uint32_t extended_mode:1;
+		}__attribute__((packed));
+	};
+	uint32_t word_3;
+};
+
+//statistics table descriptor structure
+struct stats_table_desc {
+	union {
+		uint32_t word_0;
+		struct {
+			uint32_t stats_prof_tbl_addr:24;
+			uint32_t reserved:8;
+			uint32_t type:2;
+		}__attribute__((packed));
+	};
+	uint32_t word_1;
+	union {
+		uint32_t word_2;
+		struct {
+			uint32_t opcode:8;
+			uint32_t reserved_1:5;
+			uint32_t cond_en:1;
+			uint32_t flr_en:1;
+			uint32_t nad_en:1;
+			uint32_t next_ad_index:16;
+		}__attribute__((packed));
+	};
+	union {
+		uint32_t word_3;
+		struct {
+			uint32_t stats_tbl_addr:24;
+			uint32_t reserved_2:8;
+		}__attribute__((packed));
+	};
+};
+
+//keep classification results descriptor structure
+struct keep_class_res_desc_ad {
+	union {
+		struct {
+			uint32_t reserved_1:29;
+			uint32_t PD:1;
+			uint32_t type:2;
+		}__attribute__((packed));
+		uint32_t word_0;
+	};
+	union {
+		struct {
+			uint32_t next_action_desc_index:16;
+			uint32_t reserved_2:16;
+		}__attribute__((packed));
+		uint32_t word_1;
+	};
+	union {
+		struct {
+			uint32_t fpm_nia:24;
+			uint32_t reserved_3:1;
+			uint32_t no_vspe:1;
+			uint32_t reserved_4:3;
+			uint32_t naden:1;
+			uint32_t statistics_enable:1;
+			uint32_t extended_mode:1;
+		}__attribute__((packed));
+		uint32_t word_2;
+	};
+	uint32_t statistic_counter;
+};
+
+//header modification table desc
+struct hmt_desc {
+	union {
+		struct {
+			uint32_t reserved_2:21;
+			uint32_t naden:1;
+			uint32_t pahm:1;
+			uint32_t reserved_1:7;
+			uint32_t type:2;
+		}__attribute__((packed));
+		uint32_t word_0;
+	};
+	union {
+		struct {
+			uint32_t internal_hmt_ptr:24;
+			uint32_t reserved_3:8;
+		}__attribute__((packed));
+		uint32_t word_1;
+	};
+	union {
+		struct {
+			uint32_t opcode:8;
+			uint32_t reserved_4:8;
+			uint32_t nextdescindex:16;
+		}__attribute__((packed));
+		uint32_t word_2;
+	};
+	uint32_t word_3;
+};
+
+//header removal header manipulation command
+struct hdr_removal_hmc {
+	union {
+		uint32_t word;
+		struct {
+			uint32_t hdrrmvoffset:8;
+			uint32_t hdrrmvsize:8;
+			uint32_t reserved:7;
+			uint32_t last:1;
+			uint32_t opcode:8;
+		}__attribute__((packed));
+	};
+};
+
+//header insert header manipulation command
+struct hdr_insert_hmc {
+	union {
+		uint32_t word;
+		struct {
+			uint32_t hdrinsoffset:8;
+			uint32_t hdrinssize:8;
+			uint32_t reserved:7;
+			uint32_t last:1;
+			uint32_t opcode:8;
+		}__attribute__((packed));
+	};
+};
+
+//header replace header manipulation command
+#define hdr_replace_hmc hdr_insert_hmc
+
+//internal header insert header manipulation command
+struct internal_hdr_insert_hmc {
+	union {
+		uint32_t word_0;
+		struct {
+			uint32_t hdrinsoffset:8;
+			uint32_t hdrinssize:8;
+			uint32_t reserved:7;
+			uint32_t last:1;
+			uint32_t opcode:8;
+		}__attribute__((packed));
+	};
+	union {
+		uint32_t word_1;
+		struct {
+			uint32_t hdrinsptr:24;
+			uint32_t reserved_1:8;
+		}__attribute__((packed));
+	};
+};
+//internal header replace header manipulation command
+#define internal_hdr_replace_hmc internal_hdr_insert_hmc
+
+//protocol specific header removal header manipulation command
+struct proto_specific_hdr_removal_hmc {
+	union {
+                uint32_t word;
+                struct {
+                        uint32_t reserved_1:16;
+                        uint32_t protospec_hdr_rmv_mode:4;
+                        uint32_t reserved:3;
+                        uint32_t last:1;
+                        uint32_t opcode:8;
+                }__attribute__((packed));
+        };
+};
+
+//protocol specific header insert header manipulation command
+struct proto_specific_hdr_insert_hmc {
+        union {
+                uint32_t word_0;
+                struct {
+                        uint32_t reserved_1:16;
+                        uint32_t protospec_hdr_ins_mode:4;
+                        uint32_t reserved:3;
+                        uint32_t last:1;
+                        uint32_t opcode:8;
+                }__attribute__((packed));
+        };
+        union {
+                uint32_t word_1;
+                struct {
+                        uint32_t inthdrptr:24;
+                        uint32_t hdrinssize:8;
+                }__attribute__((packed));
+        };
+
+
+};
+
+//vlan priority update header manipulation command
+struct vlan_priority_update_hmc {
+        union {
+                uint32_t word_0;
+	        struct {
+                        uint32_t vpri_def_value:3;
+                        uint32_t reserved_1:13;
+                        uint32_t vprihdr_rep_mode:3;
+                        uint32_t reserved:4;
+                        uint32_t last:1;
+                        uint32_t opcode:8;
+                }__attribute__((packed));
+        };
+        union {
+                uint32_t word_1;
+	        struct {
+			uint32_t int_hdr_rep_ptr:24;
+			uint32_t reserved_2:8;
+                }__attribute__((packed));
+        };
+};
+
+//local ipv4 update header manipulation command
+struct local_ipv4_update_hmc {
+        union {
+                uint32_t word;
+                struct {
+                        uint32_t ip_ttl:1;
+                        uint32_t ip_tos_mode:2;
+                        uint32_t reserved_1:2;
+                        uint32_t ip_dst:1;
+                        uint32_t ip_src:1;
+                        uint32_t ip_id_mode:1;
+                        uint32_t ip_tos:8;
+                        uint32_t reserved:7;
+                        uint32_t last:1;
+                        uint32_t opcode:8;
+                }__attribute__((packed));
+        };
+};
+
+
+//local tcp udp update header manipulation command
+struct local_tcp_udp_update_hmc {
+        union {
+                uint32_t word_0;
+                struct {
+                        uint32_t reserved:14;
+                        uint32_t tcp_udp_dst:1;
+                        uint32_t tcp_udp_src:1;
+                        uint32_t reserved_1:7;
+                        uint32_t last:1;
+                        uint32_t opcode:8;
+                }__attribute__((packed));
+        };
+        union {
+                uint32_t word_1;
+		struct {
+			uint32_t dst_port:16;
+			uint32_t src_port:16;
+		}__attribute__((packed));
+	};
+};
+
+
+//ipv6 header update header manipulation command
+struct ipv6_update_hmc {
+	union {
+		uint32_t word;
+		struct {
+			int32_t ip_hop_limit:1;
+			uint32_t ip_traffic_class_mode:2;
+			uint32_t reserved_1:3;
+			uint32_t ipdst:1;
+			uint32_t ipsrc:1;
+			uint32_t iptraffic_class:8;
+			uint32_t reserved:7;
+			uint32_t last:1;
+			uint32_t opcode:8;
+		}__attribute__((packed));;
+	};
+};
+
+//internal ipheader replace header manipulation command
+struct internal_iphdr_replace_hmc {
+	union {
+		uint32_t word_0;
+		struct {
+			uint32_t reserved:16;
+			uint32_t inl3smode:2;
+			uint32_t reserved_1:3;
+			int32_t ttl_hop_limit:1;
+			uint32_t ipid_mode:1;
+			uint32_t last:1;
+			uint32_t opcode:8;
+		}__attribute__((packed));
+	};
+	union {
+		uint32_t word_1;
+		struct {
+			uint32_t l3hdr_ptr:24;
+			uint32_t l3hdr_ins_size:8;
+		}__attribute__((packed));;
+	};
+	union {
+		uint32_t word_2;
+		struct {
+			uint32_t id_hdr_ptr:24;
+			uint32_t reserved_2:8;
+		}__attribute__((packed));
+	};
+};
+
+extern void *FmMurambaseAddr;
+static void display_pcd_cc_ad(void *ad);
+void display_cc_node(void *handle, const char *func_name);
+static void display_generic_5_off_ic_gmask(void *ptr);
+
+static void display_buf_data(void *dataptr, uint32_t size)
+{
+	uint32_t ii;
+	uint8_t *ptr;
+
+	ptr = (uint8_t *)dataptr;	
+	for (ii = 0; ii < size; ii++) {
+		if ((ii % 16) == 15) 
+			printk("%02x\n", *ptr);
+		else
+			printk("%02x ", *ptr);
+		ptr++;
+	}
+        if (ii % 16)
+		printk("\n");
+}
+
+static inline uint32_t swap_word(uint32_t *ptr)
+{
+	uint32_t val;
+	val =  ((*ptr >> 24) | (*ptr << 24) | 
+			((*ptr >> 8) & 0x0000ff00) |
+			((*ptr << 8) & 0xff0000));
+	return val;
+}
+
+#ifdef FM_CC_DEBUG 
+static void display_global_mask(t_FmPcdCcNode *ccnode)
+{
+	printk(KERN_CRIT "globalmask \t%p\n, size \t%d\n", 
+		ccnode->p_GlblMask, ccnode->glblMaskSize);
+	if (ccnode->p_GlblMask) {
+		display_buf_data (ccnode->p_GlblMask, ccnode->glblMaskSize);
+	}
+}
+	
+static void display_keymatch_table(t_FmPcdCcNode *ccnode)
+{
+	
+	uint32_t ii;
+	uint32_t keysize;
+	uint8_t *ptr;
+	t_FmPcd *p_FmPcd;
+
+	p_FmPcd = (t_FmPcd *)ccnode->h_FmPcd;
+	printk(KERN_CRIT "keymatchtable \t%p\n", ccnode->h_KeysMatchTable);
+	ii = (uint32_t)(XX_VirtToPhys(ccnode->h_KeysMatchTable) - 
+		p_FmPcd->physicalMuramBase);
+	printk(KERN_CRIT "keymatchtable in muram %08x\n", ii);
+	printk(KERN_CRIT "keysMatchTableMaxSize \t%d\n", 
+			ccnode->keysMatchTableMaxSize);
+	printk(KERN_CRIT "maxNumOfKeys \t%d\n", ccnode->maxNumOfKeys);
+	if (ccnode->lclMask)
+		printk(KERN_CRIT "local mask enabled\n");
+	else
+		printk(KERN_CRIT "No local mask\n");
+	keysize = (ccnode->ccKeySizeAccExtraction * sizeof(uint8_t));
+	printk(KERN_CRIT "keymatchtable in muram %08x, keysize %d, numkeys %d\n", 
+			ii, keysize, ccnode->numOfKeys);
+	ptr = (uint8_t *)ccnode->h_KeysMatchTable;
+	for (ii = 0; ii < ccnode->numOfKeys; ii++) {
+		printk("key %d::\n", ii);
+		display_buf_data((void *)ptr, keysize); 
+		if (ccnode->lclMask)
+			ptr += (2 * keysize);
+		else
+			ptr += keysize;
+	}
+}
+
+static void disp_ht_params(struct t_FmPcdHashTableParams *params)
+{
+	t_FmPcdCcNextEngineParams *missparams;
+	printk(KERN_CRIT "maxNumOfKeys\t%d\n", params->maxNumOfKeys);
+	printk(KERN_CRIT "statisticsMode\t%d\n", params->statisticsMode);
+	printk(KERN_CRIT "kgHashShift\t%d\n", params->kgHashShift);
+	printk(KERN_CRIT "hashResMask\t%d\n", params->hashResMask);
+	printk(KERN_CRIT "hashShift\t%d\n", params->hashShift);
+	printk(KERN_CRIT "matchKeySize\t%d\n", params->matchKeySize);
+	missparams = &params->ccNextEngineParamsForMiss;
+	printk(KERN_CRIT "h_Manip\t%p\n", missparams->h_Manip);
+	printk(KERN_CRIT "statisticsEn\t%d\n", missparams->statisticsEn);
+	switch(missparams->nextEngine) {
+		case e_FM_PCD_CC:
+			printk(KERN_CRIT "next eng - e_FM_PCD_CC\n"); 
+			printk(KERN_CRIT "next ccnode %p\n",
+				missparams->params.ccParams.h_CcNode);
+			break; 
+		case e_FM_PCD_PLCR:
+			printk(KERN_CRIT "next eng - e_FM_PCD_PLCR\n"); 
+			printk(KERN_CRIT "overrideParams %d\n",
+				missparams->params.plcrParams.overrideParams);
+			printk(KERN_CRIT "sharedProfile %d\n",
+				missparams->params.plcrParams.sharedProfile);
+			printk(KERN_CRIT "newFqid %d\n",
+				missparams->params.plcrParams.newFqid);
+			printk(KERN_CRIT "newRelativeStorageProfileId %d\n",
+			missparams->params.plcrParams.newRelativeStorageProfileId);
+			printk(KERN_CRIT "newFqid %d\n",
+				missparams->params.plcrParams.newFqid);
+			break; 
+		case e_FM_PCD_KG:
+			printk(KERN_CRIT "next eng - e_FM_PCD_KG\n"); 
+			printk(KERN_CRIT "overrideFqid %d\n",
+				missparams->params.kgParams.overrideFqid);
+			printk(KERN_CRIT "newFqid %d\n",
+				missparams->params.kgParams.newFqid);
+			printk(KERN_CRIT "newRelativeStorageProfileId %d\n",
+		         missparams->params.kgParams.newRelativeStorageProfileId);
+			printk(KERN_CRIT "h_DirectScheme %p\n",
+				missparams->params.kgParams.h_DirectScheme);
+			break; 
+		case e_FM_PCD_PRS:
+			printk(KERN_CRIT "next eng - e_FM_PCD_PRS\n"); 
+			break; 
+		case e_FM_PCD_FR:
+			printk(KERN_CRIT "next eng - e_FM_PCD_FR\n"); 
+			break; 
+		case e_FM_PCD_HASH:
+			printk(KERN_CRIT "next eng - e_FM_PCD_HASH\n"); 
+			break; 
+		case e_FM_PCD_DONE:
+			printk(KERN_CRIT "next eng - e_FM_PCD_DONE\n"); 
+			printk(KERN_CRIT "action %d\n",
+				missparams->params.enqueueParams.action);
+			printk(KERN_CRIT "overrideFqid %d\n",
+				missparams->params.enqueueParams.overrideFqid);
+			printk(KERN_CRIT "newFqid %d\n",
+				missparams->params.enqueueParams.newFqid);
+			printk(KERN_CRIT "newRelativeStorageProfileId %d\n",
+			missparams->params.enqueueParams.newRelativeStorageProfileId);
+			break;
+		default:
+			printk(KERN_CRIT "next eng %d is invalid\n",
+				missparams->nextEngine); 
+			break;
+	}
+}
+
+static void display_adtable(t_FmPcdCcNode *ccnode)
+{
+	uint32_t ii;
+	t_FmPcd *p_FmPcd;
+	uint8_t *ptr;
+
+	p_FmPcd = (t_FmPcd *)ccnode->h_FmPcd;
+	printk(KERN_CRIT "adtable \t%p\n", ccnode->h_AdTable);
+	ii = (uint32_t)((XX_VirtToPhys(ccnode->h_AdTable) - 
+		p_FmPcd->physicalMuramBase));
+	printk(KERN_CRIT "adtable in muram %08x\n", ii);
+	ptr = (uint8_t *)ccnode->h_AdTable;
+	for (ii = 0; ii < ccnode->numOfKeys; ii++) {
+		printk("ADENTRY %d::\n", ii);
+		display_pcd_cc_ad((uint32_t *)ptr);
+		ptr += FM_PCD_CC_AD_ENTRY_SIZE;
+	}
+}
+
+static void display_enq_params(t_FmPcdCcNextEnqueueParams *enq)
+{
+	printk(KERN_CRIT "action %08x\n", enq->action);
+	if (enq->overrideFqid)
+		printk(KERN_CRIT "Fqid override, new fqid %d(%08x)\n", 
+			enq->newFqid, enq->newFqid);
+	else 
+		printk(KERN_CRIT "No Fqid override\n");
+	printk(KERN_CRIT "newRelativeStorageProfileId %08x\n", 
+			enq->newRelativeStorageProfileId);
+}
+
+static void display_kg_params(t_FmPcdCcNextKgParams *kg)
+{
+	if (kg->overrideFqid)
+		printk(KERN_CRIT "Fqid override, new fqid %d(%08x)\n", 
+			kg->newFqid, kg->newFqid);
+	else 
+		printk(KERN_CRIT "No Fqid override\n");
+	printk(KERN_CRIT "newRelativeStorageProfileId %08x\n", 
+			kg->newRelativeStorageProfileId);
+	printk(KERN_CRIT "newscheme handle %p\n", 
+			kg->h_DirectScheme);
+}
+
+static void display_cc_params(t_FmPcdCcNextCcParams *cc)
+{
+	printk(KERN_CRIT "h_CcNode %p::\n", cc->h_CcNode);
+	display_cc_node((void *)cc->h_CcNode, __FUNCTION__);
+	
+}
+
+static void display_plcr_params(t_FmPcdCcNextPlcrParams *plcr)
+{
+	printk(KERN_CRIT "%s::fill this... plcr %p!!!!\n", __FUNCTION__, plcr);
+}
+
+static void display_next_engine(t_FmPcdCcNextEngineParams *nexteng)
+{
+	printk(KERN_CRIT "nextEngine %08x -> ", nexteng->nextEngine);
+
+	switch (nexteng->nextEngine) {
+		case e_FM_PCD_DONE:
+			{
+				t_FmPcdCcNextEnqueueParams *enq;
+				printk(KERN_CRIT "pcd done\n");
+				enq = (t_FmPcdCcNextEnqueueParams *)
+					&nexteng->params.enqueueParams;
+				display_enq_params(enq);
+				break;
+			}
+		case e_FM_PCD_KG:
+			{
+				t_FmPcdCcNextKgParams *kg;
+				printk(KERN_CRIT "keygen\n");
+				kg = &nexteng->params.kgParams;
+				display_kg_params(kg);
+				break;
+			}
+		case e_FM_PCD_CC:
+			{
+				t_FmPcdCcNextCcParams *cc;
+				printk(KERN_CRIT "coarse classification\n");
+				cc = &nexteng->params.ccParams;
+				display_cc_params(cc);
+				break;
+			}
+		case e_FM_PCD_PLCR:
+			{
+				t_FmPcdCcNextPlcrParams *plcr;
+				printk(KERN_CRIT "policer\n");
+				plcr = &nexteng->params.plcrParams;
+				display_plcr_params(plcr);
+				break;
+			}
+		case e_FM_PCD_PRS:
+			{
+				printk(KERN_CRIT "parser\n");
+				break;
+			}
+		default:
+			printk(KERN_CRIT "unknown type\n");
+			break;
+	}
+	printk(KERN_CRIT "h_Manip %p\n", nexteng->h_Manip);
+	printk(KERN_CRIT "statisticsEn %d\n", nexteng->statisticsEn);
+
+}
+
+static void display_next_engine_param(t_FmPcdCcNode *ccnode)
+{
+	uint32_t ii;
+	t_FmPcdCcKeyAndNextEngineParams *nextengparams;
+
+	nextengparams = &ccnode->keyAndNextEngineParams[0];	
+	for (ii = 0; ii < ccnode->numOfKeys; ii++) {
+		printk(KERN_CRIT "next eng param id %d\n", ii);
+		printk("key %d::", ii);
+		display_buf_data (&nextengparams->key[0], 
+			ccnode->ccKeySizeAccExtraction);
+		printk("mask %d::", ii);
+		display_buf_data (&nextengparams->mask[0], 
+			ccnode->ccKeySizeAccExtraction);
+		printk(KERN_CRIT "requiredAction %x, shadowAction %x\n",
+			nextengparams->requiredAction,
+			nextengparams->shadowAction);
+		display_next_engine(&nextengparams->nextEngineParams);
+		nextengparams++;
+	}
+}
+
+void display_cc_node(void *handle, const char *func_name)
+{
+	t_FmPcdCcNode *ccnode;
+
+	ccnode = (t_FmPcdCcNode *)handle;
+	printk(KERN_CRIT ">>>>>>>>\n%s::ccnode %p\n", func_name, ccnode);
+	if (!ccnode->externalHash) {
+		if (ccnode->maskSupport)
+			printk(KERN_CRIT "mask support enabled\n");
+		else
+			printk(KERN_CRIT "mask support disabled\n");
+		printk(KERN_CRIT "statisticsMode \t%d\n", ccnode->statisticsMode);
+		printk(KERN_CRIT "countersArraySize \t%d\n", ccnode->countersArraySize);
+		if (ccnode->isHashBucket)
+			printk(KERN_CRIT "node is a bucket of a hash table\n");
+		if (ccnode->glblMaskUpdated) {
+			printk(KERN_CRIT "global mask updated\n");
+			display_global_mask(ccnode);
+		} else
+			printk(KERN_CRIT "global mask not updated\n");
+		printk(KERN_CRIT "parseCode \t%d\n", ccnode->parseCode);
+		printk(KERN_CRIT "offset \t%d\n", ccnode->offset);
+		printk(KERN_CRIT "prsArrayOffset \t%d\n", ccnode->prsArrayOffset);
+		printk(KERN_CRIT "ccKeySizeAccExtraction \t%d\n", ccnode->ccKeySizeAccExtraction);
+		printk(KERN_CRIT "sizeOfExtraction \t%d\n", ccnode->sizeOfExtraction);
+
+		printk(KERN_CRIT "shadowAction %08x\n", ccnode->shadowAction);
+		printk(KERN_CRIT "userSizeOfExtraction %08x\n", ccnode->userSizeOfExtraction);
+		printk(KERN_CRIT "userOffset %08x\n", ccnode->userOffset);
+		printk(KERN_CRIT "kgHashShift %08x\n", ccnode->kgHashShift);
+
+		if (ccnode->h_KeysMatchTable) {
+			display_keymatch_table(ccnode);
+		} else {
+			printk(KERN_CRIT "No keymatch table\n");
+		}
+		if (ccnode->h_AdTable) {
+			display_adtable(ccnode);
+		} else {
+			printk(KERN_CRIT "No ad table\n");
+		}
+		display_next_engine_param(ccnode);
+		printk(KERN_CRIT "not ext hash >???\n");
+	} else {
+		printk(KERN_CRIT "ext hash\n");
+	}
+}
+#else
+#define display_cc_node(x, y)
+#define disp_ht_params(x)
+#endif
+
+
+#ifdef FM_CC_MURAM_DEBUG 
+static void *display_new_class_res_desc(void *ad)
+{
+	struct new_class_res_desc desc; 
+	uint32_t *ptr;
+
+	ptr = (uint32_t *)ad;
+	desc.word_0 = swap_word(ptr);
+	desc.word_1 = swap_word(ptr + 1);
+	desc.word_2 = swap_word(ptr + 2);
+	desc.word_3 = swap_word(ptr + 3);
+	printk("rspid %x, ", desc.rspid);
+	printk("fqid %x, ", desc.fqid);
+	printk("policer profile %x, ", desc.policer_profile);
+	printk("Fpm_nia %x\n", desc.fpm_nia);
+	printk("operational mode bits:: ebd %d, ebad %d, fwd %d, nl %d, cwd %d, nenq %d, vspe %d\n", 
+		desc.ebd,
+		desc.ebad,
+		desc.fwd,
+		desc.nl,
+		desc.cwd,
+		desc.nenq,
+		desc.vspe);
+	printk("ext mode %d, stats en %d, naden %d, FR %d, NO_CSPEN %d, OVOM %d\n",
+		desc.extended_mode,
+		desc.stats_en,
+		desc.naden,
+		desc.fr,
+		desc.no_cspen,
+		desc.ovom);
+	printk("Frindex/stats counter %x\n", desc.word_3);
+	if (desc.extended_mode && desc.naden) {
+		printk("next action desc %x\n", desc.next_ad_index);
+		return ((void *)((uint8_t *)FmMurambaseAddr + (desc.next_ad_index << 4)));	
+	}
+	return NULL;  
+}
+
+
+static void display_stats_ad(uint32_t *ptr)
+{
+
+	struct stats_table_desc desc;
+
+	desc.word_0 = swap_word(ptr);
+	desc.word_1 = swap_word(ptr + 1);
+	desc.word_2 = swap_word(ptr + 2);
+	desc.word_3 = swap_word(ptr + 3);
+	printk("SSSSSSSS\nstats table descriptor %p::\n", ptr);
+	printk("cond_en %d\n", desc.cond_en);
+	printk("stats_tbl_addr %x\n", desc.stats_tbl_addr);
+	if (desc.flr_en) {
+		printk("flr_stats_prof_tbl_addr %x\n", desc.stats_prof_tbl_addr);
+	}
+	if (desc.nad_en) {
+		void *ad;
+
+		printk("next action desc %x\n", desc.next_ad_index);
+		ad = (void *)((uint8_t *)FmMurambaseAddr + 
+				(desc.next_ad_index << 4));
+		printk("SSSSSSSS\n");
+		display_pcd_cc_ad(ad);
+	} else
+		printk("SSSSSSSS\n");
+}
+
+
+static uint32_t *display_hdr_removal_hmc(uint32_t *ptr)
+{
+	struct hdr_removal_hmc desc;
+
+	printk("HMC::header removal command:: muram ptr %x\n", 
+		(uint32_t)((uint8_t *)ptr - (uint8_t *)FmMurambaseAddr));
+	display_buf_data(ptr, sizeof(struct hdr_removal_hmc));
+	desc.word = swap_word(ptr);
+	printk("header removal offset %d, ", desc.hdrrmvoffset);
+	printk("header removal size %d\n", desc.hdrrmvsize);
+	ptr += (sizeof(struct hdr_removal_hmc) / sizeof(uint32_t));
+	return ptr;
+}
+
+static uint32_t *display_hdr_insert_hmc(uint32_t *ptr)
+{
+	struct hdr_insert_hmc desc;
+
+	printk("HMC::local header insert command:: muram ptr %x\n", 
+		(uint32_t)((uint8_t *)ptr - (uint8_t *)FmMurambaseAddr));
+	desc.word = swap_word(ptr);
+	printk("header insert offset %d, ", desc.hdrinsoffset);
+	printk("header insert size %d\n", desc.hdrinssize);
+	printk("header to insert::\n");
+        display_buf_data((void *)((uint32_t *)&desc + 1),
+		desc.hdrinssize);
+	ptr += (sizeof(struct hdr_insert_hmc) + 
+		(desc.hdrinssize / sizeof(uint32_t)));
+	return ptr;
+}
+
+
+static uint32_t *display_internal_hdr_insert_hmc(uint32_t *ptr)
+{
+	struct internal_hdr_insert_hmc desc;
+
+	printk("HMC::internal header insert command:: muram ptr %x\n", 
+		(uint32_t)((uint8_t *)ptr - (uint8_t *)FmMurambaseAddr));
+	desc.word_0 = swap_word(ptr);
+	desc.word_1 = swap_word(ptr + 1);
+	printk("header insert offset %d, ", desc.hdrinsoffset);
+	printk("header insert size %d\n", desc.hdrinssize);
+	printk("header ins ptr %d\n", desc.hdrinsptr);
+	printk("header to insert::\n");
+        display_buf_data(((void *)((uint8_t *)FmMurambaseAddr + 
+			desc.hdrinsptr)), desc.hdrinssize);
+	ptr += (sizeof(struct internal_hdr_insert_hmc) / sizeof(uint32_t));
+	return ptr;
+}
+
+static uint32_t *display_hdr_replace_hmc(uint32_t *ptr)
+{
+	struct hdr_replace_hmc desc;
+
+	printk("HMC::local header replace command:: muram ptr %x\n", 
+		(uint32_t)((uint8_t *)ptr - (uint8_t *)FmMurambaseAddr));
+	desc.word = swap_word(ptr);
+	printk("header replace offset %d, ", desc.hdrinsoffset);
+	printk("header replace size %d\n", desc.hdrinssize);
+	printk("header to replace::\n");
+        display_buf_data((void *)((uint8_t *)ptr + 
+		sizeof(struct hdr_replace_hmc)),
+		desc.hdrinssize);
+	ptr += ((sizeof(struct hdr_replace_hmc) + desc.hdrinssize) 
+			/ sizeof(uint32_t));
+	return ptr;
+}
+
+static uint32_t *display_internal_hdr_replace_hmc(uint32_t *ptr)
+{
+        struct internal_hdr_replace_hmc desc;
+
+        printk("HMC::internal header replace command:: muram ptr %x\n", 
+		(uint32_t)((uint8_t *)ptr - (uint8_t *)FmMurambaseAddr));
+        desc.word_0 = swap_word(ptr);
+        desc.word_1 = swap_word(ptr + 1);
+        printk("header replace offset %d, ", desc.hdrinsoffset);
+        printk("header replace size %d\n", desc.hdrinssize);
+        printk("header replace ptr %d\n", desc.hdrinsptr);
+        printk("header to replace::\n");
+        display_buf_data(((void *)((uint8_t *)FmMurambaseAddr +
+                        desc.hdrinsptr)), desc.hdrinssize);
+        ptr += (sizeof(struct internal_hdr_replace_hmc) / sizeof(uint32_t));
+        return ptr;
+}
+
+static uint32_t *display_protosprc_hdr_remove_hmc(uint32_t *ptr)
+{
+        struct proto_specific_hdr_removal_hmc desc;
+
+        printk("HMC::protocol specific header removal command:: muram ptr %x\n", 
+		(uint32_t)((uint8_t *)ptr - (uint8_t *)FmMurambaseAddr));
+        desc.word = swap_word(ptr);
+	switch (desc.protospec_hdr_rmv_mode) {
+		case 0:
+			printk("remove Ethernet/802.3 MAC header\n");
+			break;
+		case 1:
+			printk("remove stacked QTags\n");
+			break;
+		case 2:
+			printk("remove Ethernet/802.3 MAC header + MPLS hdr\n");
+			break;
+		case 3:
+			printk("remove MPLS hdr\n");
+			break;
+		default:
+			printk("reserved remove mode %x\n",
+				desc.protospec_hdr_rmv_mode);
+			break;
+	}
+        ptr += (sizeof(struct proto_specific_hdr_removal_hmc) / 
+		sizeof(uint32_t));
+        return ptr;
+}
+
+static uint32_t *display_protosprc_hdr_insert_hmc(uint32_t *ptr)
+{
+        struct proto_specific_hdr_insert_hmc desc;
+
+        printk("HMC::protocol specific header insert command:: muram ptr %x\n",
+		(uint32_t)((uint8_t *)ptr - (uint8_t *)FmMurambaseAddr));
+        desc.word_0 = swap_word(ptr);
+        desc.word_1 = swap_word(ptr + 1);
+        switch (desc.protospec_hdr_ins_mode) {
+                case 0:
+                        printk("insert MPLS hdr\n");
+                        break;
+                case 1:
+                        printk("insert and update MPLS hdr\n");
+                        break;
+		case 2:
+                        printk("insert and update PPPoE hdr\n");
+                        break;
+                default:
+                        printk("reserved insert mode %x\n",
+                                desc.protospec_hdr_ins_mode);
+			goto update_ptr;
+        }
+	display_buf_data(((void *)((uint8_t *)FmMurambaseAddr +
+                        desc.inthdrptr)), desc.hdrinssize);
+update_ptr:	
+        ptr += (sizeof(struct proto_specific_hdr_insert_hmc) /
+                sizeof(uint32_t));
+        return ptr;
+}
+
+static uint32_t *display_vlan_pri_hdr_update_hmc(uint32_t *ptr)
+{
+        struct vlan_priority_update_hmc desc;
+	uint32_t ii;
+	uint32_t val;
+	uint32_t *intptr;
+
+        printk("HMC::vlan pri header update command::muram ptr %x\n",
+		(uint32_t)((uint8_t *)ptr - (uint8_t *)FmMurambaseAddr));
+        desc.word_0 = swap_word(ptr);
+        desc.word_1 = swap_word(ptr + 1);
+        printk("default vpri value %x\n", desc.vpri_def_value);
+        switch (desc.vprihdr_rep_mode) {
+                case 0:
+                        printk("replace outermost vlan tag with defa value\n");
+                        break;
+                case 1:
+                        printk("translate dscp to vlan pri\n");
+                        printk("int hdr rep ptr %x\n", desc.int_hdr_rep_ptr);
+			intptr = (uint32_t *)((uint8_t *)FmMurambaseAddr +
+                        		desc.int_hdr_rep_ptr);
+			for (ii = 0; ii < 16; ii++) {
+				val = swap_word(intptr);	
+				printk("%02x %02x %02x %02x\n",		
+					(val >> 24), ((val >> 16) & 0xff),
+					((val >> 8) & 0xff), (val & 0xff));
+				intptr++;
+			}
+                        break;
+                default:
+                        printk("reserved vlan pri insert mode %x\n",
+                                desc.vprihdr_rep_mode);
+                        break;
+        }
+        ptr += (sizeof(struct vlan_priority_update_hmc) /
+                sizeof(uint32_t));
+        return ptr;
+}
+
+static uint32_t *display_ipv4_update_hmc(uint32_t *ptr)
+{
+        struct local_ipv4_update_hmc desc;
+	uint32_t size;
+        uint32_t val;
+        uint32_t *intptr;
+
+        printk("HMC::ipv4 update command:: muram ptr %x\n",
+		(uint32_t)((uint8_t *)ptr - (uint8_t *)FmMurambaseAddr));
+	size = (sizeof(struct local_ipv4_update_hmc) /
+                sizeof(uint32_t)); 
+        desc.word = swap_word(ptr);
+	intptr = (ptr + 1);
+ 
+	if (desc.ip_ttl)
+		printk("decrement TTL by 1\n");
+	switch (desc.ip_tos_mode) {
+		case 0:
+			break;
+		case 1:
+			printk("replace tos value with %x\n", desc.ip_tos);
+			break;
+		default:
+			printk("reserved value %x for tos mode\n", desc.ip_tos_mode);
+			break;
+	}
+	if (desc.ip_id_mode) {
+		val = swap_word(intptr);
+		printk("replace ipid field, muram ptr %x\n", (val & 0xffffff));
+		intptr++;
+		size++;
+	}
+	if (desc.ip_src) {
+		val = swap_word(intptr);
+		printk("replace sip field, ipv4 addr %08x\n", val);
+		intptr++;
+		size++;
+	}
+	if (desc.ip_dst) {
+		val = swap_word(intptr);
+		printk("replace dip field, ipv4 addr %08x\n", val);
+		size++;
+	}
+        return (ptr + size);
+}
+
+static uint32_t *display_tcp_udp_update_hmc(uint32_t *ptr)
+{
+        struct local_tcp_udp_update_hmc desc;
+
+        printk("HMC::tcp udp update command:: muram ptr %x\n", 
+		(uint32_t)((uint8_t *)ptr - (uint8_t *)FmMurambaseAddr));
+        desc.word_0 = swap_word(ptr);
+        desc.word_1 = swap_word(ptr + 1);
+	if (desc.tcp_udp_src) {
+		printk("new sport value %04x\n", desc.src_port);
+	}
+	if (desc.tcp_udp_dst) {
+		printk("new dport value %04x\n", desc.dst_port);
+	}
+        return (ptr + (sizeof(struct local_tcp_udp_update_hmc) /
+                sizeof(uint32_t)));
+}
+
+
+static uint32_t *display_ipv6_update_hmc(uint32_t *ptr)
+{
+        struct ipv6_update_hmc desc;
+	uint8_t *intptr;
+	uint32_t size;
+
+	size = (sizeof(struct ipv6_update_hmc) / sizeof(uint32_t));
+	desc.word = swap_word(ptr);
+	intptr = (uint8_t *)(ptr + 1);
+	printk("HMC::Local IPv6 update command\n");
+	if (desc.ip_hop_limit)
+		printk("decrement hop limit\n");
+	switch (desc.ip_traffic_class_mode) {
+		case 0:	
+			break;
+		case 1:
+			printk("replace traffic class with %x\n", desc.iptraffic_class);
+			break;
+		default:
+			printk("reserved traffic class mode %x\n", 
+				desc.ip_traffic_class_mode);
+			break;
+	}
+	if (desc.ipsrc) {
+		printk("new sip::\n");	
+	        display_buf_data((void *)intptr, 16);	
+		intptr += 16;
+		size += 4;
+	}
+	if (desc.ipdst) {
+		printk("new dip::\n");
+	        display_buf_data((void *)intptr, 16);	
+		size += 4;
+	}
+	return (ptr + size);
+}
+
+
+static uint32_t *display_internal_iphdr_replace_hmc(uint32_t *ptr)
+{
+        struct internal_iphdr_replace_hmc desc;
+
+	printk("HMC::Internal IP Header Replace command::\n");
+	desc.word_0 = swap_word(ptr);
+	desc.word_1 = swap_word(ptr + 1);
+	desc.word_2 = swap_word(ptr + 2);
+	if (desc.ipid_mode) {
+		printk("replace ipid, ipid ptr in muram %x\n",
+			desc.id_hdr_ptr);
+	}
+	switch (desc.inl3smode) {
+		case 0:
+			printk("replace ipv4 with ipv6 hdr, size %d::\n",
+				desc.l3hdr_ins_size);
+        		display_buf_data((void *)(desc.l3hdr_ptr + 
+					(uint8_t *)FmMurambaseAddr), 
+					desc.l3hdr_ins_size);
+			if (desc.ttl_hop_limit) 
+				printk("duplicate ttl from hop limit and decr\n");
+			break;
+		case 1:
+			printk("replace ipv6 with ipv4 hdr::\n");
+        		display_buf_data((void *)(desc.l3hdr_ptr + 
+					(uint8_t *)FmMurambaseAddr), 
+					desc.l3hdr_ins_size);
+			if (desc.ttl_hop_limit) 
+				printk("duplicate hop limit from ttl and decr\n");
+			break;
+		default:
+			printk("reserved insl3mode %d\n", desc.inl3smode);
+			break;
+	}
+	return (ptr + (sizeof(struct internal_iphdr_replace_hmc) / sizeof(uint32_t)));
+}
+
+
+static void display_hmt_entries(uint32_t hmtd_offset)
+{
+	uint32_t *ptr;
+	uint32_t opcode;
+
+	ptr = (uint32_t *)(hmtd_offset + (uint8_t *)FmMurambaseAddr);
+next_hmc:
+	printk("%s::ptr %p\n", __FUNCTION__, ptr);
+	opcode = swap_word(ptr);
+	switch (opcode >> 24) {
+		case 1:
+			ptr = display_hdr_removal_hmc(ptr);
+			break;
+		case 2:
+			ptr = display_hdr_insert_hmc(ptr);
+			break;
+		case 3:
+			ptr = display_internal_hdr_insert_hmc(ptr);
+			break;
+		case 5:
+			ptr = display_hdr_replace_hmc(ptr);
+			break;
+		case 6:
+			ptr = display_internal_hdr_replace_hmc(ptr);
+			break;
+		case 8:
+			ptr = display_protosprc_hdr_remove_hmc(ptr);
+			break;
+		case 9:
+			ptr = display_protosprc_hdr_insert_hmc(ptr);
+			break;
+		case 0xb:
+			ptr = display_vlan_pri_hdr_update_hmc(ptr);
+			break;
+		case 0xc:
+			ptr = display_ipv4_update_hmc(ptr);
+			break;
+		case 0xe:
+			ptr = display_tcp_udp_update_hmc(ptr);
+			break;
+		case 0x10:
+			ptr = display_ipv6_update_hmc(ptr);
+			break;
+		case 0x12:
+			ptr = display_internal_iphdr_replace_hmc(ptr);
+			break;
+		case 0x14:
+			printk("UDP/TCP checksum update command\n");
+			ptr++;
+			break;
+		default:
+			printk("unknown opcode %x, cannot continue\n", opcode);
+			return;
+	}
+	if (!(opcode & 0x00800000))
+		goto next_hmc;
+}
+
+static void *display_hmtd(uint32_t *ptr)
+{
+	struct hmt_desc *desc;
+	void *nextad;
+
+	printk("Header manip table desc::\n");
+	nextad = NULL;
+	desc = kzalloc (sizeof(struct hmt_desc), GFP_KERNEL);
+	if (desc) {
+		desc->word_0 = swap_word(ptr);
+		desc->word_1 = swap_word((ptr + 1));
+		desc->word_2 = swap_word((ptr + 2));
+		desc->word_3 = swap_word((ptr + 3));
+		printk("pahm\t%d, ", desc->pahm);
+		printk("internal hmt ptr\t%x\n", desc->internal_hmt_ptr);
+		if (desc->naden) {
+			printk("nextdescidx\t%x\n", (desc->nextdescindex << 4));
+			nextad = (void *)((uint8_t *)FmMurambaseAddr + 
+					(desc->nextdescindex << 4));
+		}
+		printk("HMC_HMC_HMC<<<\n");
+		display_hmt_entries(desc->internal_hmt_ptr);
+		printk("HMC_HMC_HMC>>>\n");
+		kfree(desc);
+	} else {
+		printk("kzalloc failed, cannot HM table descriptor\n");
+	}
+	return (nextad);
+}
+
+static void display_table_desc(uint32_t *ptr)
+{
+	uint32_t opcode;
+	
+	opcode = swap_word(ptr);
+	if ((opcode & 0xc0000000) == 0x40000000) {
+		opcode = swap_word(ptr + 2);
+		switch (opcode & 0xff) {
+			case 0x35:
+				display_hmtd(ptr);
+				break;
+			case 0x36:
+				display_stats_ad(ptr);
+				break;
+			case 0x2b:
+				display_generic_5_off_ic_gmask(ptr);
+				break;
+			default:
+				printk("unsupported opcode %x\n",
+					opcode);
+				break;
+		}
+	}
+}
+
+static void display_ad_table_using_offset(uint32_t ad_offset, 
+		uint32_t kt_offset, uint32_t num_entries,
+		uint32_t keylen)
+{
+	uint32_t ii;
+	uint8_t *ad_ptr;
+	uint8_t *kt_ptr;
+	uint32_t adj_keylen;
+
+	ad_ptr = (ad_offset + (uint8_t *)FmMurambaseAddr);
+	kt_ptr = (kt_offset + (uint8_t *)FmMurambaseAddr);	
+	keylen++;
+	if (keylen % 16) {
+		adj_keylen = (keylen + 16);
+		adj_keylen &= ~0xf;
+	} else
+		adj_keylen = keylen;
+	printk("keylen %d, adjkeylen %d\n", keylen, adj_keylen);
+	for (ii = 0; ii < (num_entries + 1); ii++) {
+		printk("......................\n");
+		//printk("ADENTRY %d::\n", ii);
+		display_buf_data(ad_ptr, FM_PCD_CC_AD_ENTRY_SIZE);
+		if (ii < num_entries) {
+			printk("key::\n");
+			display_buf_data((void *)kt_ptr, keylen);	
+			kt_ptr += adj_keylen;
+			printk("mask::\n");
+			display_buf_data((void *)kt_ptr, keylen);	
+			kt_ptr += adj_keylen;
+		}
+		display_pcd_cc_ad(ad_ptr);
+		ad_ptr += FM_PCD_CC_AD_ENTRY_SIZE;
+	}
+	printk("......................\n");
+}
+
+static void display_generic_5_off_ic_gmask(void *ad)
+{
+	struct generic_5_off_ic_gmask *desc;
+	uint32_t *ptr;
+
+	ptr = (uint32_t *)ad;
+	desc = kzalloc (sizeof(struct generic_5_off_ic_gmask), GFP_KERNEL);
+	if (desc) {
+		desc->word_0 = swap_word(ptr);
+		desc->word_1 = swap_word((ptr + 1));
+		desc->word_2 = swap_word((ptr + 2));
+		desc->age_mask = swap_word((ptr + 3));
+		printk("keylen\t%d\n", (desc->key_length + 1));
+		printk("cc_adbase\t%x\n", desc->cc_adbase);
+		printk("match_table_entries_num\t%d\n", 
+				desc->match_table_entries_num);
+		printk("local mask\t%d\n", desc->LM);
+		printk("match_table_ptr\t%x\n", desc->match_table_ptr);
+		printk("offset_from_parse_result\t%d\n", 
+			desc->offset_from_parse_result);
+		printk("offset\t%d\n", desc->offset);
+		printk("op_code\t%x\n", desc->op_code);
+		display_ad_table_using_offset(desc->cc_adbase,
+		desc->match_table_ptr, desc->match_table_entries_num,
+		desc->key_length);
+		kfree(desc);
+	} else {
+		printk("kzalloc failed, cannot display table descriptor\n");
+	}
+}
+
+static void *display_keep_class_result(void *ad)
+{
+	struct keep_class_res_desc_ad *desc;
+	uint32_t *ptr;
+	uint32_t next_ad_index;
+
+        ptr = (uint32_t *)ad;
+        desc = kzalloc (sizeof(struct keep_class_res_desc_ad), GFP_KERNEL);
+        if (desc) {
+                desc->word_0 = swap_word(ptr);
+                desc->word_1 = swap_word((ptr + 1));
+                desc->word_2 = swap_word((ptr + 2));
+                desc->statistic_counter = swap_word((ptr + 3));
+		if (desc->PD)
+                	printk("Policer disabled, ");
+		else
+                	printk("Policer enabled, ");
+                printk("extended mode %d,\n", desc->extended_mode);
+                printk("naden %d, ", desc->naden);
+                printk("novspe %d\n", desc->no_vspe);
+                printk("statistics_enable\t%d\n", desc->statistics_enable);
+                printk("fpm_nia\t%x\n", desc->fpm_nia);	
+		if (desc->naden) {
+                	printk("nextADindex\t%x\n", desc->next_action_desc_index);
+			next_ad_index = (desc->next_action_desc_index << 4);
+			return ((void *)((uint8_t *)FmMurambaseAddr + next_ad_index));  
+		}
+                kfree(desc);
+
+        } else {
+                printk("kzalloc failed, cannot display keep class descriptor\n");
+        }
+	return NULL;
+}
+
+static void display_pcd_cc_ad(void *ad)
+{
+	uint32_t val;
+
+	printk("============\n");
+disp_nextad:
+	val = swap_word((uint32_t *)ad);
+	switch (val >> 30) {
+		case 0:
+			printk("New Classification result type:: %p\n", ad);
+			ad = display_new_class_res_desc(ad);
+			break;
+		case 1:
+			printk("table desc type:: %p\n", ad);
+			display_table_desc(ad);
+			ad = NULL;
+			break;
+		case 2:
+			printk("Keep Classification result type:: %p\n", ad);
+			ad = display_keep_class_result(ad);
+			break;
+		case 3:
+			printk("reserved for dynamic update of CC tables\n");
+			ad = NULL;
+			break;
+	} 
+	if (ad) {
+		printk("next ad %p\n", ad);
+		display_buf_data(ad, FM_PCD_CC_AD_ENTRY_SIZE);
+		goto disp_nextad;
+	}
+	printk("============\n");
+}
+
+static void display_pcd_cc_hc(t_FmPcd *p_FmPcd, uint32_t oldAdAddrOffset,
+                        uint32_t newAdAddrOffset)
+{
+	void *ad;
+
+	ad = (void *)((uint8_t *)FmMurambaseAddr + oldAdAddrOffset);
+	printk("###### old ad::%x, ad %p\n", oldAdAddrOffset, ad);
+	display_pcd_cc_ad(ad);
+	printk("###### old ad end\n");
+	ad = (void *)((uint8_t *)FmMurambaseAddr + newAdAddrOffset);
+	printk("###### new ad::%x ad %p\n", newAdAddrOffset, ad);
+	display_pcd_cc_ad(ad);
+	printk("###### new ad end\n");
+}
+#else
+#define display_pcd_cc_hc(x, y, z);
+#endif
+
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_ehash.c b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_ehash.c
new file mode 100644
index 000000000000..82d6fc9bfe95
--- /dev/null
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_ehash.c
@@ -0,0 +1,1987 @@
+// SPDX-License-Identifier: GPL-2.0+
+/*
+ * Copyright 2018 NXP
+ */
+
+/**
+ * @file                fm_ehash.c
+ * @description         DPAA enhanced external hash functions
+ */
+
+#define __ERR_MODULE__ MODULE_FM_PCD
+
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/slab.h>
+//#include <linux/fsl_dpa_offload.h>
+//#include <linux/fsl_dpa_classifier.h>
+#include "fm_common.h"
+#include "fm_muram_ext.h"
+#include "fm_ehash.h"
+#include "fm_pcd.h"
+#include "fm_cc.h"
+#include "endian_ext.h"
+
+//#define FM_EHASH_DEBUG 1
+
+#ifdef FM_EHASH_DEBUG 
+#define FM_EHASH_PRINT printk
+#else
+#define FM_EHASH_PRINT(fmt, ...)
+#endif // CDX_DPA_DEBUG
+
+#ifndef EXCLUDE_FMAN_IPR_OFFLOAD
+#define REASSM_DEBUG_SIZE       128
+struct en_exthash_info *ipv4_reassly_tbl_info;
+struct en_exthash_info *ipv6_reassly_tbl_info;
+struct ipr_context_info *IprContextMem;
+
+extern void disp_sch_info(void *);
+extern void *FmMurambaseAddr;
+en_exthash_global_mem *en_global_muram_mem = NULL;
+
+extern void get_indexed_hash_bucket(uint8_t key_size,  uint8_t *key_ptr,
+	        uint8_t crc_shift, uint16_t mask, uint16_t *bucket_index);
+
+void display_reassem_stats(uint32_t type);
+static void display_reassem_params(uint32_t type);
+#endif
+
+#ifdef USE_ENHANCED_EHASH
+static inline void copy_ipaddr(uint32_t *src, uint8_t *dest, uint32_t size)
+{	
+	uint32_t ii;
+	uint32_t val;
+
+	for (ii = 0; ii < size; ii++) {
+		val = cpu_to_be32(*src);
+		memcpy(dest, &val, 4);
+		dest += sizeof(uint32_t);
+	}
+}
+
+
+
+#if 0
+static int fill_ehash_key_info(PCtEntry entry, struct en_ehash_entry *entry)
+{
+	unsigned char *ptr;
+	
+	ptr = &entry->key[0];
+	switch (entry->proto) {
+		case IPPROTOCOL_TCP: 
+		case IPPROTOCOL_UDP:
+			if (IS_IPV6_FLOW(entry))
+			{
+				copy_ipaddr(&entry->Saddr_v6[i], ptr, 4);
+				ptr += 16;
+				copy_ipaddr(&entry->Daddr_v6[i], ptr, 4);
+				ptr += 16;
+			} else {
+				copy_ipaddr(&entry->Saddr_v4, ptr, 1);
+				ptr += 4;
+				copy_ipaddr(&entry->Daddr_v4, ptr, 1);
+				ptr += 4;
+			}
+			*ptr++ = entry->proto;
+			*ptr++ = (entry->Sport >> 8);
+			*ptr++ = (entry->Sport & 0xff);
+			*ptr++ = (entry->Dport >> 8);
+			*ptr++ = (entry->Dport & 0xff);
+			break;
+		default:
+			DPA_ERROR("%s::protocol %d not supported\n",
+					__FUNCTION__, entry->proto);
+			return FAILURE;
+
+	}
+#if 1//
+	{
+		uint32_t size;
+
+		size = (uint32_t)(ptr - &entry->key[0]);
+		printk("keysize %d\n", size);
+		display_buf(&entry->key[0]), size);
+#endif
+	}
+	return SUCCESS;
+}
+#endif
+
+static inline struct en_exthash_tbl_entry *find_entry_in_bucket(struct en_exthash_tbl_entry *entry, 
+		uint8_t *key, uint32_t size)
+{
+#ifdef NO_CUMULATIVE_ENTRY
+	while(1) {
+		if (!entry)
+			break;
+		if (memcmp(key, &entry->hashentry.key[0], size) == 0) 
+			return entry; 
+		entry = entry->next;
+	}
+#else
+	struct en_cumulative_tbl_entry *cumulative_tbl_node = (struct en_cumulative_tbl_entry *)entry;
+	struct en_cumulative_entry *cumulative_node;
+	int ii;
+	if (!entry)
+		return NULL;
+	cumulative_node = &cumulative_tbl_node->cumulative_entry;
+	if (cumulative_node->flags & EN_CUMULATIVE_NODE)
+	{
+		while (cumulative_node)
+		{
+			for(ii=0; ii<cumulative_node->num_key_entries; ii++)
+				if (memcmp(key, &cumulative_node->data[ii*cumulative_node->key_size], size) == 0)
+					return entry;
+			if (cumulative_tbl_node->next_entry)
+			{
+				cumulative_tbl_node = cumulative_tbl_node->next_entry;
+				cumulative_node = &cumulative_tbl_node->cumulative_entry;
+			}
+			else
+				cumulative_node = NULL;
+		}
+	}
+	else if(memcmp(key, &entry->hashentry.key[0], size) == 0) 
+		return entry; 
+#endif // NO_CUMULATIVE_ENTRY
+	return NULL;
+}
+
+void *ExternalHashTableAllocEntry(t_Handle h_HashTbl) 
+{
+	void *entry;
+	struct en_exthash_info *info;
+	
+	entry = NULL;
+	info = (struct en_exthash_info *)h_HashTbl;
+	if (info) {
+		//allocate new entry
+		entry = XX_MallocSmart(sizeof(struct en_exthash_tbl_entry),
+                        0 /*info->dataMemId not used */, EN_EHASH_ENTRY_ALIGN);
+		if (entry) 
+			memset(entry, 0, sizeof(struct en_exthash_tbl_entry));
+		else {
+        		REPORT_ERROR(MAJOR, E_NO_MEMORY,
+                		     ("en_ext_hash_entry"));
+		}
+	}
+	return entry;
+}
+EXPORT_SYMBOL(ExternalHashTableAllocEntry); 
+
+void ExternalHashTableEntryFree(void *entry)
+{
+	XX_FreeSmart(entry);
+}
+EXPORT_SYMBOL(ExternalHashTableEntryFree); 
+
+void *ExternalHashTableAllocCumulativeEntry(t_Handle h_HashTbl)
+{
+	void *entry;
+	struct en_exthash_info *info;
+
+	info = (struct en_exthash_info *) h_HashTbl;
+
+	entry = XX_MallocSmart(sizeof(struct en_cumulative_tbl_entry), 0 /*info->dataMemId not used */, EN_EHASH_ENTRY_ALIGN);
+	if (entry)
+	        memset(entry, 0, sizeof(struct en_cumulative_tbl_entry));
+	else
+	{
+	        REPORT_ERROR(MAJOR, E_NO_MEMORY, ("en_cumulative_entry"));
+	}
+	return entry;
+}
+void ExternalHashTableCumulativeEntryFree(void *entry)
+{
+	XX_FreeSmart(entry);
+}
+
+
+
+#define MAX_HIST_SIZE	15
+void EhashTableWalk(void *h_HashTbl)
+{
+	uint32_t ii;
+	struct en_exthash_info *info;
+	struct en_exthash_tbl_entry *entry;
+	struct en_exthash_bucket *bucket;
+	uint32_t num_entries;
+	uint32_t bucket_entries;
+	uint32_t max_collisions;
+	uint32_t min_collisions;
+	uint32_t histo[MAX_HIST_SIZE + 2];
+	
+
+	num_entries = 0;
+	max_collisions = 0;
+	min_collisions = 0xffffffff;
+	memset(&histo[0], 0, (sizeof(uint32_t) * (MAX_HIST_SIZE + 2)));
+	info = (struct en_exthash_info *)h_HashTbl;
+	bucket = (struct en_exthash_bucket *)info->table_base;
+	printk("%s::tbl %p, num buckets %d base %p\n",
+		__FUNCTION__, info, (info->hashmask + 1), bucket);
+	for (ii = 0; ii <= info->hashmask; ii++) {
+		if (bucket->h) {
+			bucket_entries = 0;
+			entry = XX_PhysToVirt(SwapUint64(bucket->h));
+			while(entry) {
+				bucket_entries++;
+				entry = entry->next;
+			}
+			num_entries += bucket_entries;
+			if (bucket_entries > max_collisions)
+				max_collisions = bucket_entries;
+			if (bucket_entries < min_collisions)
+				min_collisions = bucket_entries;
+			if (max_collisions > MAX_HIST_SIZE)
+				histo[MAX_HIST_SIZE + 1]++;
+			else 
+				histo[max_collisions]++;
+		} else {
+			histo[0]++;
+		}	
+		bucket++;
+	}
+	printk("%s::entries %d, max colls %d, min colls %d\n",
+			__FUNCTION__, num_entries, max_collisions, 
+			min_collisions);
+	printk("num collisions\t	num_buckets\n");	
+	for (ii = 0; ii < MAX_HIST_SIZE; ii++) {
+		printk("%d\t%d\n", ii, histo[ii]);
+	}
+	printk(">15\t%d\n", histo[ii]);
+}
+EXPORT_SYMBOL(EhashTableWalk); 
+
+int ExternalHashTableEntryGetStatsAndTS(void *tbl_entry,
+				struct en_tbl_entry_stats *stats)
+{
+	struct en_exthash_tbl_entry *hash_node;
+	struct en_ehash_entry *entry;
+//	uint32_t val;
+	uint16_t flags;
+
+	hash_node = (struct en_exthash_tbl_entry *)tbl_entry;
+	if(!hash_node)
+		return -1;
+	entry = &hash_node->hashentry;
+	flags = cpu_to_be16(entry->flags);
+	stats->flags = 0;
+        if (GET_TIMESTAMP_ENABLE(flags)) {
+		stats->flags |= TIMESTAMP_VALID;
+		stats->timestamp = cpu_to_be32(entry->timestamp);
+#ifdef FM_EHASH_DEBUG 
+                printk("external  timestamp %08x\n",
+                	 stats->timestamp);
+#endif // FM_EHASH_DEBUG
+        }
+	if (GET_STATS_ENABLE(flags))
+	{
+		stats->flags |= STATS_VALID;
+		stats->pkts = be64_to_cpu(entry->packet_count);
+		stats->bytes = be64_to_cpu(entry->packet_bytes);
+#ifdef  FM_EHASH_DEBUG 
+		printk("%s(%d) stats pkts %lld , bytes %lld \n",
+			__FUNCTION__, __LINE__, stats->pkts, stats->bytes);
+#endif // FM_EHASH_DEBUG 
+	}
+#ifdef FM_EHASH_DEBUG 
+	printk("%s::stats flags %x\n", __FUNCTION__, stats->flags);
+#endif
+	return 0;
+}
+EXPORT_SYMBOL(ExternalHashTableEntryGetStatsAndTS);
+
+int ExternalHashTableAddKey(void *h_HashTbl, uint8_t keySize,
+                                      void *tbl_entry)
+{
+	struct en_exthash_info *info;
+	struct en_exthash_tbl_entry *first_entry;
+	struct en_exthash_tbl_entry *new_entry;
+	uint16_t index;
+	struct en_exthash_bucket *bucket;
+	t_Handle *h_Spinlock;
+	uint32_t intFlags;
+	int retval;
+	uint64_t phyaddr;
+#ifndef NO_CUMULATIVE_ENTRY
+	uint8_t key_align, flags;
+//	uint32_t ii;
+	struct en_cumulative_entry *cumulative_entry, *tmp;
+	struct en_cumulative_tbl_entry *tmp_tbl_entry, *cumulative_tbl_entry;
+	uint64_t bucket_phyaddr;
+#endif // NO_CUMULATIVE_ENTRY
+
+	SANITY_CHECK_RETURN_ERROR(h_HashTbl, E_INVALID_HANDLE);
+    	SANITY_CHECK_RETURN_ERROR(tbl_entry, E_NULL_POINTER);
+
+	new_entry = (struct en_exthash_tbl_entry *)tbl_entry;
+	info = (struct en_exthash_info *)h_HashTbl;
+#ifdef FM_EHASH_DEBUG 
+	printk("%s::keysize %d, shift %d, mask %x key::\n",
+		__FUNCTION__, keySize, info->hashshift,
+		info->hashmask);
+	disp_buf(&new_entry->hashentry.key[0], keySize);
+#endif
+	get_indexed_hash_bucket(keySize, &new_entry->hashentry.key[0],
+                                info->hashshift,
+                                (uint16_t)info->hashmask, &index);
+	bucket = ((struct en_exthash_bucket *)(info->table_base) + index);
+#ifdef FM_EHASH_DEBUG 
+	printk("%s::index %x\n", __FUNCTION__, index);
+	printk("%s::table base %p , basePhyAddr %p \n bucket %p, bucket phy %p spinlock %p \n", __FUNCTION__,
+		info->table_base, XX_VirtToPhys(info->table_base), bucket, XX_VirtToPhys(bucket), info->pSpinlock);
+#endif
+
+	h_Spinlock = *(info->pSpinlock + index);
+   	intFlags = XX_LockIntrSpinlock(h_Spinlock);
+
+	retval = index;
+	phyaddr = bucket->h;
+#ifdef NO_CUMULATIVE_ENTRY
+	if (phyaddr) {
+		first_entry = XX_PhysToVirt(SwapUint64(phyaddr));
+		if (find_entry_in_bucket(first_entry, &new_entry->hashentry.key[0], 
+				keySize)) {
+        		REPORT_ERROR(MAJOR, E_ALREADY_EXISTS,
+                	     ("en_ext_hash_entry"));
+			retval = -1;
+			goto func_ret;
+		}
+		first_entry->prev = new_entry;
+	} else
+		first_entry = NULL;
+	//fill next pointer info and link into chain
+	new_entry->next = first_entry;
+	//adjust the prev pointer in the old entry
+	//fill next pointer physaddr for uCode
+	// physical address was swapped before adding to bucket, so reverse it and add
+	phyaddr = SwapUint64(phyaddr);
+	new_entry->hashentry.next_entry_hi = cpu_to_be16((phyaddr >> 32) & 0xffff);
+	new_entry->hashentry.next_entry_lo = cpu_to_be32((phyaddr & 0xffffffff));
+	//change the head pointer in the bucket
+	phyaddr = XX_VirtToPhys(new_entry);
+	bucket->h = SwapUint64(phyaddr);
+#else
+	/* key should be aligned to  8 byte boundary if size > 4*/
+	if (keySize <= 2)
+		key_align =  keySize;
+	else if (keySize <= 4)
+		key_align =  4;
+	else
+		key_align =  (keySize + 7) & 0x38;
+
+	FM_EHASH_PRINT("%s(%d) tbl_entry %p, key size %d, key-align %d\n",
+		__FUNCTION__,__LINE__,tbl_entry, keySize, key_align);
+	key_align -= keySize;
+
+	// if no nodes in bucket, just add the node as it is
+	if (!phyaddr)
+	{
+		new_entry->next =  NULL;
+		//change the head pointer in the bucket
+		phyaddr = XX_VirtToPhys(new_entry);
+		bucket->h = SwapUint64(phyaddr);
+	}
+	else
+	{
+		FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+		first_entry = XX_PhysToVirt(SwapUint64(phyaddr));
+		if (find_entry_in_bucket(first_entry, &new_entry->hashentry.key[0], 
+				keySize)) {
+        		REPORT_ERROR(MAJOR, E_ALREADY_EXISTS,
+                	     ("en_ext_hash_entry"));
+			retval = -1;
+			goto func_ret;
+		}
+		FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+		// check if node is cumulative or not
+		// if not cumulative, allocate cumulative node 
+		// add the existing node and the current node to the cumulative node
+		cumulative_tbl_entry = XX_PhysToVirt(SwapUint64(phyaddr));
+		cumulative_entry = &cumulative_tbl_entry->cumulative_entry;
+		FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+		if (cumulative_entry->flags & EN_CUMULATIVE_NODE)
+		{
+			FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+			if (((cumulative_entry->key_size+EN_CU_HASH_TABLE_ENTRY_ADDR_SIZE) * 
+				    (cumulative_entry->num_key_entries+1) + EN_CU_FIXED_ELEMENTS_SIZE) <= EN_CUMULATIVE_NODE_MAX_SIZE)
+			{
+				tmp_tbl_entry = ExternalHashTableAllocCumulativeEntry (h_HashTbl);
+				if (!tmp_tbl_entry)
+				{
+					REPORT_ERROR(MAJOR, E_NO_MEMORY,
+								 ("en_cumulative_entry"));
+					retval = -1;
+					goto func_ret;
+				}
+				FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+				tmp = &tmp_tbl_entry->cumulative_entry;
+				tmp->flags = cumulative_entry->flags; 
+				tmp->key_size =  cumulative_entry->key_size;
+				tmp->next_entry_addr = cumulative_entry->next_entry_addr;
+				tmp->num_key_entries = cumulative_entry->num_key_entries+1;
+				tmp->tbl_entry_index = cumulative_entry->tbl_entry_index + cumulative_entry->key_size;
+				memcpy(tmp->data, new_entry->hashentry.key, keySize);
+				memset(tmp->data+keySize, 0, key_align);
+				memcpy(tmp->data+keySize+key_align, cumulative_entry->data,
+							1+cumulative_entry->num_key_entries*cumulative_entry->key_size);
+				phyaddr = XX_VirtToPhys(new_entry);
+				phyaddr = SwapUint64(phyaddr);
+				memcpy(tmp->data+(cumulative_entry->num_key_entries+1)*cumulative_entry->key_size+1, &phyaddr,
+					EN_CU_HASH_TABLE_ENTRY_ADDR_SIZE);
+				memcpy(tmp->data+(cumulative_entry->num_key_entries+1)*cumulative_entry->key_size+1+EN_CU_HASH_TABLE_ENTRY_ADDR_SIZE, 
+					cumulative_entry->data+1+cumulative_entry->num_key_entries*cumulative_entry->key_size, 
+					8*cumulative_entry->num_key_entries);
+				tmp_tbl_entry->next_entry = cumulative_tbl_entry->next_entry;
+				if (cumulative_tbl_entry->next_entry)
+					cumulative_tbl_entry->next_entry->prev_entry = tmp_tbl_entry;
+				// initiate host command
+				FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+				if (cumulative_tbl_entry->prev_entry)
+				{
+					phyaddr =  XX_VirtToPhys(tmp_tbl_entry);
+					phyaddr =  SwapUint64(phyaddr);
+					cumulative_tbl_entry->prev_entry->cumulative_entry.next_entry_addr =  phyaddr;
+					cumulative_tbl_entry->prev_entry->next_entry = tmp_tbl_entry;
+					tmp_tbl_entry->prev_entry =  cumulative_tbl_entry->prev_entry;
+				}
+				phyaddr =  XX_VirtToPhys(cumulative_tbl_entry);
+				phyaddr =  SwapUint64(phyaddr);
+				bucket_phyaddr = bucket->h;
+				if (bucket_phyaddr == phyaddr)
+				{
+					phyaddr =  XX_VirtToPhys(tmp_tbl_entry);
+					phyaddr =  SwapUint64(phyaddr);
+					bucket->h = phyaddr;
+				}
+				flags = cumulative_entry->flags;
+				flags = flags | EN_INVALID_CUMULATIVE_NODE;
+				cumulative_entry->flags = flags;
+				info = (struct en_exthash_info *)h_HashTbl;
+				XX_UnlockIntrSpinlock(h_Spinlock, intFlags);
+				if (FmPcdHcSync(info->pcd)) {
+					printk("%s::FmPcdHcSync failed\n", __FUNCTION__);
+					retval = -1;
+					goto func_ret;
+				}
+				ExternalHashTableCumulativeEntryFree(cumulative_tbl_entry);
+#ifdef FM_EHASH_DEBUG 
+				printk("new cumulative entry phyaddr : %p bucket content value : 0x%lx\n",
+							(void *)XX_VirtToPhys(cumulative_entry), (long unsigned int)bucket->h);
+				cumulative_entry = (struct en_cumulative_entry *)XX_PhysToVirt((physAddress_t)SwapUint64(bucket->h));
+				while (cumulative_entry)
+				{
+					printk("cumulative entry : %p \n", cumulative_entry);
+							
+						
+					printk("flags: 0x%x, key-size %d, key_entries: %d, nodes_index: %d, next_entry 0x%lx\n", 
+							cumulative_entry->flags, 
+							cumulative_entry->key_size, cumulative_entry->num_key_entries, cumulative_entry->tbl_entry_index,
+							(long unsigned int)cumulative_entry->next_entry_addr);
+					printk("cumulative key: \n");
+					for (ii=0; ii<((cumulative_entry->key_size*cumulative_entry->num_key_entries)+1); ii++)
+					{
+						if ((ii % 16) == 0)
+							printk("\n");
+						printk("%02x ", cumulative_entry->data[ii]);
+					}
+					printk("\n table entries (%d) : \n",cumulative_entry->num_key_entries);
+					for (ii = 0; ii < cumulative_entry->num_key_entries; ii++) {
+						phyaddr = *((uint64_t *)(&cumulative_entry->data[cumulative_entry->tbl_entry_index-12+ii*8]));
+						printk("table_entry ptr[%d]: %p \n", ii, (void *)XX_PhysToVirt((physAddress_t)SwapUint64(phyaddr)));
+					}
+					printk("\n");
+					if (cumulative_entry->flags & EN_NEXT_CUMULATIVE_NODE)
+					{
+						cumulative_entry = XX_PhysToVirt(SwapUint64(cumulative_entry->next_entry_addr));
+					}
+					else
+						cumulative_entry = NULL;
+				}
+#endif
+				return retval;
+			}
+			else
+			{
+				FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+				tmp_tbl_entry = ExternalHashTableAllocCumulativeEntry (h_HashTbl);
+				if (!tmp_tbl_entry)
+				{
+					REPORT_ERROR(MAJOR, E_NO_MEMORY,
+								 ("en_cumulative_entry"));
+					retval = -1;
+					return retval;
+				}
+				tmp = &tmp_tbl_entry->cumulative_entry;
+				phyaddr = XX_VirtToPhys(cumulative_tbl_entry);
+				tmp->flags = EN_NEXT_CUMULATIVE_NODE | EN_CUMULATIVE_NODE;
+				tmp->next_entry_addr = SwapUint64(phyaddr);
+				tmp_tbl_entry->next_entry =  cumulative_tbl_entry;
+				cumulative_tbl_entry->prev_entry =  tmp_tbl_entry;
+				cumulative_entry = tmp;
+				cumulative_entry->key_size = keySize+key_align;
+				cumulative_entry->num_key_entries = 1;
+				memcpy(cumulative_entry->data, new_entry->hashentry.key, keySize);
+				memset(cumulative_entry->data+keySize, 0, key_align);
+				cumulative_entry->data[keySize+key_align] = 0;
+				cumulative_entry->tbl_entry_index =  EN_CU_FIXED_ELEMENTS_SIZE+1+cumulative_entry->num_key_entries*cumulative_entry->key_size;
+				phyaddr = XX_VirtToPhys(new_entry);
+				phyaddr = SwapUint64(phyaddr);
+				memcpy(&cumulative_entry->data[cumulative_entry->key_size+1], &phyaddr, EN_CU_HASH_TABLE_ENTRY_ADDR_SIZE);
+				
+				//change the head pointer in the bucket
+				phyaddr = XX_VirtToPhys(tmp_tbl_entry);
+				bucket->h = SwapUint64(phyaddr);
+			}
+		}
+		else
+		{
+			FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+			cumulative_tbl_entry = ExternalHashTableAllocCumulativeEntry (h_HashTbl);
+			if (!cumulative_tbl_entry)
+			{
+				REPORT_ERROR(MAJOR, E_NO_MEMORY,
+							 ("en_cumulative_entry"));
+				retval = -1;
+				return retval;
+				
+			}
+			cumulative_entry = &cumulative_tbl_entry->cumulative_entry;
+			cumulative_entry->flags = EN_CUMULATIVE_NODE;
+			cumulative_entry->key_size = keySize+key_align;
+			cumulative_entry->num_key_entries = 2;
+			FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+			memcpy(cumulative_entry->data, new_entry->hashentry.key, keySize);
+			memset(cumulative_entry->data+keySize, 0, key_align);
+			FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+			memcpy(cumulative_entry->data+keySize+key_align, first_entry->hashentry.key, keySize);
+			memset(cumulative_entry->data+2*keySize+key_align, 0, key_align);
+			cumulative_entry->data[2*(keySize+key_align)] = 0;
+			cumulative_entry->tbl_entry_index =  EN_CU_FIXED_ELEMENTS_SIZE+1+cumulative_entry->num_key_entries*(keySize+key_align);
+			phyaddr = XX_VirtToPhys(new_entry);
+			phyaddr = SwapUint64(phyaddr);
+			*((uint64_t *)(cumulative_entry->data+2*(keySize+key_align)+1)) = phyaddr;
+			phyaddr = XX_VirtToPhys(first_entry);
+			phyaddr = SwapUint64(phyaddr);
+			*((uint64_t *)(cumulative_entry->data+2*(keySize+key_align)+1+EN_CU_HASH_TABLE_ENTRY_ADDR_SIZE)) = phyaddr;
+			//change the head pointer in the bucket
+			FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+			phyaddr = XX_VirtToPhys(cumulative_tbl_entry);
+			bucket->h = SwapUint64(phyaddr);
+			FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+		}
+		
+#ifdef FM_EHASH_DEBUG 
+		printk("new cumulative entry phyaddr : %p bucket content value : 0x%lx\n",
+			(void *)XX_VirtToPhys(cumulative_entry), (long unsigned int)bucket->h);
+		cumulative_entry = (struct en_cumulative_entry *)XX_PhysToVirt((physAddress_t)SwapUint64(bucket->h));
+		while (cumulative_entry)
+		{
+			printk("cumulative entry : %p \n", cumulative_entry);
+			
+//				uint32_t ii;
+			
+			printk("flags: 0x%x, key-size %d, key_entries: %d, nodes_index: %d, next_entry 0x%lx\n", 
+					cumulative_entry->flags, 
+					cumulative_entry->key_size, cumulative_entry->num_key_entries, cumulative_entry->tbl_entry_index,
+					(long unsigned int)cumulative_entry->next_entry_addr);
+			printk("cumulative key: \n");
+			for (ii=0; ii<((cumulative_entry->key_size*cumulative_entry->num_key_entries)+1); ii++)
+			{
+				if ((ii % 16) == 0)
+					printk("\n");
+				printk("%02x ", cumulative_entry->data[ii]);
+			}
+			printk("\n table entries (%d) : \n",cumulative_entry->num_key_entries);
+			for (ii = 0; ii < cumulative_entry->num_key_entries; ii++) {
+				phyaddr = *((uint64_t *)(&cumulative_entry->data[cumulative_entry->tbl_entry_index-12+ii*8]));
+				printk("table_entry ptr[%d]: %p \n", ii, (void *)XX_PhysToVirt((physAddress_t)SwapUint64(phyaddr)));
+			}
+			printk("\n");
+			if (cumulative_entry->flags & EN_NEXT_CUMULATIVE_NODE)
+			{
+				cumulative_entry = XX_PhysToVirt(SwapUint64(cumulative_entry->next_entry_addr));
+			}
+			else
+				cumulative_entry = NULL;
+		}
+#endif
+	}	
+#endif //NO_CUMULATIVE_ENTRY
+#ifdef FM_EHASH_DEBUG 
+	printk("new entry phyaddr : %p bucket content value : 0x%lx\n", phyaddr, bucket->h);
+	{
+		uint32_t ii;
+		uint8_t *ptr;
+
+		printk("hash entry::%p, next %p, prev %p\n hashentry %p::\n", 
+			new_entry, 
+			new_entry->next, new_entry->prev, &new_entry->hashentry);
+		ptr = (uint8_t *)&new_entry->hashentry;
+		for (ii = 0; ii < sizeof(struct en_ehash_entry); ii++) {
+			if ((ii % 16) == 0)
+				printk("\n");
+			printk("%02x ", *ptr);
+			ptr++;
+		}
+		printk("\n");
+	}
+#endif
+func_ret:
+    	XX_UnlockIntrSpinlock(h_Spinlock, intFlags);
+	return retval;	
+}
+EXPORT_SYMBOL(ExternalHashTableAddKey); 
+
+//called from ExternalHashTableSet only when table init fails
+static void Delete_EnEhashInfo(t_Handle handle)
+{
+	struct en_exthash_info *info;
+	uint32_t ii;
+	
+	info = (struct en_exthash_info *)handle;
+	if (info) {
+		if (info->pSpinlock) {
+			//free all bucket locks
+			for (ii = 0; ii <= info->hashmask; ii++) {
+				if (*(info->pSpinlock + ii)) {
+					XX_FreeSpinlock(*(info->pSpinlock + ii));
+				} else 
+					break;
+			}	
+			//free lock handle array
+			XX_FreeSmart(info->pSpinlock);
+			info->pSpinlock = NULL;
+		}
+		//free table info
+		kfree(info);
+	}
+}
+
+#ifndef EXCLUDE_FMAN_IPR_OFFLOAD
+extern void disp_sch_info(void *);
+void ipr_update_timestamp(void)
+{
+	uint32_t ii;
+
+	if (ipv4_reassly_tbl_info) {
+		ii = cpu_to_be32(ipv4_reassly_tbl_info->ip_reassem_info->ipr_timer);
+		ii++;
+		ipv4_reassly_tbl_info->ip_reassem_info->ipr_timer =
+			cpu_to_be32(ii);
+	}
+	if (ipv6_reassly_tbl_info)
+		ipv4_reassly_tbl_info->ip_reassem_info->ipr_timer =
+			cpu_to_be32(ii);
+
+}
+
+static int GetMuramIprContextMem(t_Handle h_FmPcd)
+{
+	int ii;
+	uint32_t *ptr;
+	uint32_t prev_addr;
+
+	if (!IprContextMem) {
+		//allocate memory for IPR context in muram and make a free list
+		IprContextMem = (struct ipr_context_info *)
+			FM_MURAM_AllocMem(FmPcdGetMuramHandle(h_FmPcd),
+					sizeof(struct ipr_context_info), IPR_CTX_ALIGN);
+		if (!IprContextMem)
+		{
+			REPORT_ERROR(MAJOR, E_NO_MEMORY, ("MURAM allocation for reassem context"));
+			return -1;
+		}
+		//make a free list
+		prev_addr = IPR_CONTEXT_EOL;
+		ptr = (uint32_t *)&IprContextMem->context_data[0][0];
+		for (ii = 0; ii < IPR_MAX_SESSIONS; ii++) {
+			*ptr = cpu_to_be32(prev_addr);
+			if (prev_addr == IPR_CONTEXT_EOL)
+				prev_addr =
+					(uint32_t)((uint8_t *)IprContextMem - (uint8_t *)FmMurambaseAddr);
+			else
+				prev_addr += IPR_MAX_SESSSIZE;
+			ptr += (IPR_MAX_SESSSIZE / sizeof(uint32_t));
+		}
+		IprContextMem->next_free_ctx = cpu_to_be32(prev_addr);
+		ii = (int)((uint8_t *)IprContextMem - (uint8_t *)FmMurambaseAddr);
+		{
+			uint32_t *ptr;
+			uint32_t count;
+
+			prev_addr = cpu_to_be32(IprContextMem->next_free_ctx);
+			printk("%s::IprContextMem %p, %08x, next free ctx %08x\n",
+					__FUNCTION__, IprContextMem, ii, prev_addr);
+			count = 0;
+			while(1) {
+				if (prev_addr == IPR_CONTEXT_EOL)
+					break;
+#if 0
+				printk("memaddr %08x\n", prev_addr);
+#endif
+				ptr = (uint32_t *)(FmMurambaseAddr + prev_addr);
+				prev_addr = cpu_to_be32(*ptr);
+				count++;
+			}
+			printk("%d free contexts initialized\n", count);
+		}
+	} else {
+		ii = (int)((uint8_t *)IprContextMem - (uint8_t *)FmMurambaseAddr);
+	}
+	//return offset in muram of IPR context in muram
+	return ii;
+}
+#endif
+
+extern void disp_sch_info(void *);
+t_Handle ExternalHashTableSet(t_Handle h_FmPcd, t_FmPcdHashTableParams *p_Param)
+{
+	struct en_exthash_info *info;
+	t_Handle h_FmMuram;
+	uint32_t ii;
+	uint8_t num_of_zeroes = 0;
+	struct en_exthash_node *node;
+	uint64_t tblphysaddr;
+	t_FmPcd *p_FmPcd = (t_FmPcd*)h_FmPcd;
+#ifndef EXCLUDE_FMAN_IPR_OFFLOAD
+	uint32_t gpp_table;
+	uint32_t table_type;
+
+	p_Param->table_type &= TABLE_TYPE_MASK;
+	switch (p_Param->table_type) {
+		case IPV4_REASSM_TABLE:
+			if (ipv4_reassly_tbl_info) {
+#ifdef FM_EHASH_DEBUG 
+				printk("%s::ipv4_reassly_tbl_info already created %p\n",
+						__FUNCTION__, ipv4_reassly_tbl_info);
+#endif
+				return (t_Handle)ipv4_reassly_tbl_info;
+			}
+			gpp_table = 0;
+			table_type = REASSEMBLY_TABLE;
+			//override xml definitions
+			p_Param->hashResMask = (MAX_REASSM_BUCKETS - 1);
+			break;
+		case IPV6_REASSM_TABLE:
+			if (ipv6_reassly_tbl_info) {
+#ifdef FM_EHASH_DEBUG 
+				printk("%s::ipv6_reassly_tbl_info already created %p\n",
+						__FUNCTION__, ipv6_reassly_tbl_info);
+#endif
+				return (t_Handle)ipv6_reassly_tbl_info;
+			}
+			table_type = REASSEMBLY_TABLE;
+			//override xml definitions
+			p_Param->hashResMask = (MAX_REASSM_BUCKETS - 1);
+			gpp_table = 0;
+			break;
+		case IPV4_UDP_TABLE:
+		case IPV4_TCP_TABLE:
+		case ESP_IPV4_TABLE:
+		case IPV6_UDP_TABLE:
+		case IPV6_TCP_TABLE:
+		case ESP_IPV6_TABLE:
+		case IPV4_3TUPLE_UDP_TABLE:
+		case IPV4_3TUPLE_TCP_TABLE:
+		case IPV6_3TUPLE_UDP_TABLE:
+		case IPV6_3TUPLE_TCP_TABLE:
+			table_type = L4_TABLE;
+			gpp_table = 1;
+			break;
+
+		case IPV4_MULTICAST_TABLE:
+		case IPV6_MULTICAST_TABLE:
+			table_type = L3_TABLE;
+			gpp_table = 1;
+			break;
+		default:
+			table_type = L2_TABLE;
+			gpp_table = 1;
+			break;
+
+	}
+#endif
+	//allocate table info structure
+	info = kzalloc(sizeof(struct en_exthash_info), GFP_KERNEL);
+	if (!info) {
+        	REPORT_ERROR(MAJOR, E_NO_MEMORY,
+                	     ("allocation for en_ext_hash_info"));
+        	return NULL;
+	}
+#ifdef FM_EHASH_DEBUG 
+	printk("%s(%d) info %p \n",__FUNCTION__,__LINE__,info);
+#endif
+	memset(info, 0, sizeof(struct en_exthash_info));
+		
+	//determine number of bits set in the hash mask
+	ii = p_Param->hashResMask;
+#ifdef CONFIG_FMAN_ARM
+        __asm__ ("clz %0,%1\n"
+                        : "=r"(num_of_zeroes)
+                        : "r"(ii));
+#else
+        __asm__ ("cntlzw %0,%1\n"
+                        : "=r"(num_of_zeroes)
+                        : "r"(ii));
+#endif
+	h_FmMuram = FmPcdGetMuramHandle(h_FmPcd);
+    	if (!h_FmMuram) {
+        	REPORT_ERROR(MAJOR, E_INVALID_HANDLE,
+                	     ("muram"));
+		goto err_ret;
+	}
+	info->hashmask = p_Param->hashResMask;
+	info->pcd = h_FmPcd;
+#ifndef EXCLUDE_FMAN_IPR_OFFLOAD 
+	info->type = p_Param->table_type;
+	if (gpp_table) 
+#endif
+	{
+		//spin locks are required for tables filled by GPP
+		//not required for reassembly tables, used by uCode only
+		//allocate memory for bucket lock handles
+		info->pSpinlock = XX_MallocSmart((sizeof(t_Handle *) * (info->hashmask + 1)),
+							0, sizeof(t_Handle));
+		if (!info->pSpinlock) {
+			REPORT_ERROR(MAJOR, E_NO_MEMORY,
+				("spin lock array"));
+			goto err_ret;
+		}
+		//allocate and initialize spin locks on all buckets
+		for (ii = 0; ii <= info->hashmask; ii++) {
+			*(info->pSpinlock + ii) = XX_InitSpinlock();
+			if (!*(info->pSpinlock + ii)) {
+				REPORT_ERROR(MAJOR, E_NO_MEMORY,
+						("spinlock for en_ext_hash"));
+				goto err_ret;
+			}
+		}
+	}
+		info->tablesize = (sizeof(struct en_exthash_bucket) << (64 - num_of_zeroes) );
+    	info->table_base = XX_MallocSmart(info->tablesize, 0 /*p_Param->externalHashParams.dataMemId not used */, 
+			EN_EXTHASH_TBL_ALIGNMENT);
+    	if (!info->table_base)
+    	{
+        	REPORT_ERROR(MAJOR, E_NO_MEMORY,
+                	     ("en_ext_hash_table"));
+		goto err_ret;
+    	}
+	//clear table
+	memset(info->table_base, 0, info->tablesize);
+	//allocate node for table in muram
+// following code may not be rqd -- TBD
+//	{
+//		t_FmPcd *p_FmPcd = (t_FmPcd *)h_FmPcd;
+ //       	ii = (uint32_t)((XX_VirtToPhys(info->h_Ad)
+ //                               - p_FmPcd->physicalMuramBase));
+//	}
+	info->keysize = p_Param->matchKeySize;       
+        info->hashshift = p_Param->hashShift;
+        //info->dataMemId = p_Param->externalHashParams.dataMemId;
+//        info->dataLiodnOffset = p_Param->externalHashParams.dataMemId;
+//	if (p_Param->agingSupport) 
+		info->flags |= TIMESTAMP_EN;
+	if (p_Param->statisticsMode) 
+		info->flags |= STATS_EN;
+	//fill AD
+	node = &info->node;
+	memset(node, 0, sizeof(struct en_exthash_node));
+	node->key_size = info->keysize;		
+	node->hash_bytes_offset = info->hashshift;	
+	/* convert the hash mask value to hash mask bits */
+	if (info->hashmask > 0x7fff)
+	{
+		REPORT_ERROR(MAJOR, E_INVALID_VALUE, 
+			("unsupported hash mask value"));
+		goto err_ret;
+	}
+	for (ii =0; ii <15; ii++)
+	{
+		if ((info->hashmask + 1) & (1 << ii))
+			break;
+	}
+
+	if ((1 << ii) != (info->hashmask +1))
+	{
+		REPORT_ERROR(MAJOR, E_INVALID_VALUE, 
+			("unsupported hash mask value"));
+		goto err_ret;
+	}
+	node->hash_mask_bits = ii;
+	node->int_buf_pool_addr = p_FmPcd->InternalBufMgmtMuramArea;
+	node->global_mem_offset = EN_INTERNAL_BUFF_POOL_SIZE >> 8; /* value compressed */
+	/* assign the MURAM reserved space of global params/stats to global muram pointer */
+	if (!en_global_muram_mem)
+	{
+		en_global_muram_mem = (en_exthash_global_mem *)
+			((uint8_t *)(p_FmPcd->pIntMuramPtr)+EN_INTERNAL_BUFF_POOL_SIZE);
+	}
+#ifdef FM_EHASH_DEBUG 
+	printk("%s::table type %d, word_1 0x%x, hashmask+1 0x%x, hashmask bits 0x%x, global mem offset 0x%x\n",
+	__FUNCTION__, p_Param->table_type, node->word_1, info->hashmask+1, node->hash_mask_bits,
+	node->global_mem_offset);
+#endif
+	tblphysaddr = XX_VirtToPhys(info->table_base);
+	node->table_base_hi = ((tblphysaddr >> 32) & 0xffff);	
+	node->table_base_lo = (tblphysaddr & 0xffffffff);		
+#ifndef EXCLUDE_FMAN_IPR_OFFLOAD
+	node->table_type = table_type;
+#endif
+	//check next engine for miss action
+#ifndef EXCLUDE_FMAN_IPR_OFFLOAD
+	if (gpp_table) 
+#endif
+	{
+		switch (p_Param->ccNextEngineParamsForMiss.nextEngine) {
+			case e_FM_PCD_KG:
+			{
+				//Keygen
+				t_FmPcdCcNextKgParams *kgparams;
+				kgparams =
+					&p_Param->ccNextEngineParamsForMiss.params.kgParams;
+#ifdef FM_EHASH_DEBUG 
+				printk("%s::Nextengine = KG, kgparams->h_DirectScheme %p\n", 
+					__FUNCTION__, kgparams->h_DirectScheme);
+#endif
+				node->nia = (NIA_ENG_KG | NIA_KG_DIRECT);
+				if (kgparams->overrideFqid) 
+                    			node->nia |= (kgparams->newFqid | NIA_KG_CC_EN);
+                		node->nia |= FmPcdKgGetSchemeId(kgparams->h_DirectScheme);
+#ifdef FM_EHASH_DEBUG 
+				disp_sch_info(kgparams->h_DirectScheme);
+#endif
+				node->miss_action_type = EN_EHASH_MISS_ACTION_NIA;
+				break;
+		}
+		case e_FM_PCD_DONE:
+		{
+				//BMI
+				t_FmPcdCcNextEnqueueParams *enqparams;
+				enqparams = 
+					&p_Param->ccNextEngineParamsForMiss.params.enqueueParams;
+#ifdef FM_EHASH_DEBUG
+                               printk("%s:: EN_EHASH_MISS_ACTION_NIA %d , ovrdfqid %d\n",
+                                       __FUNCTION__, EN_EHASH_MISS_ACTION_NIA,enqparams->overrideFqid);
+#endif
+				if (enqparams->overrideFqid)
+					node->fqid = enqparams->newFqid;
+				if (enqparams->overrideFqid)
+				{
+					node->miss_action_type = EN_EHASH_MISS_ACTION_ENQUE;
+				}
+				else
+					node->miss_action_type = EN_EHASH_MISS_ACTION_DONE;
+#ifdef FM_EHASH_DEBUG
+printk("node->fqid : %d \n", node->fqid);
+#endif
+				break;
+		}
+		default:
+			node->miss_action_type = EN_EHASH_MISS_ACTION_DROP;
+#ifdef FM_EHASH_DEBUG
+			printk("%s::Nextengine type %d not supported, drop case\n", __FUNCTION__,
+				p_Param->ccNextEngineParamsForMiss.nextEngine);
+#endif
+			break;
+		}
+	}
+#ifndef EXCLUDE_FMAN_IPR_OFFLOAD
+	else {
+		//ipr table
+		uint32_t mem_size;
+		int iprctxinfo;
+
+		iprctxinfo = GetMuramIprContextMem(h_FmPcd);
+		if (iprctxinfo == -1)
+			goto err_ret;
+
+		mem_size = (sizeof(struct ip_reassembly_params) +
+							REASSM_DEBUG_SIZE);
+				//reassembly table, allocate stats and other info
+				info->ip_reassem_info = (struct ip_reassembly_params *)
+						PTR_TO_UINT(FM_MURAM_AllocMem(FmPcdGetMuramHandle(h_FmPcd),
+							mem_size, sizeof(uint64_t)));
+				if (!info->ip_reassem_info)
+				{
+					REPORT_ERROR(MAJOR, E_NO_MEMORY, ("MURAM allocation for reassem info"));
+					goto err_ret;
+				}
+				node->reassm_param =
+						(uint32_t)((uint8_t *)info->ip_reassem_info - (uint8_t *)FmMurambaseAddr);
+				info->ip_reassem_info->type = (p_Param->table_type);
+				info->ip_reassem_info->table_base_hi =
+						cpu_to_be32(tblphysaddr >> 32);
+				info->ip_reassem_info->table_base_lo = cpu_to_be32(tblphysaddr & 0xffffffff);
+				info->ip_reassem_info->table_mask = cpu_to_be32(p_Param->hashResMask);
+				info->ip_reassem_info->timeout_val = cpu_to_be32(p_Param->timeout_val);
+				info->ip_reassem_info->timeout_fqid = cpu_to_be32(p_Param->timeout_fqid);
+				info->ip_reassem_info->max_frags = cpu_to_be32(p_Param->max_frags);
+				info->ip_reassem_info->min_frag_size = cpu_to_be32(p_Param->min_frag_size);
+				info->ip_reassem_info->max_con_reassm = cpu_to_be32(p_Param->max_sessions);
+				info->ip_reassem_info->timer_tnum = 0xffffffff; //no task assigned yet
+				info->ip_reassem_info->curr_sessions = 0;
+				info->ip_reassem_info->reassly_dbg =
+						cpu_to_be32(node->reassm_param + sizeof(struct ip_reassembly_params));
+		info->ip_reassem_info->context_info = cpu_to_be32(iprctxinfo);
+		memset(&info->ip_reassem_info->stats, 0, sizeof(struct ip_reassembly_stats));
+		for (ii = 0; ii < MAX_REASSM_BUCKETS; ii++) {
+			info->ip_reassem_info->bucket_lock[ii] = 0;
+			info->ip_reassem_info->bucket_head[ii] = (uint64_t)0;
+		}
+#ifdef FM_EHASH_DEBUG
+		if (p_Param->table_type == IPV4_REASSM_TABLE)
+			printk("%s::ipv4 reassem param ", __FUNCTION__);
+		else
+			printk("%s::ipv6 reassem param ", __FUNCTION__);
+		printk("%x, size %d dbg %x\n",
+				node->reassm_param,
+				(uint32_t)(sizeof(struct ip_reassembly_params) +
+				REASSM_DEBUG_SIZE),
+				cpu_to_be32(info->ip_reassem_info->reassly_dbg));
+		printk(KERN_INFO "%s::en ext hash reassem table created, handle %p\n",
+				__FUNCTION__, info);
+#endif
+	}
+#endif
+
+#ifdef FM_EHASH_DEBUG
+	printk(KERN_INFO "%s::en ext hash table created, handle %p\n",
+			__FUNCTION__, info);
+	printk("ad_word_0::%08x\n", node->word_0);
+	printk("ad_word_1::%08x\n", node->table_base_lo);
+	printk("ad_word_2::%08x\n", node->word_1);
+	printk("ad_word_3::%08x\n", node->word_2);
+#endif //FM_EHASH_DEBUG
+
+#ifndef EXCLUDE_FMAN_IPR_OFFLOAD
+	switch (p_Param->table_type) {
+		case IPV4_REASSM_TABLE:
+			ipv4_reassly_tbl_info = info;
+#ifdef FM_EHASH_DEBUG
+			printk("%s::saving ipv4_reassly_tbl_info %p\n",
+					__FUNCTION__, ipv4_reassly_tbl_info);
+#endif
+			break;
+		case IPV6_REASSM_TABLE:
+			ipv6_reassly_tbl_info = info;
+#ifdef FM_EHASH_DEBUG
+			printk("%s::saving ipv6_reassly_tbl_info %p\n",
+					__FUNCTION__, ipv6_reassly_tbl_info);
+#endif
+			break;
+		default:
+			break;
+	}
+#endif
+#ifdef FM_EHASH_DEBUG
+	//display_ehashtbl_info(info, __FUNCTION__);
+	printk("%s::handle %p\n", __FUNCTION__, info);
+#endif //FM_EHASH_DEBUG
+	return (t_Handle)info;
+err_ret:
+	Delete_EnEhashInfo(info);	
+	return NULL;
+}
+
+
+t_Error ExternalHashTableModifyMissNextEngine(t_Handle h_HashTbl, t_FmPcdCcNextEngineParams *p_FmPcdCcNextEngineParams)
+{
+	struct en_exthash_info *info;
+	struct en_exthash_node node;
+
+	info = (struct en_exthash_info *)h_HashTbl;
+
+	node.word_0 = GET_UINT32(((struct en_exthash_node *)info->h_Ad)->word_0);
+	node.word_2 = GET_UINT32(((struct en_exthash_node *)info->h_Ad)->word_2);
+
+	//set action type to miss temporarily
+	node.miss_action_type = EN_EHASH_MISS_ACTION_DROP;
+	WRITE_UINT32(((struct en_exthash_node *)info->h_Ad)->word_0, node.word_0);
+
+	//set new miss action
+	switch (p_FmPcdCcNextEngineParams->nextEngine) {
+		case e_FM_PCD_KG:
+		{
+			//Keygen
+			t_FmPcdCcNextKgParams *kgparams;
+			kgparams = &p_FmPcdCcNextEngineParams->params.kgParams;
+#ifdef FM_EHASH_DEBUG
+			printk("%s::Nextengine = KG, kgparams->h_DirectScheme %p\n",
+				__FUNCTION__, kgparams->h_DirectScheme);
+#endif
+			node.nia = (NIA_ENG_KG | NIA_KG_DIRECT | NIA_KG_CC_EN);
+			node.nia |= FmPcdKgGetSchemeId(kgparams->h_DirectScheme);
+#ifdef FM_EHASH_DEBUG
+			disp_sch_info(kgparams->h_DirectScheme);
+#endif
+			node.miss_action_type = EN_EHASH_MISS_ACTION_NIA;
+			break;
+		}
+               case e_FM_PCD_DONE:
+		{
+			//BMI
+			t_FmPcdCcNextEnqueueParams *enqparams;
+			enqparams =
+				&p_FmPcdCcNextEngineParams->params.enqueueParams;
+#ifdef FM_EHASH_DEBUG
+			printk("%s:: EN_EHASH_MISS_ACTION_NIA %d , ovrdfqid %d\n",
+				__FUNCTION__, EN_EHASH_MISS_ACTION_NIA,enqparams->overrideFqid);
+#endif
+			if (enqparams->overrideFqid)
+				node.fqid = enqparams->newFqid;
+			if (enqparams->overrideFqid)
+			{
+				node.miss_action_type = EN_EHASH_MISS_ACTION_ENQUE;
+			}
+			else
+				node.miss_action_type = EN_EHASH_MISS_ACTION_DONE;
+			break;
+		}
+		case e_FM_PCD_PLCR:
+		{
+			t_FmPcdCcNextPlcrParams *plcrparams;
+
+			plcrparams =
+				&p_FmPcdCcNextEngineParams->params.plcrParams;
+			node.miss_action_type = EN_EHASH_MISS_ACTION_NIA;
+			if (plcrparams->sharedProfile)
+				node.nia = (NIA_ENG_PLCR | NIA_PLCR_ABSOLUTE | plcrparams->newRelativeProfileId);
+			else
+				node.nia = (NIA_ENG_PLCR | plcrparams->newRelativeProfileId);
+			break;
+		}
+
+		default:
+			node.miss_action_type = EN_EHASH_MISS_ACTION_DROP;
+#ifdef FM_EHASH_DEBUG
+			printk("%s::Nextengine type %d not supported, drop case\n", __FUNCTION__,
+				p_FmPcdCcNextEngineParams->nextEngine);
+#endif
+			break;
+	}
+	//write the new params
+	WRITE_UINT32(((struct en_exthash_node *)info->h_Ad)->word_2, node.word_2);
+	WRITE_UINT32(((struct en_exthash_node *)info->h_Ad)->word_0, node.word_0);
+#ifdef FM_EHASH_DEBUG
+	node.word_0 = GET_UINT32(((struct en_exthash_node *)info->h_Ad)->word_0);
+	node.table_base_lo = GET_UINT32(((struct en_exthash_node *)info->h_Ad)->table_base_lo);
+	printk("ad_word_0::%p, %08x\n", &(((struct en_exthash_node *)info->h_Ad)->word_0),
+                                       node.word_0);
+	printk("ad_word_1::%p, %08x\n", &(((struct en_exthash_node *)info->h_Ad)->table_base_lo),
+                                       node.table_base_lo);
+	printk("ad_word_2::%p, %08x\n", &(((struct en_exthash_node *)info->h_Ad)->word_1),
+                                       node.word_1);
+	printk("ad_word_3::%p, %08x\n", &(((struct en_exthash_node *)info->h_Ad)->word_2),
+                                       node.word_2);
+#endif
+	return E_OK;
+}
+
+int ExternalHashTableFmPcdHcSync(void *h_HashTbl)
+{
+	struct en_exthash_info *info;
+	info = (struct en_exthash_info *)h_HashTbl;
+	if (FmPcdHcSync(info->pcd)) {
+		printk("%s::FmPcdHcSync failed\n", __FUNCTION__);
+		return -1;
+	}
+	return 0;
+}
+EXPORT_SYMBOL(ExternalHashTableFmPcdHcSync); 
+
+int ExternalHashTableDeleteKey(void *h_HashTbl, uint16_t index, void *tbl_entry)
+{
+	t_Handle *h_Spinlock;
+	uint32_t intFlags;
+	uint64_t phyaddr;
+	struct en_exthash_info *info;
+	struct en_exthash_bucket *bucket;
+	struct en_exthash_tbl_entry *entry;
+	struct en_exthash_tbl_entry *temp_entry;
+#ifndef NO_CUMULATIVE_ENTRY
+	struct en_cumulative_entry *cumulative_entry, *tmp;
+	struct en_cumulative_tbl_entry *cumulative_tbl_entry, *tmp_tbl_entry = NULL;
+	uint8_t ii, match=0, flags;
+#else
+	uint64_t update_entry; 
+#endif // NO_CUMULATIVE_ENTRY
+
+#ifdef FM_EHASH_DEBUG
+	printk("%s::tbl %p, index %x\n", __FUNCTION__, h_HashTbl, index);
+#endif
+	info = (struct en_exthash_info *)h_HashTbl;
+	bucket = ((struct en_exthash_bucket *)info->table_base + index);
+	entry = (struct en_exthash_tbl_entry *)tbl_entry;
+	h_Spinlock = *(info->pSpinlock + index);
+	intFlags = XX_LockIntrSpinlock(h_Spinlock);
+#ifdef NO_CUMULATIVE_ENTRY
+	//SET_INVALID_ENTRY(entry->hashentry.flags); // setting invalid flag
+        update_entry = SwapUint64(entry->hashentry.next_entry);
+        SET_INVALID_ENTRY_64BIT(update_entry);
+        entry->hashentry.next_entry = SwapUint64(update_entry);
+	if (entry->prev) {
+                //adjust software links
+		temp_entry = entry->prev;
+		temp_entry->next = entry->next;
+		if (entry->next)
+			(entry->next)->prev = temp_entry;
+		//temp_entry->hashentry.next_entry_lo = entry->hashentry.next_entry_lo;
+		//temp_entry->hashentry.next_entry_hi = entry->hashentry.next_entry_hi;
+                update_entry = (entry->hashentry.next_entry & (~0xffff));
+                temp_entry->hashentry.next_entry = (update_entry | (temp_entry->hashentry.flags));
+	} else {
+		phyaddr = XX_VirtToPhys(entry->next);
+		bucket->h = SwapUint64(phyaddr);
+//                phyaddr = SwapUint64(entry->hashentry.next_entry_lo |
+  //                      (entry->hashentry.next_entry_hi << 32));
+                //remove from head
+                //zero prev of next entry
+		if (entry->next)
+			(entry->next)->prev = NULL;
+	}
+	XX_UnlockIntrSpinlock(h_Spinlock, intFlags);
+	if (FmPcdHcSync(info->pcd)) {
+		printk("%s::FmPcdHcSync failed\n", __FUNCTION__);
+		return -1;
+	}
+	return 0;
+#else
+	FM_EHASH_PRINT("%s(%d) tbl_entry %p\n", __FUNCTION__,__LINE__,tbl_entry);
+	// check if it normal node or cumulative node 
+	// no cumulative node, its only one node in hash bucket, delete
+	phyaddr = XX_VirtToPhys(entry);
+	if (bucket->h == SwapUint64(phyaddr))
+	{
+		FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+		bucket->h = 0;
+		XX_UnlockIntrSpinlock(h_Spinlock, intFlags);
+		if (FmPcdHcSync(info->pcd)) {
+			printk("%s::FmPcdHcSync failed\n", __FUNCTION__);
+			return -1;
+		}
+		return 0;
+	}
+	else
+	{
+		FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+		// get cumulative entry node address.
+		phyaddr = bucket->h;
+		cumulative_tbl_entry = XX_PhysToVirt(SwapUint64(phyaddr));
+		cumulative_entry = &cumulative_tbl_entry->cumulative_entry;
+		if (!(cumulative_entry->flags & EN_CUMULATIVE_NODE))
+		{
+			FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+       		REPORT_ERROR(MAJOR, E_INVALID_STATE,
+                	     ("Invalid state"));
+			XX_UnlockIntrSpinlock(h_Spinlock, intFlags);
+			return -1;
+		}
+		// find matching cumulative entry
+		do
+		{
+			for (ii=0; ii<cumulative_entry->num_key_entries; ii++)
+			{
+				FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+				phyaddr = *((uint64_t *)(&cumulative_entry->data[cumulative_entry->tbl_entry_index - 12 + ii*8]));
+				temp_entry = XX_PhysToVirt(SwapUint64(phyaddr));
+				if (temp_entry == tbl_entry)
+				{
+					match = 1;
+					break;
+				}
+			}
+			if (match)
+				break;
+			if (cumulative_tbl_entry->next_entry)
+			{
+				cumulative_tbl_entry = cumulative_tbl_entry->next_entry;
+				cumulative_entry = &cumulative_tbl_entry->cumulative_entry;
+			}
+			else
+				cumulative_entry =  NULL;
+		}while (cumulative_entry);
+		if (match) // if found
+		{
+			FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+			// cumulative entry might have the next entry, in that case, get the last table entry in last cumulative entry
+			// and overwrite it with to-be-deleted table entry
+			flags =  cumulative_entry->flags | EN_INVALID_CUMULATIVE_NODE;
+			cumulative_entry->flags = flags;
+			if ((cumulative_entry->num_key_entries > 2) ||
+				((cumulative_entry->num_key_entries == 2) &&
+				  ((cumulative_tbl_entry->prev_entry) || (cumulative_tbl_entry->next_entry))))
+			{
+				tmp_tbl_entry = ExternalHashTableAllocCumulativeEntry (h_HashTbl);
+				if (!tmp_tbl_entry)
+				{
+					REPORT_ERROR(MAJOR, E_NO_MEMORY,
+								 ("en_cumulative_entry"));
+					XX_UnlockIntrSpinlock(h_Spinlock, intFlags);
+					return -1;
+				}
+				FM_EHASH_PRINT(" case 1 num keys > 1 %s(%d)\n",__FUNCTION__,__LINE__);
+				tmp = &tmp_tbl_entry->cumulative_entry;
+				tmp->flags = cumulative_entry->flags & 0xbf; 
+				tmp->key_size =  cumulative_entry->key_size;
+				tmp->next_entry_addr = cumulative_entry->next_entry_addr;
+				tmp->num_key_entries = cumulative_entry->num_key_entries-1;
+				tmp->tbl_entry_index = cumulative_entry->tbl_entry_index - cumulative_entry->key_size;
+				FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+				if (ii)
+				{
+					FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+					memcpy(tmp->data, &cumulative_entry->data, (ii*cumulative_entry->key_size));
+					memcpy(&tmp->data[tmp->num_key_entries*tmp->key_size+1], 
+						&cumulative_entry->data[cumulative_entry->num_key_entries*tmp->key_size+1], ii*EN_CU_HASH_TABLE_ENTRY_ADDR_SIZE);
+				}
+				if (ii < cumulative_entry->num_key_entries-1)
+				{
+					FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+					memcpy(tmp->data+(ii*cumulative_entry->key_size), 
+						&cumulative_entry->data[(ii+1)*cumulative_entry->key_size],
+					(cumulative_entry->num_key_entries-ii-1)*cumulative_entry->key_size+1);
+					memcpy(&tmp->data[(tmp->num_key_entries*tmp->key_size)+1+(ii*EN_CU_HASH_TABLE_ENTRY_ADDR_SIZE)], 
+						&cumulative_entry->data[cumulative_entry->num_key_entries*tmp->key_size+1+((ii+1)*EN_CU_HASH_TABLE_ENTRY_ADDR_SIZE)],
+						(tmp->num_key_entries - ii)*EN_CU_HASH_TABLE_ENTRY_ADDR_SIZE);
+				}
+				if (cumulative_tbl_entry->next_entry)
+				{
+					FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+					tmp_tbl_entry->next_entry = cumulative_tbl_entry->next_entry;
+					cumulative_tbl_entry->next_entry->prev_entry = tmp_tbl_entry;
+				}
+				phyaddr = SwapUint64(XX_VirtToPhys(tmp_tbl_entry));
+				if (cumulative_tbl_entry->prev_entry)
+				{
+					FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+					cumulative_tbl_entry->prev_entry->cumulative_entry.next_entry_addr = phyaddr;
+					tmp_tbl_entry->prev_entry = cumulative_tbl_entry->prev_entry;
+					cumulative_tbl_entry->prev_entry->next_entry =  tmp_tbl_entry;
+				}
+				else
+				{
+					FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+					bucket->h = phyaddr;
+				}
+				XX_UnlockIntrSpinlock(h_Spinlock, intFlags);
+				if (FmPcdHcSync(info->pcd)) {
+					printk("%s::FmPcdHcSync failed\n", __FUNCTION__);
+					return -1;
+				}
+				ExternalHashTableCumulativeEntryFree(cumulative_tbl_entry);
+			}
+			else  // if only one entry in list and there is next pointer
+			{
+				FM_EHASH_PRINT("%s(%d)\n",__FUNCTION__,__LINE__);
+				if ((!(cumulative_tbl_entry->next_entry) &&
+					  !(cumulative_tbl_entry->prev_entry) &&
+					 (cumulative_entry->num_key_entries == 2)) || 
+					((!cumulative_tbl_entry->prev_entry) && 
+					 (cumulative_tbl_entry->next_entry) && 
+					 (cumulative_tbl_entry->next_entry->cumulative_entry.num_key_entries == 1) &&
+					 (!cumulative_tbl_entry->next_entry->next_entry)) ||
+					((cumulative_tbl_entry->prev_entry) && 
+					 !(cumulative_tbl_entry->next_entry) && 
+					 (cumulative_tbl_entry->prev_entry->cumulative_entry.num_key_entries == 1) &&
+					 (!cumulative_tbl_entry->prev_entry->prev_entry))) 
+				{
+					// special case where only one entry in list exists
+					if (cumulative_tbl_entry->next_entry)
+					{
+						FM_EHASH_PRINT("%s(%d) special case where only one entry in list exists\n",__FUNCTION__,__LINE__);
+						tmp_tbl_entry = cumulative_tbl_entry->next_entry;
+						flags = tmp_tbl_entry->cumulative_entry.flags | EN_INVALID_CUMULATIVE_NODE;
+						tmp_tbl_entry->cumulative_entry.flags =	flags;
+						phyaddr = *((uint64_t *)
+							(&tmp_tbl_entry->cumulative_entry.data[tmp_tbl_entry->cumulative_entry.tbl_entry_index-EN_CU_FIXED_ELEMENTS_SIZE]));
+						bucket->h = phyaddr;
+					}
+					else if (cumulative_tbl_entry->prev_entry)
+					{
+						FM_EHASH_PRINT("%s(%d) special case where only one entry in list exists\n",__FUNCTION__,__LINE__);
+						tmp_tbl_entry = cumulative_tbl_entry->prev_entry;
+						flags = tmp_tbl_entry->cumulative_entry.flags | EN_INVALID_CUMULATIVE_NODE;
+						tmp_tbl_entry->cumulative_entry.flags =	flags;
+						phyaddr = *((uint64_t *)
+							(&tmp_tbl_entry->cumulative_entry.data[tmp_tbl_entry->cumulative_entry.tbl_entry_index-EN_CU_FIXED_ELEMENTS_SIZE]));
+						bucket->h = phyaddr;
+					}
+					else
+					{
+						tmp_tbl_entry = NULL;
+						if (ii)
+							phyaddr = *((uint64_t *)(&cumulative_entry->data[cumulative_entry->tbl_entry_index-EN_CU_FIXED_ELEMENTS_SIZE]));
+						else					
+							phyaddr = *((uint64_t *)(&cumulative_entry->data[cumulative_entry->tbl_entry_index-EN_CU_FIXED_ELEMENTS_SIZE+EN_CU_HASH_TABLE_ENTRY_ADDR_SIZE]));
+						bucket->h = phyaddr;
+						FM_EHASH_PRINT("%s(%d) special case where only one entry %p in list exists\n",__FUNCTION__,__LINE__,
+							XX_PhysToVirt(SwapUint64(phyaddr)));
+					}
+					XX_UnlockIntrSpinlock(h_Spinlock, intFlags);
+					if (FmPcdHcSync(info->pcd)) {
+						printk("%s::FmPcdHcSync failed\n", __FUNCTION__);
+						return -1;
+					}
+					if (tmp_tbl_entry)
+						ExternalHashTableCumulativeEntryFree(tmp_tbl_entry);
+					ExternalHashTableCumulativeEntryFree(cumulative_tbl_entry);
+				}
+				else if (!cumulative_tbl_entry->prev_entry) // this is the first cumulative entry in list
+				{
+					if (cumulative_tbl_entry->next_entry)
+					{
+						// update the bucket with next cumulative node
+						FM_EHASH_PRINT("%s(%d) update the bucket with next cumulative node as no prev entry \n",__FUNCTION__,__LINE__);
+						cumulative_tbl_entry->next_entry->prev_entry =  NULL;
+						phyaddr = SwapUint64(XX_VirtToPhys(cumulative_tbl_entry->next_entry));
+						bucket->h = phyaddr;
+						XX_UnlockIntrSpinlock(h_Spinlock, intFlags);
+						if (FmPcdHcSync(info->pcd)) {
+							printk("%s::FmPcdHcSync failed\n", __FUNCTION__);
+							return -1;
+						}
+						ExternalHashTableCumulativeEntryFree(cumulative_tbl_entry);						
+					}
+					else // no next node , no prev node , only table entry in node ==> invalid case
+					{
+						FM_EHASH_PRINT("%s(%d)no next node , no prev node , only table entry in node ==> invalid case\n",__FUNCTION__,__LINE__);
+						REPORT_ERROR(MAJOR, E_INVALID_STATE,
+									 ("Invalid state"));
+						XX_UnlockIntrSpinlock(h_Spinlock, intFlags);
+						return -1;
+					}
+				}
+				else // this node is not the first node
+				{
+					FM_EHASH_PRINT("%s(%d) this node is not the first node \n",__FUNCTION__,__LINE__);
+					if (cumulative_tbl_entry->next_entry)
+					{
+						// update the bucket with next cumulative node
+						FM_EHASH_PRINT("%s(%d) update the next cumulative node with prev entry\n",__FUNCTION__,__LINE__);
+						cumulative_tbl_entry->next_entry->prev_entry =  cumulative_tbl_entry->prev_entry;
+						cumulative_tbl_entry->prev_entry->next_entry =	cumulative_tbl_entry->next_entry;
+						cumulative_tbl_entry->prev_entry->cumulative_entry.next_entry_addr = cumulative_tbl_entry->cumulative_entry.next_entry_addr ;
+					}
+					else
+					{
+						flags = cumulative_tbl_entry->prev_entry->cumulative_entry.flags & ~EN_NEXT_CUMULATIVE_NODE;
+						FM_EHASH_PRINT("%s(%d) update the next cumulative node with prev entry\n",__FUNCTION__,__LINE__);
+						cumulative_tbl_entry->prev_entry->cumulative_entry.flags = flags;
+						cumulative_tbl_entry->prev_entry->next_entry =	NULL;
+						cumulative_tbl_entry->prev_entry->cumulative_entry.next_entry_addr = 0;
+					}
+					XX_UnlockIntrSpinlock(h_Spinlock, intFlags);
+					if (FmPcdHcSync(info->pcd)) {
+						printk("%s::FmPcdHcSync failed\n", __FUNCTION__);
+						return -1;
+					}
+					ExternalHashTableCumulativeEntryFree(cumulative_tbl_entry);						
+				}
+			}
+		}// match not found
+		else
+		{
+			XX_UnlockIntrSpinlock(h_Spinlock, intFlags);
+			REPORT_ERROR(MAJOR, E_INVALID_STATE,
+						 ("No matching node"));
+			return -1;
+		}
+		
+	}
+
+#ifdef FM_EHASH_DEBUG
+	printk("%s(%d)\n",__FUNCTION__,__LINE__);
+	cumulative_entry = XX_PhysToVirt(SwapUint64(bucket->h));
+	if (!cumulative_entry)
+		return 0;
+	if (!(cumulative_entry->flags & EN_CUMULATIVE_NODE))
+	{
+		printk("head ptr: %p\n", cumulative_entry);
+	}
+	while (cumulative_entry && (cumulative_entry->flags & EN_CUMULATIVE_NODE))
+	{
+		printk("cumulative entry : %p \n", cumulative_entry);
+		{
+			uint32_t ii;
+		
+			printk("flags: 0x%x, key-size %d, key_entries: %d, nodes_index: %d, next_entry 0x%lx\n", 
+				cumulative_entry->flags, 
+				cumulative_entry->key_size, cumulative_entry->num_key_entries, cumulative_entry->tbl_entry_index,
+				(long unsigned int)(cumulative_entry->next_entry_addr));
+			printk("cumulative key: \n");
+			for (ii=0; ii<((cumulative_entry->key_size*cumulative_entry->num_key_entries)+1); ii++)
+			{
+				if ((ii % 16) == 0)
+					printk("\n");
+				printk("%02x ", cumulative_entry->data[ii]);
+			}
+			printk(" table entries (%d) : \n",cumulative_entry->num_key_entries);
+			for (ii = 0; ii < cumulative_entry->num_key_entries; ii++) {
+				phyaddr = *((uint64_t *)(&cumulative_entry->data[cumulative_entry->tbl_entry_index-12+ii*8]));
+				printk("table_entry ptr[%d]: %p\n", ii, XX_PhysToVirt(SwapUint64(phyaddr)));
+			}
+			printk("\n");
+		}
+		if (cumulative_entry->flags & EN_NEXT_CUMULATIVE_NODE)
+		{
+			cumulative_entry = XX_PhysToVirt(SwapUint64(cumulative_entry->next_entry_addr));
+		}
+		else
+			cumulative_entry = NULL;
+	}
+#endif // FM_EHASH_DEBUG
+#endif // NO_CUMULATIVE_ENTRY
+#ifdef NO_CUMULATIVE_ENTRY
+	XX_UnlockIntrSpinlock(h_Spinlock, intFlags);
+	if (FmPcdHcSync(info->pcd)) {
+		printk("%s::FmPcdHcSync failed\n", __FUNCTION__);
+		return -1;
+	}
+#endif //NO_CUMULATIVE_ENTRY
+	return 0;
+}
+
+#ifndef EXCLUDE_FMAN_IPR_OFFLOAD
+int ExternalHashSetReasslyPool(uint32_t type, uint32_t ctx_bpid, 
+		uint32_t ctx_bsize, uint32_t frag_bpid, uint32_t frag_bsize, 
+		uint32_t txc_fqid, uint32_t ipr_timer_freq)
+{
+	uint32_t ii;
+
+	switch (type)
+	{
+		case IPV4_REASSM_TABLE:
+			if (!ipv4_reassly_tbl_info) {
+				printk("%s::ipv4 frag table not setup\n", __FUNCTION__);
+				return -1;
+			}
+			printk("ipv4 reassembly ctx_bpid %d, frag_bpid %d timerfreq %d\n", 
+					ctx_bpid, frag_bpid, ipr_timer_freq);
+			ipv4_reassly_tbl_info->ip_reassem_info->reassem_bpid = 
+				cpu_to_be32(ctx_bpid);
+			ipv4_reassly_tbl_info->ip_reassem_info->reassem_bsize = 
+				cpu_to_be32(ctx_bsize);
+			ipv4_reassly_tbl_info->ip_reassem_info->frag_bpid = 
+				cpu_to_be32(frag_bpid);
+			ipv4_reassly_tbl_info->ip_reassem_info->frag_bsize = 
+				cpu_to_be32(frag_bsize);
+			ii = cpu_to_be32(ipv4_reassly_tbl_info->ip_reassem_info->timeout_val);  
+			ipv4_reassly_tbl_info->ip_reassem_info->timeout_val = 
+				cpu_to_be32(ii / ipr_timer_freq);  
+			ipv4_reassly_tbl_info->ip_reassem_info->txc_fqid = 
+				cpu_to_be32(txc_fqid);
+			break;
+		case IPV6_REASSM_TABLE:
+			if (!ipv6_reassly_tbl_info) {
+				printk("%s::ipv6 frag table not setup\n", __FUNCTION__);
+				return -1;
+			}
+			printk("ipv6 reassembly ctx_bpid %d, frag_bpid %d timerfreq %d\n", 
+					ctx_bpid, frag_bpid, ipr_timer_freq);
+			ipv6_reassly_tbl_info->ip_reassem_info->reassem_bpid = 
+				cpu_to_be32(ctx_bpid);
+			ipv6_reassly_tbl_info->ip_reassem_info->reassem_bsize = 
+				cpu_to_be32(ctx_bsize);
+			ipv6_reassly_tbl_info->ip_reassem_info->frag_bpid = 
+				cpu_to_be32(frag_bpid);
+			ipv6_reassly_tbl_info->ip_reassem_info->frag_bsize = 
+				cpu_to_be32(frag_bsize);
+			ii = cpu_to_be32(ipv4_reassly_tbl_info->ip_reassem_info->timeout_val);  
+			ipv6_reassly_tbl_info->ip_reassem_info->timeout_val = 
+				cpu_to_be32(ii / ipr_timer_freq);  
+			ipv6_reassly_tbl_info->ip_reassem_info->txc_fqid = 
+				cpu_to_be32(txc_fqid);
+			break;
+
+
+		default:
+			printk("%s::invalid frag table type %d\n", __FUNCTION__, type);
+			return -1;
+	}
+	return 0;
+}
+
+static void display_debug_info(struct ip_reassembly_params *params)
+{
+	char *sbuf;
+	char *buf;
+	uint8_t *ptr;
+	uint32_t ii;
+
+	buf = (char *)kzalloc(1024, GFP_KERNEL);
+	sbuf = buf;
+	if (sbuf) {	
+		sbuf += sprintf(sbuf, "debug info::\n");
+		ptr = ((uint8_t *)params + sizeof(struct ip_reassembly_params));
+		for (ii = 0; ii < REASSM_DEBUG_SIZE; ii++) {
+			if ((ii % 16) == 15)
+				sbuf += sprintf(sbuf, "%02x\n", *ptr);
+			else
+				sbuf += sprintf(sbuf, "%02x ", *ptr);
+			ptr++;
+		}
+	}
+	sbuf += sprintf(sbuf, "\n");
+	printk("%s", buf);
+	kfree(buf);	
+}
+
+static void display_reassem_params(uint32_t type)
+{
+	struct ip_reassembly_params *params;
+
+	switch (type)
+	{
+		case IPV4_REASSM_TABLE:
+			if (!ipv4_reassly_tbl_info) {
+				printk("%s::ipv4 frag table not setup\n", __FUNCTION__);
+				return;
+			}
+			printk("ipv4 reassembly params::");
+			params = ipv4_reassly_tbl_info->ip_reassem_info; 
+			break;
+		case IPV6_REASSM_TABLE:
+			if (!ipv6_reassly_tbl_info) {
+				printk("%s::ipv6 frag table not setup\n", __FUNCTION__);
+				return;
+			}
+			printk("ipv6 reassembly params::");
+			params = ipv6_reassly_tbl_info->ip_reassem_info; 
+			break;
+
+		default:
+			printk("%s::invalid frag table type %d\n", __FUNCTION__, type);
+			return;
+	}
+	printk("%p\n", params);
+	{
+		uint64_t ii;
+
+		ii = ((uint64_t)(cpu_to_be32(params->table_base_hi)) << 32);
+		ii |= cpu_to_be32(params->table_base_lo);
+		printk("table base\t%p\n", (void *)ii);
+	}
+	printk("type\t%x\n", cpu_to_be32(params->type));
+	printk("ipr_timer\t%d\n",
+			cpu_to_be32(params->ipr_timer));
+	printk("timeoutval\t%d\n",
+			cpu_to_be32(params->timeout_val));
+	printk("timeout_fqid\t%x(%d)\n",
+			cpu_to_be32(params->timeout_fqid),
+			cpu_to_be32(params->timeout_fqid));
+	printk("max_frags\t%d\n",
+			cpu_to_be32(params->max_frags));
+	printk("min_frag_size\t%d\n",
+			cpu_to_be32(params->min_frag_size));
+	printk("max_con_reassm\t%d\n",
+			cpu_to_be32(params->max_con_reassm));
+	printk("reassem_bpid\t%d\n",
+			cpu_to_be32(params->reassem_bpid));
+	printk("table mask\t%d\n",
+			cpu_to_be32(params->table_mask));
+	printk("reassly_dbg\t%x\n",
+			cpu_to_be32(params->reassly_dbg));
+	printk("timer_info\t%x\n",
+			cpu_to_be32(params->timer_tnum));
+	printk("txc_fqid\t0x%x\n",
+			(cpu_to_be32(params->txc_fqid) & 0xffffff));
+#if 0
+	{
+		uint32_t ii;
+		uint8_t *ptr;
+
+		ptr = (uint8_t *)params;
+		for (ii = 0; ii < sizeof(struct ip_reassembly_params); ii++) {
+			if (ii % 16 == 15)
+				printk("%02x\n", *(ptr + ii));
+			else
+				printk("%02x ", *(ptr + ii));
+		}
+		printk("\n");
+	}
+#endif
+}
+
+int get_ip_reassem_info(uint32_t type, struct ip_reassembly_info *info)
+{
+	struct ip_reassembly_params *params;
+
+	switch (type)
+	{
+		case IPV4_REASSM_TABLE:
+			if (!ipv4_reassly_tbl_info) {
+				printk("%s::ipv4 frag table not setup\n", __FUNCTION__);
+				return -1;
+			}
+			params = ipv4_reassly_tbl_info->ip_reassem_info; 
+			break;
+		case IPV6_REASSM_TABLE:
+			if (!ipv6_reassly_tbl_info) {
+				printk("%s::ipv6 frag table not setup\n", __FUNCTION__);
+				return -1;
+			}
+			params = ipv6_reassly_tbl_info->ip_reassem_info; 
+			break;
+		default:
+			printk("%s::invalid frag table type %d\n", __FUNCTION__, type);
+			return -1;
+	}
+	info->num_frag_pkts = params->stats.num_frag_pkts;
+	info->num_reassemblies = params->stats.num_reassemblies;
+	info->num_completed_reassly = params->stats.num_completed_reassly;
+	info->num_sess_matches = params->stats.num_sess_matches;
+	info->num_frags_too_small = params->stats.num_frags_too_small;
+	info->num_reassm_timeouts = params->stats.num_reassm_timeouts;
+	info->num_overlapping_frags = params->stats.num_overlapping_frags;
+	info->num_too_many_frags = params->stats.num_too_many_frags;
+	info->num_failed_bufallocs = params->stats.num_failed_bufallocs;
+	info->num_failed_ctxallocs = params->stats.num_failed_ctxallocs;
+	info->num_fatal_errors = params->stats.num_fatal_errors;
+	info->num_failed_ctxdeallocs = params->stats.num_failed_ctxdeallocs;
+	info->table_mask = params->table_mask;
+	info->ipr_timer = params->ipr_timer;
+	info->timeout_val = params->timeout_val;
+	info->timeout_fqid = params->timeout_fqid;
+	info->max_frags = params->max_frags; 
+	info->min_frag_size = params->min_frag_size;
+	info->max_con_reassm = params->max_con_reassm;
+	info->reassem_bpid = params->reassem_bpid;
+	info->reassem_bsize = params->reassem_bsize;
+	info->frag_bpid = params->frag_bpid; 
+	info->frag_bsize = params->frag_bsize;
+	info->timer_tnum = params->timer_tnum;
+	info->reassly_dbg = params->reassly_dbg;
+	info->curr_sessions = params->curr_sessions;
+	info->txc_fqid = params->txc_fqid; 
+	display_debug_info(params);
+	return 0;
+}
+
+void display_reassem_stats(uint32_t type)
+{
+	struct ip_reassembly_stats *stats;
+
+	display_reassem_params(type);
+	switch (type)
+	{
+		case IPV4_REASSM_TABLE:
+			if (!ipv4_reassly_tbl_info) {
+				printk("%s::ipv4 frag table not setup\n", __FUNCTION__);
+				return;
+			}
+			stats = &ipv4_reassly_tbl_info->ip_reassem_info->stats;
+			printk("ipv4 reassembly statistics::\n");
+			break;
+		case IPV6_REASSM_TABLE:
+			if (!ipv6_reassly_tbl_info) {
+				printk("%s::ipv6 frag table not setup\n", __FUNCTION__);
+				return;
+			}
+			stats = &ipv6_reassly_tbl_info->ip_reassem_info->stats;
+			printk("ipv6 reassembly statistics::\n");
+			break;
+
+		default:
+			printk("%s::invalid frag table type %d\n", __FUNCTION__, type);
+			return;
+	}
+
+	printk("num_frag_pkts\t%p\n",
+			(void *)(cpu_to_be64(stats->num_frag_pkts)));
+	printk("num_reassemblies\t%p\n",
+			(void *)(cpu_to_be64(stats->num_reassemblies)));
+	printk("num_completed_reassly\t%p\n",
+			(void *)(cpu_to_be64(stats->num_completed_reassly)));
+	printk("num_sess_matches\t%p\n",
+			(void *)(cpu_to_be64(stats->num_sess_matches)));
+	printk("frags too small\t%p\n",
+			(void *)(cpu_to_be64(stats->num_frags_too_small)));
+	printk("num_reassm_failures\t%p\n",
+			(void *)(cpu_to_be64(stats->num_reassm_timeouts)));
+	printk("overlapping fragments\t%p\n",
+			(void *)(cpu_to_be64(stats->num_overlapping_frags)));
+	printk("too many frags\t%p\n",
+			(void *)(cpu_to_be64(stats->num_too_many_frags)));
+	printk("num_failed_bufallocs\t%p\n",
+			(void *)(cpu_to_be64(stats->num_failed_bufallocs)));
+	printk("num_failed_ctxallocs\t%p\n",
+			(void *)(cpu_to_be64(stats->num_failed_ctxallocs)));
+	printk("reassm_count\t%p\n",
+			(void *)(cpu_to_be64(stats->reassm_count)));
+	printk("num_failed_ctxdeallocs\t%p\n",
+			(void *)(cpu_to_be64(stats->num_failed_ctxdeallocs)));
+	printk("num_fatal_errors\t%p\n",
+			(void *)(cpu_to_be64(stats->num_fatal_errors)));
+
+}
+EXPORT_SYMBOL(get_ip_reassem_info);
+EXPORT_SYMBOL(display_reassem_stats);
+EXPORT_SYMBOL(ipv4_reassly_tbl_info);
+EXPORT_SYMBOL(ipv6_reassly_tbl_info);
+EXPORT_SYMBOL(ExternalHashSetReasslyPool);
+EXPORT_SYMBOL(ipr_update_timestamp);
+#endif
+EXPORT_SYMBOL(ExternalHashTableDeleteKey); 
+
+int32_t ExternalHashGetSECfailureStats(en_SEC_failure_stats *stats)
+{
+	if (!stats)
+		return -1;
+
+	stats->anti_replay_late_errs =
+		GET_UINT32(en_global_muram_mem->SEC_failure_stats.anti_replay_late_errs);
+		
+
+	stats->anti_replay_replay_errs =
+		GET_UINT32(en_global_muram_mem->SEC_failure_stats.anti_replay_replay_errs);
+	
+	stats->buff_pool_depletion_errs =
+		GET_UINT32(en_global_muram_mem->SEC_failure_stats.buff_pool_depletion_errs);
+	
+	stats->buff_too_small_errs =
+		GET_UINT32(en_global_muram_mem->SEC_failure_stats.buff_too_small_errs);
+	
+	stats->cmpnd_frame_read_errs =
+		GET_UINT32(en_global_muram_mem->SEC_failure_stats.cmpnd_frame_read_errs);
+	
+	stats->cmpnd_frame_write_errs =
+		GET_UINT32(en_global_muram_mem->SEC_failure_stats.cmpnd_frame_write_errs);
+	
+	stats->DECO_watchdog_timer_timedout_errs =
+		GET_UINT32(en_global_muram_mem->SEC_failure_stats.DECO_watchdog_timer_timedout_errs);
+	
+	stats->DMA_errs =
+		GET_UINT32(en_global_muram_mem->SEC_failure_stats.DMA_errs);
+	
+	stats->hw_errs =
+		GET_UINT32(en_global_muram_mem->SEC_failure_stats.hw_errs);
+	
+	stats->icv_failures =
+		GET_UINT32(en_global_muram_mem->SEC_failure_stats.icv_failures);
+	
+	stats->input_frame_read_errs =
+		GET_UINT32(en_global_muram_mem->SEC_failure_stats.input_frame_read_errs);
+	
+	stats->ipsec_pad_chk_failures =
+		GET_UINT32(en_global_muram_mem->SEC_failure_stats.ipsec_pad_chk_failures);
+
+	stats->ipsec_ttl_zero_errs =
+		GET_UINT32(en_global_muram_mem->SEC_failure_stats.ipsec_ttl_zero_errs);
+	
+	stats->other_errs =
+		GET_UINT32(en_global_muram_mem->SEC_failure_stats.other_errs);
+	
+	stats->output_frame_length_rollover_errs =
+		GET_UINT32(en_global_muram_mem->SEC_failure_stats.output_frame_length_rollover_errs);
+	
+	stats->output_frame_too_large_errs =
+		GET_UINT32(en_global_muram_mem->SEC_failure_stats.output_frame_too_large_errs);
+	
+	stats->output_frame_write_errs =
+		GET_UINT32(en_global_muram_mem->SEC_failure_stats.output_frame_write_errs);
+	
+	stats->prehdr_read_errs = 
+		GET_UINT32(en_global_muram_mem->SEC_failure_stats.prehdr_read_errs);
+	
+	stats->protocol_format_errs =
+		GET_UINT32(en_global_muram_mem->SEC_failure_stats.protocol_format_errs);
+	
+	stats->seq_num_overflows =
+		GET_UINT32(en_global_muram_mem->SEC_failure_stats.seq_num_overflows);
+	
+	stats->tbl_buff_pool_depletion_errs =
+		GET_UINT32(en_global_muram_mem->SEC_failure_stats.tbl_buff_pool_depletion_errs);
+	
+	stats->tbl_buff_too_small_errs =
+		GET_UINT32(en_global_muram_mem->SEC_failure_stats.tbl_buff_too_small_errs);
+
+	return 0;
+}
+EXPORT_SYMBOL(ExternalHashGetSECfailureStats);
+
+int32_t ExternalHashResetSECfailureStats(void)
+{
+	if (!en_global_muram_mem)
+		return -1;
+	
+	WRITE_UINT32(en_global_muram_mem->SEC_failure_stats.anti_replay_late_errs, 0);
+		
+	WRITE_UINT32(en_global_muram_mem->SEC_failure_stats.anti_replay_replay_errs, 0);
+	
+	WRITE_UINT32(en_global_muram_mem->SEC_failure_stats.buff_pool_depletion_errs, 0);
+	
+	WRITE_UINT32(en_global_muram_mem->SEC_failure_stats.buff_too_small_errs, 0);
+	
+	WRITE_UINT32(en_global_muram_mem->SEC_failure_stats.cmpnd_frame_read_errs, 0);
+	
+	WRITE_UINT32(en_global_muram_mem->SEC_failure_stats.cmpnd_frame_write_errs, 0);
+	
+	WRITE_UINT32(en_global_muram_mem->SEC_failure_stats.DECO_watchdog_timer_timedout_errs, 0);
+	
+	WRITE_UINT32(en_global_muram_mem->SEC_failure_stats.DMA_errs, 0);
+	
+	WRITE_UINT32(en_global_muram_mem->SEC_failure_stats.hw_errs, 0);
+	
+	WRITE_UINT32(en_global_muram_mem->SEC_failure_stats.icv_failures, 0);
+	
+	WRITE_UINT32(en_global_muram_mem->SEC_failure_stats.input_frame_read_errs, 0);
+	
+	WRITE_UINT32(en_global_muram_mem->SEC_failure_stats.ipsec_pad_chk_failures, 0);
+
+	WRITE_UINT32(en_global_muram_mem->SEC_failure_stats.ipsec_ttl_zero_errs, 0);
+	
+	WRITE_UINT32(en_global_muram_mem->SEC_failure_stats.other_errs, 0);
+	
+	WRITE_UINT32(en_global_muram_mem->SEC_failure_stats.output_frame_length_rollover_errs, 0);
+	
+	WRITE_UINT32(en_global_muram_mem->SEC_failure_stats.output_frame_too_large_errs, 0);
+	
+	WRITE_UINT32(en_global_muram_mem->SEC_failure_stats.output_frame_write_errs, 0);
+	
+	WRITE_UINT32(en_global_muram_mem->SEC_failure_stats.prehdr_read_errs, 0);
+	
+	WRITE_UINT32(en_global_muram_mem->SEC_failure_stats.protocol_format_errs, 0);
+	
+	WRITE_UINT32(en_global_muram_mem->SEC_failure_stats.seq_num_overflows, 0);
+	
+	WRITE_UINT32(en_global_muram_mem->SEC_failure_stats.tbl_buff_pool_depletion_errs, 0);
+	
+	WRITE_UINT32(en_global_muram_mem->SEC_failure_stats.tbl_buff_too_small_errs, 0);
+
+	return 0;
+}
+
+EXPORT_SYMBOL(ExternalHashResetSECfailureStats);
+
+int32_t ExternalHashSetDscpVlanpcpMapCfg(en_dscp_vlanpcp_map_cfg *map)
+{
+	int32_t index;
+
+	if ((!en_global_muram_mem) || (!map))
+		return -1;
+
+	for(index = 0; index <= MAX_VLAN_PCP; index++)
+		WRITE_UINT8(en_global_muram_mem->dscp_vlanpcp_map.dscp_vlanpcp[index], map->dscp_vlanpcp[index]);
+
+	return 0;
+}
+EXPORT_SYMBOL(ExternalHashSetDscpVlanpcpMapCfg);
+
+int32_t ExternalHashGetDscpVlanpcpMapCfg(en_dscp_vlanpcp_map_cfg *map)
+{
+	int32_t index;
+
+	if ((!en_global_muram_mem) || (!map))
+		return -1;
+
+	for(index = 0; index <= MAX_VLAN_PCP; index++)
+		map->dscp_vlanpcp[index] = GET_UINT8(en_global_muram_mem->dscp_vlanpcp_map.dscp_vlanpcp[index]);
+
+	return 0;
+}
+EXPORT_SYMBOL(ExternalHashGetDscpVlanpcpMapCfg);
+
+#endif
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_kg.c b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_kg.c
index 7c5cf467380f..b042ffa4b07a 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_kg.c
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_kg.c
@@ -1243,6 +1243,7 @@ static t_Error BuildSchemeRegs(t_FmPcdKgScheme            *p_Scheme,
                         p_SchemeRegs->kgse_ppc = ppcTmp;
                     }
                 }
+                printk("%s::kgse_ppc %08x\n", __FUNCTION__, ppcTmp);
             }
             break;
         case (e_FM_PCD_DONE):
@@ -1254,6 +1255,14 @@ static t_Error BuildSchemeRegs(t_FmPcdKgScheme            *p_Scheme,
         default:
              RETURN_ERROR(MAJOR, E_NOT_SUPPORTED, ("Next engine not supported"));
     }
+#if 0 //BMR bypass classification
+    printk("%s::actual_kgse_mode %08x\n", __FUNCTION__, tmpReg);
+    if (p_SchemeParams->nextEngine == e_FM_PCD_CC) {
+		tmpReg =  (KG_SCH_MODE_EN | GET_NIA_BMI_AC_ENQ_FRAME(p_FmPcd));
+		tmpReg |= (uint32_t)(grpBase << KG_SCH_MODE_CCOBASE_SHIFT);
+    }
+    printk("%s::kgse_mode %08x\n", __FUNCTION__, tmpReg);
+#endif
     p_SchemeRegs->kgse_mode = tmpReg;
 
     p_SchemeRegs->kgse_mv = p_Scheme->matchVector;
@@ -1571,6 +1580,8 @@ static t_Error BuildSchemeRegs(t_FmPcdKgScheme            *p_Scheme,
                 generic = FALSE;
             }
         }
+	//bmr
+	knownTmp |= KG_SCH_KN_PORT_ID;
         p_SchemeRegs->kgse_ekfc = knownTmp;
 
         selectTmp = 0;
@@ -2773,6 +2784,16 @@ uint8_t FmPcdKgGetSchemeId(t_Handle h_Scheme)
 
 }
 
+void disp_sch_info(t_Handle h_Scheme)
+{
+	t_FmPcdKgScheme *scheme;
+
+	scheme = (t_FmPcdKgScheme *)h_Scheme;
+	printk("scheme %p\n", h_Scheme);
+	printk("id %d, mv %x\n", scheme->schemeId,
+		scheme->matchVector);
+
+}
 bool FmPcdKgGetVspe(t_Handle h_Scheme)
 {
     return ((t_FmPcdKgScheme*)h_Scheme)->vspe;
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_manip.c b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_manip.c
index b8c18e0edf83..bebb799e2df1 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_manip.c
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_manip.c
@@ -3315,6 +3315,74 @@ static t_Error FmPcdManipModifyUpdate(t_Handle h_Manip, t_Handle h_Ad,
 /*****************************************************************************/
 /*              Inter-module API routines                                    */
 /*****************************************************************************/
+void FmPcdManipGetInternaltHmTdAndNonHmAd(t_Handle h_Manip, t_Handle *p_InernalHmtd, t_Handle *p_NonHmAd)
+{
+    t_FmPcdManip *p_FirstManip, *p_Manip = (t_FmPcdManip *)h_Manip;
+
+    ASSERT_COND(h_Manip);
+    ASSERT_COND(p_InernalHmtd);
+    ASSERT_COND(p_NonHmAd);
+
+    *p_InernalHmtd = NULL;
+    *p_NonHmAd = NULL;
+ 
+    p_FirstManip = p_Manip;
+    do {
+        if ((p_Manip->type == e_FM_PCD_MANIP_HDR) && (p_Manip->dataSize)) {
+            *p_InernalHmtd = p_FirstManip->h_Ad;
+            break;
+        }
+        if (p_Manip->type != e_FM_PCD_MANIP_HDR) {
+            *p_NonHmAd = p_Manip->h_Ad;
+            break;
+        }
+        p_Manip = p_Manip->h_NextManip;
+    } while (p_Manip);
+}
+
+void FmPcdManipLocalHMGetParams(t_Handle h_Manip, t_FmPcdManipHmCcParams *p_Params, t_Handle *h_ManipIter)
+{
+    t_FmPcdManip *p_Manip;
+
+    ASSERT_COND(h_Manip);
+    ASSERT_COND(h_ManipIter);
+    ASSERT_COND(p_Params);
+
+    p_Manip = (t_FmPcdManip *)h_Manip;
+ 
+    if (p_Manip->type != e_FM_PCD_MANIP_HDR)
+    {
+        p_Params->p_Hmct = NULL;
+        p_Params->tableSize = 0;
+        *h_ManipIter = NULL;
+        return;
+    }
+ 
+    if (*h_ManipIter == NULL) {
+        /* jump to the end of the HM chain */
+        while (p_Manip->h_NextManip &&
+                (((t_FmPcdManip *)p_Manip->h_NextManip)->type == e_FM_PCD_MANIP_HDR))
+            p_Manip = p_Manip->h_NextManip;
+    } else {
+        p_Manip = *h_ManipIter;
+    }
+
+    do {
+        if (!MANIP_IS_UNIFIED(p_Manip) ||
+                MANIP_IS_UNIFIED_FIRST(p_Manip))
+        {
+            p_Params->p_Hmct = p_Manip->p_Hmct;
+            p_Params->tableSize += p_Manip->tableSize;
+            p_Params->parseAfterHm = !p_Manip->dontParseAfterManip;
+            p_Manip = p_Manip->h_PrevManip;
+            break;
+        }
+        p_Params->tableSize += p_Manip->tableSize;
+        p_Manip = p_Manip->h_PrevManip;
+    } while (p_Manip);
+
+    *h_ManipIter = p_Manip;
+}
 
 t_Error FmPcdManipUpdate(t_Handle h_FmPcd, t_Handle h_PcdParams,
                          t_Handle h_FmPort, t_Handle h_Manip, t_Handle h_Ad,
@@ -3976,3 +4044,60 @@ t_Error FM_PCD_ManipGetStatistics(t_Handle h_ManipNode,
 
     return E_OK;
 }
+
+#ifdef CONFIG_DBG_UCODE_INFRA
+t_Error FmPcdDbgUcodeHCmd(t_Handle h_FmPcd,
+									uint32_t muram_addr_offset,
+									uint8_t  *data,
+									uint8_t  size)
+{
+    t_FmPcd *p_FmPcd = (t_FmPcd*)h_FmPcd;
+    t_Error err = E_OK;
+
+    ASSERT_COND(p_FmPcd);
+
+    if ((err = FmHcPcdDbgUcodeHCmd(p_FmPcd->h_Hc, muram_addr_offset,
+                                      data, size)) != E_OK)
+        RETURN_ERROR(MAJOR, err, NO_MSG);
+
+    return E_OK;
+}
+EXPORT_SYMBOL(FmPcdDbgUcodeHCmd);
+
+t_Error FmPcdDbgUcodeTest(t_Handle h_FmPcd,
+				uint32_t opcode,
+				uint32_t *data,
+				uint16_t data_size)
+{
+	t_FmPcd *p_FmPcd = (t_FmPcd*)h_FmPcd;
+	t_Error err = E_OK;
+
+	ASSERT_COND(p_FmPcd);
+
+	if ((err = FmHcPcdDbgUcodeTest(p_FmPcd->h_Hc,
+							opcode, data, data_size)) != E_OK)
+		RETURN_ERROR(MAJOR, err, NO_MSG);
+
+	return E_OK;
+}
+EXPORT_SYMBOL(FmPcdDbgUcodeTest);
+
+#ifdef CONFIG_DMAR_TEST
+t_Error FmPcdDMAreadTest(t_Handle h_FmPcd,
+						uint32_t muram_addr_offset,
+						uint8_t *ptr, uint8_t size)
+{
+	t_FmPcd *p_FmPcd = (t_FmPcd*)h_FmPcd;
+	t_Error err = E_OK;
+
+	ASSERT_COND(p_FmPcd);
+
+	if ((err = FmHcPcdDMAreadTest(p_FmPcd->h_Hc, muram_addr_offset,
+							ptr, size)) != E_OK)
+		RETURN_ERROR(MAJOR, err, NO_MSG);
+
+	return E_OK;
+}
+EXPORT_SYMBOL(FmPcdDMAreadTest);
+#endif //CONFIG_DMAR_TEST
+#endif // CONFIG_DBG_UCODE_INFRA
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_pcd.c b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_pcd.c
index 5d96727f7251..a790c3cdb38c 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_pcd.c
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_pcd.c
@@ -55,6 +55,14 @@
 #include "fm_prs.h"
 #include "fm_hc.h"
 #include "fm_muram_ext.h"
+#ifdef USE_ENHANCED_EHASH
+#include "fm_ehash.h"
+#endif /*USE_ENHANCED_EHASH */
+#if (DPAA_VERSION >= 11)
+//time stamp infrastructure for use in the case of ext hash tables
+struct ext_hash_ts_info extHashTsInfo;
+EXPORT_SYMBOL(extHashTsInfo);
+#endif
 
 /****************************************/
 /*       static functions               */
@@ -367,7 +375,89 @@ static void ReleaseFreeLocksLst(t_FmPcd *p_FmPcd)
     }
 }
 
+#if (DPAA_VERSION >= 11)
+static void ReleaseFEsList(t_FmPcd *p_FmPcd)
+{
+    t_FmPcdFEObj *p_FeObj;
+    uint32_t intFlags;
+
+    intFlags = XX_LockIntrSpinlock(p_FmPcd->h_Spinlock);
+    while (!LIST_IsEmpty(&p_FmPcd->feInfo.enqLst))
+    {
+        p_FeObj = FM_PCD_FE_OBJ(p_FmPcd->feInfo.enqLst.p_Next);
+        LIST_DelAndInit(&p_FeObj->node);
+        FM_MURAM_FreeMem(p_FmPcd->h_FmMuram, p_FeObj->h_FE);
+        XX_Free(p_FeObj);
+    }
+    while (!LIST_IsEmpty(&p_FmPcd->feInfo.availableFeLst))
+    {
+        p_FeObj = FM_PCD_FE_OBJ(p_FmPcd->feInfo.availableFeLst.p_Next);
+        LIST_DelAndInit(&p_FeObj->node);
+        FM_MURAM_FreeMem(p_FmPcd->h_FmMuram, p_FeObj->h_FE);
+        XX_Free(p_FeObj);
+    }
+    XX_UnlockIntrSpinlock(p_FmPcd->h_Spinlock, intFlags);
+}
+
+static __inline__ t_FmPcdFEObj* DequeueFEObj(t_FmPcd *p_FmPcd, t_List *p_List)
+{
+    t_FmPcdFEObj *p_FeObj = NULL;
+    uint32_t    intFlags;
+
+    intFlags = XX_LockIntrSpinlock(p_FmPcd->h_Spinlock);
+    if (!LIST_IsEmpty(p_List))
+    {
+        p_FeObj = FM_PCD_FE_OBJ(p_List->p_Next);
+        LIST_DelAndInit(&p_FeObj->node);
+    }
+    XX_UnlockIntrSpinlock(p_FmPcd->h_Spinlock, intFlags);
 
+    return p_FeObj;
+}
+
+static __inline__ void EnqueueFEObj(t_FmPcd *p_FmPcd, t_List *p_List, t_FmPcdFEObj *p_FeObj)
+{
+    uint32_t   intFlags;
+
+    intFlags = XX_LockIntrSpinlock(p_FmPcd->h_Spinlock);
+    LIST_AddToTail(&p_FeObj->node, p_List);
+    XX_UnlockIntrSpinlock(p_FmPcd->h_Spinlock, intFlags);
+}
+
+static t_Error AllocFEObjs(t_FmPcd *p_FmPcd)
+{
+    t_Handle h_FmMuram = NULL;
+    t_FmPcdFEObj *p_FeObj;
+    uint32_t i;
+
+    ASSERT_COND(p_FmPcd);
+
+    h_FmMuram = FmPcdGetMuramHandle(p_FmPcd);
+    if (!h_FmMuram)
+        RETURN_ERROR(MAJOR, E_INVALID_HANDLE, ("FM MURAM"));
+
+    INIT_LIST(&p_FmPcd->feInfo.availableFeLst);
+
+    for (i=0; i<100; i++) {
+        p_FeObj = (t_FmPcdFEObj *)XX_Malloc(sizeof(t_FmPcdFEObj));
+        if (!p_FeObj)
+            RETURN_ERROR(MAJOR, E_NO_MEMORY, ("FM-PCD FE obj!"));
+        memset(p_FeObj, 0, sizeof(t_FmPcdFEObj));
+ 
+        p_FeObj->h_FE = (t_Handle)FM_MURAM_AllocMem(h_FmMuram,
+                                                    FM_PCD_FE_MAX_SIZE,
+                                                    FM_PCD_FE_ALIGN);
+        if (!p_FeObj->h_FE)
+            RETURN_ERROR(MAJOR, E_NO_MEMORY, ("MURAM allocation for FE"));
+        memset((uint8_t *)p_FeObj->h_FE, 0, FM_PCD_FE_MAX_SIZE);
+ 
+        EnqueueFEObj(p_FmPcd, &p_FmPcd->feInfo.availableFeLst, p_FeObj);
+    }
+
+    return E_OK;
+}
+
+#endif /* (DPAA_VERSION >= 11) */
 
 /*****************************************************************************/
 /*              Inter-module API routines                                    */
@@ -786,6 +876,49 @@ bool FmPcdIsAdvancedOffloadSupported(t_Handle h_FmPcd)
     ASSERT_COND(h_FmPcd);
     return ((t_FmPcd*)h_FmPcd)->advancedOffloadSupport;
 }
+
+#if (DPAA_VERSION >= 11)
+t_Handle FmPcdGetFE(t_Handle h_FmPcd, t_FmPcdFEParams *p_FeParams)
+{
+    t_FmPcd     *p_FmPcd = (t_FmPcd *)h_FmPcd;
+    uint32_t    intFlags;
+    t_List      *p_Pos, *p_List;
+    t_Handle    h_FE = NULL;
+    t_FmPcdFEObj *p_FeObj;
+
+    ASSERT_COND(h_FmPcd);
+    ASSERT_COND((p_FeParams->type == e_FM_PCD_FE_T_ENQ));
+
+    p_List = &p_FmPcd->feInfo.enqLst;
+
+    intFlags = FmPcdLock(h_FmPcd);
+    LIST_FOR_EACH(p_Pos, p_List)
+    {
+        p_FeObj = FM_PCD_FE_OBJ(p_Pos);
+        if (memcmp(&p_FeObj->feParams, p_FeParams, sizeof(t_FmPcdFEParams)) == 0)
+        {
+            h_FE = p_FeObj->h_FE;
+            break;
+        }
+    }
+    FmPcdUnlock(h_FmPcd, intFlags);
+
+    if (!h_FE) {
+        p_FeObj = DequeueFEObj(p_FmPcd, &p_FmPcd->feInfo.availableFeLst);
+        if (!p_FeObj) {
+            REPORT_ERROR(MAJOR, E_EMPTY, ("FM-PCD FE obj!"));
+            return NULL;
+        }
+        h_FE = p_FeObj->h_FE;
+        FmPcdCcBuildFE(h_FmPcd, p_FeParams, h_FE);
+        memcpy(&p_FeObj->feParams, p_FeParams, sizeof(t_FmPcdFEParams));
+        EnqueueFEObj(p_FmPcd, p_List, p_FeObj);
+    }
+
+    return h_FE;
+}
+#endif /* DPAA_VERSION >= 11 */
+
 /*********************** End of inter-module routines ************************/
 
 
@@ -919,6 +1052,14 @@ t_Error FM_PCD_Init(t_Handle h_FmPcd)
     t_FmPcd         *p_FmPcd = (t_FmPcd*)h_FmPcd;
     t_Error         err = E_OK;
     t_FmPcdIpcMsg   msg;
+#if (DPAA_VERSION >= 11)
+    t_FmPcdFEObj *p_FeObj;
+    t_FmPcdFEParams feParams;
+    int i;
+#endif /* DPAA_VERSION >= 11 */
+#ifdef USE_ENHANCED_EHASH
+	uint32_t global_data_size;
+#endif /* USE_ENHANCED_EHASH */
 
     SANITY_CHECK_RETURN_ERROR(p_FmPcd, E_INVALID_HANDLE);
     SANITY_CHECK_RETURN_ERROR(p_FmPcd->p_FmPcdDriverParam, E_INVALID_HANDLE);
@@ -1018,11 +1159,136 @@ t_Error FM_PCD_Init(t_Handle h_FmPcd)
     }
     IOMemSet32(UINT_TO_PTR(p_FmPcd->capwapFrameIdAddr), 0,  2);
 
+#if (DPAA_VERSION >= 11)
+    {
+       extHashTsInfo.max_ext_ts_timers = MAX_EXT_TS_TIMERS;
+       /* allocate memory for external timestamp used in ext hash table */
+       extHashTsInfo.ptr =
+               FM_MURAM_AllocMem(p_FmPcd->h_FmMuram, (MAX_EXT_TS_TIMERS * EXT_TS_SIZE), EXT_TS_SIZE);
+       if (!extHashTsInfo.ptr) {
+               FM_PCD_Free(p_FmPcd);
+               RETURN_ERROR(MAJOR, E_NO_MEMORY, ("MURAM allocation for Ext TS"));
+       }
+       extHashTsInfo.offset = (uint32_t)(XX_VirtToPhys(extHashTsInfo.ptr) -
+                       p_FmPcd->physicalMuramBase);
+       printk("%s::ext timers %d, base ptr %p, muram base %p, offset %x\n", __FUNCTION__,
+                       extHashTsInfo.max_ext_ts_timers, extHashTsInfo.ptr,
+                       (void *)p_FmPcd->physicalMuramBase, extHashTsInfo.offset);
+   }
+#endif
+
+#if (DPAA_VERSION >= 11)
+    err = AllocFEObjs(p_FmPcd);
+    if (err) {
+        FM_PCD_Free(p_FmPcd);
+        RETURN_ERROR(MAJOR, err, NO_MSG);
+    }
+ 
+    /* Singleton MUX-FE */
+    p_FeObj = DequeueFEObj(p_FmPcd, &p_FmPcd->feInfo.availableFeLst);
+    if (!p_FeObj) {
+        FM_PCD_Free(p_FmPcd);
+        RETURN_ERROR(MAJOR, E_EMPTY, ("No Free FE-Obj"));
+    }
+    memset(&feParams, 0, sizeof(t_FmPcdFEParams));
+    feParams.type = e_FM_PCD_FE_T_MUX;
+    feParams.wsOffset = FE_MUX_CONTEXT_OFFSET;
+    p_FmPcd->feInfo.h_Mux = p_FeObj->h_FE;
+    FmPcdCcBuildFE(p_FmPcd, &feParams, p_FmPcd->feInfo.h_Mux);
+    XX_Free(p_FeObj);
+ 
+    /* Singleton Transition-FE */
+    p_FeObj = DequeueFEObj(p_FmPcd, &p_FmPcd->feInfo.availableFeLst);
+    if (!p_FeObj) {
+        FM_PCD_Free(p_FmPcd);
+        RETURN_ERROR(MAJOR, E_EMPTY, ("No Free FE-Obj"));
+    }
+    memset(&feParams, 0, sizeof(t_FmPcdFEParams));
+    feParams.type = e_FM_PCD_FE_T_TRANSITION;
+    feParams.wsOffset = FE_TRANSITION_CONTEXT_OFFSET;
+    feParams.u.transition.deallocateBuffer = TRUE;
+    feParams.u.transition.nextADFromWS = TRUE;
+    p_FmPcd->feInfo.h_Transition = p_FeObj->h_FE;
+    FmPcdCcBuildFE(p_FmPcd, &feParams, p_FmPcd->feInfo.h_Transition);
+    XX_Free(p_FeObj);
+
+    /* Singleton Exit-FE */
+    p_FeObj = DequeueFEObj(p_FmPcd, &p_FmPcd->feInfo.availableFeLst);
+    if (!p_FeObj) {
+        FM_PCD_Free(p_FmPcd);
+        RETURN_ERROR(MAJOR, E_EMPTY, ("No Free FE-Obj"));
+    }
+    memset(&feParams, 0, sizeof(t_FmPcdFEParams));
+    feParams.type = e_FM_PCD_FE_T_EXIT;
+    feParams.u.exit.deallocateBuffer = TRUE;
+    p_FmPcd->feInfo.h_Exit = p_FeObj->h_FE;
+    FmPcdCcBuildFE(p_FmPcd, &feParams, p_FmPcd->feInfo.h_Exit);
+    XX_Free(p_FeObj);
+
+    memset(&feParams, 0, sizeof(t_FmPcdFEParams));
+    feParams.type = e_FM_PCD_FE_T_HM;
+    feParams.h_NextFE = p_FmPcd->feInfo.h_Exit;
+    for (i=0; i<FM_MAX_HM_CONTEXTS; i++) {
+        /* Singleton HM (with-parse)-FE */
+        p_FeObj = DequeueFEObj(p_FmPcd, &p_FmPcd->feInfo.availableFeLst);
+        if (!p_FeObj) {
+            FM_PCD_Free(p_FmPcd);
+            RETURN_ERROR(MAJOR, E_EMPTY, ("No Free FE-Obj"));
+        }
+        feParams.wsOffset = FE_HM_CONTEXT_OFFSET(i);
+        feParams.u.hm.parseAfterHm = TRUE;
+        p_FmPcd->feInfo.hm[i].h_HmWParse = p_FeObj->h_FE;
+        FmPcdCcBuildFE(p_FmPcd, &feParams, p_FmPcd->feInfo.hm[i].h_HmWParse);
+        XX_Free(p_FeObj);
+
+        /* Singleton HM (without-parse)-FE */
+        p_FeObj = DequeueFEObj(p_FmPcd, &p_FmPcd->feInfo.availableFeLst);
+        if (!p_FeObj) {
+            FM_PCD_Free(p_FmPcd);
+            RETURN_ERROR(MAJOR, E_EMPTY, ("No Free FE-Obj"));
+        }
+        feParams.wsOffset = FE_HM_CONTEXT_OFFSET(i);
+        feParams.u.hm.parseAfterHm = FALSE;
+        p_FmPcd->feInfo.hm[i].h_HmWOParse = p_FeObj->h_FE;
+        FmPcdCcBuildFE(p_FmPcd, &feParams, p_FmPcd->feInfo.hm[i].h_HmWOParse);
+        XX_Free(p_FeObj);
+    }
+
+    INIT_LIST(&p_FmPcd->feInfo.enqLst);
+#endif /* DPAA_VERSION >= 11 */
+
     XX_Free(p_FmPcd->p_FmPcdDriverParam);
     p_FmPcd->p_FmPcdDriverParam = NULL;
 
     FmRegisterPcd(p_FmPcd->h_Fm, p_FmPcd);
 
+#ifdef USE_ENHANCED_EHASH
+	global_data_size = (sizeof(en_exthash_global_mem) / 256) * 256 + 256;
+	
+
+	/* allocate MURAM memory for Internal buffers and global data */
+	p_FmPcd->pIntMuramPtr = FM_MURAM_AllocMem(p_FmPcd->h_FmMuram, 
+    						EN_INTERNAL_BUFF_POOL_SIZE+global_data_size, 256);
+    if (!p_FmPcd->pIntMuramPtr)
+    {
+        FM_PCD_Free(p_FmPcd);
+        RETURN_ERROR(MAJOR, E_EMPTY, ("MURAM alloc error"));	
+    }
+    p_FmPcd->InternalBufMgmtMuramArea = (uint32_t)(XX_VirtToPhys(p_FmPcd->pIntMuramPtr) -
+                       p_FmPcd->physicalMuramBase);
+    printk("%s(%d) pIntMuramPtr %p InternalBufMgmtMuramArea %x, size 0x%x \n",
+		__FUNCTION__,__LINE__, p_FmPcd->pIntMuramPtr,p_FmPcd->InternalBufMgmtMuramArea,
+		EN_INTERNAL_BUFF_POOL_SIZE+global_data_size);
+
+    if (p_FmPcd->InternalBufMgmtMuramArea & 0xff)
+    {
+        FM_PCD_Free(p_FmPcd);
+        RETURN_ERROR(MAJOR, E_EMPTY, ("InternalBufMgmtMuramArea should be aligned to 256"));	
+    }
+    p_FmPcd->InternalBufMgmtMuramArea >>= 8;
+    printk("%s(%d) pIntMuramPtr %p InternalBufMgmtMuramArea %x \n",__FUNCTION__,__LINE__, p_FmPcd->pIntMuramPtr,p_FmPcd->InternalBufMgmtMuramArea);
+#endif //USE_ENHANCED_EHASH
+
     return E_OK;
 }
 
@@ -1030,6 +1296,28 @@ t_Error FM_PCD_Free(t_Handle h_FmPcd)
 {
     t_FmPcd                             *p_FmPcd =(t_FmPcd *)h_FmPcd;
     t_Error                             err = E_OK;
+#if (DPAA_VERSION >= 11)
+    int         i;
+
+    ReleaseFEsList(p_FmPcd);
+
+    if (p_FmPcd->feInfo.h_Exit)
+        FM_MURAM_FreeMem(p_FmPcd->h_FmMuram, p_FmPcd->feInfo.h_Exit);
+
+    if (p_FmPcd->feInfo.h_Mux)
+        FM_MURAM_FreeMem(p_FmPcd->h_FmMuram, p_FmPcd->feInfo.h_Mux);
+
+    if (p_FmPcd->feInfo.h_Transition)
+        FM_MURAM_FreeMem(p_FmPcd->h_FmMuram, p_FmPcd->feInfo.h_Transition);
+
+    for (i=0; i<FM_MAX_HM_CONTEXTS; i++) {
+        if (p_FmPcd->feInfo.hm[i].h_HmWParse)
+            FM_MURAM_FreeMem(p_FmPcd->h_FmMuram, p_FmPcd->feInfo.hm[i].h_HmWParse);
+
+        if (p_FmPcd->feInfo.hm[i].h_HmWOParse)
+            FM_MURAM_FreeMem(p_FmPcd->h_FmMuram, p_FmPcd->feInfo.hm[i].h_HmWOParse);
+    }
+#endif /* (DPAA_VERSION >= 11) */
 
     if (p_FmPcd->ipv6FrameIdAddr)
         FM_MURAM_FreeMem(p_FmPcd->h_FmMuram, UINT_TO_PTR(p_FmPcd->ipv6FrameIdAddr));
@@ -1037,6 +1325,11 @@ t_Error FM_PCD_Free(t_Handle h_FmPcd)
     if (p_FmPcd->capwapFrameIdAddr)
         FM_MURAM_FreeMem(p_FmPcd->h_FmMuram, UINT_TO_PTR(p_FmPcd->capwapFrameIdAddr));
 
+#ifdef USE_ENHANCED_EHASH
+    if (p_FmPcd->pIntMuramPtr)
+        FM_MURAM_FreeMem(p_FmPcd->h_FmMuram, p_FmPcd->pIntMuramPtr);
+#endif //USE_ENHANCED_EHASH
+
     if (p_FmPcd->enabled)
         FM_PCD_Disable(p_FmPcd);
 
@@ -1572,7 +1865,8 @@ t_Error FM_PCD_SetAdvancedOffloadSupport(t_Handle h_FmPcd)
         revInfo.packageRev = IP_OFFLOAD_PACKAGE_NUMBER;
     }
     if (!IS_OFFLOAD_PACKAGE(revInfo.packageRev))
-        RETURN_ERROR(MAJOR, E_NOT_SUPPORTED, ("Fman ctrl code package"));
+		RETURN_ERROR(MAJOR, E_NOT_SUPPORTED, ("Fman version (%d) is not matching with the kernel fman version(%d). Please update proper fman version", revInfo.packageRev, ASK_UCODE_PACKAGE_NUMBER));
+	
 
     if (!p_FmPcd->h_Hc)
         RETURN_ERROR(MAJOR, E_INVALID_HANDLE, ("HC must be initialized in this mode"));
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_pcd.h b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_pcd.h
index 9d78c8d76029..7888b95f0345 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_pcd.h
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_pcd.h
@@ -198,6 +198,28 @@ typedef struct {
                                 portId for PLCR in any environment */
 } t_FmPcdAllocMng;
 
+#if (DPAA_VERSION >= 11)
+typedef struct {
+    t_FmPcdFEParams feParams;
+    t_Handle        h_FE;
+    t_List          node;
+} t_FmPcdFEObj;
+#define FM_PCD_FE_OBJ(ptr)  LIST_OBJECT(ptr, t_FmPcdFEObj, node)
+
+typedef struct {
+    t_Handle    h_Mux;
+    t_Handle    h_Exit;
+    t_Handle    h_Transition;
+    struct {
+        t_Handle    h_HmWParse;
+        t_Handle    h_HmWOParse;
+    } hm[FM_MAX_HM_CONTEXTS];
+
+    t_List      availableFeLst;
+    t_List      enqLst;
+} t_FmPcdFEInfo;
+#endif /* DPAA_VERSION >= 11 */
+
 typedef struct {
     volatile bool       lock;
     bool                used;
@@ -368,6 +390,14 @@ typedef struct {
     uintptr_t                   capwapFrameIdAddr;
     bool                        advancedOffloadSupport;
 
+#if (DPAA_VERSION >= 11)
+    t_FmPcdFEInfo               feInfo;
+#endif /* DPAA_VERSION >= 11 */
+ 
+#ifdef USE_ENHANCED_EHASH
+    uint32_t			InternalBufMgmtMuramArea; // MURAM address area used for internal buffers in EHASH
+    void *pIntMuramPtr; // MURAM pointer for internal buffers in EHASH
+#endif //USE_ENHANCED_EHASH
     t_FmPcdDriverParam          *p_FmPcdDriverParam;
 } t_FmPcd;
 
@@ -455,6 +485,16 @@ t_CcNodeInformation* FindNodeInfoInReleventLst(t_List *p_List, t_Handle h_Info,
 t_List *FmPcdManipGetSpinlock(t_Handle h_Manip);
 t_List *FmPcdManipGetNodeLstPointedOnThisManip(t_Handle h_Manip);
 
+typedef struct
+{
+    uint8_t     *p_Hmct;
+    uint16_t    tableSize;
+    bool        parseAfterHm;
+} t_FmPcdManipHmCcParams;
+
+void FmPcdManipLocalHMGetParams(t_Handle h_Manip, t_FmPcdManipHmCcParams *p_Params, t_Handle *h_ManipIter);
+void FmPcdManipGetInternaltHmTdAndNonHmAd(t_Handle h_Manip, t_Handle *p_InernalHmtd, t_Handle *p_NonHmAd);
+
 typedef struct
 {
     t_Handle    h_StatsAd;
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_plcr.c b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_plcr.c
index 473ad4bde0d9..259b0a279f30 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_plcr.c
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_plcr.c
@@ -161,6 +161,14 @@ static t_Error SetProfileNia(t_FmPcd *p_FmPcd, e_FmPcdEngine nextEngine, u_FmPcd
                 RETURN_ERROR(MAJOR, E_INVALID_STATE, ("Invalid profile "));
             nia |= NIA_ENG_PLCR | NIA_PLCR_ABSOLUTE | absoluteProfileId;
             break;
+		case e_FM_PCD_PRS:
+			//send it to parser
+			nia |= 0x00480200;
+			break;
+		case e_FM_PCD_CC:
+			//send it to coarse classifier
+			nia |= 0x26;
+			break;
         default:
             RETURN_ERROR(MAJOR, E_INVALID_SELECTION, NO_MSG);
     }
@@ -345,7 +353,7 @@ static t_Error BuildProfileRegs(t_FmPcd                     *p_FmPcd,
 
     bitFor1Micro = FmGetTimeStampScale(p_FmPcd->h_Fm);
     if (bitFor1Micro == 0)
-    RETURN_ERROR(MAJOR, E_NOT_AVAILABLE, ("Timestamp scale"));
+		RETURN_ERROR(MAJOR, E_NOT_AVAILABLE, ("Timestamp scale"));
 
 /* Set G, Y, R Nia */
     err = SetProfileNia(p_FmPcd, p_ProfileParams->nextEngineOnGreen,  &(p_ProfileParams->paramsOnGreen), &gnia);
@@ -460,7 +468,8 @@ static t_Error BuildProfileRegs(t_FmPcd                     *p_FmPcd,
                                 pemode |= FM_PCD_PLCR_PEMODE_FLS_L4;
                                 break;
                             case e_FM_PCD_PLCR_FULL_FRM_LEN:
-                                pemode |= FM_PCD_PLCR_PEMODE_FLS_FULL;
+								/* for full frame length, include FCS size for calculation */
+								pemode |= (FM_PCD_PLCR_PEMODE_FLS_FULL | FM_PCD_PLCR_PEMODE_FCS);
                                 break;
                             default:
                                 RETURN_ERROR(MAJOR, E_INVALID_SELECTION, NO_MSG);
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_plcr.h b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_plcr.h
index 2bb8b969956c..e00c6cf0d993 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_plcr.h
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Pcd/fm_plcr.h
@@ -76,6 +76,7 @@
 #define FM_PCD_PLCR_PEMODE_FLS_L4             0x0000E000
 #define FM_PCD_PLCR_PEMODE_FLS_FULL           0x0000F000
 #define FM_PCD_PLCR_PEMODE_RBFLS              0x00000800
+#define FM_PCD_PLCR_PEMODE_FCS                0x00000400
 #define FM_PCD_PLCR_PEMODE_TRA                0x00000004
 #define FM_PCD_PLCR_PEMODE_TRB                0x00000002
 #define FM_PCD_PLCR_PEMODE_TRC                0x00000001
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Port/fm_port.c b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Port/fm_port.c
index 3662edc25213..00dee8f4cbf0 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Port/fm_port.c
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Port/fm_port.c
@@ -53,6 +53,11 @@
 /****************************************/
 /*       static functions               */
 /****************************************/
+
+#define MAX_FMANS  1
+#define MAX_OF_PORTS    8
+static t_FmPort *OfPortInfo[MAX_FMANS][MAX_OF_PORTS];
+
 static t_Error CheckInitParameters(t_FmPort *p_FmPort)
 {
     t_FmPortDriverParam *p_Params = p_FmPort->p_FmPortDriverParam;
@@ -662,7 +667,9 @@ static t_Error InitLowLevelDriver(t_FmPort *p_FmPort)
     {
         case (e_FM_PORT_TYPE_RX_10G):
         case (e_FM_PORT_TYPE_RX):
-            portParams.err_mask = (RX_ERRS_TO_ENQ & ~portParams.discard_mask);
+            //portParams.err_mask = (RX_ERRS_TO_ENQ & ~portParams.discard_mask);
+	    //not required to enqueue error frames
+            portParams.err_mask = 0;
             if (!p_FmPort->imEn)
             {
                 if (p_DriverParams->forwardReuseIntContext)
@@ -752,6 +759,12 @@ static t_Error InitLowLevelDriver(t_FmPort *p_FmPort)
         }
     }
 
+	if (p_FmPort->portType == e_FM_PORT_TYPE_OH_OFFLINE_PARSING) {
+		OfPortInfo[0][p_FmPort->portId] = p_FmPort;
+		printk("%s::of port %s id %d, handle %p\n", __FUNCTION__,
+				p_FmPort->name, p_FmPort->portId, p_FmPort);
+	}
+
     return E_OK;
 }
 
@@ -819,6 +832,7 @@ static bool CheckOhBmiCounter(t_FmPort *p_FmPort, e_FmPortCounters counter)
         case (e_FM_PORT_COUNTERS_LENGTH_ERR):
         case (e_FM_PORT_COUNTERS_UNSUPPRTED_FORMAT):
         case (e_FM_PORT_COUNTERS_DEALLOC_BUF):
+        case (e_FM_PORT_COUNTERS_RX_OUT_OF_BUFFERS_DISCARD):
             return TRUE;
         case (e_FM_PORT_COUNTERS_RX_FILTER_FRAME):
             if (p_FmPort->portType == e_FM_PORT_TYPE_OH_HOST_COMMAND)
@@ -2154,6 +2168,89 @@ t_Error FmPortGetSetCcParams(t_Handle h_FmPort,
 
     return E_OK;
 }
+
+#if (DPAA_VERSION >= 11)
+t_Error FmPortSetFESupport(t_Handle h_FmPort)
+{
+    t_FmPort *p_FmPort = (t_FmPort*)h_FmPort;
+    t_FmPcdCtrlParamsPage *p_ParamsPage;
+    uint8_t *p_Ptr, i, totalNumOfTnums;
+
+    if (p_FmPort->supportFE)
+    	return E_OK;
+
+    FmPortSetGprFunc(p_FmPort, e_FM_PORT_GPR_MURAM_PAGE,
+                     (void**)&p_ParamsPage);
+    ASSERT_COND(p_ParamsPage);
+
+
+    totalNumOfTnums =
+            (uint8_t)(p_FmPort->tasks.num + p_FmPort->tasks.extra);
+
+    p_FmPort->internalFEBufferPoolAddr =
+            PTR_TO_UINT(FM_MURAM_AllocMem(p_FmPort->h_FmMuram,
+                            (uint32_t)(totalNumOfTnums * BMI_FIFO_UNITS*2),
+                            BMI_FIFO_UNITS));
+    if (!p_FmPort->internalFEBufferPoolAddr)
+        RETURN_ERROR(
+                MAJOR, E_NO_MEMORY,
+                ("MURAM alloc for FE internal buffers pool"));
+    IOMemSet32(UINT_TO_PTR(p_FmPort->internalFEBufferPoolAddr),
+            0, (uint32_t)(totalNumOfTnums * BMI_FIFO_UNITS*2));
+
+    p_FmPort->internalFEBufferPoolManagementIndexAddr =
+            PTR_TO_UINT(FM_MURAM_AllocMem(p_FmPort->h_FmMuram,
+                            (uint32_t)(5 + totalNumOfTnums),
+                            4));
+    if (!p_FmPort->internalFEBufferPoolManagementIndexAddr)
+        RETURN_ERROR(
+                MAJOR,
+                E_NO_MEMORY,
+                ("MURAM alloc for FE internal buffers management"));
+
+    p_Ptr =
+            (uint8_t*)UINT_TO_PTR(p_FmPort->internalFEBufferPoolManagementIndexAddr);
+    WRITE_UINT32(
+            *(uint32_t*)p_Ptr,
+            (uint32_t)(XX_VirtToPhys(UINT_TO_PTR(p_FmPort->internalFEBufferPoolAddr)) - p_FmPort->fmMuramPhysBaseAddr));
+    /* Initialize the pool management index to 4: */
+    WRITE_UINT8(*p_Ptr, 4);
+    for (i = 0, p_Ptr += 4; i < totalNumOfTnums; i++, p_Ptr++)
+        WRITE_UINT8(*p_Ptr, i);
+    WRITE_UINT8(*p_Ptr, 0xFF);
+
+    WRITE_UINT32(p_ParamsPage->internalFEBufferDepletionCounter, 0);
+    WRITE_UINT32(p_ParamsPage->internalFEBufferManagementIndexAddr,
+            (uint32_t)(XX_VirtToPhys(UINT_TO_PTR(p_FmPort->internalFEBufferPoolManagementIndexAddr))
+                                            - p_FmPort->fmMuramPhysBaseAddr));
+
+    p_FmPort->supportFE = TRUE;
+
+    return E_OK;
+}
+
+t_Error FmPortDeleteFESupport(t_Handle h_FmPort)
+{
+    t_FmPort *p_FmPort = (t_FmPort*)h_FmPort;
+    t_FmPcdCtrlParamsPage *p_ParamsPage;
+
+    if (!p_FmPort->supportFE)
+        return E_OK;
+
+    FmPortSetGprFunc(p_FmPort, e_FM_PORT_GPR_MURAM_PAGE,
+                     (void**)&p_ParamsPage);
+    ASSERT_COND(p_ParamsPage);
+
+    p_FmPort->supportFE = FALSE;
+    WRITE_UINT32(p_ParamsPage->internalFEBufferManagementIndexAddr, 0);
+ 
+    FM_MURAM_FreeMem(p_FmPort->h_FmMuram, UINT_TO_PTR(p_FmPort->internalFEBufferPoolAddr));
+    FM_MURAM_FreeMem(p_FmPort->h_FmMuram, UINT_TO_PTR(p_FmPort->internalFEBufferPoolManagementIndexAddr));
+ 
+    return E_OK;
+}
+#endif /* (DPAA_VERSION >= 11) */
+
 /*********************** End of inter-module routines ************************/
 
 /****************************************/
@@ -3939,6 +4036,21 @@ t_Error FM_PORT_SetErrorsRoute(t_Handle h_FmPort, fmPortFrameErrSelect_t errs)
     return E_OK;
 }
 
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+t_Error FM_PORT_SetDiscardMask(t_Handle h_FmPort, fmPortFrameErrSelect_t errs)
+{
+    t_FmPort *p_FmPort = (t_FmPort*)h_FmPort;
+    int err;
+
+    err = fman_port_set_discard_mask(&p_FmPort->port, (uint32_t)errs);
+    if (err != 0)
+        RETURN_ERROR(MAJOR, E_INVALID_VALUE, ("fman_port_set_discard_mask"));
+
+    return E_OK;
+}
+EXPORT_SYMBOL(FM_PORT_SetDiscardMask);
+#endif
+
 t_Error FM_PORT_SetAllocBufCounter(t_Handle h_FmPort, uint8_t poolId,
                                    bool enable)
 {
@@ -4490,6 +4602,8 @@ t_Error FM_PORT_PcdPlcrAllocProfiles(t_Handle h_FmPort, uint16_t numOfProfiles)
 
     return E_OK;
 }
+EXPORT_SYMBOL(FM_PORT_PcdPlcrAllocProfiles);
+
 
 t_Error FM_PORT_PcdPlcrFreeProfiles(t_Handle h_FmPort)
 {
@@ -5240,7 +5354,14 @@ t_Error FM_PORT_DeletePCD(t_Handle h_FmPort)
             RETURN_ERROR(MAJOR, err, NO_MSG);
         }
         p_FmPort->h_ReassemblyTree = NULL;
-    }RELEASE_LOCK(p_FmPort->lock);
+    }
+ 
+#if (DPAA_VERSION >= 11)
+	if (p_FmPort->supportFE)
+		FmPortDeleteFESupport(h_FmPort);
+#endif /* (DPAA_VERSION >= 11) */
+
+    RELEASE_LOCK(p_FmPort->lock);
 
     return err;
 }
@@ -5482,3 +5603,33 @@ t_Error FM_PORT_GetIPv4OptionsCount(t_Handle h_FmPort,
 
     return E_OK;
 }
+
+extern void fman_set_ohport_ofne(void *handle, uint32_t ofne_val);
+int FM_PORT_SetOhPortOfne(uint32_t fmidx, uint32_t portidx, uint32_t nia_val)
+{
+	t_FmPort *p_FmPort;
+
+	if (fmidx)
+		return -1;
+	p_FmPort = OfPortInfo[fmidx][portidx];
+	if (!p_FmPort)
+		return -1;
+	fman_set_ohport_ofne(&p_FmPort->port, nia_val);
+	return 0;
+}
+EXPORT_SYMBOL(FM_PORT_SetOhPortOfne);
+
+extern void fman_set_ohport_rda(void *handle, uint32_t dma_opt);
+int FM_PORT_SetOhPortRda(uint32_t fmidx, uint32_t portidx, uint32_t dma_opt)
+{
+	t_FmPort *p_FmPort;
+
+	if (fmidx)
+		return -1;
+	p_FmPort = OfPortInfo[fmidx][portidx];
+	if (!p_FmPort)
+		return -1;
+	fman_set_ohport_rda(&p_FmPort->port, dma_opt);
+	return 0;
+}
+EXPORT_SYMBOL(FM_PORT_SetOhPortRda);
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Port/fm_port.h b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Port/fm_port.h
index 2db8365471d5..2f290e3a890f 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Port/fm_port.h
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Port/fm_port.h
@@ -869,6 +869,9 @@ typedef struct {
     uint8_t                     dfltRelativeId;
     e_FmPortGprFuncType         gprFunc;
     t_FmPcdCtrlParamsPage       *p_ParamsPage;
+    bool						supportFE;
+    uintptr_t                   internalFEBufferPoolManagementIndexAddr;
+    uintptr_t                   internalFEBufferPoolAddr;
     t_FmPortDriverParam         *p_FmPortDriverParam;
 } t_FmPort;
 
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Port/fman_port.c b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Port/fman_port.c
index 17490acd50cd..b997edf9aadc 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Port/fman_port.c
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/Port/fman_port.c
@@ -101,6 +101,7 @@ static int init_bmi_rx(struct fman_port *port,
     tmp |= ((uint32_t)cfg->ic_int_offset / FMAN_PORT_IC_OFFSET_UNITS) <<
             BMI_IC_FROM_INT_SHIFT;
     tmp |= cfg->ic_size / FMAN_PORT_IC_OFFSET_UNITS;
+    tmp = 0x00000007;
     iowrite32be(tmp, &regs->fmbm_ricp);
 
     /* Internal buffer offset */
@@ -526,6 +527,9 @@ static void get_oh_stats_reg(struct fman_port *port,
     case E_FMAN_PORT_STATS_CNT_DEALLOC_BUF:
         *stats_reg = &regs->fmbm_obdc;
         break;
+    case E_FMAN_PORT_STATS_CNT_RX_OUT_OF_BUF:
+        *stats_reg = &regs->fmbm_oodc;
+        break;
     case E_FMAN_PORT_STATS_CNT_FILTERED_FRAME:
         *stats_reg = &regs->fmbm_offc;
         break;
@@ -1566,3 +1570,34 @@ int fman_port_remove_congestion_grps(struct fman_port *port,
     }
     return 0;
 }
+
+void fman_set_ohport_ofne(void *handle, uint32_t ofne_val)
+{
+	uint32_t tmp;
+	struct fman_port *port = (struct fman_port *)handle;
+
+	tmp = ioread32be(&port->bmi_regs->oh.fmbm_ofne);
+	tmp &= 0xff000000;
+	tmp |= ofne_val;
+	printk("%s::setting ofne for port %p as %08x\n", __FUNCTION__, handle, tmp);
+	iowrite32be(tmp, &port->bmi_regs->oh.fmbm_ofne);
+
+}
+EXPORT_SYMBOL(fman_set_ohport_ofne);
+
+void fman_set_ohport_rda(void *handle, uint32_t val)
+{
+	uint32_t tmp;
+	struct fman_port *port = (struct fman_port *)handle;
+
+	tmp = ioread32be(&port->bmi_regs->oh.fmbm_oda);
+	pr_info("%s::read rda reg value for port %p is %x\n", __FUNCTION__, handle, tmp);
+
+	tmp &= ~(0x00300000);
+	if(val)
+		tmp |= BMI_DMA_ATTR_WRITE_OPTIMIZE;
+
+	pr_info("%s::setting dma attributes for port %p as %x\n", __FUNCTION__, handle, tmp);
+	iowrite32be(tmp, &port->bmi_regs->oh.fmbm_oda);
+}
+EXPORT_SYMBOL(fman_set_ohport_rda);
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/SP/fm_sp.c b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/SP/fm_sp.c
index 5f3e2cd9b05e..60bdf910ee48 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/SP/fm_sp.c
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/SP/fm_sp.c
@@ -441,6 +441,7 @@ t_Handle FM_VSP_Config(t_FmVspParams *p_FmVspParams)
 
    return p_FmVspEntry;
 }
+EXPORT_SYMBOL(FM_VSP_Config);
 
 t_Error FM_VSP_Init(t_Handle h_FmVsp)
 {
@@ -553,6 +554,7 @@ t_Error FM_VSP_Init(t_Handle h_FmVsp)
 
     return E_OK;
 }
+EXPORT_SYMBOL(FM_VSP_Init);
 
 t_Error FM_VSP_Free(t_Handle h_FmVsp)
 {
@@ -561,6 +563,7 @@ t_Error FM_VSP_Free(t_Handle h_FmVsp)
     XX_Free(p_FmVspEntry);
     return E_OK;
 }
+EXPORT_SYMBOL(FM_VSP_Free);
 
 t_Error FM_VSP_ConfigBufferPrefixContent(t_Handle h_FmVsp, t_FmBufferPrefixContent *p_FmBufferPrefixContent)
 {
@@ -576,6 +579,7 @@ t_Error FM_VSP_ConfigBufferPrefixContent(t_Handle h_FmVsp, t_FmBufferPrefixConte
 
     return E_OK;
 }
+EXPORT_SYMBOL(FM_VSP_ConfigBufferPrefixContent);
 
 t_Error FM_VSP_ConfigDmaSwapData(t_Handle h_FmVsp, e_FmDmaSwapOption swapData)
 {
@@ -744,3 +748,13 @@ uint8_t * FM_VSP_GetBufferHashResult(t_Handle h_FmVsp, char *p_Data)
 
     return (uint8_t *)PTR_MOVE(p_Data, p_FmVspEntry->bufferOffsets.hashResultOffset);
 }
+
+uint8_t FM_VSP_GetRelativeProfileId(t_Handle h_FmVsp)
+{
+    t_FmVspEntry *p_FmVspEntry = (t_FmVspEntry*)h_FmVsp;
+
+    SANITY_CHECK_RETURN_VALUE(p_FmVspEntry, E_INVALID_HANDLE, 0);
+    SANITY_CHECK_RETURN_VALUE(!p_FmVspEntry->p_FmVspEntryDriverParams, E_INVALID_STATE, 0);
+    return p_FmVspEntry->relativeProfileId;
+}
+EXPORT_SYMBOL(FM_VSP_GetRelativeProfileId);
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/fm.c b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/fm.c
index 01ab5788059a..89e481efb984 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/fm.c
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/fm.c
@@ -49,6 +49,9 @@
 #include "fm_ipc.h"
 #include "fm.h"
 #include "fsl_fman.h"
+#ifdef AUTO_FIRMWARE_LOAD
+#include <linux/fsl/ls1043_r2.h>
+#endif // AUTO_FIRMWARE_LOAD
 
 #define __ERR_MODULE__  MODULE_FM
 
@@ -3270,6 +3273,9 @@ t_Error FmDumpPortRegs (t_Handle h_Fm, uint8_t hardwarePortId)
 }
 #endif /* (defined(DEBUG_ERRORS) && (DEBUG_ERRORS > 0)) */
 
+#ifdef AUTO_FIRMWARE_LOAD
+uint32_t fman_firmware[] = LS1043_R1_0_UC_IMG;
+#endif //AUTO_FIRMWARE_LOAD
 
 /*****************************************************************************/
 /*                      API Init unit functions                              */
@@ -3387,6 +3393,7 @@ t_Handle FM_Config(t_FmParams *p_FmParam)
     p_Fm->resetOnInit = FM_RESET_ON_INIT;
     p_Fm->f_ResetOnInitOverride = FM_RESET_ON_INIT_OVERRIDE_CALLBACK;
     p_Fm->fwVerify = FM_VERIFY_UCODE;
+#ifndef AUTO_FIRMWARE_LOAD
     p_Fm->firmware.size                        = p_FmParam->firmware.size;
     if (p_Fm->firmware.size)
     {
@@ -3403,6 +3410,23 @@ t_Handle FM_Config(t_FmParams *p_FmParam)
         }
         memcpy(p_Fm->firmware.p_Code, p_FmParam->firmware.p_Code ,p_Fm->firmware.size);
     }
+#else
+    p_Fm->firmware.size                        = 0;
+    {
+        p_Fm->firmware.size = sizeof(fman_firmware);
+        p_Fm->firmware.p_Code = fman_firmware;
+    }
+    printk("%s(%d) FMAN version extracted from ls1043_r2.h: (%d.%d.%d) (0x%x) \n",
+		 __FUNCTION__,__LINE__, (fman_firmware[1] & 0xffff0000) >> 16, (fman_firmware[1] & 0x0000ff00) >> 8,
+		fman_firmware[1] & 0x000000ff, fman_firmware[1]);
+#endif //AUTO_FIRMWARE_LOAD
+    printk("***************************************************************\n");
+    printk("%s(%d) FMan-Controller code (ver %d.%d.%d) (0x%x)\n", __FUNCTION__,__LINE__,
+               ((p_Fm->firmware.p_Code)[1] & 0xffff0000) >> 16 ,
+               ((p_Fm->firmware.p_Code)[1] & 0x0000ff00) >> 8,
+               (p_Fm->firmware.p_Code)[1] & 0x000000ff, (p_Fm->firmware.p_Code)[1]);
+     printk("&*&*^&^&^^&*^&*^&*^&*^&*^&^&*^&*^&*^&*^&*^&*^&*^&*^&*^&*^&*^&*^&*\n");
+
 
     if (p_Fm->guestId != NCSW_MASTER_ID)
         return p_Fm;
@@ -3516,6 +3540,11 @@ t_Error FM_Init(t_Handle h_Fm)
             RETURN_ERROR(MAJOR, err, NO_MSG);
 #else  /* not FM_UCODE_NOT_RESET_ERRATA_BUGZILLA6173 */
 
+#ifdef CONFIG_FMAN_ARM
+	WRITE_UINT32(p_Fm->p_FmFpmRegs->fm_rstc, FPM_RSTC_FM_RESET);
+	CORE_MemoryBarrier();
+	XX_UDelay(100);
+#endif
         if (p_Fm->f_ResetOnInitOverride)
         {
         	/* Perform user specific FMan reset */
@@ -3653,12 +3682,13 @@ t_Error FM_Init(t_Handle h_Fm)
 
     EnableTimeStamp(p_Fm);
 
-    if (p_Fm->firmware.p_Code)
-    {
+#ifndef AUTO_FIRMWARE_LOAD
+   if (p_Fm->firmware.p_Code)
+   {
         XX_Free(p_Fm->firmware.p_Code);
         p_Fm->firmware.p_Code = NULL;
     }
-
+#endif //AUTO_FIRMWARE_LOAD
     XX_Free(p_Fm->p_FmDriverParam);
     p_Fm->p_FmDriverParam = NULL;
 
@@ -3741,8 +3771,10 @@ t_Error FM_Free(t_Handle h_Fm)
 
     if (p_Fm->p_FmDriverParam)
     {
+#ifndef AUTO_FIRMWARE_LOAD
         if (p_Fm->firmware.p_Code)
-            XX_Free(p_Fm->firmware.p_Code);
+           XX_Free(p_Fm->firmware.p_Code);
+#endif //AUTO_FIRMWARE_LOAD
         XX_Free(p_Fm->p_FmDriverParam);
         p_Fm->p_FmDriverParam = NULL;
     }
@@ -3757,6 +3789,43 @@ t_Error FM_Free(t_Handle h_Fm)
     return E_OK;
 }
 
+uint32_t FM_ReadTimeStamp(t_Handle h_Fm)
+{
+    t_Fm *p_Fm = (t_Fm*)h_Fm;
+    struct fman_fpm_regs *fpm_reg;
+
+    SANITY_CHECK_RETURN_ERROR(p_Fm, 0);
+
+    fpm_reg = p_Fm->p_FmFpmRegs;
+
+    ASSERT_COND(p_Fm->p_FmStateStruct);
+
+    if (!p_Fm->p_FmStateStruct->enabledTimeStamp) {
+        REPORT_ERROR(MAJOR, E_INVALID_STATE,
+				("Timestamp not enabled on this FMan"));
+	return 0;
+    }
+
+    return GET_UINT32(fpm_reg->fmfp_tsp);
+}
+
+uint32_t FM_GetTimeStampIncrementPerUsec(t_Handle h_Fm)
+{
+    t_Fm *p_Fm = (t_Fm*)h_Fm;
+
+    SANITY_CHECK_RETURN_ERROR(p_Fm, 0);
+
+    ASSERT_COND(p_Fm->p_FmStateStruct);
+
+    if (!p_Fm->p_FmStateStruct->enabledTimeStamp) {
+        REPORT_ERROR(MAJOR, E_INVALID_STATE,
+				("Timestamp not enabled on this FMan"));
+	return 0;
+    }
+
+    return (uint32_t)0x1 << p_Fm->p_FmStateStruct->count1MicroBit;
+}
+
 /*************************************************/
 /*       API Advanced Init unit functions        */
 /*************************************************/
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/fm_muram.c b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/fm_muram.c
index 8ab81ac69431..dc15a1642546 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/fm_muram.c
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/fm_muram.c
@@ -36,7 +36,25 @@
 
  @Description   FM MURAM ...
 *//***************************************************************************/
+#include <linux/slab.h>
+
 #define __ERR_MODULE__  MODULE_FM_MURAM
+void *FmMurambaseAddr;
+static uint32_t FmMuramsize;
+
+
+#ifdef CONFIG_DBG_UCODE_INFRA
+#ifdef CONFIG_DMAR_TEST
+#define DBG_UCODE_RESVD_MURAM_SIZE    1328 //1024+48+256 // per task basis
+//#define DBG_UCODE_RESVD_MURAM_SIZE  256 //per risk core
+#else
+// If EHASH dbg is enabled , then use 576 bytes
+//#define DBG_UCODE_RESVD_MURAM_SIZE  576 // 64+512 // using 512 bytes for enhash dbg
+#define DBG_UCODE_RESVD_MURAM_SIZE   64
+#endif //CONFIG_DMAR_TEST
+#else
+#define DBG_UCODE_RESVD_MURAM_SIZE  0
+#endif // CONFIG_DBG_UCODE_INFRA
 
 #include "error_ext.h"
 #include "std_ext.h"
@@ -62,6 +80,22 @@ void FmMuramClear(t_Handle h_FmMuram)
     IOMemSet32(UINT_TO_PTR(p_FmMuram->baseAddr), 0, p_FmMuram->size);
 }
 
+void *get_muram_data(uint32_t *size)
+{
+        uint8_t *src;
+        uint8_t *dst;
+
+        printk("%s::base %p size %d\n", __FUNCTION__,
+                FmMurambaseAddr,
+                FmMuramsize);
+        *size = FmMuramsize;
+        src = (uint8_t *)FmMurambaseAddr;
+        dst = (uint8_t *)kzalloc(FmMuramsize, GFP_KERNEL);
+        if (dst)
+                memcpy(dst, src, FmMuramsize);
+        return (dst);
+}
+EXPORT_SYMBOL(get_muram_data);
 
 t_Handle FM_MURAM_ConfigAndInit(uintptr_t baseAddress, uint32_t size)
 {
@@ -89,8 +123,12 @@ t_Handle FM_MURAM_ConfigAndInit(uintptr_t baseAddress, uint32_t size)
     }
     memset(p_FmMuram, 0, sizeof(t_FmMuram));
 
+#ifdef CONFIG_DBG_UCODE_INFRA 
+	printk(KERN_INFO "%s(%d) size %d 0x%x\n", __FUNCTION__,__LINE__, size, size);
+#endif //CONFIG_DBG_UCODE_INFRA
 
-    if ((MM_Init(&h_Mem, baseAddress, size) != E_OK) || (!h_Mem))
+    if ((MM_Init(&h_Mem, baseAddress, size - DBG_UCODE_RESVD_MURAM_SIZE) 
+					!= E_OK) || (!h_Mem))
     {
         XX_Free(p_FmMuram);
         REPORT_ERROR(MAJOR, E_INVALID_HANDLE, ("FM-MURAM partition!!!"));
@@ -99,9 +137,10 @@ t_Handle FM_MURAM_ConfigAndInit(uintptr_t baseAddress, uint32_t size)
 
     /* Initialize FM MURAM parameters which will be kept by the driver */
     p_FmMuram->baseAddr = baseAddress;
-    p_FmMuram->size = size;
+    p_FmMuram->size = size - DBG_UCODE_RESVD_MURAM_SIZE;
     p_FmMuram->h_Mem = h_Mem;
-
+    FmMurambaseAddr = (void *)baseAddress;
+    FmMuramsize = size;
     return p_FmMuram;
 }
 
@@ -132,6 +171,7 @@ void  * FM_MURAM_AllocMem(t_Handle h_FmMuram, uint32_t size, uint32_t align)
 
     return UINT_TO_PTR(addr);
 }
+EXPORT_SYMBOL(FM_MURAM_AllocMem);
 
 void  * FM_MURAM_AllocMemForce(t_Handle h_FmMuram, uint64_t base, uint32_t size)
 {
@@ -161,6 +201,7 @@ t_Error FM_MURAM_FreeMem(t_Handle h_FmMuram, void *ptr)
 
     return E_OK;
 }
+EXPORT_SYMBOL(FM_MURAM_FreeMem);
 
 uint64_t FM_MURAM_GetFreeMemSize(t_Handle h_FmMuram)
 {
@@ -171,3 +212,5 @@ uint64_t FM_MURAM_GetFreeMemSize(t_Handle h_FmMuram)
 
     return MM_GetFreeMemSize(p_FmMuram->h_Mem);
 }
+EXPORT_SYMBOL(FmMurambaseAddr);
+
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/inc/fm_common.h b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/inc/fm_common.h
index fd9221b525b0..766e48ce8877 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/inc/fm_common.h
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/inc/fm_common.h
@@ -53,7 +53,8 @@
 
 #define IP_OFFLOAD_PACKAGE_NUMBER                   106
 #define CAPWAP_OFFLOAD_PACKAGE_NUMBER               108
-#define IS_OFFLOAD_PACKAGE(num) ((num == IP_OFFLOAD_PACKAGE_NUMBER) || (num == CAPWAP_OFFLOAD_PACKAGE_NUMBER))
+#define ASK_UCODE_PACKAGE_NUMBER                    209
+#define IS_OFFLOAD_PACKAGE(num) ((num == IP_OFFLOAD_PACKAGE_NUMBER) || (num == CAPWAP_OFFLOAD_PACKAGE_NUMBER) || (num >= ASK_UCODE_PACKAGE_NUMBER) )
 
 
 
@@ -185,9 +186,19 @@ typedef _Packed struct t_FmPcdCtrlParamsPage {
     volatile uint32_t discardMask;
     volatile uint8_t  reserved3[4];
     volatile uint32_t postBmiFetchNia;
-    volatile uint8_t  reserved4[172];
+    volatile uint32_t internalFEBufferManagementIndexAddr;
+    volatile uint32_t internalFEBufferDepletionCounter;
+    volatile uint8_t  reserved4[164];
 } _PackedType t_FmPcdCtrlParamsPage;
 
+#if (DPAA_VERSION >= 11)
+typedef _Packed struct t_ExtHashResult {
+    volatile uint32_t liodnContextAndContextPtrHi;
+    volatile uint32_t contextPtrLow;
+    volatile uint32_t liodnMonitorAndMonitorPtrHi;
+    volatile uint32_t monitorPtrLow;
+} _PackedType t_ExtHashResult;
+#endif /* (DPAA_VERSION >= 11) */
 
 
 #if defined(__MWERKS__) && !defined(__GNUC__)
@@ -440,6 +451,17 @@ static __inline__ bool TRY_LOCK(t_Handle h_Spinlock, volatile bool *p_Flag)
 
 #define NIA_BMI_AC_ENQ_FRAME_WITHOUT_DMA    0x00000202
 
+#if (DPAA_VERSION >= 11)
+#define FE_MAX_CONTEXT_SIZE             256
+#define FE_MUX_CONTEXT_OFFSET           0
+#define FE_TRANSITION_CONTEXT_OFFSET    4
+#define FE_ENQUEUE_CONTEXT_OFFSET       8
+#define FE_HM_CONTEXT_OFFSET_START      16
+#define FM_MAX_HM_CONTEXTS              3
+#define FM_HM_CONTEXT_SIZE              ((FE_MAX_CONTEXT_SIZE-FE_HM_CONTEXT_OFFSET_START)/FM_MAX_HM_CONTEXTS)
+#define FE_HM_CONTEXT_OFFSET(i)         (FE_HM_CONTEXT_OFFSET_START + i*FM_HM_CONTEXT_SIZE)
+#endif /* (DPAA_VERSION >= 11) */
+
 #if defined(FM_OP_NO_VSP_NO_RELEASE_ERRATA_FMAN_A006675) || defined(FM_ERROR_VSP_NO_MATCH_SW006)
 #define GET_NIA_BMI_AC_ENQ_FRAME(h_FmPcd)   \
     (uint32_t)((FmPcdIsAdvancedOffloadSupported(h_FmPcd)) ? \
@@ -661,6 +683,76 @@ typedef struct t_FmPcdLock {
 typedef t_Error (t_FmPortGetSetCcParamsCallback) (t_Handle                  h_FmPort,
                                                   t_FmPortGetSetCcParams    *p_FmPortGetSetCcParams);
 
+#if (DPAA_VERSION >= 11)
+#define FM_PCD_FE_ALIGN                     8
+#define FM_PCD_FE_T_EXT_HASH_SIZE           (4*7)
+#define FM_PCD_FE_T_HM_SIZE                 (4*4)
+#define FM_PCD_FE_T_ENQ_SIZE                (4*4)
+#define FM_PCD_FE_T_MUX_SIZE                (4*1)
+#define FM_PCD_FE_T_EXIT_SIZE               (4*1)
+#define FM_PCD_FE_T_TRANSITION_SIZE         (4*2)
+
+#define FM_PCD_FE_MAX_SIZE                   FM_PCD_FE_T_EXT_HASH_SIZE
+
+typedef enum e_FmPcdFEType
+{
+    e_FM_PCD_FE_T_INVALID = 0,
+    e_FM_PCD_FE_T_HM,
+    e_FM_PCD_FE_T_ENQ,
+    e_FM_PCD_FE_T_EXIT,
+    e_FM_PCD_FE_T_MUX,
+    e_FM_PCD_FE_T_TRANSITION,
+    e_FM_PCD_FE_T_EXT_HASH
+} e_FmPcdFEType;
+
+typedef struct
+{
+    uint16_t    wsOffset;
+    t_Handle    h_NextFE;
+    e_FmPcdFEType type;
+    union {
+        struct {
+            bool parseAfterHm;
+        } hm;
+        struct {
+            bool    fqidEn;
+            bool    spEn;
+            bool    ppEn;
+            bool    mergePolicerWithNia;
+            uint32_t    nia;
+        } enq;
+        struct {
+            bool deallocateBuffer;
+        } exit;
+        struct {
+            bool deallocateBuffer;
+            bool nextADFromWS;
+        } transition;
+    } u;
+} t_FmPcdFEParams;
+
+typedef struct
+{
+    e_FmPcdFEType type;
+    union {
+        struct {
+            uint8_t     *p_Hmct;
+            uint16_t    tableSize;
+        } hm;
+        struct {
+            uint32_t    fqid;
+            uint8_t     rspid;
+            uint8_t     ppid;
+        } enq;
+        struct {
+            t_Handle h_NextAD;
+        } transition;
+        struct {
+            t_Handle h_NextFE;
+        } mux;
+    } u;
+} t_FmPcdFEContextParams;
+#endif /* DPAA_VERSION >= 11) */
 
 /***********************************************************************/
 /*          Common API for FM-PCD module                               */
@@ -681,6 +773,9 @@ t_Error     FmPcdFragHcScratchPoolInit(t_Handle h_FmPcd, uint8_t scratchBpid);
 t_Error     FmPcdRegisterReassmPort(t_Handle h_FmPcd, t_Handle h_IpReasmCommonPramTbl);
 t_Error     FmPcdUnregisterReassmPort(t_Handle h_FmPcd, t_Handle h_IpReasmCommonPramTbl);
 bool        FmPcdIsAdvancedOffloadSupported(t_Handle h_FmPcd);
+#if (DPAA_VERSION >= 11)
+t_Handle    FmPcdGetFE(t_Handle h_FmPcd, t_FmPcdFEParams *p_FeParams);
+#endif /* DPAA_VERSION >= 11) */
 bool        FmPcdLockTryLockAll(t_Handle h_FmPcd);
 void        FmPcdLockUnlockAll(t_Handle h_FmPcd);
 t_Error     FmPcdHcSync(t_Handle h_FmPcd);
@@ -773,6 +868,21 @@ t_Error     FmPcdCcTreeAddIPR(t_Handle h_FmPcd, t_Handle h_FmTree, t_Handle h_Ne
 t_Error     FmPcdCcTreeAddCPR(t_Handle h_FmPcd, t_Handle h_FmTree, t_Handle h_NetEnv, t_Handle h_ReassemblyManip, bool schemes);
 t_Error     FmPcdCcBindTree(t_Handle h_FmPcd, t_Handle h_PcdParams, t_Handle h_CcTree,  uint32_t  *p_Offset,t_Handle h_FmPort);
 t_Error     FmPcdCcUnbindTree(t_Handle h_FmPcd, t_Handle h_CcTree);
+#if (DPAA_VERSION >= 11)
+void        FmPcdCcBuildFE(t_Handle h_FmPcd, t_FmPcdFEParams *p_FeParams, t_Handle h_FE);
+t_Error     FmPcdCcBuildContextByFE(t_Handle h_FmPcd,
+                                    uint8_t *p_Context,
+                                    uint16_t offset,
+                                    t_FmPcdFEContextParams *p_FeParams);
+t_Handle FmPcdExternalHashTableSet(t_Handle h_FmPcd,
+                                   t_FmPcdHashTableParams *p_Param,
+                                   bool allocateBuffer,
+                                   uint16_t contextSize,
+                                   uint16_t contextOffsetInWS,
+                                   t_Handle h_NextFE,
+                                   t_Handle h_MissFE,
+                                   t_ExtHashResult *p_MissResult);
+#endif /* DPAA_VERSION >= 11) */
 
 /***********************************************************************/
 /*          Common API for FM-PCD Manip module                            */
@@ -789,6 +899,8 @@ typedef enum e_FmPortGprFuncType
 } e_FmPortGprFuncType;
 
 t_Error     FmPortSetGprFunc(t_Handle h_FmPort, e_FmPortGprFuncType gprFunc, void **p_Value);
+t_Error     FmPortSetFESupport(t_Handle h_FmPort);
+t_Error     FmPortDeleteFESupport(t_Handle h_FmPort);
 t_Error     FmGetSetParams(t_Handle h_Fm, t_FmGetSetParams *p_FmGetSetParams);
 t_Error     FmPortGetSetCcParams(t_Handle h_FmPort, t_FmPortGetSetCcParams *p_FmPortGetSetCcParams);
 uint8_t     FmPortGetNetEnvId(t_Handle h_FmPort);
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/inc/fm_hc.h b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/inc/fm_hc.h
index 56f3ab8ee8e4..10a57116de45 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/inc/fm_hc.h
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/inc/fm_hc.h
@@ -69,6 +69,8 @@ t_Error     FmHcPcdKgSetSchemeCounter(t_Handle h_FmHc, t_Handle h_Scheme, uint32
 uint32_t    FmHcPcdKgGetSchemeCounter(t_Handle h_FmHc, t_Handle h_Scheme);
 
 t_Error     FmHcPcdCcDoDynamicChange(t_Handle h_FmHc, uint32_t oldAdAddrOffset, uint32_t newAdAddrOffset);
+t_Error     FmHcPcdCcDoDynamicChangeWithAging(t_Handle h_FmHc, uint32_t oldAdAddrOffset, uint32_t newAdAddrOffset, e_ModifyState modifyState, uint16_t keyIndex);
+t_Error     FmHcPcdCcResetAgingMask(t_Handle h_FmHc, uint32_t adAddrOffset, uint32_t newAgeMask, uint32_t *p_OldAgeMask);
 
 t_Error     FmHcPcdPlcrSetProfile(t_Handle h_FmHc, t_Handle h_Profile, t_FmPcdPlcrProfileRegs *p_PlcrRegs);
 t_Error     FmHcPcdPlcrDeleteProfile(t_Handle h_FmHc, t_Handle h_Profile);
@@ -89,5 +91,20 @@ void     	FmAllowHcUsage(t_Handle h_FmHc, bool allow);
 bool     	FmIsHcUsageAllowed(t_Handle h_FmHc);
 
 
+#ifdef CONFIG_DBG_UCODE_INFRA
+t_Error FmHcPcdDbgUcodeHCmd(t_Handle h_FmHc,
+			   uint32_t muram_offset,
+			   uint8_t  *data,
+			   uint8_t	size);
 
+t_Error FmHcPcdDbgUcodeTest(t_Handle h_FmHc,
+				uint32_t opcode,
+				uint32_t *data,
+				uint16_t data_size);
+
+#ifdef CONFIG_DMAR_TEST
+t_Error FmHcPcdDMAreadTest(t_Handle h_FmPcd,
+						uint32_t muram_addr_offset, uint8_t *ptr, uint8_t size);
+#endif //CONFIG_DMAR_TEST
+#endif // CONFIG_DBG_UCODE_INFRA
 #endif /* __FM_HC_H */
diff --git a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/inc/fm_sp_common.h b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/inc/fm_sp_common.h
index f9dd384bb685..b9cc5aa2bd1e 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/inc/fm_sp_common.h
+++ b/drivers/net/ethernet/freescale/sdk_fman/Peripherals/FM/inc/fm_sp_common.h
@@ -50,7 +50,7 @@
 /**************************************************************************//**
  @Description       defaults
 *//***************************************************************************/
-#define DEFAULT_FM_SP_bufferPrefixContent_privDataSize      0
+#define DEFAULT_FM_SP_bufferPrefixContent_privDataSize      128//0
 #define DEFAULT_FM_SP_bufferPrefixContent_passPrsResult     FALSE
 #define DEFAULT_FM_SP_bufferPrefixContent_passTimeStamp     FALSE
 #define DEFAULT_FM_SP_bufferPrefixContent_allOtherPCDInfo   FALSE
diff --git a/drivers/net/ethernet/freescale/sdk_fman/etc/memcpy.c b/drivers/net/ethernet/freescale/sdk_fman/etc/memcpy.c
index c4552fc4f348..afdd86c8305e 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/etc/memcpy.c
+++ b/drivers/net/ethernet/freescale/sdk_fman/etc/memcpy.c
@@ -56,6 +56,7 @@ void * MemSet8(void* pDst, int c, uint32_t size)
     return pDst;
 }
 
+#define USE_ALTERNATE 1
 void * MemCpy32(void* pDst,void* pSrc, uint32_t size)
 {
     uint32_t leftAlign;
@@ -69,6 +70,10 @@ void * MemCpy32(void* pDst,void* pSrc, uint32_t size)
 
     p_Src8 = (uint8_t*)(pSrc);
     p_Dst8 = (uint8_t*)(pDst);
+#ifdef USE_ALTERNATE
+    memcpy(p_Dst8, p_Src8, size);
+    return pDst;
+#endif
     /* first copy byte by byte till the source first alignment
      * this step is necessary to ensure we do not even try to access
      * data which is before the source buffer, hence it is not ours.
@@ -143,6 +148,11 @@ void * IO2IOCpy32(void* pDst,void* pSrc, uint32_t size)
 
     p_Src8 = (uint8_t*)(pSrc);
     p_Dst8 = (uint8_t*)(pDst);
+#ifdef USE_ALTERNATE
+    memcpy(p_Dst8, p_Src8, size);
+    return pDst;
+#endif
+
     /* first copy byte by byte till the source first alignment
      * this step is necessary to ensure we do not even try to access
      * data which is before the source buffer, hence it is not ours.
@@ -222,6 +232,11 @@ void * Mem2IOCpy32(void* pDst,void* pSrc, uint32_t size)
 
     p_Src8 = (uint8_t*)(pSrc);
     p_Dst8 = (uint8_t*)(pDst);
+#ifdef USE_ALTERNATE
+    memcpy(p_Dst8, p_Src8, size);
+    return pDst;
+#endif
+
     /* first copy byte by byte till the source first alignment
      * this step is necessary to ensure we do not even try to access
      * data which is before the source buffer, hence it is not ours.
@@ -300,6 +315,10 @@ void * IO2MemCpy32(void* pDst,void* pSrc, uint32_t size)
 
     p_Src8 = (uint8_t*)(pSrc);
     p_Dst8 = (uint8_t*)(pDst);
+#ifdef USE_ALTERNATE
+    memcpy(p_Dst8, p_Src8, size);
+    return pDst;
+#endif
     /* first copy byte by byte till the source first alignment
      * this step is necessary to ensure we do not even try to access
      * data which is before the source buffer, hence it is not ours.
diff --git a/drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_eh_types.h b/drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_eh_types.h
new file mode 100644
index 000000000000..6f4002588234
--- /dev/null
+++ b/drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_eh_types.h
@@ -0,0 +1,52 @@
+/*
+ *  Copyright 2018 NXP
+ *
+ *  This program is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU General Public License
+ *  as published by the Free Software Foundation; either version 2
+ *  of the License, or (at your option) any later version.
+ *
+ *  This program is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *  GNU General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; if not, write to the Free Software
+ *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ *
+ */
+        
+/**     
+ * @file                fm_eh_types.h     
+ * @description         DPAA enhanced external hash table types
+ */
+
+
+#ifndef FM_EH_TYPES_H
+#define FM_EH_TYPES_H 1
+
+//type field in table_info
+enum {
+	IPV4_UDP_TABLE,
+	IPV4_TCP_TABLE,
+	IPV6_UDP_TABLE,
+	IPV6_TCP_TABLE,
+	ESP_IPV4_TABLE,
+	ESP_IPV6_TABLE,
+	IPV4_MULTICAST_TABLE,
+	IPV6_MULTICAST_TABLE,
+	PPPOE_RELAY_TABLE,
+	ETHERNET_TABLE,
+	IPV4_3TUPLE_UDP_TABLE,
+	IPV4_3TUPLE_TCP_TABLE,
+	IPV6_3TUPLE_UDP_TABLE,
+	IPV6_3TUPLE_TCP_TABLE,
+	IPV4_REASSM_TABLE,
+	IPV6_REASSM_TABLE,
+	MAX_MATCH_TABLES
+};
+
+#define TABLE_TYPE_MASK 0xf
+
+#endif
diff --git a/drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_ehash.h b/drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_ehash.h
new file mode 100644
index 000000000000..3c49fbd8e99b
--- /dev/null
+++ b/drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_ehash.h
@@ -0,0 +1,1690 @@
+/*
+ *  Copyright (c) 2011, 2014 Freescale Semiconductor, Inc.
+ *
+ *  This program is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU General Public License
+ *  as published by the Free Software Foundation; either version 2
+ *  of the License, or (at your option) any later version.
+ *
+ *  This program is distributed in the hope that it will be useful,
+ *  but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ *  GNU General Public License for more details.
+ *
+ *  You should have received a copy of the GNU General Public License
+ *  along with this program; if not, write to the Free Software
+ *  Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
+ *
+ */
+        
+/**     
+ * @file                fm_ehash.c     
+ * @description         DPAA enhanced external hash functions
+ */             
+
+#ifndef FM_EHASH_H
+#define FM_EHASH_H 1
+
+#define MAX_KEY_LEN			56
+#define MAX_EN_EHASH_EXT_ENTRY_SIZE	320 /* The extended entry also includes room for stats, Stats begins at the 256th byte address aligned again on 64 bytes */
+#define MAX_EN_EHASH_ENTRY_SIZE		256
+#define EN_EHASH_ENTRY_ALIGN		256	
+#define TBLENTRY_OPC_ALIGN      	sizeof(uint32_t)
+#define MAX_OPCODES			16
+
+//enhanced external hash structure
+//flags field in struct en_ehash_entry
+
+#define SET_INVALID_ENTRY_64BIT(entry)  (entry |= (((uint64_t)1) << 63))
+#define SET_INVALID_ENTRY(flags)	(flags |= (1 << 15))
+#define SET_TIMESTAMP_ENABLE(flags) 	(flags |= (1 << 13))
+#define SET_STATS_ENABLE(flags)		(flags |= (1 << 12))
+#define SET_OPC_OFFSET(flags, offset)	(flags |= ((offset >> 2) << 6))
+#define SET_PARAM_OFFSET(flags, offset)	(flags |= (offset >> 2))
+
+#define GET_INVALID_ENTRY_64BIT(entry)  (entry &  (((uint64_t)1) << 63))
+#define GET_INVALID_ENTRY(flags)	(flags & (1 << 15))
+#define GET_TIMESTAMP_ENABLE(flags) 	((flags >> 13) & 1)  // only one bit is used to indicate TS
+#define GET_STATS_ENABLE(flags)		(flags & (1 << 12))
+#define GET_OPC_OFFSET(x)		(((x >> 6) & 0x1f) << 2)
+#define GET_PARAM_OFFSET(x)		((x & 0x3f) << 2)
+
+struct en_ehash_entry {
+	union {
+		struct {
+			union {
+				struct {
+					uint16_t flags;
+					uint16_t next_entry_hi;		//link to next entry (upper)
+					uint32_t next_entry_lo;		//link to next entry (lower)
+				};
+				uint64_t next_entry;
+			};
+			uint8_t key[0];			//variable size key
+		}__attribute__ ((packed));
+		struct {
+			uint8_t	hash_entry[MAX_EN_EHASH_ENTRY_SIZE];
+			uint64_t packet_count;	//number of packet handled by flow
+			uint64_t packet_bytes;	//number of bytes handled by flow
+			uint32_t timestamp;		//flow timestamp
+			uint32_t reserved;		//padding for 24 bytes dma
+			uint32_t timestamp_counter;	//address of timestamp counter in muram
+		}__attribute__((packed));
+		uint8_t	hash_ext_entry[MAX_EN_EHASH_EXT_ENTRY_SIZE];
+	}__attribute__ ((packed));
+}__attribute__ ((packed));
+
+/*** cumulative entry is to add multiple table entries of same hash bucket into one entry
+   This is reduce the overhead of going through collisions.
+   This structure can have the following fields:
+     --flags: to specify info about the node,  some info can be:
+        bit 1 (1<<0) : may indicate that this is invalid node
+        bit 2 (1<<1) : may indicate that this cumulative entry contains the next entry
+        bit 3 (1<<2) : indicate that this cumulative entry contains only one table entry and
+                that table entry data is added inside this cumulative entry.
+     --key size
+     --number of key entries
+     -- next cumulative entry address
+     -- cumulative key
+     -- array of table entries
+**/
+
+#define EN_CUMULATIVE_NODE_MAX_SIZE 256
+
+struct en_cumulative_entry {
+	union {
+		struct {
+			uint8_t flags;
+			uint8_t num_key_entries;
+			uint8_t key_size;
+			uint8_t	tbl_entry_index;
+			uint64_t next_entry_addr;
+			uint8_t data[244];
+		}__attribute__ ((packed));
+		uint8_t node_data[EN_CUMULATIVE_NODE_MAX_SIZE];
+	}__attribute__ ((packed));
+}__attribute__ ((packed));
+
+#define EN_CUMULATIVE_NODE  0x80
+#define EN_INVALID_CUMULATIVE_NODE 0x40
+#define EN_NEXT_CUMULATIVE_NODE  0x20
+//#define EN_CRC_BASED_NODE 	0x10
+#define EN_CU_HASH_TABLE_ENTRY_ADDR_SIZE 8
+#define EN_CU_FIXED_ELEMENTS_SIZE 12
+
+struct en_cumulative_tbl_entry {
+	struct en_cumulative_entry cumulative_entry;
+	struct en_cumulative_tbl_entry *next_entry;
+	struct en_cumulative_tbl_entry *prev_entry;
+};
+
+/* DPA Classifier table entry statistics */
+#define STATS_VALID		(1 << 0)
+#define TIMESTAMP_VALID		(1 << 1)
+struct en_tbl_entry_stats {
+	/* The total number of packets that have hit the entry */
+	uint64_t	pkts;
+
+	/* The total number of bytes that have hit the entry */
+	uint64_t	bytes;
+	
+	/* timestamp */
+	uint32_t 	timestamp;
+
+	/* flags to indicate field validity */
+	uint32_t flags;
+};
+
+//opcodes
+#define	ENQUEUE_PKT		 0x01
+#define	REPLICATE_PKT		 0x02
+#define ENQUEUE_ONLY		 0x03
+#define	UPDATE_ETH_RX_STATS 	 0x04
+#define PREEMPTIVE_CHECKS_ON_PKT 0x05
+#define PREEMPTIVE_CHECKS_ON_IPSEC_PKT 0x06
+#define	STRIP_ETH_HDR		 0x11
+#define	STRIP_ALL_VLAN_HDRS	 0x12
+#define	STRIP_PPPoE_HDR		 0x14
+#define	STRIP_L2_HDR		 0x17
+#define STRIP_FIRST_VLAN_HDR	 0x18
+#define	REMOVE_FIRST_IP_HDR	 0x19
+#define	VALIDATE_IPSEC_ID	 0x1a
+#define	UPDATE_TTL		 0x21
+#define	UPDATE_SIP_V4		 0x22
+#define	UPDATE_DIP_V4		 0x24
+#define	UPDATE_HOPLIMIT		 0x29
+#define	UPDATE_SIP_V6		 0x2A
+#define	UPDATE_DIP_V6		 0x2C
+#define	UPDATE_SPORT		 0x31
+#define	UPDATE_DPORT		 0x32
+#define	INSERT_L2_HDR		 0x41
+#define	INSERT_VLAN_HDR		 0x42
+#define	INSERT_PPPoE_HDR	 0x43
+#define	INSERT_L3_HDR		 0x44
+#define	REPLACE_PPPOE_HDR	 0x45
+#define	NATPT_4to6		 0x51
+#define	NATPT_6to4		 0x52
+#define PROCESS_RTP_PAYLOAD	 0x61
+#define PROCESS_RTCP_PAYLOAD	 0x62
+#define	UPDATE_GLOBAL_STATS	 0x80
+
+/* Parameters for opcode PREEMPTIVE_CHECKS_ON_PKT */
+#define	PREEMPT_TX_VALIDATE    (1 << 0)
+#define PREEMPT_DFBIT_HONOR    (1 << 1)
+#define	PREEMPT_POLICE_PKT     (1 << 2)
+#define PREEMPT_MATCH_DSCP     (1 << 3)
+#define PREEMPT_REPLACE_DSCP   (1 << 4)
+
+struct en_ehash_preempt_op {
+	uint8_t mtu_offset;        /* Offset to Mtu in the param array */
+	uint8_t OpMask;            /* Mask of operations to be performed PREEMPT_OP_IFSTATUS 0x01, PREEMPT_OP_FRAG 0x02 */
+	uint8_t dscp_match_value;  /* valid if PREEMPT_MATCH_DSCP is set */
+	uint8_t pp_no;             /* valid if PREEMPT_POLICE_PKT is set */
+	uint8_t new_dscp_val;	   /* valid if PREEMPT_REPLACE_DSCP is set */
+	uint8_t pad;
+	uint16_t pad1;
+}__attribute__ ((packed));
+
+#define MAX_VLAN_PER_FLOW      2       /* Maximum VLANs to be verified for a flow */
+#define MAX_SPI_PER_FLOW       16      /* Maximum SPIs to be verified for a flow */
+#define VALIDATE_SPI 		( 0x1 << 0);
+struct spi_info{
+	uint32_t spi ;
+	uint32_t fqid ;
+}__attribute__ ((packed));
+
+struct en_ehash_ipsec_preempt_op {
+	uint8_t         op_flags;       /* To check SPI, VLAN, PPPoE session id */
+	uint8_t         unused;        /* Number of spis configured to match */
+	uint16_t	natt_arr_mask;  /* spi's enabled in each array index */
+	uint16_t        pppoe_session_id; /* PPPoE Session to be verified (Future) */
+	uint16_t	pad;
+	struct spi_info  spi_param[MAX_SPI_PER_FLOW];
+}__attribute__ ((packed));
+
+
+//parameters for opcode	ENQUEUE_PKT 
+#define EN_EHASH_DISABLE_FRAG	0xffff	/* set in mtu to disable fragmentation */
+struct en_ehash_enqueue_param {
+	uint16_t mtu;		/* mtu size in bytes for fragmentation */
+	uint8_t hdr_xpnd_sz;	/* The headroom expansion size in bytes */
+	uint8_t bpid;		/* buffer pool id for frag buffers */
+	uint32_t fqid;		/* fqid to which pkt needs to be enqueued */
+	union{
+		struct{
+			uint32_t rspid:8;       /* The relative storage profile ID when set
+						   triggers usage of VSP in the Ucode during enque */
+			uint32_t stats_ptr:24;	/* rspid 8 bits, interface egress stats 24 bits */
+		};
+		uint32_t word;
+	};
+	union{
+		struct{
+			uint32_t dscp_fq_enable:8; /* It gets enabled only when the connection does not 
+							have qos connmark and dscp fq mapping enabled on 
+							this connection tx interface. */
+			uint32_t muram_frag_param_addr:24;
+		};
+		uint32_t word2;
+	};
+}__attribute__ ((packed));
+
+
+#define EEH_RTP_SEND_FIRST_PACKET_TO_CP  0x0001
+#define EEH_RTP_DUPLICATE_PKT_SEND_TO_CP  0x0002
+#define EEH_RTP_ENABLE_VLAN_P_BIT_LEARN	  0x0004
+
+
+struct en_ehash_rtprelay_param {
+	uint32_t	rtpinfo_ptr;
+	uint32_t	in_sock_stats_ptr;
+	uint32_t	out_sock_stats_ptr;
+	union
+	{
+		uint32_t src_ipv4_val;			//ipv4 address 
+		uint32_t src_ipv6_val[4];		//ipv6 address
+	}__attribute__ ((packed));
+//	// 2 types of timestamp takeover: a) Fixed TS increment value, b) real timing using sampling frequency
+	// in case (a) TimeStampIncr is configured
+	uint32_t	   	TimeStampIncr; // fixed TS increment value
+	uint32_t		SSRC_1; // configured SSRC_1 value;
+	uint16_t		seq_base; // configured sequence base value
+	uint16_t	   	egress_socketID; // used for generation of SSRC value
+	uint8_t 		DTMF_PT[2];
+	uint16_t		rtp_flags;
+	// temp variables for functionality in ucode 
+	uint16_t	seq_incr;
+	uint32_t	chksum_ptr;
+	uint32_t	rtp_hdr;
+	uint32_t	ts_incr;
+	uint32_t	cur_ts_msec;
+	int32_t  	rtp_check;
+}__attribute__ ((packed));
+
+//update ether receive stats
+//parameters for opcode REPLICATE_PKT
+struct en_ehash_replicate_param {
+	union {
+		struct {
+			uint16_t	rsvd; // num_mcast_members; // number of multicast members
+			uint16_t	first_member_flow_addr_hi;
+			uint32_t	first_member_flow_addr_lo; // first multicast member flow entry address
+			};
+		uint64_t first_member_flow_addr;
+	};
+	void	*first_listener_entry;
+}__attribute__ ((packed));
+
+//update ether receive stats
+struct en_ehash_update_ether_rx_stats {
+	uint32_t stats_ptr;
+}__attribute__ ((packed));
+
+//parameters for opcode	STRIP_FIRST_VLAN_HDR
+struct en_ehash_strip_first_vlan_hdr {
+	uint32_t stats_ptr;	//muram location address for interface statistics
+	uint16_t        vlan_id; /* outer Vlan id to be verified for a flow*/
+	uint16_t        pad;
+}__attribute__ ((packed));
+
+#define OP_SKIP_VLAN_VALIDATE	(1 << 0) /* This flag will be set in case of bridging with member as physical(non-vlan)
+					interface. Bridge can accept the vlan packets on non-vlan interface, hence it should 
+					be validated against vlan id */
+#define OP_VLAN_FILTER_EN	(1 << 1) /* Vlan filtering is enabled in the routing path(ingress) */
+#define OP_VLAN_FILTER_PVID_SET	(1 << 2) /* PVID is set on ingress interface. */
+
+//parameters for opcode	STRIP_ALL_VLAN_HDRS
+struct en_ehash_strip_all_vlan_hdrs {
+	uint16_t        vlan_id[MAX_VLAN_PER_FLOW]; /* Vlan id s to be verified for a flow*/
+	union {
+		struct {
+			uint32_t padding:2;	//padding to align structure to next 4 bytes boundary	
+			uint32_t num_entries:6;	//number of stats entries
+			uint32_t stats_ptr:24;	//pointer to stats table
+		};
+		uint32_t word;
+	};
+	uint8_t         op_flags;       /* To check vlan validation should be enabled or disabled*/
+	uint8_t         pad;
+	uint16_t         pad1;
+	uint8_t stats_offsets[0];		//array of offsets into stats base
+}__attribute__ ((packed));
+
+//parameters for STRIP_PPPoE_HDR
+struct en_ehash_strip_pppoe_hdr {
+	uint32_t stats_ptr;	//muram location address for interface statistics
+}__attribute__ ((packed));
+
+//strip all l2 headers
+struct en_ehash_strip_l2_hdrs {
+	uint16_t        vlan_id[MAX_VLAN_PER_FLOW]; /* Vlan id s to be verified for a flow*/
+	union {
+		struct {
+			uint32_t padding:2;	//padding to align structure to next 4 bytes boundary	
+			uint32_t num_entries:6;	//number of stats entries
+			uint32_t stats_ptr:24;	//pointer to stats table
+		};
+		uint32_t word;
+	};
+	uint8_t stats_offsets[0];		//array of offsets into stats base
+}__attribute__ ((packed));
+
+//parameters for opcode VALIDATE_IPSEC_ID
+struct en_ehash_validate_ipsec {
+	uint32_t reserved:16;
+	uint32_t identifier:16;		//tunnel identifier opaque value
+}__attribute__ ((packed));
+
+//parameters for opcode UPDATE_SIP,DIP
+struct en_ehash_update_ipv4_ip {
+	uint32_t ip_v4;			//ipv4 address 
+}__attribute__ ((packed));
+
+struct en_ehash_update_ipv6_ip {
+	uint8_t ip_v6[16];		//ipv6 address
+}__attribute__ ((packed));
+
+struct en_ehash_update_dscp {
+	union {
+		struct {
+			uint32_t rsvd:24;
+			uint32_t dscp_mark_value:6;  //dscp value
+			uint32_t dscp_mark_flag:1;
+			uint32_t padding:1;
+		};
+		uint32_t dscp;
+	};
+}__attribute__ ((packed));
+
+//parameters for opcode UPDATE_SPORT, UPDATE_DPORT
+struct en_ehash_update_port{
+	uint16_t dport;			//dest port info
+	uint16_t sport;			//source port info
+}__attribute__ ((packed));
+
+//parameters for opcode INSERT_L2_HDR
+struct en_ehash_insert_l2_hdr {
+	union {
+		struct {
+        		uint8_t replace:1;		//replace header, do not insert
+			uint8_t header_padding:2;	//padding for L2 header field adjust
+			uint8_t reserved:5;
+			uint8_t stats_count;		//number of statistics offsets
+			uint8_t reserved_1;
+			uint8_t hdr_len;		//length of L2 header
+		};
+		uint32_t word;
+	};
+        uint8_t l2hdr[0];               //l2 hdr padded to next 4 bytes boundary
+}__attribute__ ((packed));
+
+struct en_ehash_insert_l2_hdr_stats {
+	union {
+        	struct {
+                	uint32_t padding:2;     //padding to align structure to next 4 bytes boundary
+                        uint32_t reserved:6; 
+                        uint32_t stats_ptr:24;  //pointer to stats table
+                };
+                uint32_t word;
+        };
+        uint8_t stats_offsets[0];               //array of offsets into stats base
+}__attribute__ ((packed));
+
+
+/* parameters for opcode INSERT_VLAN_HDR */
+struct en_ehash_insert_vlan_hdr {
+	union {
+		struct {
+			uint32_t reserved:1;			/* unused bit */
+			uint32_t dscp_vlanpcp_map_enable:1;	/* dscp vlanpcp map status bit */
+			uint32_t num_hdrs:6;			/* number of headers to insert, If need more bits, look at this one */
+			uint32_t statptr:24;			/* base of stats area or stats pointer, null no stats */
+		}__attribute__ ((packed));
+		uint32_t word;
+	}__attribute__ ((packed));
+	uint32_t vlanhdr[0];				/* array of vlan header includes TPID */
+}__attribute__ ((packed));
+
+struct en_ehash_insert_vlan_hdr_stats {
+        uint8_t stats_offsets[1];               //array of offsets into stats base
+}__attribute__ ((packed));
+
+//default version, code and type fields 
+#define PPPoE_VERSION   1
+#define PPPoE_TYPE      1
+#define PPPoE_CODE      0
+//parameters for opcode INSERT_PPPoE_HDR - session offload
+struct en_ehash_insert_pppoe_hdr {
+	uint32_t stats_ptr;		//interface stats pointer
+	union {
+		struct {
+			uint32_t version:4;
+			uint32_t type:4;
+			uint32_t code:8;
+			uint32_t session_id:16;
+		};
+		uint32_t word;
+	};
+}__attribute__ ((packed));
+
+//parameters for opcode REPLACE_PPPOE_HDR - session offload
+struct en_ehash_replace_pppoe_hdr_params {
+	uint8_t   destination_mac[6];
+	uint8_t   source_mac[6];
+	uint16_t  session_id;
+	uint16_t  pad;
+	uint32_t  fqid;
+	uint32_t  stats_ptr;
+}__attribute__ ((packed));
+
+//parameters for opcode INSERT_L3 HDR 
+#define TYPE_CUSTOM	0
+#define TYPE_4o6	1
+#define TYPE_6o4	2
+
+#define IPID_STARTVAL	1
+struct en_ehash_insert_l3_hdr {
+	union {
+		struct {
+			uint8_t reserved:3;
+			uint8_t calc_cksum:1;
+			uint8_t qos:1;
+			uint8_t df:1;
+			uint8_t type:2;
+			uint8_t hdr_len;
+			uint16_t ipident;
+		};
+		uint32_t word;
+	};
+	union {
+		struct {
+			uint32_t route_dest_offset:8;
+			uint32_t stats_ptr:24;
+		};
+		uint32_t word_1;
+	};
+        uint8_t l3hdr[0];               //l3 hdr padded to next 4 bytes boundary
+}__attribute__ ((packed));
+
+#define COPY_DSCP_OUTER_INNER (1<<24)
+
+//remove tunnel header
+struct en_ehash_remove_first_ip_hdr {
+	uint32_t flags:8; /* currently only one bit is used for dscp copy */
+	uint32_t stats_ptr:24;
+}__attribute__ ((packed));
+
+
+struct en_ehash_portinfo
+{
+	uint32_t reserved[3]; /* This overlaps with statistics info en_ehash_ifstats, it is not to be used.  */
+	uint32_t port_info; /* LSbit is port status 0 => port down 1 => port up */
+}__attribute__ ((packed));
+
+
+struct en_ehash_ifportinfo
+{
+	struct en_ehash_portinfo rxpinfo;
+	struct en_ehash_portinfo txpinfo;
+}__attribute__ ((packed));
+
+//basic statistics structure
+struct en_ehash_stats
+{
+	uint64_t bytes;
+	uint32_t pkts;
+	uint32_t reserved; /* This 32 bit field overlaps struct en_ehash_portinfo, so it is not to be used */
+}__attribute__ ((packed));
+
+struct en_ehash_stats_with_ts {
+	uint64_t bytes;
+	uint32_t pkts;
+	uint32_t pad;
+	uint64_t timestamp;
+}__attribute__ ((packed));
+
+//statistics structure
+struct en_ehash_ifstats {
+	struct en_ehash_stats rxstats;
+	struct en_ehash_stats txstats;
+}__attribute__ ((packed));
+
+#define STATS_WITH_TS	(1 << 7)
+//statistics structure with timestamp
+struct en_ehash_ifstats_with_ts {
+	struct en_ehash_stats_with_ts rxstats;
+	struct en_ehash_stats_with_ts txstats;
+}__attribute__ ((packed));
+
+//statistics table structure
+struct en_ehash_stats_tbl {
+	uint32_t table_indicator:1;	//set for table indication, valid in the first entry only
+	uint32_t num_entries:7;		//number of entries in table, valid in the first entry only
+	uint32_t stats_ptr:24;		//muRam address of en_ehash_stats member
+}__attribute__ ((packed));
+
+//NATPT structures
+struct en_ehash_natpt_hdr {
+	union {
+		struct {
+			uint32_t reserved:6;
+			uint32_t tcu:1; //traffic class update
+			uint32_t hlu:1; //hop limit update
+			uint32_t hdrlen:8; //length of header
+			uint32_t reserved1:16;
+		}ip4to6;
+		struct {
+			uint16_t reserved:5;
+			uint16_t ipu:1; //ipidentifier update
+			uint16_t tou:1; //tos update
+			uint16_t tlu:1; //ttl update
+			uint16_t hdrlen:8; //length of header
+			uint16_t ipident; //flow based ipidentifier
+		}ip6to4;
+		uint32_t word;
+	};
+        uint8_t l3hdr[0];               //l3 hdr padded to next 4 bytes boundary
+}__attribute__ ((packed));
+
+//4 to 6 
+#define NATPT_TCU	(1 << 25)
+#define NATPT_HLU	(1 << 24)
+//6 to 4 
+#define NATPT_IPU	(1 << 26)
+#define NATPT_TOU	(1 << 25)
+#define NATPT_TLU	(1 << 24)
+
+
+//types for miss_action_type
+#define EN_EHASH_MISS_ACTION_DROP       3
+#define EN_EHASH_MISS_ACTION_NIA        1
+#define EN_EHASH_MISS_ACTION_ENQUE      2
+#define EN_EHASH_MISS_ACTION_DONE       0
+//AD for this table, defines assuming a LE GPP core
+
+/* Following structure is used to update SEC failure stats in ucode */
+typedef struct en_SEC_failure_stats_s
+{
+	uint32_t icv_failures; /* incremented when a ucode receives ICV failure*/
+	uint32_t hw_errs; /* when SEC returns hw errors */
+	uint32_t CCM_AAD_size_errs;  /* When SEC recturns CCM AAD size error, increment it */
+	uint32_t anti_replay_late_errs; /* when SEC returns ANTI REPLAY LATE errors */
+	uint32_t anti_replay_replay_errs; /* when SEC returns ANTI REPLAY REPLAY errors */
+	uint32_t seq_num_overflows; /* when SEC returns SEQ NUM OVERFLOW errors */
+	uint32_t DMA_errs; /* when SEC returns DMA errors */
+	uint32_t DECO_watchdog_timer_timedout_errs; /* when DECO watchdog timer timedout */
+	uint32_t input_frame_read_errs; /*when SEC returns input frame read errors */
+	uint32_t protocol_format_errs; /* when SEC returns protocol format errors */
+	uint32_t ipsec_ttl_zero_errs; /* when SEC returns IPSEC TTL or hop limit either came in as 0 or decremented to 0 */
+	uint32_t ipsec_pad_chk_failures; /* when SEC returns IPSEC padding check error found */
+	uint32_t output_frame_length_rollover_errs; /* when SEC returns output frame length rollover */
+	uint32_t tbl_buff_too_small_errs;/* when SEC returns table buffer too small */
+	uint32_t tbl_buff_pool_depletion_errs; /* when SEC returns table buffer pool depletions */
+	uint32_t output_frame_too_large_errs; /* when SEC returns output frame too large */
+	uint32_t cmpnd_frame_write_errs; /* when SEC returns compound frame write errors */
+	uint32_t buff_too_small_errs; /* when SEC returns buffer too small errors */
+	uint32_t buff_pool_depletion_errs; /* when SEC returns buffer pool depeletion errors */
+	uint32_t output_frame_write_errs; /* when SEC returns output frame write errors */
+	uint32_t cmpnd_frame_read_errs; /* when SEC returns compound frame read errors */
+	uint32_t prehdr_read_errs; /* when SEC returns when preheader read errors */
+	uint32_t other_errs; /* when SEC returns errors other than above */
+} __attribute__ ((packed)) en_SEC_failure_stats;
+
+#define	MAX_VLAN_PCP	7
+/*
+* DSCP to VLAN PCP mapping structure. Each array element value is pcp
+* mapped to the DSCP. DSCP 64 values divided into 8 groups.  0-7, 8-15, ..
+* Each DSCP group mapped to one vlan pcp value.
+*/
+typedef struct en_dscp_vlanpcp_map_cfg_s
+{
+	uint8_t		dscp_vlanpcp[MAX_VLAN_PCP + 1];
+} __attribute__ ((packed)) en_dscp_vlanpcp_map_cfg;
+/*this structure is used to maintain a kind of global stats or 
+  global info maintained between ucode and CP */
+/* currently using for SEC failure statistics and dscp vlanpcp mapping , can be extended further based
+  on requirement */
+typedef struct en_exthash_global_mem_s
+{
+	en_dscp_vlanpcp_map_cfg	dscp_vlanpcp_map;
+	en_SEC_failure_stats	SEC_failure_stats;
+} __attribute__ ((packed)) en_exthash_global_mem;
+
+int32_t ExternalHashGetSECfailureStats(en_SEC_failure_stats *stats);
+int32_t ExternalHashResetSECfailureStats(void);
+int32_t ExternalHashSetDscpVlanpcpMapCfg(en_dscp_vlanpcp_map_cfg *map);
+int32_t ExternalHashGetDscpVlanpcpMapCfg(en_dscp_vlanpcp_map_cfg *map);
+
+#ifdef EXCLUDE_FMAN_IPR_OFFLOAD 
+struct en_exthash_node {
+	union {
+		struct {
+			uint32_t table_base_hi:16;	//upper addr of 40 bit table phys addr
+			uint32_t hash_bytes_offset:2;	//bytes of FMAN hash result to use
+			uint32_t reserved_1:6;
+			uint32_t key_size:6;		//size in bytes of key
+			uint32_t miss_action_type:2;	//miss action
+		}__attribute__ ((packed));
+		uint32_t word_0;
+	}__attribute__ ((packed));
+	uint32_t table_base_lo;		//lower addr of 40 bit table phys addr
+	union {
+		struct {
+			uint32_t global_mem_offset:12; /* Global memory space of structure en_exthash_global_mem
+				is located in MURAM  at int_buf_pool_addr + (global_mem_offset *256)*/
+			uint32_t hash_mask_bits:4; /* hash mask bits will be saved to table descriptor*/
+					/* to get the hash mask value , ucode should do (1 << hash_mask_bits) -1 ,
+						assumption is table is always power of 2 and 
+						hash mask bits value will not exceed 15 (0xf)*/
+			uint32_t int_buf_pool_addr:16; /* actual address is * 256 , value compressed from 3 bytes to 2 bytes*/
+		}__attribute__ ((packed));;
+		uint32_t word_1;
+	}__attribute__ ((packed));
+	union {
+		union {
+			uint32_t nia;		//nia  to use if type is EN_EHASH_MISS_ACTION_NIA
+			uint32_t fqid;		//fqid to use if type is EN_EHASH_MISS_ACTION_ENQUE
+		}__attribute__ ((packed));
+		uint32_t word_2;
+	}__attribute__ ((packed));
+}__attribute__ ((packed));
+#else
+//table type
+#define REASSEMBLY_TABLE                (1 << 3)
+#define L4_TABLE                        (1 << 2)
+#define L3_TABLE                        (1 << 1)
+#define L2_TABLE                        (1 << 0)
+struct en_exthash_node {
+	union {
+		struct {
+			uint32_t table_base_hi:8;       //upper addr of 40 bit table phys addr
+			uint32_t ipv4_ad_offset:8;      //ipv4 ad offset in this tree
+			uint32_t hash_bytes_offset:3;   //offset in hash value
+			uint32_t reserved:1;
+			uint32_t table_type:4;
+			uint32_t key_size:6;            //size in bytes of key
+			uint32_t miss_action_type:2;    //miss action
+		}__attribute__ ((packed));
+		uint32_t word_0;
+	}__attribute__ ((packed));
+	uint32_t table_base_lo;         //lower addr of 40 bit table phys addr
+	union {
+		struct {
+			uint32_t hash_mask_bits:4; /* hash mask bits will be saved to table descriptor*/
+			/* to get the hash mask value , ucode should do (1 << hash_mask_bits) -1 ,
+			   assumption is table is always power of 2 and 
+			   hash mask bits value will not exceed 15 (0xf)*/
+			uint32_t global_mem_offset:12; /* Global memory space of structure en_exthash_global_mem
+											  is located in MURAM  at int_buf_pool_addr + global_mem_offset */
+			uint32_t int_buf_pool_addr:16;
+		}__attribute__ ((packed));;
+		uint32_t word_1;
+	}__attribute__ ((packed));
+	union {
+		uint32_t nia;   //nia if type is EN_EHASH_MISS_ACTION_NIA
+		uint32_t fqid;  //fqid if type  EN_EHASH_MISS_ACTION_ENQUE
+		uint32_t reassm_param;//pointer to reassembly parameters in muram, for ipv4/v6 reassembly tables
+		uint32_t word_2;
+	}__attribute__ ((packed));
+}__attribute__ ((packed));
+
+//ipv4/6 reassembly statistics
+struct ip_reassembly_stats {
+	uint64_t num_frag_pkts;
+	uint64_t num_reassemblies;
+	uint64_t num_completed_reassly;
+	uint64_t num_sess_matches;
+	uint64_t num_frags_too_small;
+	uint64_t num_reassm_timeouts;
+	uint64_t num_overlapping_frags;
+	uint64_t num_too_many_frags;
+	uint64_t num_failed_bufallocs;
+	uint64_t num_failed_ctxallocs;
+	uint64_t num_fatal_errors;
+	uint64_t num_failed_ctxdeallocs;
+	uint32_t reassm_count;
+	uint32_t pad;
+}__attribute__ ((packed));
+
+
+#define IPR_MAX_SESSIONS        256
+#define IPR_MAX_SESSSIZE        256
+#define IPR_CTX_ALIGN           256
+#define UCODE_MAX_TASKS         128
+#define TASK_PRIV_MEMSIZE       32
+#define IPR_CONTEXT_EOL         0xffffffff
+struct ipr_context_info {
+	uint8_t context_data[IPR_MAX_SESSIONS][IPR_MAX_SESSSIZE];
+	uint8_t task_priv_data[UCODE_MAX_TASKS][TASK_PRIV_MEMSIZE];
+	uint32_t next_free_ctx;
+}__attribute__ ((packed));
+
+#define MAX_REASSM_BUCKETS              (1 << 4)
+//ipv4/6 reassembly info
+struct ip_reassembly_params {
+	uint32_t table_base_hi;         //reassembly table base
+	uint32_t table_base_lo;
+	struct ip_reassembly_stats stats; //stats
+	uint32_t table_mask;            //hash mask
+	uint32_t type;                  //type of table
+	uint32_t ipr_timer;             //ipr timer location
+	uint32_t timeout_val;           //reassembly timeout
+	uint32_t timeout_fqid;          //fqid for timeout fragments
+	uint32_t min_frag_size;         //min frag size other than last
+	uint32_t reassem_bpid;          //buffer pool for re-assembly context
+	uint32_t reassem_bsize;         //size of buffers in reassem_context
+	uint32_t frag_bpid;             //buffer pool for re-assembly fragments
+	uint32_t frag_bsize;            //size of buffers in reassem_bpid
+	uint32_t reassly_dbg;           //debug area
+	uint32_t context_info;          //context info structute ptr in muram
+	uint32_t curr_sessions;         //curr reassembly sessions
+	uint32_t txc_fqid;              //fqid for handling SG buffers
+	uint32_t timer_tnum;            //timer task number
+	uint32_t max_frags;             //max allowed frags per session
+	uint32_t max_con_reassm;        //max concurrent reassemblies
+	uint32_t bucket_base;           //base of bucket
+	uint32_t bucket_lock[MAX_REASSM_BUCKETS];//locks for hash buckets, should be the last member
+	uint32_t bucket_head[MAX_REASSM_BUCKETS];//head pointers of collision list
+}__attribute__ ((packed));
+
+//ipv4/v6 config and stats info required by cmm
+struct ip_reassembly_info {
+	u_int64_t num_frag_pkts;
+	u_int64_t num_reassemblies;
+	u_int64_t num_completed_reassly;
+	u_int64_t num_sess_matches;
+	u_int64_t num_frags_too_small;
+	u_int64_t num_reassm_timeouts;
+	u_int64_t num_overlapping_frags;
+	u_int64_t num_too_many_frags;
+	u_int64_t num_failed_bufallocs;
+	u_int64_t num_failed_ctxallocs;
+	u_int64_t num_fatal_errors;
+	u_int64_t num_failed_ctxdeallocs;
+	uint32_t table_mask;            //hash mask
+	uint32_t ipr_timer;             //ipr timer location
+	uint32_t timeout_val;           //reassembly timeout
+	uint32_t timeout_fqid;          //fqid for timeout fragments
+	uint32_t max_frags;             //max allowed sessions per session
+	uint32_t min_frag_size;         //min frag size other than last
+	uint32_t max_con_reassm;        //max concurrent reassemblies
+	uint32_t reassem_bpid;          //buffer pool for re-assembly context
+	uint32_t reassem_bsize;         //size of buffers in reassem_context
+	uint32_t frag_bpid;             //buffer pool for re-assembly fragments
+	uint32_t frag_bsize;            //size of buffers in reassem_bpid
+	uint32_t timer_tnum;            //timer task number
+	uint32_t reassly_dbg;           //debug area
+	uint32_t curr_sessions;         //curr reassembly sessions
+	uint32_t txc_fqid;              //fqid for handling SG buffers
+};
+#endif
+
+#define EN_INTERNAL_BUFF_POOL_SIZE (256*128)
+#define EN_EXTHASH_TBL_ALIGNMENT	256
+#define TIMESTAMP_EN	(1 << 0)
+#define STATS_EN	(1 << 1)
+struct en_exthash_info {
+	uint32_t flags;
+	void *table_base;	//base of table in DDR
+	void **pSpinlock;	//array of spin locks for each bucket
+	void *h_Ad;		//handle to muRam holding AD
+	struct en_exthash_node node; //ccnode
+	uint32_t tablesize;	//number of bytes allocated for hash table
+	uint32_t hashmask;	//mask to be used on hash value to get to bucket
+	uint32_t keysize;	//size of key in bytes
+	uint32_t hashshift;	//number of bytes to shift the fman hash result
+	uint32_t dataMemId;	//memory partition id
+	uint32_t dataLiodnOffset; //LIODN offsdet for access to ext hash table
+	uint32_t num_keys; 	// number of keys in the table currently
+	uint32_t max_collisions;//max collisions in the table that occured anytime upto now.
+	void *pcd;		//pcd handle
+#ifndef EXCLUDE_FMAN_IPR_OFFLOAD
+	uint32_t type;		//table type
+	struct ip_reassembly_params *ip_reassem_info; //muram area,used in case of reassembly tables only 
+#endif
+};
+
+struct en_exthash_tbl_entry {
+	struct en_ehash_entry hashentry;
+	struct en_exthash_tbl_entry *prev;
+	struct en_exthash_tbl_entry *next;
+	uint8_t	*replicate_params;
+	union{
+		uint8_t *enqueue_params;
+		uint8_t *ipsec_preempt_params;
+	};
+};
+
+struct en_exthash_bucket{
+	uint64_t h;
+	uint64_t pad;
+};
+
+static inline void display_mcast_member_tbl_entry(struct en_ehash_entry *entry);
+static inline void display_tbl_ad(void *h_Ad)
+{
+	uint8_t *ptr;
+	uint32_t ii;
+
+	ptr = (uint8_t *)h_Ad;
+	for (ii = 0; ii < sizeof(struct en_exthash_node); ii++) 
+		printk("%02x ", *(ptr + ii));
+	printk("\n");
+}
+
+static inline void display_ehashtbl_info(void *handle, char *func)
+{
+	struct en_exthash_info *info;
+	
+	info = (struct en_exthash_info *)handle;
+	printk("%s::en_ehash info %p\n", func, info);
+	printk("flags\t%08x\n", info->flags);
+	printk("table_base\t%p\n", info->table_base);
+	printk("hash mask\t%x\n", info->hashmask);
+	printk("key size\t%d\n", info->keysize);
+	printk("hash shift\t%d\n", info->hashshift);
+	printk("table size\t%d\n", info->tablesize);
+	printk("datamemId\t%d\n", info->dataMemId);
+	printk("dataLiodnOffset\t%d\n", info->dataLiodnOffset);
+	printk("num keys\t%d\n", info->num_keys);
+	printk("max collisions \t%d\n", info->max_collisions);
+	printk("Ad handle\t%p\n", info->h_Ad);
+	display_tbl_ad(info->h_Ad);
+}
+
+static inline void disp_buf(void *buf, uint32_t size)
+{
+        uint8_t *ptr;
+	uint32_t ii,jj=0;
+	uint8_t buff[200];
+
+        ptr = buf;
+        for (ii = 0; ii < size; ii++) {
+                
+		if (ii && (ii % 16 == 0))
+		{
+			buff[jj] = 0;
+			printk("%s\n",buff);
+			jj = 0;
+		}
+		jj += sprintf(buff+jj, "%02x ", *ptr);
+                ptr++;
+        }
+	buff[jj] = 0;
+	printk("%s\n", buff);
+}
+
+
+static inline void *display_l2hdr_insert_opc(void *ptr)
+{
+	struct en_ehash_insert_l2_hdr *l2hdrins;
+	struct en_ehash_insert_l2_hdr_stats *stats;
+	uint32_t size;
+	uint32_t word;
+	uint32_t len;
+	uint32_t padding;
+
+	printk("opcode : INSERT_L2_HDR\n");
+	l2hdrins = (struct en_ehash_insert_l2_hdr *)ptr;
+	word = cpu_to_be32(l2hdrins->word);
+	len = (word & 0xff);
+	padding = ((word >> 29) & 3);
+	if (word & (1 << 31))
+		printk("Replace hdr, size %d\n", len);
+	else
+		printk("insert hdr, size %d\n", len);
+        disp_buf(&l2hdrins->l2hdr[0], len);
+	printk("stats count %d\n", l2hdrins->stats_count);
+	size = (sizeof(struct en_ehash_insert_l2_hdr) + len + padding);
+	//stats count
+	len = ((word >> 16) & 0xff);
+	if (len) {
+		size += sizeof(struct en_ehash_insert_l2_hdr_stats);
+		stats = (struct en_ehash_insert_l2_hdr_stats *)((uint8_t *)ptr + size);
+		word = cpu_to_be32(stats->word);
+		padding = (word >> 30);
+		//get stats pointer
+		word &= 0xffffffff;
+		if (len == 1) {
+			printk("stats pointer %x\n", word);
+		} else {
+			uint32_t ii;
+			for (ii = 0; ii < len; ii++) {
+				printk("offset %d stats ptr %lx\n", 
+					stats->stats_offsets[ii], 
+				  	(word + stats->stats_offsets[ii] * 
+						sizeof(struct en_ehash_stats)));	
+			}
+		}
+		size += padding;
+	}
+	return ((uint8_t *)ptr + size);
+}
+
+static inline void *display_enqparams_opc(void *ptr)
+{
+	struct en_ehash_enqueue_param *param;
+
+	printk("opcode : ENQUEUE_PKT\n");
+	param = (struct en_ehash_enqueue_param *)ptr;
+	printk("mtu\t%d\n", cpu_to_be16(param->mtu));
+	//printk("bpid\t%d\n", cpu_to_be16(param->bpid));
+	printk("bpid\t%d\n", param->bpid);
+	printk("fqid\t%d(0x%x)\n", 
+		cpu_to_be32(param->fqid),
+		cpu_to_be32(param->fqid));
+	printk("stats_ptr\t%x\n", cpu_to_be32(param->stats_ptr));
+	return ((uint8_t *)ptr + sizeof(struct en_ehash_enqueue_param));
+}
+
+static inline void *display_preemptchkipsecparams_opc(void *ptr)
+{
+	struct en_ehash_ipsec_preempt_op *param;
+	int i;
+
+	printk("opcode : PREEMPTIVE_CHECKS_ON_IPSEC_PKT\n");
+	param = (struct en_ehash_ipsec_preempt_op *)ptr;
+	printk(" Opcode Flags \t%x\n", param->op_flags);
+	printk("NATT Mask\t%x\n", param->natt_arr_mask);
+	printk("PPPoE session\t%d\n", param->pppoe_session_id);
+	for (i = 0; i < MAX_SPI_PER_FLOW; i++)
+	{
+		printk("%d:SPI :\t%x - FQID :\t%x\n", i, param->spi_param[i].spi,  param->spi_param[i].fqid);
+		
+	}
+		
+	return ((uint8_t *)ptr + sizeof(struct en_ehash_ipsec_preempt_op));
+}
+
+static inline void *display_preemptchkparams_opc(void *ptr)
+{
+        struct en_ehash_preempt_op *param;
+
+        printk("opcode : PREEMPTIVE_CHECKS_ON_PKT\n");
+        param = (struct en_ehash_preempt_op *)ptr;
+        printk("mtu offset\t%d\n", param->mtu_offset);
+        printk("OP Mask\t%d\n", param->OpMask);
+        printk("DSCP Match value\t%d\n", param->dscp_match_value);
+        printk("Policer profile number \t%d(0x%x)\n",
+                param->pp_no,param->pp_no);
+        return ((uint8_t *)ptr + sizeof(struct en_ehash_preempt_op));
+}
+
+
+static inline void *display_pppoe_relay_opc(void *ptr)
+{
+  struct en_ehash_replace_pppoe_hdr_params *param;
+
+  printk("opcode : REPLACE_PPPOE_HDR\n");
+  param = (struct en_ehash_replace_pppoe_hdr_params *)ptr;
+  printk("\nDestination Mac:");
+  disp_buf(ptr, 6);
+  printk("\nSource Mac:");
+  disp_buf(ptr+6,6);
+  printk("\nsession id:%d",cpu_to_be16(param->session_id));
+  printk("\r\n");
+  //printk("stats_ptr\t%x\n", cpu_to_be32(param->stats_ptr));
+  return ((uint8_t *)ptr + sizeof(struct en_ehash_replace_pppoe_hdr_params));
+}
+
+static inline void *display_dscp(void *ptr)
+{
+	struct en_ehash_update_dscp *param = (struct en_ehash_update_dscp *)ptr;
+	uint32_t word;
+
+	word = cpu_to_be32(param->dscp);
+	if(word & 2) {
+		printk("dscp_mark flag\n");
+		printk("dscp_mark %x size %lu\n", (word >> 2),sizeof(struct en_ehash_update_dscp));
+	}
+	else
+		printk("NO DSCP marking for this FLOW\n");
+
+	return (param + 1);
+}
+
+static inline void *display_ttlupdate_opc(void *ptr)
+{
+	printk("opcode : UPDATE_TTL\n");
+	return display_dscp(ptr);
+}
+
+static inline void *display_hoplupdate_opc(void *ptr)
+{
+	printk("opcode : UPDATE_HOPLIMIT\n");
+	return display_dscp(ptr);
+}
+
+static inline void *display_replicate_opc(void *ptr)
+{
+	struct en_ehash_replicate_param *param = (struct en_ehash_replicate_param *)ptr;
+	struct en_exthash_tbl_entry *tbl_entry;
+	int ii = 0;
+	uint64_t phyaddr;
+
+	printk("opcode : REPLICATE_PKT\n");
+	printk("Group table entry addr HI : 0x%04x, LO : 0x%08x\n", 
+		param->first_member_flow_addr_hi, param->first_member_flow_addr_lo);
+	phyaddr = be16_to_cpu(param->first_member_flow_addr_hi);
+	phyaddr = (phyaddr << 32);
+	phyaddr |= be32_to_cpu(param->first_member_flow_addr_lo);
+	while(1)//	for (ii=0; ii< be16_to_cpu(param->num_mcast_members); ii++)
+	{
+		printk("mcast member(%d) info:\n",ii);
+		//tbl_entry = (struct en_exthash_tbl_entry *)XX_PhysToVirt(phyaddr);
+		tbl_entry = (struct en_exthash_tbl_entry *)phys_to_virt(phyaddr);
+		display_mcast_member_tbl_entry(&tbl_entry->hashentry);
+		phyaddr =  be16_to_cpu(tbl_entry->hashentry.next_entry_hi);
+		phyaddr = phyaddr << 32;
+		phyaddr |=  be32_to_cpu(tbl_entry->hashentry.next_entry_lo);
+		ii++;
+		if (!phyaddr)	
+			break;
+	}
+	printk("no. of mcast members : %d\n", ii);
+	return (param + 1);
+}
+
+static inline void *display_strip_eth_hdr_opc(void *ptr)
+{
+	printk("opcode : STRIP_ETH_HDR\n");
+	return ptr;
+}
+
+static inline void *display_update_eth_rx_stats_opc(void *ptr)
+{
+	struct en_ehash_update_ether_rx_stats *param;
+
+	param = (struct en_ehash_update_ether_rx_stats *)ptr;
+	printk("opcode : UPDATE_ETH_RX_STATS\n");
+	printk("interface stats pointer %08x\n",
+			cpu_to_be32(param->stats_ptr));
+	return (param + 1);
+}
+
+static inline void *display_strip_allvlan_hdr_opc(void *ptr)
+{
+	struct en_ehash_strip_all_vlan_hdrs *param;
+	uint32_t size;
+	uint32_t word;
+	uint32_t padding;
+	uint32_t num_entries;
+	uint32_t stats_ptr;
+
+	param = (struct en_ehash_strip_all_vlan_hdrs *)ptr;
+	printk("opcode : STRIP_ALL_VLAN_HDRS\n");
+	printk(" Opcode Flags \t%x\n", param->op_flags);
+	printk("VLAN Match 1\t%d\n", param->vlan_id[0]);
+	printk("VLAN Match 2\t%d\n", param->vlan_id[1]);
+	size = sizeof(struct en_ehash_strip_all_vlan_hdrs);
+	word = cpu_to_be32(param->word);
+	padding = (word >> 30);
+	stats_ptr = (word & 0xffffff);
+	num_entries = ((word >> 24) & 0x3f);
+	printk("num entries %d, padding %d\n", num_entries, padding);
+	if (stats_ptr) {
+		if (num_entries > 1) {
+			uint32_t ii;
+			size += (num_entries + padding);
+			for (ii = 0; ii < num_entries; ii++) {
+				printk("offset %d, statsptr %lx\n",
+					param->stats_offsets[ii],	
+					(stats_ptr + 
+					(param->stats_offsets[ii] * sizeof(struct en_ehash_stats))));
+			} 
+		} else {
+			printk("stats ptr %x\n", stats_ptr);
+		}
+	}
+	return ((uint8_t *)ptr + size);
+}
+
+static inline void *display_strip_pppoe_hdr_opc(void *ptr)
+{
+	struct en_ehash_strip_pppoe_hdr *param;
+
+	param = (struct en_ehash_strip_pppoe_hdr *)ptr;
+	printk("opcode : STRIP_PPPoE_HDR\n");
+	printk("stats ptr %08x\n", cpu_to_be32(param->stats_ptr));
+	return (param + 1);
+}
+
+static inline void *display_strip_l2_hdr_opc(void *ptr)
+{
+	struct en_ehash_strip_l2_hdrs *param;
+	uint32_t size;
+	uint32_t word;
+	uint32_t padding;
+	uint32_t num_entries;
+	uint32_t stats_ptr;
+
+	param = (struct en_ehash_strip_l2_hdrs *)ptr;
+	printk("opcode : STRIP_L2_HDR\n");
+	printk("VLAN Match 1\t%d\n", param->vlan_id[0]);
+	printk("VLAN Match 2\t%d\n", param->vlan_id[1]);
+	size = sizeof(struct en_ehash_strip_l2_hdrs);
+	word = cpu_to_be32(param->word);
+	padding = (word >> 30);
+	stats_ptr = (word & 0xffffff);
+	num_entries = ((word >> 24) & 0x3f);
+	printk("num entries %d, padding %d\n", num_entries, padding);
+	if (stats_ptr) {
+		if (num_entries >= 1) {
+			uint32_t ii;
+			size += (num_entries + padding);
+			for (ii = 0; ii < num_entries; ii++) {
+				printk("offset %d, statsptr %lx\n",
+						param->stats_offsets[ii],
+						(stats_ptr +
+						 (param->stats_offsets[ii] * sizeof(struct en_ehash_stats))));
+			}
+		} else {
+			printk("stats ptr %x\n", stats_ptr);
+		}
+	}
+	return ((uint8_t *)ptr + size);
+}
+
+
+static inline void *display_strip_firstvlan_opc(void *ptr)
+{
+	struct en_ehash_strip_first_vlan_hdr *param;
+
+	param = (struct en_ehash_strip_first_vlan_hdr *)ptr;
+	printk("opcode : STRIP_FIRST_VLAN_HDR\n");
+	printk("interface stats pointer %08x\n",
+			param->stats_ptr);
+	printk("VLAN Match \t%d\n", param->vlan_id);
+	return (param + 1);
+}
+
+static inline void *display_strip_first_iphdr(void *ptr)
+{
+	
+	struct en_ehash_remove_first_ip_hdr *param;
+
+	param = (struct en_ehash_remove_first_ip_hdr *)ptr;
+	printk("opcode : REMOVE_FIRST_IP_HDR\n");
+	printk("stats ptr %x\n", cpu_to_be32(param->stats_ptr));
+	printk("dscp prpagation from outer to inner%d\n",cpu_to_be32((param->flags >> 24) & 1));
+	return (param + 1);
+}
+
+static inline void *display_validate_ipsecid_opc(void *ptr)
+{
+	printk("opcode : VALIDATE_IPSEC_ID\n");
+	return ptr;
+}
+
+static inline void *display_update_nat_ipv4_opc(void *ptr, uint32_t opcode)
+{
+	struct en_ehash_update_ipv4_ip *param;
+
+	printk("opcode : %02x\n", opcode);
+	param = (struct en_ehash_update_ipv4_ip *)ptr;
+	if ((opcode & UPDATE_TTL) == UPDATE_TTL)
+		printk("update TTL\n");
+	if ((opcode & UPDATE_SIP_V4) == UPDATE_SIP_V4) {
+		printk("update SIP V4 - SIP::%08x\n", htonl(param->ip_v4));
+		param++;
+	}
+	if ((opcode & UPDATE_DIP_V4) == UPDATE_DIP_V4) {
+		printk("update DIP V4 - DIP::%08x\n", htonl(param->ip_v4));
+		param++;
+	}
+	return param;
+}
+
+static inline void *display_update_nat_ipv6_opc(void *ptr, uint32_t opcode)
+{
+	struct en_ehash_update_ipv6_ip *param;
+
+	printk("opcode : %02x\n", opcode);
+	param = (struct en_ehash_update_ipv6_ip *)ptr;
+	if ((opcode & UPDATE_HOPLIMIT) == UPDATE_HOPLIMIT)
+		printk("update UPDATE_HOPLIMIT\n");
+	if ((opcode & UPDATE_SIP_V6) == UPDATE_SIP_V6) {
+		printk("update SIP V6 - SIP::%pI6c", param->ip_v6);
+		param++;
+	}
+	if ((opcode & UPDATE_DIP_V6) == UPDATE_DIP_V6) {
+		printk("update DIP V6 - DIP::%pI6c", param->ip_v6);
+		param++;
+	}
+	return param;
+}
+
+static inline void *display_update_nat_port_opc(void *ptr, uint32_t opcode)
+{
+	struct en_ehash_update_port *param;
+	
+	printk("opcode : %02x\n", opcode);
+	param = (struct en_ehash_update_port *)ptr;
+	if ((opcode & UPDATE_SPORT) == UPDATE_SPORT) {
+		printk("update SPORT - SPORT::%d\n", htons(param->sport));
+	}
+	if ((opcode & UPDATE_DPORT) == UPDATE_DPORT) {
+		printk("update DPORT - DPORT::%d\n", htons(param->dport));
+	}
+	param++;
+	return param;
+}
+
+static inline void *display_vlanhdr_insert_opc(void *ptr)
+{
+	uint32_t ii;
+	uint32_t stats_addr;
+	struct en_ehash_insert_vlan_hdr *param;
+	struct en_ehash_insert_vlan_hdr_stats *vlan_stats;
+	uint32_t *vlanhdr;
+	uint32_t num_hdrs;
+	uint32_t padding;
+	uint32_t size;
+
+	printk("opcode : INSERT_VLAN_HDR\n");
+	param = (struct en_ehash_insert_vlan_hdr *)ptr;
+	ii = cpu_to_be32(param->word);
+	num_hdrs = ((ii >> 24) & 0x3f);
+	stats_addr = (ii & 0xffffff);
+	printk("num headers %d stats ptr %x\n", 
+		num_hdrs, stats_addr);
+	padding = (ii >> 30);
+	vlanhdr = &param->vlanhdr[0];
+	for (ii = 0; ii < num_hdrs; ii++) {
+		disp_buf(vlanhdr, sizeof(uint32_t));	
+		printk("vlan hdr %08x\n", htonl(*vlanhdr));
+		vlanhdr++;
+	}
+	size = (sizeof(struct en_ehash_insert_vlan_hdr) + 
+		(num_hdrs * sizeof(uint32_t))); 
+	if (stats_addr) {
+		vlan_stats = (struct en_ehash_insert_vlan_hdr_stats *)vlanhdr;
+		if (num_hdrs == 1)
+			printk("stats ptr %x\n", stats_addr);
+		else {
+			for (ii = 0; ii < num_hdrs; ii++) 
+				printk ("stats offset %d:: %lx\n", 
+					vlan_stats->stats_offsets[ii],
+				  	(stats_addr + (vlan_stats->stats_offsets[ii] * 
+						sizeof(struct en_ehash_stats))));
+			size += (padding + num_hdrs);	
+		}
+	}
+	return(ptr + size);
+}
+
+static inline void *display_pppoehdr_insert_opc(void *ptr)
+{
+	uint32_t size;
+	struct en_ehash_insert_pppoe_hdr *param;
+
+	printk("opcode : INSERT_PPPoE_HDR\n");
+	param = (struct en_ehash_insert_pppoe_hdr *)ptr;
+	printk("version %d, type %d, code %d\n\n",
+			param->version,
+			param->type,
+			param->code);
+	printk("session id %d\n", param->session_id);
+	printk("stats ptr %x\n", param->stats_ptr);
+	size = sizeof(struct en_ehash_insert_pppoe_hdr);
+	return ((uint8_t *)ptr + ALIGN(size, sizeof(uint32_t)));
+}
+
+static inline void *display_l3hdr_insert_opc(void *ptr)
+{
+	struct en_ehash_insert_l3_hdr *param;
+	uint32_t word;
+
+	printk("opcode : INSERT_L3_HDR - ");
+	param = (struct en_ehash_insert_l3_hdr *)ptr;
+	word = cpu_to_be32(param->word);
+	switch ((word >> 24) & 3) {
+
+		case TYPE_4o6:
+			printk("TYPE_4o6\n");
+			break;
+		case TYPE_6o4:
+			printk("TYPE_6o4\n");
+			break;
+		default:
+			printk("TYPE_CUSTOM\n");
+			break;
+	}
+	printk("hdr len %d\n", param->hdr_len);
+	printk("df %d, qos %d, cs %d\n", 
+		((word >> 28) & 1),
+		((word >> 27) & 1),
+		((word >> 29) & 1));
+	printk("stats ptr %x\n", param->stats_ptr);
+	disp_buf(&param->l3hdr[0], param->hdr_len);
+	return ((uint8_t *)ptr + 
+		ALIGN((sizeof(struct en_ehash_insert_l3_hdr) + 
+					param->hdr_len), sizeof(uint32_t)));
+}
+
+static inline void *display_upd_glbl_stats_opc(void *ptr)
+{
+	printk("opcode : UPDATE_GLOBAL_STATS\n");
+	return ptr;
+}
+
+static inline void *display_rtp_opc(void *ptr)
+{
+        struct en_ehash_rtprelay_param   *param;
+        uint32_t  word;
+
+        printk("opcode : PROCESS_RTP_PAYLOAD\n");
+        param = (struct en_ehash_rtprelay_param *)ptr;
+
+        word = be32_to_cpu(param->in_sock_stats_ptr);
+        printk ("In Socket stats ptr: %x \n", word);
+        word = be32_to_cpu(param->out_sock_stats_ptr);
+        printk ("Out Socket stats ptr: %x \n", word);
+        word = be32_to_cpu(param->rtpinfo_ptr);
+        printk("RTP info ptr: %x\n", word);
+        word = be32_to_cpu(param->src_ipv4_val);
+        printk("src ipv4: %x\n", word);
+        word = be32_to_cpu(param->TimeStampIncr);
+        printk("TimestampiIncr :0x%x(%d) \n", word, word);
+        word = be16_to_cpu(param->seq_base);
+        printk("seq_base : %x(%d)\n", word, word);
+        word = be16_to_cpu(param->egress_socketID);
+        printk("egress_socketID : %x(%d)\n", word, word);
+        printk("DTMF_PT[0] %d DTMF_PT[1] %d\n",param->DTMF_PT[0], param->DTMF_PT[1]);
+		word = be16_to_cpu(param->rtp_flags);
+	printk("Send first packet to CP : %s \n", 
+			(word & EEH_RTP_SEND_FIRST_PACKET_TO_CP) ? "TRUE" : "FALSE");
+	printk("Duplicate packet and send to CP: %s \n",
+			(word & EEH_RTP_DUPLICATE_PKT_SEND_TO_CP) ? "TRUE" : "FALSE");
+
+	printk("VLAN P bit learning feature : %s \n",
+		(word & EEH_RTP_ENABLE_VLAN_P_BIT_LEARN) ? "Enabled" : "Disabled");
+        return ((uint8_t*) ptr +(sizeof (struct en_ehash_rtprelay_param)));
+}
+
+static inline void *display_rtcp_opc(void *ptr)
+{
+        struct en_ehash_rtprelay_param   *param;
+        uint32_t  word;
+
+        printk("opcode : PROCESS_RTCP_PAYLOAD\n");
+        param = (struct en_ehash_rtprelay_param *)ptr;
+
+        word = be32_to_cpu(param->in_sock_stats_ptr);
+        printk ("In Socket stats ptr: %x \n", word);
+        word = be32_to_cpu(param->out_sock_stats_ptr);
+        printk ("Out Socket stats ptr: %x \n", word);
+        word = be32_to_cpu(param->rtpinfo_ptr);
+        printk("RTP info ptr: %x\n", word);
+        word = be32_to_cpu(param->src_ipv4_val);
+        printk("src ipv4: %x\n", word);
+		word = be32_to_cpu(param->SSRC_1);
+		printk("SSRC_1	: %x (%d)\n", word, word);
+		word = be16_to_cpu(param->rtp_flags);
+		printk("Send first packet to CP : %s \n", 
+			(word & EEH_RTP_SEND_FIRST_PACKET_TO_CP) ? "TRUE" : "FALSE");
+		printk("Duplicate packet and send to CP: %s \n",
+			(word & EEH_RTP_DUPLICATE_PKT_SEND_TO_CP) ? "TRUE" : "FALSE");
+        return ((uint8_t*) ptr +(sizeof (struct en_ehash_rtprelay_param)));
+}
+
+
+static inline void display_mcast_member_tbl_entry(struct en_ehash_entry *entry)
+{
+	uint8_t *opc_ptr;
+	uint8_t *param_ptr;
+	uint64_t addr;
+	uint32_t ii;
+	uint16_t flags;
+	flags = cpu_to_be16(entry->flags);
+	opc_ptr = ((uint8_t *)entry + GET_OPC_OFFSET(flags));
+	param_ptr = ((uint8_t *)entry + GET_PARAM_OFFSET(flags));
+	addr = ((uint64_t)entry->next_entry_hi << 32);
+	addr |= entry->next_entry_lo;
+	printk("next_entry\t%p\n", (void *)addr);
+	for (ii = 0; ii < MAX_OPCODES; ii++) {
+		printk("opc ptr\t%p\n", opc_ptr);
+		printk("param ptr\t%p\n", param_ptr);
+		switch (*opc_ptr) {
+			case 0:
+				printk("end of opcodelist\n");
+				return;
+			case ENQUEUE_PKT:
+				param_ptr = display_enqparams_opc(param_ptr);	
+				return;
+			case PREEMPTIVE_CHECKS_ON_PKT:
+				param_ptr = display_preemptchkparams_opc(param_ptr);	
+				break;
+			case UPDATE_ETH_RX_STATS:	
+				param_ptr = display_update_eth_rx_stats_opc(param_ptr);	
+				break;
+			case STRIP_ETH_HDR:          
+				param_ptr = display_strip_eth_hdr_opc(param_ptr);
+				break;
+			case STRIP_ALL_VLAN_HDRS:
+				param_ptr = display_strip_allvlan_hdr_opc(param_ptr);
+				break;
+			case STRIP_PPPoE_HDR:
+				param_ptr = display_strip_pppoe_hdr_opc(param_ptr);
+				break;
+			case STRIP_FIRST_VLAN_HDR: 
+				param_ptr = display_strip_firstvlan_opc(param_ptr);
+				break;
+			case STRIP_L2_HDR:
+				param_ptr = display_strip_l2_hdr_opc(param_ptr);
+				break;
+			case REMOVE_FIRST_IP_HDR:
+				param_ptr = display_strip_first_iphdr(param_ptr);
+				break;
+			case VALIDATE_IPSEC_ID:
+				param_ptr = display_validate_ipsecid_opc(param_ptr);
+				break;
+			case UPDATE_TTL:
+				param_ptr = display_ttlupdate_opc(param_ptr);
+				break;
+			case UPDATE_HOPLIMIT:
+				param_ptr = display_hoplupdate_opc(param_ptr);
+				break;
+			case UPDATE_SIP_V4:
+			case (UPDATE_SIP_V4 | UPDATE_TTL):
+			case UPDATE_DIP_V4:
+			case (UPDATE_DIP_V4 | UPDATE_TTL):
+			case (UPDATE_SIP_V4 | UPDATE_DIP_V4):
+			case (UPDATE_SIP_V4 | UPDATE_DIP_V4 | UPDATE_TTL):
+				param_ptr = display_update_nat_ipv4_opc(param_ptr, *opc_ptr);
+				break;
+			case UPDATE_SIP_V6:
+			case (UPDATE_SIP_V6 | UPDATE_HOPLIMIT): 
+			case UPDATE_DIP_V6:
+			case (UPDATE_DIP_V6 | UPDATE_HOPLIMIT):
+			case (UPDATE_SIP_V6 | UPDATE_DIP_V6):
+			case (UPDATE_SIP_V6 | UPDATE_DIP_V6 | UPDATE_HOPLIMIT):
+				param_ptr = display_update_nat_ipv6_opc(param_ptr, *opc_ptr);
+				break;
+			case UPDATE_SPORT:
+			case UPDATE_DPORT:
+			case (UPDATE_SPORT | UPDATE_DPORT):
+				param_ptr = display_update_nat_port_opc(param_ptr, *opc_ptr);
+				break;
+			case INSERT_L2_HDR:
+				param_ptr = display_l2hdr_insert_opc(param_ptr);
+				break;
+			case INSERT_VLAN_HDR:
+				param_ptr = display_vlanhdr_insert_opc(param_ptr);
+				break;
+			case INSERT_PPPoE_HDR:        
+				param_ptr = display_pppoehdr_insert_opc(param_ptr);
+				break;
+			case INSERT_L3_HDR:
+				param_ptr = display_l3hdr_insert_opc(param_ptr);
+				break;
+			case UPDATE_GLOBAL_STATS:
+				param_ptr = display_upd_glbl_stats_opc(param_ptr);
+				break;
+			default:
+				printk("unknown opcode %d\n", *opc_ptr);
+			break;
+
+		}
+		opc_ptr++;
+	}
+}
+
+static inline void *display_natpt_4to6_opc(void *ptr)
+{
+	struct en_ehash_natpt_hdr *param;
+	uint32_t word;
+	uint32_t hdrlen;
+
+	printk("opcode : NATPT_4to6 - ");
+	param = (struct en_ehash_natpt_hdr *)ptr;
+	word = cpu_to_be32(param->word);
+	hdrlen = ((word >> 16) & 0xff);
+	printk("header length %d\n", hdrlen);
+	if (word & NATPT_TCU)
+		printk("update traffic class from ipv4 header\n");
+	else
+		printk("use traffic class from template\n");
+	if (word & NATPT_HLU)
+		printk("update HOP length from ipv4 header TTL\n");
+	else
+		printk("use HOP length from template\n");
+	disp_buf(&param->l3hdr, hdrlen);	
+	return ((uint8_t *)ptr + sizeof(struct en_ehash_natpt_hdr) + 
+			((word >> 16) & 0xff));
+}
+
+static inline void *display_natpt_6to4_opc(void *ptr)
+{
+	uint32_t word;
+	struct en_ehash_natpt_hdr *param;
+	uint32_t hdrlen;
+
+	printk("opcode : NATPT_6to4 - ");
+	param = (struct en_ehash_natpt_hdr *)ptr;
+	word = cpu_to_be32(param->word);
+	printk("ipident %d\n", (word & 0xffff));
+	hdrlen = ((word >> 16) & 0xff);
+	printk("header length %d\n", hdrlen);
+	if (word & NATPT_IPU)
+		printk("use ipident from template\n");
+	else
+		printk("update ipident from flow\n");
+	
+	if (word & NATPT_TOU)
+		printk("update tos from ipv6 header\n");
+	else
+		printk("use tos from template\n");
+
+	if (word & NATPT_TLU)
+		printk("update ttl value from ipv6 header\n");
+	else
+		printk("use ttl value from template\n");
+	disp_buf(&param->l3hdr, hdrlen);	
+	return ((uint8_t *)ptr + sizeof(struct en_ehash_natpt_hdr) + 
+			((word >> 16) & 0xff));
+}
+
+static inline void display_ehash_tbl_entry(struct en_ehash_entry *entry, uint32_t keysize)
+{
+	uint8_t *opc_ptr;
+	uint8_t *param_ptr;
+	uint64_t addr;
+	uint32_t ii;
+	uint16_t flags;
+
+	printk("entry %p\n", entry);
+	disp_buf(entry, MAX_EN_EHASH_EXT_ENTRY_SIZE);
+	flags = cpu_to_be16(entry->flags);
+	opc_ptr = ((uint8_t *)entry + GET_OPC_OFFSET(flags));
+	param_ptr = ((uint8_t *)entry + GET_PARAM_OFFSET(flags));
+	if (GET_TIMESTAMP_ENABLE(flags)) {	
+		printk("external timestamp addr %08x\n",
+			cpu_to_be32(entry->timestamp_counter));
+	} 
+	if (GET_STATS_ENABLE(flags))
+		printk("statistics\tenabled\n");
+	printk("opc offset\t%d\n", GET_OPC_OFFSET(flags));
+	printk("param offset\t%d\n", GET_PARAM_OFFSET(flags));
+	addr = ((uint64_t)entry->next_entry_hi << 32);
+	addr |= entry->next_entry_lo;
+	printk("next_entry\t%p\n", (void *)addr);
+	printk("key :: size %d\n", keysize);
+	disp_buf(&entry->key[0], keysize);
+	for (ii = 0; ii < MAX_OPCODES; ii++) {
+		printk("opc ptr\t%p\n", opc_ptr);
+		printk("param ptr\t%p\n", param_ptr);
+		switch (*opc_ptr) {
+			case 0:
+				printk("end of opcodelist\n");
+				return;
+			case ENQUEUE_ONLY:
+				printk("opcode:ENQUEUE ONLY\n");
+				return;
+			case ENQUEUE_PKT:
+				param_ptr = display_enqparams_opc(param_ptr);	
+				return;
+			case PREEMPTIVE_CHECKS_ON_PKT:
+				param_ptr = display_preemptchkparams_opc(param_ptr);	
+				break;
+			case PREEMPTIVE_CHECKS_ON_IPSEC_PKT:
+				param_ptr = display_preemptchkipsecparams_opc(param_ptr);	
+				break;
+			case REPLICATE_PKT:
+				param_ptr = display_replicate_opc(param_ptr);
+				break;
+			case UPDATE_ETH_RX_STATS:	
+				param_ptr = display_update_eth_rx_stats_opc(param_ptr);	
+				break;
+			case STRIP_ETH_HDR:          
+				param_ptr = display_strip_eth_hdr_opc(param_ptr);
+				break;
+			case STRIP_ALL_VLAN_HDRS:
+				param_ptr = display_strip_allvlan_hdr_opc(param_ptr);
+				break;
+			case STRIP_PPPoE_HDR:
+				param_ptr = display_strip_pppoe_hdr_opc(param_ptr);
+				break;
+			case STRIP_L2_HDR:
+				param_ptr = display_strip_l2_hdr_opc(param_ptr);
+				break;
+			case STRIP_FIRST_VLAN_HDR: 
+				param_ptr = display_strip_firstvlan_opc(param_ptr);
+				break;
+			case REMOVE_FIRST_IP_HDR:
+				param_ptr = display_strip_first_iphdr(param_ptr);
+				break;
+			case VALIDATE_IPSEC_ID:
+				param_ptr = display_validate_ipsecid_opc(param_ptr);
+				break;
+			case UPDATE_TTL:
+				param_ptr = display_ttlupdate_opc(param_ptr);
+				break;
+			case UPDATE_HOPLIMIT:
+				param_ptr = display_hoplupdate_opc(param_ptr);
+				break;
+			case UPDATE_SIP_V4:
+			case (UPDATE_SIP_V4 | UPDATE_TTL):
+			case UPDATE_DIP_V4:
+			case (UPDATE_DIP_V4 | UPDATE_TTL):
+			case (UPDATE_SIP_V4 | UPDATE_DIP_V4):
+			case (UPDATE_SIP_V4 | UPDATE_DIP_V4 | UPDATE_TTL):
+				param_ptr = display_update_nat_ipv4_opc(param_ptr, *opc_ptr);
+				break;
+			case UPDATE_SIP_V6:
+			case (UPDATE_SIP_V6 | UPDATE_HOPLIMIT): 
+			case UPDATE_DIP_V6:
+			case (UPDATE_DIP_V6 | UPDATE_HOPLIMIT):
+			case (UPDATE_SIP_V6 | UPDATE_DIP_V6):
+			case (UPDATE_SIP_V6 | UPDATE_DIP_V6 | UPDATE_HOPLIMIT):
+				param_ptr = display_update_nat_ipv6_opc(param_ptr, *opc_ptr);
+				break;
+			case UPDATE_SPORT:
+			case UPDATE_DPORT:
+			case (UPDATE_SPORT | UPDATE_DPORT):
+				param_ptr = display_update_nat_port_opc(param_ptr, *opc_ptr);
+				break;
+			case INSERT_L2_HDR:
+				param_ptr = display_l2hdr_insert_opc(param_ptr);
+				break;
+			case INSERT_VLAN_HDR:
+				param_ptr = display_vlanhdr_insert_opc(param_ptr);
+				break;
+			case INSERT_PPPoE_HDR:        
+				param_ptr = display_pppoehdr_insert_opc(param_ptr);
+				break;
+			case INSERT_L3_HDR:
+				param_ptr = display_l3hdr_insert_opc(param_ptr);
+				break;
+			case UPDATE_GLOBAL_STATS:
+				param_ptr = display_upd_glbl_stats_opc(param_ptr);
+				break;
+			case NATPT_4to6:
+				param_ptr = display_natpt_4to6_opc(param_ptr);
+				break;
+			case NATPT_6to4:
+				param_ptr = display_natpt_6to4_opc(param_ptr);
+				break;
+			case REPLACE_PPPOE_HDR:
+				param_ptr = display_pppoe_relay_opc(param_ptr);
+				break;
+			case PROCESS_RTP_PAYLOAD:
+				param_ptr = display_rtp_opc(param_ptr);
+				break;
+			case PROCESS_RTCP_PAYLOAD:
+				param_ptr = display_rtcp_opc(param_ptr);
+				break;
+			default:
+				printk("unknown opcode %d\n", *opc_ptr);
+			break;
+
+		}
+		opc_ptr++;
+	}
+}
+
+extern void *ExternalHashTableAllocEntry(void *h_HashTbl);
+extern void ExternalHashTableEntryFree(void *entry);
+extern int ExternalHashTableFmPcdHcSync(void *h_HashTbl);
+
+#endif
diff --git a/drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_ext.h b/drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_ext.h
index fccf32569a7b..004e4dc8909e 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_ext.h
+++ b/drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_ext.h
@@ -182,6 +182,21 @@ typedef _Packed struct t_FmPrsResult {
                                          FM_FD_ERR_LENGTH               | \
                                          FM_FD_ERR_DMA) /**< TX Error FD bits */
 
+#define FM_RFSDM_DEFAULT		(FM_FD_ERR_DMA |\
+					 FM_FD_ERR_PHYSICAL |\
+					 FM_FD_ERR_SIZE |\
+					 FM_FD_ERR_CLS_DISCARD |\
+					 FM_FD_ERR_EXTRACTION |\
+					 FM_FD_ERR_NO_SCHEME |\
+					 FM_FD_ERR_KEYSIZE_OVERFLOW |\
+					 FM_FD_ERR_ILL_PLCR|\
+					 FM_FD_ERR_PRS_TIMEOUT|\
+					 FM_FD_ERR_PLCR_FRAME_LEN|\
+					 FM_FD_ERR_PRS_ILL_INSTRUCT|\
+					 FM_FD_ERR_PRS_HDR_ERR|\
+					 FM_FD_ERR_BLOCK_LIMIT_EXCEEDED)
+
+
 #define FM_FD_RX_STATUS_ERR_MASK        (FM_FD_ERR_UNSUPPORTED_FORMAT   | \
                                          FM_FD_ERR_LENGTH               | \
                                          FM_FD_ERR_DMA                  | \
@@ -1478,6 +1493,38 @@ t_Error FM_SetPortsBandwidth(t_Handle h_Fm, t_FmPortsBandwidthParams *p_PortsBan
 *//***************************************************************************/
 t_Handle FM_GetMuramHandle(t_Handle h_Fm);
 
+/**************************************************************************//*
+ @Function      FM_ReadTimeStamp
+
+ @Description   Reads the FMan engine's timestamp.
+
+ @Param[in]     h_Fm                A handle to an FM Module.
+
+ @Return        The indicated engine's timestamp on success; zero otherwise.
+
+ @Cautions      Allowed only following FM_Init().
+                This routine should NOT be called from guest-partition
+                (i.e. guestId != NCSW_MASTER_ID)
+*//***************************************************************************/
+uint32_t FM_ReadTimeStamp(t_Handle h_Fm);
+
+/**************************************************************************//*
+ @Function      FM_GetTimeStampIncrementPerUsec
+
+ @Description   Provides the value of the FMan engine's timestamp increment
+                per microsecond.
+
+ @Param[in]     h_Fm                A handle to an FM Module.
+
+ @Return        The value the timestamp is incremented with each microsecond
+                on success; zero otherwise.
+
+ @Cautions      Allowed only following FM_Init().
+                This routine should NOT be called from guest-partition
+                (i.e. guestId != NCSW_MASTER_ID)
+*//***************************************************************************/
+uint32_t FM_GetTimeStampIncrementPerUsec(t_Handle h_Fm);
+
 /** @} */ /* end of FM_runtime_control_grp group */
 /** @} */ /* end of FM_lib_grp group */
 /** @} */ /* end of FM_grp group */
diff --git a/drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_mac_ext.h b/drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_mac_ext.h
index 16db1a125124..abb0706798b2 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_mac_ext.h
+++ b/drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_mac_ext.h
@@ -764,6 +764,7 @@ t_Error FM_MAC_RemovelExactMatchMacAddr(t_Handle h_FmMac, t_EnetAddr *p_EnetAddr
  @Cautions      Allowed only after FM_MAC_Init().
 *//***************************************************************************/
 t_Error FM_MAC_SetPromiscuous(t_Handle h_FmMac, bool enable);
+t_Error FM_MAC_SetAllMulti(t_Handle h_FmMac, bool enable);
 
 /**************************************************************************//**
  @Function      FM_MAC_AdjustLink
diff --git a/drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_pcd_ext.h b/drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_pcd_ext.h
index 6e5db2aaf500..98c9c0778580 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_pcd_ext.h
+++ b/drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_pcd_ext.h
@@ -45,8 +45,10 @@
 #include "list_ext.h"
 #include "fm_ext.h"
 #include "fsl_fman_kg.h"
+#include "fm_eh_types.h"
 
-
+//use enhanced external hash implementation
+#define USE_ENHANCED_EHASH 1
 /**************************************************************************//**
  @Group         FM_grp Frame Manager API
 
@@ -508,6 +510,22 @@ t_Error FM_PCD_Disable(t_Handle h_FmPcd);
 *//***************************************************************************/
 uint32_t FM_PCD_GetCounter(t_Handle h_FmPcd, e_FmPcdCounters counter);
 
+/**************************************************************************//**
+ @Function      FmPcdPlcrProfileGetAbsoluteId
+
+ @Description   Returns absolute profile Id by profile handle.
+
+
+ @Param[in]     h_Profile       A handle to the profile.
+
+ @Return        Absolute profile ID.
+
+ @Cautions      Allowed only following FM_PCD_Init().
+*//***************************************************************************/
+
+uint16_t     FmPcdPlcrProfileGetAbsoluteId(t_Handle h_Profile);
+
+
 /**************************************************************************//**
 @Function       FM_PCD_PrsLoadSw
 
@@ -1699,6 +1717,7 @@ typedef struct t_FmPcdKgSchemeParams {
         uint8_t                         relativeSchemeId;       /**< if modify=FALSE:Partition relative scheme id */
         t_Handle                        h_Scheme;               /**< if modify=TRUE: a handle of the existing scheme */
     } id;
+    bool                                shared;           	/**< This scheme is shared */
     bool                                alwaysDirect;           /**< This scheme is reached only directly, i.e. no need
                                                                      for match vector; KeyGen will ignore it when matching */
     struct {                                                    /**< HL Relevant only if alwaysDirect = FALSE */
@@ -1944,8 +1963,7 @@ typedef struct t_FmPcdHashTableParams {
     uint16_t                    maxNumOfKeys;               /**< Maximum Number Of Keys that will (ever) be used in this Hash-table */
     e_FmPcdCcStatsMode          statisticsMode;             /**< If not e_FM_PCD_CC_STATS_MODE_NONE, the required structures for the
                                                                  requested statistics mode will be allocated according to maxNumOfKeys. */
-    uint8_t                     kgHashShift;                /**< KG-Hash-shift as it was configured in the KG-scheme
-                                                                 that leads to this hash-table. */
+    uint8_t                     kgHashShift;                /**< Obsolete; will be considered as '0'. */
     uint16_t                    hashResMask;                /**< Mask that will be used on the hash-result;
                                                                  The number-of-sets for this hash will be calculated
                                                                  as (2^(number of bits set in 'hashResMask'));
@@ -1956,6 +1974,28 @@ typedef struct t_FmPcdHashTableParams {
 
     t_FmPcdCcNextEngineParams   ccNextEngineParamsForMiss;  /**< Parameters for defining the next engine when a key is not matched */
 
+    bool                        agingSupport;               /**< TRUE to enable aging support for all keys of this hash table */
+
+#if (DPAA_VERSION >= 11)
+    bool                        externalHash;               /**< TRUE to use external hash table */
+
+#ifndef EXCLUDE_FMAN_IPR_OFFLOAD
+    uint32_t                    table_type;                 /**< ip reassembly table type */
+    struct {
+        uint32_t                timeout_val;                /**< reassembly timeout */
+        uint32_t                timeout_fqid;               /**< fqid for reassembly failures */
+        uint32_t                max_frags;                  /**< max allowed fragments */
+        uint32_t                min_frag_size;              /**< min allowed frag size except last frag */
+        uint32_t                max_sessions;               /**< max conn reassembly sessions */
+    };
+#endif
+
+    struct {
+        uint8_t                 dataMemId;                  /**< Memory partition ID for external hash table */
+        uint16_t                dataLiodnOffs;              /**< LIODN offset for external hash access */
+        uintptr_t               missMonitorAddr;            /**< User-allocated miss monitor address */
+    } externalHashParams;
+#endif /* (DPAA_VERSION >= 11) */
 } t_FmPcdHashTableParams;
 
 /**************************************************************************//**
@@ -3362,8 +3402,7 @@ t_Error FM_PCD_MatchTableGetNextEngine(t_Handle                     h_CcNode,
  @Param[in]     p_KgKey                 Pointer to the key; must be like the key
                                         that the KG is generated, i.e. the same
                                         extraction and with mask if exist.
- @Param[in]     kgHashShift             Hash-shift as it was configured in the KG
-                                        scheme that leads to this hash.
+ @Param[in]     kgHashShift             Obsolete; will be considered as '0'
  @Param[out]    p_CcNodeBucketHandle    Pointer to the bucket of the provided key.
  @Param[out]    p_BucketIndex           Index to the bucket of the provided key
  @Param[out]    p_LastIndex             Pointer to last index in the bucket of the
@@ -3445,6 +3484,7 @@ t_Error FM_PCD_HashTableAddKey(t_Handle            h_HashTbl,
                                uint8_t             keySize,
                                t_FmPcdCcKeyParams  *p_KeyParams);
 
+#ifndef USE_ENHANCED_EHASH
 /**************************************************************************//**
  @Function      FM_PCD_HashTableRemoveKey
 
@@ -3462,7 +3502,6 @@ t_Error FM_PCD_HashTableAddKey(t_Handle            h_HashTbl,
 t_Error FM_PCD_HashTableRemoveKey(t_Handle h_HashTbl,
                                   uint8_t  keySize,
                                   uint8_t  *p_Key);
-
 /**************************************************************************//**
  @Function      FM_PCD_HashTableModifyNextEngine
 
@@ -3486,6 +3525,7 @@ t_Error FM_PCD_HashTableModifyNextEngine(t_Handle                  h_HashTbl,
                                          uint8_t                   keySize,
                                          uint8_t                   *p_Key,
                                          t_FmPcdCcNextEngineParams *p_FmPcdCcNextEngineParams);
+#endif  // USE_ENHANCED_EHASH
 
 /**************************************************************************//**
  @Function      FM_PCD_HashTableModifyMissNextEngine
@@ -3522,6 +3562,21 @@ t_Error FM_PCD_HashTableModifyMissNextEngine(t_Handle                  h_HashTbl
 t_Error FM_PCD_HashTableGetMissNextEngine(t_Handle                     h_HashTbl,
                                           t_FmPcdCcNextEngineParams    *p_FmPcdCcNextEngineParams);
 
+/**************************************************************************//*
+ @Function      FM_PCD_HashTableModifyMissMonitorAddr
+
+ @Description   Modifies the miss monitor address.
+
+ @Param[in]     h_HashTbl                   A handle to a hash table
+ @Param[out]    monitorAddr   				Miss monitor address to be modified
+
+ @Return        E_OK on success; Error code otherwise.
+
+ @Cautions      Allowed only following FM_PCD_HashTableSet().
+*//***************************************************************************/
+t_Error FM_PCD_HashTableModifyMissMonitorAddr(t_Handle h_HashTbl,
+        									  uintptr_t monitorAddr);
+
 /**************************************************************************//**
  @Function      FM_PCD_HashTableFindNGetKeyStatistics
 
@@ -3575,6 +3630,75 @@ t_Error FM_PCD_HashTableFindNGetKeyStatistics(t_Handle                 h_HashTbl
 t_Error FM_PCD_HashTableGetMissStatistics(t_Handle                 h_HashTbl,
                                           t_FmPcdCcKeyStatistics   *p_MissStatistics);
 
+/**************************************************************************//**
+@Function      FM_PCD_HashTableGetKeyAging
+
+@Description   This routine may be used to retrieve the aging status for the
+               provided key.
+
+@Param[in]     h_HashTbl       A handle to a hash table
+@Param[in]     p_Key           Pointer to a key
+@Param[in]     keySize         Size of provided key
+@Param[in]     reset           TRUE if the user wishes to reset the aging
+                               status of this key to 1 after reading it;
+                               FALSE otherwise (key aging status will be
+                               read and not changed);
+@Param[out]    p_KeyAging      FALSE if the provided key was accessed since
+                               it's status was last set, TRUE otherwise.
+
+@Return        E_OK on success; Error code otherwise.
+
+@Cautions      Allowed only following FM_PCD_HashTableSet() with aging support
+               enabled.
+*//***************************************************************************/
+t_Error FM_PCD_HashTableGetKeyAging(t_Handle h_HashTbl,
+                                    uint8_t *p_Key,
+                                    uint8_t keySize,
+                                    bool reset,
+                                    bool *p_KeyAging);
+
+/**************************************************************************//**
+@Function      FM_PCD_HashTableGetBucketAging
+
+@Description   This routine may be used to retrieve the aging status for the
+               hash table bucket.
+
+@Param[in]     h_HashTbl            A handle to a hash table
+@Param[in]     bucketId             Id of the requested bucket
+@Param[in]     reset                TRUE if the user wishes to reset the aging
+                                    status of this bucket to all 1-s after reading;
+                                    FALSE otherwise (aging mask will be read
+                                    and not changed)
+@Param[out]    p_BucketAgingMask    Aging mask of the requested bucket;
+                                    A zero bit in the mask means that the key
+                                    represented by that bit was accessed since the
+                                    bit was last set, otherwise the bit remains
+                                    set to 1;
+                                    The MSB bit represents the first key in the
+                                    bucket, the 2nd MSB bit represents the second
+                                    key, etc..
+@Param[out]    agedKeysArray        If the user will provide a handle to a
+                                    preallocated array, this routine will copy
+                                    into that array all the keys from the requested
+                                    bucket for which the aging status is non-zero,
+                                    meaning all the keys that were not accessed since
+                                    their aging mask was last set;
+                                    The user may set this parameters to NULL to
+                                    disable this option
+
+@Return        E_OK on success; Error code otherwise
+
+@Cautions      Allowed only following FM_PCD_HashTableSet() with aging support
+               Enabled;
+               If 'agedKeysArray' is provided, it must have 31 entries large enough
+               to hold the entire keys
+*//***************************************************************************/
+t_Error FM_PCD_HashTableGetBucketAging(t_Handle h_HashTbl,
+                                       uint16_t bucketId,
+                                       bool reset,
+                                       uint32_t *p_BucketAgingMask,
+                                       uint8_t *agedKeysArray[31]);
+
 /**************************************************************************//**
  @Function      FM_PCD_ManipNodeSet
 
@@ -3697,4 +3821,24 @@ t_Error FM_PCD_FrmReplicRemoveMember(t_Handle h_FrmReplicGroup,
 /** @} */ /* end of FM_PCD_grp group */
 /** @} */ /* end of FM_grp group */
 
+//external hash table time stamp options
+#define MAX_EXT_TS_TIMERS       4
+#define EXT_TS_TYPE             uint32_t
+#define EXT_TS_SIZE             sizeof(EXT_TS_TYPE)
+struct ext_hash_ts_info {
+        uint32_t max_ext_ts_timers;
+        void *ptr;
+        uint32_t offset;
+};
+#define FM_PCD_UpdateExtTimeStamp(id, val) \
+{\
+        *((EXT_TS_TYPE *)extHashTsInfo.ptr + id) = (EXT_TS_TYPE)val;\
+}
+#define FM_PCD_GetExtTimeStampAddr(id) \
+	(extHashTsInfo.offset + (id * EXT_TS_SIZE))
+
+#define FM_PCD_GetExtTsRef(id)\
+        (extHashTsInfo.offset + (id * EXT_TS_SIZE))
+extern struct ext_hash_ts_info extHashTsInfo;
+
 #endif /* __FM_PCD_EXT */
diff --git a/drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_port_ext.h b/drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_port_ext.h
index 259d194b44d3..4164670d52e3 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_port_ext.h
+++ b/drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_port_ext.h
@@ -1732,6 +1732,25 @@ t_Error FM_PORT_SetRxL4ChecksumVerify(t_Handle h_FmPort, bool enable);
 *//***************************************************************************/
 t_Error FM_PORT_SetErrorsRoute(t_Handle h_FmPort, fmPortFrameErrSelect_t errs);
 
+/**************************************************************************//**
+ @Function      FM_PORT_SetDiscardMask
+
+ @Description   Sets user provided DiscardMask value  to Port BMI register 
+			rfsdm in case of rx
+			ofsdm in case of op port
+
+                used for Rx and OP ports only
+
+ @Param[in]     h_FmPort    A handle to a FM Port module.
+ @Param[in]     errs        A list of errors to discard the frame.
+
+ @Return        E_OK on success; Error code otherwise.
+
+ @Cautions      Allowed only following FM_PORT_Config() and before FM_PORT_Init().
+*//***************************************************************************/
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+t_Error FM_PORT_SetDiscardMask(t_Handle h_FmPort, fmPortFrameErrSelect_t errs);
+#endif
 /**************************************************************************//**
  @Function      FM_PORT_SetIMExceptions
 
diff --git a/drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_vsp_ext.h b/drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_vsp_ext.h
index f9aed0363d7c..741d0ab8a2e7 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_vsp_ext.h
+++ b/drivers/net/ethernet/freescale/sdk_fman/inc/Peripherals/fm_vsp_ext.h
@@ -402,6 +402,20 @@ uint64_t * FM_VSP_GetBufferTimeStamp(t_Handle h_FmVsp, char *p_Data);
 *//***************************************************************************/
 uint8_t * FM_VSP_GetBufferHashResult(t_Handle h_FmVsp, char *p_Data);
 
+/**************************************************************************//**
+ @Function      FM_VSP_GetRelativeProfileId
+
+ @Description   Given the VSP handle, the configured relative storage profile
+		id is returned.
+
+ @Param[in]     h_FmVsp    - FM PORT module descriptor
+
+ @Return        Relative storage Profile ID.
+
+ @Cautions      Allowed only following FM_VSP_Init().
+*//***************************************************************************/
+
+uint8_t FM_VSP_GetRelativeProfileId(t_Handle h_FmVsp);
 
 /** @} */ /* end of FM_VSP_control_grp group */
 /** @} */ /* end of FM_VSP_grp group */
diff --git a/drivers/net/ethernet/freescale/sdk_fman/inc/flib/fsl_fman.h b/drivers/net/ethernet/freescale/sdk_fman/inc/flib/fsl_fman.h
index 6136c46e8667..48d9a3e2acd0 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/inc/flib/fsl_fman.h
+++ b/drivers/net/ethernet/freescale/sdk_fman/inc/flib/fsl_fman.h
@@ -35,6 +35,7 @@
 
 #include "std_ext.h"
 
+//#define AUTO_FIRMWARE_LOAD 1  // currently flash the bin file
 struct fman_ext_pool_params {
 	uint8_t                 id;    /**< External buffer pool id */
 	uint16_t                size;  /**< External buffer pool buffer size */
diff --git a/drivers/net/ethernet/freescale/sdk_fman/inc/flib/fsl_fman_port.h b/drivers/net/ethernet/freescale/sdk_fman/inc/flib/fsl_fman_port.h
index 080a23e963b9..f8936fd2f2e0 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/inc/flib/fsl_fman_port.h
+++ b/drivers/net/ethernet/freescale/sdk_fman/inc/flib/fsl_fman_port.h
@@ -286,7 +286,9 @@ struct fman_port_oh_bmi_regs {
 	uint32_t fmbm_ofwdc;		/**< Rx Frames WRED Discard Counter  */
 	uint32_t fmbm_ofldec;		/**< O/H Frames List DMA Error Cntr */
 	uint32_t fmbm_obdc;		/**< O/H Buffers Deallocate Counter */
-	uint32_t reserved0218[0x17];	/**< (0x218 - 0x27F) */
+	uint32_t fmbm_oodc;      	/**< O/H Out of Buffers Discard Counter */
+	uint32_t fmbm_opec;      	/**< O/H Prepare to enqueue Counter */
+	uint32_t reserved0218[0x15];	/**< (0x218 - 0x27F) */
 	uint32_t fmbm_opc;		/**< O/H Performance Counters  */
 	uint32_t fmbm_opcp;		/**< O/H Performance Count Parameters */
 	uint32_t fmbm_occn;		/**< O/H Cycle Counter  */
diff --git a/drivers/net/ethernet/freescale/sdk_fman/inc/stdlib_ext.h b/drivers/net/ethernet/freescale/sdk_fman/inc/stdlib_ext.h
index 48615b7d0dff..937f8f7d6481 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/inc/stdlib_ext.h
+++ b/drivers/net/ethernet/freescale/sdk_fman/inc/stdlib_ext.h
@@ -35,53 +35,18 @@
 #include "stdarg_ext.h"
 #include "std_ext.h"
 
+/*
+ * Note: strlen, strnlen, strcpy, strncpy, strtok are provided by
+ * <linux/string.h> in modern kernels. The kernel's FORTIFY_SOURCE
+ * implementation defines these as macros, so we cannot redeclare them.
+ */
+
 /**
  * atoi - convert a character to a int
  * @s: The start of the string
  */
 int atoi(const char *s);
 
-/**
- * strnlen - Find the length of a length-limited string
- * @s: The string to be sized
- * @count: The maximum number of bytes to search
- */
-size_t strnlen(const char * s, size_t count);
-
-/**
- * strlen - Find the length of a string
- * @s: The string to be sized
- */
-size_t strlen(const char * s);
-
-/**
- * strtok - Split a string into tokens
- * @s: The string to be searched
- * @ct: The characters to search for
- *
- * WARNING: strtok is deprecated, use strsep instead.
- */
-char * strtok(char * s,const char * ct);
-
-/**
- * strncpy - Copy a length-limited, %NUL-terminated string
- * @dest: Where to copy the string to
- * @src: Where to copy the string from
- * @count: The maximum number of bytes to copy
- *
- * Note that unlike userspace strncpy, this does not %NUL-pad the buffer.
- * However, the result is not %NUL-terminated if the source exceeds
- * @count bytes.
- */
-char * strncpy(char * dest,const char *src,size_t count);
-
-/**
- * strcpy - Copy a %NUL terminated string
- * @dest: Where to copy the string to
- * @src: Where to copy the string from
- */
-char * strcpy(char * dest,const char *src);
-
 /**
  * vsscanf - Unformat a buffer into a list of arguments
  * @buf:    input buffer
diff --git a/drivers/net/ethernet/freescale/sdk_fman/ls1043_dflags.h b/drivers/net/ethernet/freescale/sdk_fman/ls1043_dflags.h
index 67d96367f075..25af9ed23a19 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/ls1043_dflags.h
+++ b/drivers/net/ethernet/freescale/sdk_fman/ls1043_dflags.h
@@ -34,6 +34,8 @@
 #define __dflags_h
 
 #define LS1043
+#define DPAA_VERSION 11
+#define CONFIG_FMAN_ARM 1
 
 #define DEBUG_ERRORS        1
 
diff --git a/drivers/net/ethernet/freescale/sdk_fman/src/inc/wrapper/lnxwrp_exp_sym.h b/drivers/net/ethernet/freescale/sdk_fman/src/inc/wrapper/lnxwrp_exp_sym.h
index 9667d45d7f75..071a623929ca 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/src/inc/wrapper/lnxwrp_exp_sym.h
+++ b/drivers/net/ethernet/freescale/sdk_fman/src/inc/wrapper/lnxwrp_exp_sym.h
@@ -92,18 +92,22 @@ EXPORT_SYMBOL(FM_PCD_MatchTableGetKeyCounter);
 EXPORT_SYMBOL(FM_PCD_MatchTableGetKeyStatistics);
 EXPORT_SYMBOL(FM_PCD_MatchTableFindNGetKeyStatistics);
 EXPORT_SYMBOL(FM_PCD_MatchTableGetMissStatistics);
-EXPORT_SYMBOL(FM_PCD_HashTableGetMissStatistics);
 EXPORT_SYMBOL(FM_PCD_HashTableSet);
-EXPORT_SYMBOL(FM_PCD_HashTableDelete);
 EXPORT_SYMBOL(FM_PCD_HashTableAddKey);
+#ifndef USE_ENHANCED_EHASH
+EXPORT_SYMBOL(FM_PCD_HashTableDelete);
+EXPORT_SYMBOL(FM_PCD_HashTableGetMissStatistics);
 EXPORT_SYMBOL(FM_PCD_HashTableRemoveKey);
+EXPORT_SYMBOL(FM_PCD_HashTableFindNGetKeyStatistics);
 EXPORT_SYMBOL(FM_PCD_HashTableModifyNextEngine);
-EXPORT_SYMBOL(FM_PCD_HashTableModifyMissNextEngine);
 EXPORT_SYMBOL(FM_PCD_HashTableGetMissNextEngine);
-EXPORT_SYMBOL(FM_PCD_HashTableFindNGetKeyStatistics);
+EXPORT_SYMBOL(FM_PCD_HashTableModifyMissMonitorAddr);
+#endif //USE_ENHANCED_EHASH
+EXPORT_SYMBOL(FM_PCD_HashTableModifyMissNextEngine);
 EXPORT_SYMBOL(FM_PCD_PlcrProfileSet);
 EXPORT_SYMBOL(FM_PCD_PlcrProfileDelete);
 EXPORT_SYMBOL(FM_PCD_PlcrProfileGetCounter);
+EXPORT_SYMBOL(FmPcdPlcrProfileGetAbsoluteId);
 EXPORT_SYMBOL(FM_PCD_PlcrProfileSetCounter);
 EXPORT_SYMBOL(FM_PCD_ManipNodeSet);
 EXPORT_SYMBOL(FM_PCD_ManipNodeDelete);
diff --git a/drivers/net/ethernet/freescale/sdk_fman/src/inc/wrapper/lnxwrp_fsl_fman.h b/drivers/net/ethernet/freescale/sdk_fman/src/inc/wrapper/lnxwrp_fsl_fman.h
index 99759baead31..b13716ff41e6 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/src/inc/wrapper/lnxwrp_fsl_fman.h
+++ b/drivers/net/ethernet/freescale/sdk_fman/src/inc/wrapper/lnxwrp_fsl_fman.h
@@ -580,6 +580,8 @@ int fm_mac_resume(struct fm_mac_dev *fm_mac_dev);
 
 int fm_mac_set_promiscuous(struct fm_mac_dev *fm_mac_dev,
 		bool enable);
+int fm_mac_set_allmulti(struct fm_mac_dev *fm_mac_dev,
+		bool enable);
 
 int fm_mac_remove_hash_mac_addr(struct fm_mac_dev *fm_mac_dev,
 		t_EnetAddr *mac_addr);
diff --git a/drivers/net/ethernet/freescale/sdk_fman/src/system/sys_io.c b/drivers/net/ethernet/freescale/sdk_fman/src/system/sys_io.c
index b52ff95ce9e9..902e43060ca7 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/src/system/sys_io.c
+++ b/drivers/net/ethernet/freescale/sdk_fman/src/system/sys_io.c
@@ -144,6 +144,9 @@ uint64_t SYS_PhysToVirt(uint64_t addr)
     }
     return PTR_TO_UINT(phys_to_virt((unsigned long)addr));
 }
+#ifdef CONFIG_DBG_UCODE_INFRA 
+EXPORT_SYMBOL(SYS_PhysToVirt);
+#endif // CONFIG_DBG_UCODE_INFRA
 
 uint64_t SYS_VirtToPhys(uint64_t addr)
 {
@@ -157,3 +160,4 @@ uint64_t SYS_VirtToPhys(uint64_t addr)
         return (uint64_t)(addr - p_IoMap->virtAddr + p_IoMap->physAddr);
     return (uint64_t)virt_to_phys(UINT_TO_PTR(addr));
 }
+EXPORT_SYMBOL(SYS_VirtToPhys);
diff --git a/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_fm.c b/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_fm.c
index e10512983b60..55498f4c9643 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_fm.c
+++ b/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_fm.c
@@ -1319,6 +1319,17 @@ void *fm_port_get_handle(const struct fm_port *port)
 }
 EXPORT_SYMBOL(fm_port_get_handle);
 
+int fm_port_get_hwid(const struct fm_port *port)
+{
+	uint8_t id;
+
+	t_LnxWrpFmPortDev *p_LnxWrpFmPortDev = (t_LnxWrpFmPortDev*)port;
+	return(FmPortGetHardwarePortId(p_LnxWrpFmPortDev->h_Dev));
+
+}
+EXPORT_SYMBOL(fm_port_get_hwid);
+
+
 u64 *fm_port_get_buffer_time_stamp(const struct fm_port *port,
 		const void *data)
 {
@@ -1610,12 +1621,28 @@ int fm_mac_resume(struct fm_mac_dev *fm_mac_dev)
 }
 EXPORT_SYMBOL(fm_mac_resume);
 
+int fm_mac_set_allmulti(struct fm_mac_dev *fm_mac_dev,
+		bool enable)
+{
+	int	_errno;
+	t_Error	err;
+
+	err = FM_MAC_SetAllMulti(fm_mac_dev, enable);
+	_errno = -GET_ERROR_TYPE(err);
+	if (unlikely(_errno < 0))
+		pr_err("FM_MAC_SetPromiscuous() = 0x%08x\n", err);
+
+	return _errno;
+}
+EXPORT_SYMBOL(fm_mac_set_allmulti);
+
 int fm_mac_set_promiscuous(struct fm_mac_dev *fm_mac_dev,
 		bool enable)
 {
 	int	_errno;
 	t_Error	err;
 
+        printk("%s::%d \r\n", __FUNCTION__, __LINE__);
 	err = FM_MAC_SetPromiscuous(fm_mac_dev, enable);
 	_errno = -GET_ERROR_TYPE(err);
 	if (unlikely(_errno < 0))
diff --git a/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_fm.h b/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_fm.h
index 6e6f07eb499e..8082ab10fb43 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_fm.h
+++ b/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_fm.h
@@ -52,7 +52,8 @@
 
 #define FM_MAX_NUM_OF_ADV_SETTINGS          10
 
-#define LNXWRP_FM_NUM_OF_SHARED_PROFILES    16
+/*#define LNXWRP_FM_NUM_OF_SHARED_PROFILES    16  default value */
+#define LNXWRP_FM_NUM_OF_SHARED_PROFILES    144 /* currently 140 shared profiles are in use */
 
 #if defined(CONFIG_FMAN_DISABLE_OH_TO_REUSE_RESOURCES)
 #define FM_10G_OPENDMA_MIN_TRESHOLD 8 /* 10g minimum treshold if only HC is enabled and no OH port enabled */
diff --git a/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_fm_port.c b/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_fm_port.c
index ea4235847686..1aa05d79cfdf 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_fm_port.c
+++ b/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_fm_port.c
@@ -792,11 +792,10 @@ static t_Error InitFmPortDev(t_LnxWrpFmPortDev *p_LnxWrpFmPortDev)
 
 
     if ((p_LnxWrpFmPortDev->settings.param.portType != e_FM_PORT_TYPE_TX) &&
-        (p_LnxWrpFmPortDev->settings.param.portType != e_FM_PORT_TYPE_TX_10G)) {
-            if (FM_PORT_ConfigErrorsToDiscard(p_LnxWrpFmPortDev->h_Dev, (FM_PORT_FRM_ERR_IPRE |
-                                                                         FM_PORT_FRM_ERR_IPR_NCSP |
-                                                                         FM_PORT_FRM_ERR_CLS_DISCARD)) !=E_OK)
-            RETURN_ERROR(MAJOR, E_INVALID_STATE, NO_MSG);
+        (p_LnxWrpFmPortDev->settings.param.portType != e_FM_PORT_TYPE_TX_10G)) { 
+            /*(FM_PORT_FRM_ERR_IPRE | FM_PORT_FRM_ERR_IPR_NCSP | FM_PORT_FRM_ERR_CLS_DISCARD*/
+            if (FM_PORT_ConfigErrorsToDiscard(p_LnxWrpFmPortDev->h_Dev, FM_RFSDM_DEFAULT) != E_OK)
+            	RETURN_ERROR(MAJOR, E_INVALID_STATE, NO_MSG);
     }
 
     if (CheckNConfigFmPortAdvArgs(p_LnxWrpFmPortDev) != E_OK)
diff --git a/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_ioctls_fm.c b/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_ioctls_fm.c
index f97c37f06255..3264467869d3 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_ioctls_fm.c
+++ b/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_ioctls_fm.c
@@ -2173,6 +2173,11 @@ Status: not exported
 #endif
         case FM_PCD_IOC_HASH_TABLE_GET_MISS_STAT:
         {
+#ifdef USE_ENHANCED_EHASH
+            RETURN_ERROR(MINOR, E_INVALID_SELECTION,
+                ("invalid ioctl: cmd:0x%08x(type:0x%02x, nr: %d.\n",
+                cmd, _IOC_TYPE(cmd), _IOC_NR(cmd)));
+#else
             ioc_fm_pcd_cc_tbl_get_stats_t param;
 
 #if defined(CONFIG_COMPAT)
@@ -2237,7 +2242,7 @@ Status: not exported
                                   sizeof(ioc_fm_pcd_cc_tbl_get_stats_t)))
                     RETURN_ERROR(MINOR, E_READ_FAILED, NO_MSG);
             }
-
+#endif //USE_ENHANCED_EHASH
             break;
         }
 
@@ -2347,6 +2352,11 @@ Status: not exported
 #endif
         case FM_PCD_IOC_HASH_TABLE_DELETE:
         {
+#ifdef USE_ENHANCED_EHASH
+            RETURN_ERROR(MINOR, E_INVALID_SELECTION,
+                ("invalid ioctl: cmd:0x%08x(type:0x%02x, nr: %d.\n",
+                cmd, _IOC_TYPE(cmd), _IOC_NR(cmd)));
+#else
             ioc_fm_obj_t id;
 
             memset(&id, 0, sizeof(ioc_fm_obj_t));
@@ -2369,6 +2379,7 @@ Status: not exported
             }
 
             err = FM_PCD_HashTableDelete(id.obj);
+#endif  // USE_ENHANCED_EHASH
             break;
         }
 
@@ -2498,6 +2509,11 @@ Status: not exported
 #endif
         case FM_PCD_IOC_HASH_TABLE_REMOVE_KEY:
         {
+#ifdef USE_ENHANCED_EHASH
+            RETURN_ERROR(MINOR, E_INVALID_SELECTION,
+                ("invalid ioctl: cmd:0x%08x(type:0x%02x, nr: %d.\n",
+                cmd, _IOC_TYPE(cmd), _IOC_NR(cmd)));
+#else
             ioc_fm_pcd_hash_table_remove_key_params_t *param = NULL;
 
             param = (ioc_fm_pcd_hash_table_remove_key_params_t*) XX_Malloc(
@@ -2574,6 +2590,7 @@ Status: not exported
             if (param->p_key)
                 XX_Free(param->p_key);
             XX_Free(param);
+#endif // USE_ENHANCED_EHASH
             break;
         }
 
@@ -3379,6 +3396,9 @@ Status: not exported
     }
 
         default:
+            /* Silently reject TTY ioctls (e.g., TCGETS from isatty()) */
+            if (_IOC_TYPE(cmd) == 'T')
+                return E_NOT_SUPPORTED;
             RETURN_ERROR(MINOR, E_INVALID_SELECTION,
                 ("invalid ioctl: cmd:0x%08x(type:0x%02x, nr: %d.\n",
                 cmd, _IOC_TYPE(cmd), _IOC_NR(cmd)));
@@ -3651,6 +3671,30 @@ t_Error LnxwrpFmIOCTL(t_LnxWrpFmDev *p_LnxWrpFmDev, unsigned int cmd, unsigned l
         }
         break;
 
+        case FM_IOC_READ_TIMESTAMP:
+        {
+            uint32_t ts;
+
+            ts = FM_ReadTimeStamp(p_LnxWrpFmDev->h_Dev);
+
+            if (copy_to_user((uint32_t *)arg, &ts, sizeof(uint32_t)))
+                err = E_READ_FAILED;
+
+        }
+        break;
+
+        case FM_IOC_GET_TIMESTAMP_INCREMENT:
+        {
+            uint32_t ts_inc;
+
+            ts_inc = FM_GetTimeStampIncrementPerUsec(p_LnxWrpFmDev->h_Dev);
+
+            if (copy_to_user((uint32_t *)arg, &ts_inc, sizeof(uint32_t)))
+                err = E_READ_FAILED;
+
+        }
+        break;
+
         default:
             return LnxwrpFmPcdIOCTL(p_LnxWrpFmDev, cmd, arg, compat);
     }
@@ -4612,6 +4656,9 @@ t_Error LnxwrpFmPortIOCTL(t_LnxWrpFmPortDev *p_LnxWrpFmPortDev, unsigned int cmd
         }
 
         default:
+            /* Silently reject TTY ioctls (e.g., TCGETS from isatty()) */
+            if (_IOC_TYPE(cmd) == 'T')
+                return E_NOT_SUPPORTED;
             RETURN_ERROR(MINOR, E_INVALID_SELECTION,
                 ("invalid ioctl: cmd:0x%08x(type:0x%02x, nr:0x%02x.\n",
                 cmd, _IOC_TYPE(cmd), _IOC_NR(cmd)));
diff --git a/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_ioctls_fm_compat.h b/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_ioctls_fm_compat.h
index 41df9a906b03..448291e32f68 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_ioctls_fm_compat.h
+++ b/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_ioctls_fm_compat.h
@@ -236,6 +236,7 @@ typedef struct ioc_compat_fm_pcd_cc_key_params_t {
     compat_uptr_t                              p_key;
     compat_uptr_t                              p_mask;
     ioc_compat_fm_pcd_cc_next_engine_params_t  cc_next_engine_params; /**< compat structure*/
+	compat_uptr_t				monitor_addr;
 } ioc_compat_fm_pcd_cc_key_params_t;
 
 typedef struct ioc_compat_keys_params_t {
@@ -266,6 +267,13 @@ typedef struct ioc_compat_fm_pcd_hash_table_params_t {
     uint8_t                     hash_shift;
     uint8_t                     match_key_size;
     ioc_compat_fm_pcd_cc_next_engine_params_t   cc_next_engine_params_for_miss;
+	bool			aging_support;
+	bool			external_hash;
+	struct {
+		uint8_t		data_mem_id;
+		uint16_t	data_liodn_offs;
+		compat_uptr_t	miss_monitor_addr;
+	} external_hash_params;
     compat_uptr_t               id;
 } ioc_compat_fm_pcd_hash_table_params_t;
 
diff --git a/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_sysfs_fm.c b/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_sysfs_fm.c
index 7329446372b3..e0cec33f098f 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_sysfs_fm.c
+++ b/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_sysfs_fm.c
@@ -46,6 +46,14 @@
 #include "../../sdk_fman/Peripherals/FM/fm.h"
 #include <linux/delay.h>
 
+static ssize_t show_fm_dma_cmd_queue(struct device *dev,
+                                struct device_attribute *attr,
+                                char *buf);
+static ssize_t show_fm_dma_cam_queue(struct device *dev,
+                                struct device_attribute *attr,
+                                char *buf);
+static int fm_get_counter(void *h_fm, enum fman_counters cnt_e, uint32_t *cnt_val);
+
 enum fm_dma_match_stats {
 	FM_DMA_COUNTERS_CMQ_NOT_EMPTY,
 	FM_DMA_COUNTERS_BUS_ERROR,
@@ -858,6 +866,23 @@ static DEVICE_ATTR(scheme_29, S_IRUGO, show_fm_schemes, NULL);
 static DEVICE_ATTR(scheme_30, S_IRUGO, show_fm_schemes, NULL);
 static DEVICE_ATTR(scheme_31, S_IRUGO, show_fm_schemes, NULL);
 
+static DEVICE_ATTR(fm_dma_cmdq_0, S_IRUGO, show_fm_dma_cmd_queue, NULL);
+static DEVICE_ATTR(fm_dma_cmdq_8, S_IRUGO, show_fm_dma_cmd_queue, NULL);
+static DEVICE_ATTR(fm_dma_cmdq_16, S_IRUGO, show_fm_dma_cmd_queue, NULL);
+static DEVICE_ATTR(fm_dma_cmdq_24, S_IRUGO, show_fm_dma_cmd_queue, NULL);
+static DEVICE_ATTR(fm_dma_cmdq_32, S_IRUGO, show_fm_dma_cmd_queue, NULL);
+static DEVICE_ATTR(fm_dma_cmdq_40, S_IRUGO, show_fm_dma_cmd_queue, NULL);
+static DEVICE_ATTR(fm_dma_cmdq_48, S_IRUGO, show_fm_dma_cmd_queue, NULL);
+static DEVICE_ATTR(fm_dma_cmdq_56, S_IRUGO, show_fm_dma_cmd_queue, NULL);
+
+static DEVICE_ATTR(fm_dma_camq_0, S_IRUGO, show_fm_dma_cam_queue, NULL);
+static DEVICE_ATTR(fm_dma_camq_8, S_IRUGO, show_fm_dma_cam_queue, NULL);
+static DEVICE_ATTR(fm_dma_camq_16, S_IRUGO, show_fm_dma_cam_queue, NULL);
+static DEVICE_ATTR(fm_dma_camq_24, S_IRUGO, show_fm_dma_cam_queue, NULL);
+static DEVICE_ATTR(fm_dma_camq_32, S_IRUGO, show_fm_dma_cam_queue, NULL);
+static DEVICE_ATTR(fm_dma_camq_40, S_IRUGO, show_fm_dma_cam_queue, NULL);
+static DEVICE_ATTR(fm_dma_camq_48, S_IRUGO, show_fm_dma_cam_queue, NULL);
+static DEVICE_ATTR(fm_dma_camq_56, S_IRUGO, show_fm_dma_cam_queue, NULL);
 
 static struct attribute *fm_dev_stats_attributes[] = {
 	&dev_attr_enq_total_frame.attr,
@@ -1022,6 +1047,43 @@ static struct attribute *fm_dev_schemes_attributes[] = {
 	NULL
 };
 
+static struct attribute *fm_dma_cmdq_attributes[] = {
+	&dev_attr_fm_dma_cmdq_0.attr,
+	&dev_attr_fm_dma_cmdq_8.attr,
+	&dev_attr_fm_dma_cmdq_16.attr,
+	&dev_attr_fm_dma_cmdq_24.attr,
+	&dev_attr_fm_dma_cmdq_32.attr,
+	&dev_attr_fm_dma_cmdq_40.attr,
+	&dev_attr_fm_dma_cmdq_48.attr,
+	&dev_attr_fm_dma_cmdq_56.attr,
+	NULL
+};
+
+
+static struct attribute *fm_dma_camq_attributes[] = {
+        &dev_attr_fm_dma_camq_0.attr,
+        &dev_attr_fm_dma_camq_8.attr,
+        &dev_attr_fm_dma_camq_16.attr,
+        &dev_attr_fm_dma_camq_24.attr,
+        &dev_attr_fm_dma_camq_32.attr,
+        &dev_attr_fm_dma_camq_40.attr,
+        &dev_attr_fm_dma_camq_48.attr,
+        &dev_attr_fm_dma_camq_56.attr,
+        NULL
+};
+
+
+
+static const struct attribute_group fm_dev_fm_dma_cmdq_grp = {
+	.name = "fm_dma_cmdq",
+	.attrs = fm_dma_cmdq_attributes
+};
+
+static const struct attribute_group fm_dev_fm_dma_camq_grp = {
+	.name = "fm_dma_camq",
+	.attrs = fm_dma_camq_attributes
+};
+
 static const struct attribute_group fm_dev_stats_attr_grp = {
 	.name = "statistics",
 	.attrs = fm_dev_stats_attributes
@@ -1047,6 +1109,130 @@ static const struct attribute_group fm_dev_profiles_attr_grp = {
 	.attrs = fm_dev_profiles_attributes
 };
 
+#define MAX_CMD_QUE_DMP_COUNT        8
+#define QT_CMD_QUEUE_ENTRY           (1 << 16)
+#define QT_CAM_QUEUE_ENTRY           (2 << 16)
+int fm_dump_ccqueue(void *h_fm, char *buf, int nn, uint32_t start, uint32_t type)
+{
+	t_Fm            *p_Fm = (t_Fm *)h_fm;
+        uint8_t         i = 0;
+        int             n = nn;
+
+	FM_DMP_SUBTITLE(buf, n, "\n");
+	if (type == QT_CMD_QUEUE_ENTRY) {
+		FM_DMP_TITLE(buf, n, NULL, "FMDM cmd queue %d - %d", start, (start + MAX_CMD_QUE_DMP_COUNT - 1));
+	} else {
+		FM_DMP_TITLE(buf, n, NULL, "FMDM cam queue %d - %d", start, (start + MAX_CMD_QUE_DMP_COUNT - 1));
+	}
+	for (i = start; i < (start + MAX_CMD_QUE_DMP_COUNT); i++) {
+                uint32_t tmp;
+                tmp = (type | i);
+                iowrite32be(tmp, &p_Fm->p_FmDmaRegs->fmdmccqdr);
+                FM_DMP_V32(buf, n, p_Fm->p_FmDmaRegs, fmdmccqdr);
+                FM_DMP_V32(buf, n, p_Fm->p_FmDmaRegs, fmdmccqvr1);
+                FM_DMP_V32(buf, n, p_Fm->p_FmDmaRegs, fmdmccqvr2);
+                FM_DMP_V32(buf, n, p_Fm->p_FmDmaRegs, fmdmcqvr3);
+                FM_DMP_V32(buf, n, p_Fm->p_FmDmaRegs, fmdmcqvr4);
+                FM_DMP_V32(buf, n, p_Fm->p_FmDmaRegs, fmdmcqvr5);
+                FM_DMP_LN(buf, n, "\n");
+        }
+        FM_DMP_LN(buf, n, "\n");
+	return n;
+}
+
+
+static ssize_t show_fm_dma_cam_queue(struct device *dev,
+                                struct device_attribute *attr,
+                                char *buf)
+{
+	unsigned long flags;
+	unsigned n = 0;	
+	int start;
+
+#if (defined(DEBUG_ERRORS) && (DEBUG_ERRORS > 0))
+	t_LnxWrpFmDev *p_wrp_fm_dev = NULL;
+#endif
+	if (attr == NULL || buf == NULL || dev == NULL)
+		return -EINVAL;
+
+#if (defined(DEBUG_ERRORS) && (DEBUG_ERRORS > 0))
+
+	p_wrp_fm_dev = (t_LnxWrpFmDev *) dev_get_drvdata(dev);
+	if (WARN_ON(p_wrp_fm_dev == NULL))
+		return -EINVAL;
+
+	local_irq_save(flags);
+
+	n = snprintf(buf, PAGE_SIZE, "FM DMA CAM queue dump.\n");
+
+	if (!p_wrp_fm_dev->active || !p_wrp_fm_dev->h_Dev)
+		return -EIO;
+
+	if (!sscanf(attr->attr.name, "fm_dma_camq_%d", &start))
+                        return -EINVAL;
+
+	n = fm_dump_ccqueue(p_wrp_fm_dev->h_Dev, buf, n,
+			start, QT_CAM_QUEUE_ENTRY);
+
+	local_irq_restore(flags);
+#else
+
+	local_irq_save(flags);
+	n = snprintf(buf, PAGE_SIZE,
+			"Debug level is too low to dump registers!!!\n");
+	local_irq_restore(flags);
+#endif /* (defined(DEBUG_ERRORS) && ... */
+
+	return n;
+}
+
+static ssize_t show_fm_dma_cmd_queue(struct device *dev,
+                                struct device_attribute *attr,
+                                char *buf)
+{
+	unsigned long flags;
+	unsigned n = 0;	
+	int start;
+
+#if (defined(DEBUG_ERRORS) && (DEBUG_ERRORS > 0))
+	t_LnxWrpFmDev *p_wrp_fm_dev = NULL;
+#endif
+	if (attr == NULL || buf == NULL || dev == NULL)
+		return -EINVAL;
+
+#if (defined(DEBUG_ERRORS) && (DEBUG_ERRORS > 0))
+
+	p_wrp_fm_dev = (t_LnxWrpFmDev *) dev_get_drvdata(dev);
+	if (WARN_ON(p_wrp_fm_dev == NULL))
+		return -EINVAL;
+
+	local_irq_save(flags);
+
+	n = snprintf(buf, PAGE_SIZE, "FM DMA CMD queue dump.\n");
+
+	if (!p_wrp_fm_dev->active || !p_wrp_fm_dev->h_Dev)
+		return -EIO;
+
+	if (!sscanf(attr->attr.name, "fm_dma_cmdq_%d", &start))
+                        return -EINVAL;
+
+	n = fm_dump_ccqueue(p_wrp_fm_dev->h_Dev, buf, n,
+			start, QT_CMD_QUEUE_ENTRY);
+
+	local_irq_restore(flags);
+#else
+
+	local_irq_save(flags);
+	n = snprintf(buf, PAGE_SIZE,
+			"Debug level is too low to dump registers!!!\n");
+	local_irq_restore(flags);
+#endif /* (defined(DEBUG_ERRORS) && ... */
+
+	return n;
+}
+
+
+
 static ssize_t show_fm_regs(struct device *dev,
 				struct device_attribute *attr,
 				char *buf)
@@ -1330,6 +1516,12 @@ int fm_sysfs_create(struct device *dev)
 	if (sysfs_create_group(&dev->kobj, &fm_dev_cls_plans_attr_grp) != 0)
 		return -EIO;
 
+	if (sysfs_create_group(&dev->kobj, &fm_dev_fm_dma_cmdq_grp) != 0)
+		return -EIO;
+
+	if (sysfs_create_group(&dev->kobj, &fm_dev_fm_dma_camq_grp) != 0)
+		return -EIO;
+
 	/* Registers dump entry - in future will be moved to debugfs */
 	if (device_create_file(dev, &dev_attr_fm_regs) != 0)
 		return -EIO;
diff --git a/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_sysfs_fm_port.c b/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_sysfs_fm_port.c
index 12471f6f8597..b3f8704f1883 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_sysfs_fm_port.c
+++ b/drivers/net/ethernet/freescale/sdk_fman/src/wrapper/lnxwrp_sysfs_fm_port.c
@@ -230,7 +230,7 @@ static struct attribute *fm_oh_port_dev_stats_attributes[] = {
 	/* &dev_attr_port_rx_bad_frame.attr, */
 	/* &dev_attr_port_rx_large_frame.attr, */
 	&dev_attr_port_rx_out_of_buffers_discard.attr,
-	/*&dev_attr_port_rx_filter_frame.attr, */
+	&dev_attr_port_rx_filter_frame.attr, 
 	NULL
 };
 
@@ -667,6 +667,9 @@ int fm_port_dump_regs_bmi(void *h_dev, char *buf, int nn)
 		FM_DMP_V32(buf, n, &p_bmi->ohPortBmiRegs, fmbm_offc);
 		FM_DMP_V32(buf, n, &p_bmi->ohPortBmiRegs, fmbm_ofwdc);
 		FM_DMP_V32(buf, n, &p_bmi->ohPortBmiRegs, fmbm_ofldec);
+		FM_DMP_V32(buf, n, &p_bmi->ohPortBmiRegs, fmbm_obdc);
+		FM_DMP_V32(buf, n, &p_bmi->ohPortBmiRegs, fmbm_oodc);
+		FM_DMP_V32(buf, n, &p_bmi->ohPortBmiRegs, fmbm_opec);
 		FM_DMP_V32(buf, n, &p_bmi->ohPortBmiRegs, fmbm_opc);
 		FM_DMP_V32(buf, n, &p_bmi->ohPortBmiRegs, fmbm_opcp);
 		FM_DMP_V32(buf, n, &p_bmi->ohPortBmiRegs, fmbm_occn);
@@ -698,6 +701,9 @@ int fm_port_dump_regs_bmi(void *h_dev, char *buf, int nn)
 		FM_DMP_V32(buf, n, &p_bmi->rxPortBmiRegs, fmbm_rfpne);
 		FM_DMP_V32(buf, n, &p_bmi->rxPortBmiRegs, fmbm_rpso);
 		FM_DMP_V32(buf, n, &p_bmi->rxPortBmiRegs, fmbm_rpp);
+#ifdef USE_ENHANCED_EHASH
+		FM_DMP_V32(buf, n, &p_bmi->rxPortBmiRegs, fmbm_rccb); 
+#endif
 		FM_DMP_TITLE(buf, n, &(p_bmi->rxPortBmiRegs.fmbm_rprai),
 			"fmbm_rprai");
 		for (i = 0; i < FM_PORT_PRS_RESULT_NUM_OF_WORDS; ++i) {
diff --git a/drivers/net/ethernet/freescale/sdk_fman/src/xx/xx_arm_linux.c b/drivers/net/ethernet/freescale/sdk_fman/src/xx/xx_arm_linux.c
index 8c677e254aff..b4505edeb111 100644
--- a/drivers/net/ethernet/freescale/sdk_fman/src/xx/xx_arm_linux.c
+++ b/drivers/net/ethernet/freescale/sdk_fman/src/xx/xx_arm_linux.c
@@ -298,11 +298,18 @@ void * XX_MallocSmart(uint32_t size, int memPartitionId, uint32_t alignment)
     return xx_MallocSmart(size,memPartitionId, alignment);
 }
 
+#ifdef CONFIG_DBG_UCODE_INFRA 
+EXPORT_SYMBOL(XX_MallocSmart);
+#endif // CONFIG_DBG_UCODE_INFRA
+
 void XX_FreeSmart(void *p)
 {
     xx_FreeSmart(p);
 }
 
+#ifdef CONFIG_DBG_UCODE_INFRA 
+EXPORT_SYMBOL(XX_FreeSmart);
+#endif // CONFIG_DBG_UCODE_INFRA
 
 void XX_Free(void *p)
 {
diff --git a/drivers/net/ppp/ppp_generic.c b/drivers/net/ppp/ppp_generic.c
index afc1566488b3..52ffb64c16de 100644
--- a/drivers/net/ppp/ppp_generic.c
+++ b/drivers/net/ppp/ppp_generic.c
@@ -54,6 +54,10 @@
 #include <net/net_namespace.h>
 #include <net/netns/generic.h>
 
+#if defined(CONFIG_CPE_FAST_PATH)
+#include <linux/jiffies.h>
+#endif
+
 #define PPP_VERSION	"2.4.2"
 
 /*
@@ -3519,6 +3523,14 @@ ppp_connect_channel(struct channel *pch, int unit)
 
  outl:
 	write_unlock_bh(&pch->upl);
+#if defined(CONFIG_CPE_FAST_PATH)
+	if ((ppp->dev) && (!ppp->closing)) {
+		rtnl_lock();
+		rtmsg_ifinfo(RTM_NEWLINK, ppp->dev, 0, GFP_KERNEL, 0, NULL);
+		rtnl_unlock();
+	}
+#endif
+
  out:
 	mutex_unlock(&pn->all_ppp_mutex);
 	return ret;
diff --git a/drivers/net/ppp/pppoe.c b/drivers/net/ppp/pppoe.c
index 2ea4f4890d23..454468f3a8d6 100644
--- a/drivers/net/ppp/pppoe.c
+++ b/drivers/net/ppp/pppoe.c
@@ -948,6 +948,14 @@ static int __pppoe_xmit(struct sock *sk, struct sk_buff *skb)
 
 	skb->protocol = cpu_to_be16(ETH_P_PPP_SES);
 	skb->dev = dev;
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)  
+	if((skb->ipsec_offload == 1) && (!secpath_exists(skb)))
+	{
+		dev_hard_header(skb, dev, ETH_P_PPP_SES,
+				dev->dev_addr, po->pppoe_pa.remote, data_len);
+	}
+	else
+#endif
 
 	dev_hard_header(skb, dev, ETH_P_PPP_SES,
 			po->pppoe_pa.remote, NULL, data_len);
@@ -1030,17 +1038,32 @@ static int pppoe_seq_show(struct seq_file *seq, void *v)
 {
 	struct pppox_sock *po;
 	char *dev_name;
+#if defined(CONFIG_CPE_FAST_PATH)
+	char *ppp_name;
+#endif
 
 	if (v == SEQ_START_TOKEN) {
+#if defined(CONFIG_CPE_FAST_PATH)
+		seq_puts(seq, "Id   Address           Device     PPPDevice  Unit\n");
+#else
 		seq_puts(seq, "Id       Address              Device\n");
+#endif
 		goto out;
 	}
 
 	po = v;
 	dev_name = po->pppoe_pa.dev;
+#if defined(CONFIG_CPE_FAST_PATH)
+	ppp_name = ppp_dev_name(&po->chan);
+	if (!ppp_name)
+		goto out;
 
+	seq_printf(seq, "%04X %pM %-10s %-10s %d\n",
+	ntohs(po->pppoe_pa.sid), po->pppoe_pa.remote, dev_name, ppp_name, ppp_unit_number(&po->chan));
+#else
 	seq_printf(seq, "%08X %pM %8s\n",
 		po->pppoe_pa.sid, po->pppoe_pa.remote, dev_name);
+#endif
 out:
 	return 0;
 }
diff --git a/drivers/net/usb/usbnet.c b/drivers/net/usb/usbnet.c
index ccf45ca2feb5..93bf0481c7ce 100644
--- a/drivers/net/usb/usbnet.c
+++ b/drivers/net/usb/usbnet.c
@@ -31,6 +31,15 @@
 #include <linux/kernel.h>
 #include <linux/pm_runtime.h>
 
+#ifdef CONFIG_CPE_FAST_PATH
+/*
+ * We alllocate extra 64 Bytes to reserve headroom in the sk_buff
+ * To be used by Fast Path (Head Room must be 4 Byte aligned
+ * because USB 2.0 controller doesn't support 2 byte alignment
+ */
+#define C2K_USBNET_SKB_HEADROOM_FAST_PATH 64
+#endif
+
 /*-------------------------------------------------------------------------*/
 
 /*
@@ -504,11 +513,19 @@ static int rx_submit (struct usbnet *dev, struct urb *urb, gfp_t flags)
 		usb_free_urb(urb);
 		return -ENOLINK;
 	}
-
+#ifdef CONFIG_CPE_FAST_PATH
+	/* 
+	* We alllocate extra 64 Bytes to reserve headroom in the sk_buff 
+	* To be used by Fast Path (Head Room must be 4 Byte aligned 
+	* because USB 2.0 controller doesn't support 2 byte alignment
+	*/
+	skb = __netdev_alloc_skb(dev->net, size + C2K_USBNET_SKB_HEADROOM_FAST_PATH, GFP_ATOMIC);
+#else
 	if (test_bit(EVENT_NO_IP_ALIGN, &dev->flags))
 		skb = __netdev_alloc_skb(dev->net, size, flags);
 	else
 		skb = __netdev_alloc_skb_ip_align(dev->net, size, flags);
+#endif
 	if (!skb) {
 		netif_dbg(dev, rx_err, dev->net, "no rx skb\n");
 		usbnet_defer_kevent (dev, EVENT_RX_MEMORY);
@@ -516,6 +533,10 @@ static int rx_submit (struct usbnet *dev, struct urb *urb, gfp_t flags)
 		return -ENOMEM;
 	}
 
+#ifdef CONFIG_CPE_FAST_PATH
+	skb_reserve (skb, C2K_USBNET_SKB_HEADROOM_FAST_PATH);
+#endif    
+
 	entry = (struct skb_data *) skb->cb;
 	entry->urb = urb;
 	entry->dev = dev;
diff --git a/drivers/staging/fsl_qbman/Kconfig b/drivers/staging/fsl_qbman/Kconfig
index ef7973c1fdfa..46d74d33600a 100644
--- a/drivers/staging/fsl_qbman/Kconfig
+++ b/drivers/staging/fsl_qbman/Kconfig
@@ -39,6 +39,13 @@ config FSL_SDK_BMAN
 	bool "Freescale Buffer Manager (BMan) support"
 	default y
 
+config FSL_ASK_QMAN_PORTAL_NAPI
+	bool "Enable QMAN Portal NAPI"
+	default y
+	help
+	  This enables NAPI scheduling in portal driver instead of in each
+	  Ethernet driver.
+
 if FSL_SDK_BMAN
 
 config FSL_BMAN_CONFIG
diff --git a/drivers/staging/fsl_qbman/fsl_usdpaa.c b/drivers/staging/fsl_qbman/fsl_usdpaa.c
index db3825b2ff18..b859f2c018b9 100644
--- a/drivers/staging/fsl_qbman/fsl_usdpaa.c
+++ b/drivers/staging/fsl_qbman/fsl_usdpaa.c
@@ -2461,7 +2461,7 @@ static int __init usdpaa_init(void)
 	u64 tmp_size = phys_size;
 	u64 tmp_start = phys_start;
 	u64 tmp_pfn_start = pfn_start;
-
+	printk(KERN_CRIT "Freescale USDPAA process driver\n");
 	pr_info("Freescale USDPAA process driver\n");
 	if (!phys_start) {
 		pr_warn("fsl-usdpaa: no region found\n");
diff --git a/drivers/staging/fsl_qbman/qman_config.c b/drivers/staging/fsl_qbman/qman_config.c
index 114e2773845b..a44e26aff945 100644
--- a/drivers/staging/fsl_qbman/qman_config.c
+++ b/drivers/staging/fsl_qbman/qman_config.c
@@ -963,6 +963,7 @@ int qman_sp_enable_ceetm_mode(enum qm_dc_portal portal, u16 sub_portal)
 	qm_out(DCP_CFG(portal), dcp_cfg);
 	return 0;
 }
+EXPORT_SYMBOL(qman_sp_enable_ceetm_mode);
 
 int qman_sp_disable_ceetm_mode(enum qm_dc_portal portal, u16 sub_portal)
 {
@@ -975,6 +976,7 @@ int qman_sp_disable_ceetm_mode(enum qm_dc_portal portal, u16 sub_portal)
 	qm_out(DCP_CFG(portal), dcp_cfg);
 	return 0;
 }
+EXPORT_SYMBOL(qman_sp_disable_ceetm_mode);
 
 int qman_ceetm_get_xsfdr(enum qm_dc_portal portal, unsigned int *num)
 {
diff --git a/drivers/staging/fsl_qbman/qman_high.c b/drivers/staging/fsl_qbman/qman_high.c
index 4085aa9a2dcb..dc08f09b127e 100644
--- a/drivers/staging/fsl_qbman/qman_high.c
+++ b/drivers/staging/fsl_qbman/qman_high.c
@@ -34,6 +34,9 @@
 
 #include "qman_low.h"
 
+#include <linux/net.h>
+#include <linux/netdevice.h>
+
 /* Compilation constants */
 #define DQRR_MAXFILL	15
 #define EQCR_ITHRESH	4	/* if EQCR congests, interrupt threshold */
@@ -69,6 +72,33 @@
 			spin_unlock(&__fq478->fqlock); \
 	} while (0)
 
+#if 1
+#define display_ceetm_cmd(a,b,c)
+#else
+#define display_ceetm_cmd(a, b, c) _display_ceetm_cmd((char *)__FUNCTION__, a, b, c)
+static void _display_ceetm_cmd(char *func, uint32_t verb, void *buf, uint32_t size)
+{
+	uint8_t *ptr;
+	uint32_t ii,jj=0;
+	uint8_t buff[200];
+
+	ptr = buf;
+	jj = sprintf(buff, "%s::\n%02x ", func, verb);
+	for (ii = 1; ii <= size; ii++) {
+		if (ii && ((ii % 16) == 0))
+		{
+			buff[jj] = 0;
+			printk("%s\n", buff);
+			jj = 0;
+		}
+		jj += sprintf(buff+jj, "%02x ", *ptr);
+		ptr++;
+	}
+	buff[jj] = 0;
+	printk("%s\n\n", buff);
+}
+#endif
+
 static inline void fq_set(struct qman_fq *fq, u32 mask)
 {
 	set_bits(mask, &fq->flags);
@@ -128,6 +158,10 @@ struct qman_portal {
 	u8 alloced;
 	/* power management data */
 	u32 save_isdr;
+#ifdef CONFIG_FSL_ASK_QMAN_PORTAL_NAPI
+	struct net_device dummy_dev;
+	struct napi_struct napi;
+#endif
 #if __BYTE_ORDER__ == __ORDER_LITTLE_ENDIAN__
 	/* Keep a shadow copy of the DQRR on LE systems as the SW needs to
 	 * do byte swaps of DQRR read only memory.  First entry must be aligned
@@ -473,7 +507,16 @@ static irqreturn_t portal_isr(__always_unused int irq, void *ptr)
 
 	/* DQRR-handling if it's interrupt-driven */
 	if (is & QM_PIRQ_DQRI) {
+#ifndef CONFIG_FSL_ASK_QMAN_PORTAL_NAPI
 		__poll_portal_fast(p, CONFIG_FSL_QMAN_POLL_LIMIT);
+#else
+		/* Disable QMan IRQ and invoke NAPI */
+		qman_p_irqsource_remove(p, QM_PIRQ_DQRI);
+		if (napi_schedule_prep(&p->napi))
+		{
+			__napi_schedule(&p->napi);
+		}
+#endif
 		clear = QM_DQAVAIL_MASK | QM_PIRQ_DQRI;
 	}
 
@@ -575,6 +618,27 @@ struct dev_pm_domain qman_portal_device_pm_domain = {
 	}
 };
 
+
+
+#ifdef CONFIG_FSL_ASK_QMAN_PORTAL_NAPI
+static int qman_portal_dqrr_poll(struct napi_struct *napi, int budget)
+{
+	struct qman_portal *portal = container_of(napi, struct qman_portal, napi);
+
+	int cleaned = qman_p_poll_dqrr(portal, budget);
+
+	if (cleaned < budget) {
+		int tmp;
+		napi_complete(napi);
+		tmp = qman_p_irqsource_add(portal, QM_PIRQ_DQRI);
+		//     DPA_BUG_ON(tmp);
+	}
+
+	return cleaned;
+}
+#endif
+
+
 struct qman_portal *qman_create_portal(
 			struct qman_portal *portal,
 			const struct qm_portal_config *config,
@@ -737,6 +801,12 @@ struct qman_portal *qman_create_portal(
 			goto fail_dqrr_mr_empty;
 		}
 	}
+#ifdef CONFIG_FSL_ASK_QMAN_PORTAL_NAPI
+	/* Initilize NAPI for Rx processing */
+	init_dummy_netdev(&portal->dummy_dev);
+	netif_napi_add(&portal->dummy_dev, &portal->napi, qman_portal_dqrr_poll);
+	napi_enable(&portal->napi);
+#endif
 	/* Success */
 	portal->config = config;
 	/*
@@ -832,6 +902,11 @@ void qman_destroy_portal(struct qman_portal *qm)
 	const struct qm_portal_config *pcfg;
 	int i;
 
+#ifdef CONFIG_FSL_ASK_QMAN_PORTAL_NAPI
+	napi_disable(&qm->napi);
+	netif_napi_del(&qm->napi);
+#endif
+
 	/* Stop dequeues on the portal */
 	qm_dqrr_sdqcr_set(&qm->p, 0);
 
@@ -3170,6 +3245,7 @@ static int qman_ceetm_configure_lfqmt(struct qm_mcc_ceetm_lfqmt_config *opts)
 	p = get_affine_portal();
 	PORTAL_IRQ_LOCK(p, irqflags);
 
+	display_ceetm_cmd(QM_CEETM_VERB_LFQMT_CONFIG, opts, sizeof(struct qm_mcc_ceetm_lfqmt_config));
 	mcc = qm_mc_start(&p->p);
 	mcc->lfqmt_config = *opts;
 	qm_mc_commit(&p->p, QM_CEETM_VERB_LFQMT_CONFIG);
@@ -3233,6 +3309,7 @@ static int qman_ceetm_configure_cq(struct qm_mcc_ceetm_cq_config *opts)
 
 	mcc = qm_mc_start(&p->p);
 	mcc->cq_config = *opts;
+	display_ceetm_cmd(QM_CEETM_VERB_CQ_CONFIG, opts, sizeof(struct qm_mcc_ceetm_cq_config));
 	qm_mc_commit(&p->p, QM_CEETM_VERB_CQ_CONFIG);
 	while (!(mcr = qm_mc_result(&p->p)))
 		cpu_relax();
@@ -3296,7 +3373,7 @@ static int qman_ceetm_configure_dct(struct qm_mcc_ceetm_dct_config *opts)
 
 	p = get_affine_portal();
 	PORTAL_IRQ_LOCK(p, irqflags);
-
+	display_ceetm_cmd(QM_CEETM_VERB_DCT_CONFIG, opts, sizeof(struct qm_mcc_ceetm_dct_config));
 	mcc = qm_mc_start(&p->p);
 	mcc->dct_config = *opts;
 	qm_mc_commit(&p->p, QM_CEETM_VERB_DCT_CONFIG);
@@ -3360,6 +3437,8 @@ static int qman_ceetm_configure_class_scheduler(
 
 	mcc = qm_mc_start(&p->p);
 	mcc->csch_config = *opts;
+	display_ceetm_cmd(QM_CEETM_VERB_CLASS_SCHEDULER_CONFIG, opts,
+		sizeof(struct qm_mcc_ceetm_class_scheduler_config));
 	qm_mc_commit(&p->p, QM_CEETM_VERB_CLASS_SCHEDULER_CONFIG);
 	while (!(mcr = qm_mc_result(&p->p)))
 		cpu_relax();
@@ -3410,7 +3489,7 @@ static int qman_ceetm_query_class_scheduler(struct qm_ceetm_channel *channel,
 	return 0;
 }
 
-static int qman_ceetm_configure_mapping_shaper_tcfc(
+int qman_ceetm_configure_mapping_shaper_tcfc(
 		struct qm_mcc_ceetm_mapping_shaper_tcfc_config *opts)
 {
 	struct qm_mc_command *mcc;
@@ -3423,6 +3502,8 @@ static int qman_ceetm_configure_mapping_shaper_tcfc(
 	PORTAL_IRQ_LOCK(p, irqflags);
 
 	mcc = qm_mc_start(&p->p);
+	display_ceetm_cmd(QM_CEETM_VERB_MAPPING_SHAPER_TCFC_CONFIG, opts, 
+	       sizeof(struct qm_mcc_ceetm_mapping_shaper_tcfc_config));
 	mcc->mst_config = *opts;
 	qm_mc_commit(&p->p, QM_CEETM_VERB_MAPPING_SHAPER_TCFC_CONFIG);
 	while (!(mcr = qm_mc_result(&p->p)))
@@ -3440,6 +3521,7 @@ static int qman_ceetm_configure_mapping_shaper_tcfc(
 	}
 	return 0;
 }
+EXPORT_SYMBOL(qman_ceetm_configure_mapping_shaper_tcfc);
 
 static int qman_ceetm_query_mapping_shaper_tcfc(
 		struct qm_mcc_ceetm_mapping_shaper_tcfc_query *opts,
@@ -3485,7 +3567,7 @@ static int qman_ceetm_configure_ccgr(struct qm_mcc_ceetm_ccgr_config *opts)
 
 	p = get_affine_portal();
 	PORTAL_IRQ_LOCK(p, irqflags);
-
+	display_ceetm_cmd(QM_CEETM_VERB_CCGR_CONFIG, opts, sizeof(struct qm_mcc_ceetm_ccgr_config));
 	mcc = qm_mc_start(&p->p);
 	mcc->ccgr_config = *opts;
 
@@ -3903,6 +3985,7 @@ int qman_ceetm_lni_enable_shaper(struct qm_ceetm_lni *lni, int coupled,
 	lni->shaper_couple = coupled;
 	lni->oal = oal;
 
+	memset(&config_opts, 0, sizeof(struct qm_mcc_ceetm_mapping_shaper_tcfc_config));
 	config_opts.cid = cpu_to_be16(CEETM_COMMAND_LNI_SHAPER | lni->idx);
 	config_opts.dcpid = lni->dcp_idx;
 	config_opts.shaper_config.cpl = coupled;
@@ -3936,7 +4019,8 @@ int qman_ceetm_lni_disable_shaper(struct qm_ceetm_lni *lni)
 		pr_err("The shaper has been disabled\n");
 		return -EINVAL;
 	}
-
+	
+	memset(&config_opts, 0, sizeof(struct qm_mcc_ceetm_mapping_shaper_tcfc_config));
 	config_opts.cid = cpu_to_be16(CEETM_COMMAND_LNI_SHAPER | lni->idx);
 	config_opts.dcpid = lni->dcp_idx;
 	config_opts.shaper_config.cpl = lni->shaper_couple;
@@ -4173,6 +4257,7 @@ int qman_ceetm_lni_set_tcfcc(struct qm_ceetm_lni *lni,
 		return -EINVAL;
 	}
 
+	memset(&config_opts, 0, sizeof(struct qm_mcc_ceetm_mapping_shaper_tcfc_config));
 	query_opts.cid = cpu_to_be16(CEETM_COMMAND_TCFC | lni->idx);
 	query_opts.dcpid = lni->dcp_idx;
 	if (qman_ceetm_query_mapping_shaper_tcfc(&query_opts, &query_result)) {
@@ -4254,6 +4339,7 @@ int qman_ceetm_channel_claim(struct qm_ceetm_channel **channel,
 	p = kzalloc(sizeof(*p), GFP_KERNEL);
 	if (!p)
 		return -ENOMEM;
+	memset(&config_opts, 0, sizeof(struct qm_mcc_ceetm_mapping_shaper_tcfc_config));
 	p->idx = channel_idx;
 	p->dcp_idx = lni->dcp_idx;
 	p->lni_idx = lni->idx;
@@ -4264,7 +4350,7 @@ int qman_ceetm_channel_claim(struct qm_ceetm_channel **channel,
 						channel_idx);
 	config_opts.dcpid = lni->dcp_idx;
 	config_opts.channel_mapping.map_lni_id = lni->idx;
-	config_opts.channel_mapping.map_shaped = 0;
+	config_opts.channel_mapping.map_shaped = 1;
 	if (qman_ceetm_configure_mapping_shaper_tcfc(&config_opts)) {
 		pr_err("Can't map channel#%d for LNI#%d\n",
 						channel_idx, lni->idx);
@@ -4296,7 +4382,7 @@ int qman_ceetm_channel_release(struct qm_ceetm_channel *channel)
 			channel->dcp_idx);
 		return -EINVAL;
 	}
-
+	memset(&config_opts, 0, sizeof(struct qm_mcc_ceetm_mapping_shaper_tcfc_config));
 	config_opts.cid = cpu_to_be16(CEETM_COMMAND_CHANNEL_SHAPER |
 				      channel->idx);
 	config_opts.dcpid = channel->dcp_idx;
@@ -4334,7 +4420,7 @@ int qman_ceetm_channel_enable_shaper(struct qm_ceetm_channel *channel,
 		pr_err("This channel shaper has been enabled!\n");
 		return -EINVAL;
 	}
-
+	memset(&config_opts, 0, sizeof(struct qm_mcc_ceetm_mapping_shaper_tcfc_config));
 	channel->shaper_enable = 1;
 	channel->shaper_couple = coupled;
 
@@ -4347,6 +4433,7 @@ int qman_ceetm_channel_enable_shaper(struct qm_ceetm_channel *channel,
 		return -EINVAL;
 	}
 
+	memset(&config_opts, 0, sizeof(struct qm_mcc_ceetm_mapping_shaper_tcfc_config));
 	config_opts.cid = cpu_to_be16(CEETM_COMMAND_CHANNEL_MAPPING |
 						channel->idx);
 	config_opts.dcpid = channel->dcp_idx;
@@ -4441,7 +4528,7 @@ int qman_ceetm_channel_set_commit_rate(struct qm_ceetm_channel *channel,
 		pr_err("Fail to get the current channel shaper setting\n");
 		return -EINVAL;
 	}
-
+	memset(&config_opts, 0, sizeof(struct qm_mcc_ceetm_mapping_shaper_tcfc_config));
 	channel->cr_token_rate.whole = token_rate->whole;
 	channel->cr_token_rate.fraction = token_rate->fraction;
 	channel->cr_token_bucket_limit = token_limit;
@@ -4534,7 +4621,8 @@ int qman_ceetm_channel_set_excess_rate(struct qm_ceetm_channel *channel,
 		pr_err("Fail to get the current channel shaper setting\n");
 		return -EINVAL;
 	}
-
+	
+	memset(&config_opts, 0, sizeof(struct qm_mcc_ceetm_mapping_shaper_tcfc_config));
 	channel->er_token_rate.whole = token_rate->whole;
 	channel->er_token_rate.fraction = token_rate->fraction;
 	channel->er_token_bucket_limit = token_limit;
@@ -4618,7 +4706,7 @@ int qman_ceetm_channel_set_weight(struct qm_ceetm_channel *channel,
 		pr_err("This channel is a shaped one\n");
 		return -EINVAL;
 	}
-
+	memset(&config_opts, 0, sizeof(struct qm_mcc_ceetm_mapping_shaper_tcfc_config));
 	channel->cr_token_bucket_limit = token_limit;
 	config_opts.cid = cpu_to_be16(CEETM_COMMAND_CHANNEL_SHAPER |
 						channel->idx);
@@ -4668,7 +4756,7 @@ int qman_ceetm_channel_set_group(struct qm_ceetm_channel *channel, int group_b,
 		pr_err("Can't query channel#%d's scheduler!\n", channel->idx);
 		return -EINVAL;
 	}
-
+	memset(&config_opts, 0, sizeof(struct qm_mcc_ceetm_mapping_shaper_tcfc_config));
 	config_opts.cqcid = cpu_to_be16(channel->idx);
 	config_opts.dcpid = channel->dcp_idx;
 	config_opts.gpc_combine_flag = !group_b;
@@ -4759,6 +4847,7 @@ int qman_ceetm_channel_set_group_er_eligibility(struct qm_ceetm_channel
 						channel->idx);
 		return -EINVAL;
 	}
+	memset(&csch_config, 0, sizeof(struct qm_mcc_ceetm_class_scheduler_config));
 	csch_config.cqcid = cpu_to_be16(channel->idx);
 	csch_config.dcpid = channel->dcp_idx;
 	csch_config.gpc_combine_flag = csch_query.gpc_combine_flag;
@@ -4806,6 +4895,7 @@ int qman_ceetm_channel_set_cq_cr_eligibility(struct qm_ceetm_channel *channel,
 						channel->idx);
 		return -EINVAL;
 	}
+	memset(&csch_config, 0, sizeof(struct qm_mcc_ceetm_class_scheduler_config));
 	csch_config.cqcid = cpu_to_be16(channel->idx);
 	csch_config.dcpid = channel->dcp_idx;
 	csch_config.gpc_combine_flag = csch_query.gpc_combine_flag;
@@ -4889,7 +4979,7 @@ int qman_ceetm_cq_claim(struct qm_ceetm_cq **cq,
 		pr_err("Can't allocate memory for CQ#%d!\n", idx);
 		return -ENOMEM;
 	}
-
+	memset(&cq_config, 0, sizeof(struct qm_mcc_ceetm_cq_config));
 	list_add_tail(&p->node, &channel->class_queues);
 	p->idx = idx;
 	p->is_claimed = 1;
@@ -4938,7 +5028,7 @@ int qman_ceetm_cq_claim_A(struct qm_ceetm_cq **cq,
 		pr_err("Can't allocate memory for CQ#%d!\n", idx);
 		return -ENOMEM;
 	}
-
+	memset(&cq_config, 0, sizeof(struct qm_mcc_ceetm_cq_config));
 	list_add_tail(&p->node, &channel->class_queues);
 	p->idx = idx;
 	p->is_claimed = 1;
@@ -4986,7 +5076,7 @@ int qman_ceetm_cq_claim_B(struct qm_ceetm_cq **cq,
 		pr_err("Can't allocate memory for CQ#%d!\n", idx);
 		return -ENOMEM;
 	}
-
+	memset(&cq_config, 0, sizeof(struct qm_mcc_ceetm_cq_config));
 	list_add_tail(&p->node, &channel->class_queues);
 	p->idx = idx;
 	p->is_claimed = 1;
@@ -5040,7 +5130,7 @@ int qman_ceetm_set_queue_weight(struct qm_ceetm_cq *cq,
 						cq->parent->idx);
 		return -EINVAL;
 	}
-
+	memset(&config_opts, 0, sizeof(struct qm_mcc_ceetm_class_scheduler_config));
 	config_opts.cqcid = cpu_to_be16(cq->parent->idx);
 	config_opts.dcpid = cq->parent->dcp_idx;
 	config_opts.crem = query_result.crem;
@@ -5257,6 +5347,7 @@ int qman_ceetm_lfq_claim(struct qm_ceetm_lfq **lfq,
 	p = kmalloc(sizeof(*p), GFP_KERNEL);
 	if (!p)
 		return -ENOMEM;
+	memset(&lfqmt_config, 0, sizeof(struct qm_mcc_ceetm_lfqmt_config));
 	p->idx = lfqid;
 	p->dctidx = (u16)(lfqid & CEETM_LFQMT_LFQID_LSB);
 	p->parent = cq->parent;
diff --git a/include/linux/fsl_oh_port.h b/include/linux/fsl_oh_port.h
new file mode 100644
index 000000000000..03eb762aa0a4
--- /dev/null
+++ b/include/linux/fsl_oh_port.h
@@ -0,0 +1,26 @@
+// SPDX-License-Identifier: GPL-2.0+
+/*
+ * Copyright 2018 NXP
+ */
+
+/*
+ * include/linux/fsl_oh_port.h
+ *
+ * Definitions for offline parsing port device related flags or structures i
+ */
+
+#ifndef _FSL_OH_PORT_H_
+#define _FSL_OH_PORT_H_
+
+#define MAX_FMANS               1
+#define MAX_OFFLINE_PORTS       4
+
+struct fman_offline_port_info {
+	char port_name[32];
+	uint32_t channel_id;
+	uint32_t err_fqid;
+	uint32_t default_fqid;
+};
+int oh_port_driver_get_port_info(struct fman_offline_port_info *info);
+
+#endif
diff --git a/include/linux/fsl_qman.h b/include/linux/fsl_qman.h
index c42bde697436..68225db4d865 100644
--- a/include/linux/fsl_qman.h
+++ b/include/linux/fsl_qman.h
@@ -3963,6 +3963,12 @@ static inline int qman_portals_probed(void) {
 	return 1;
 }
 
+int qman_ceetm_configure_mapping_shaper_tcfc(
+	struct qm_mcc_ceetm_mapping_shaper_tcfc_config *opts);
+/* Macro used to configure queue for control traffic, 7 is the highest */
+#define QOS_DEFAULT_QUEUE      7
+#define QOS_LEAST_PRIORITY_QUEUE   0
+
 #ifdef __cplusplus
 }
 #endif
diff --git a/include/linux/if_bridge.h b/include/linux/if_bridge.h
index 3ff96ae31bf6..c3097859102e 100644
--- a/include/linux/if_bridge.h
+++ b/include/linux/if_bridge.h
@@ -71,6 +71,23 @@ void brioctl_set(int (*hook)(struct net *net, struct net_bridge *br,
 int br_ioctl_call(struct net *net, struct net_bridge *br, unsigned int cmd,
 		  struct ifreq *ifr, void __user *uarg);
 
+#if defined(CONFIG_CPE_FAST_PATH)
+struct brevent_fdb_update{
+	char * mac_addr;
+	struct net_device * dev;
+	struct net_device * brdev;
+};
+
+enum brevent_notif_type {
+	BREVENT_PORT_DOWN = 1,  /* arg is struct net_device ptr */
+	BREVENT_FDB_UPDATE  /* arg is struct brevent_fdb_update ptr */
+};
+
+int register_brevent_notifier(struct notifier_block *nb);
+int unregister_brevent_notifier(struct notifier_block *nb);
+int call_brevent_notifiers(unsigned long val, void *v);
+#endif
+
 #if IS_ENABLED(CONFIG_BRIDGE) && IS_ENABLED(CONFIG_BRIDGE_IGMP_SNOOPING)
 int br_multicast_list_adjacent(struct net_device *dev,
 			       struct list_head *br_ip_list);
diff --git a/include/linux/netdevice.h b/include/linux/netdevice.h
index 35b886385f32..18df164f5752 100644
--- a/include/linux/netdevice.h
+++ b/include/linux/netdevice.h
@@ -2071,6 +2071,10 @@ struct net_device {
 	__cacheline_group_begin(net_device_read_rx);
 	struct bpf_prog __rcu	*xdp_prog;
 	struct list_head	ptype_specific;
+#if defined(CONFIG_CPE_FAST_PATH)
+	/* This is pointing to network device that offload WiFi data to PFE */
+	struct net_device	*wifi_offload_dev;
+#endif
 	int			ifindex;
 	unsigned int		real_num_rx_queues;
 	struct netdev_rx_queue	*_rx;
@@ -3097,10 +3101,27 @@ u16 dev_pick_tx_zero(struct net_device *dev, struct sk_buff *skb,
 int __dev_queue_xmit(struct sk_buff *skb, struct net_device *sb_dev);
 int __dev_direct_xmit(struct sk_buff *skb, u16 queue_id);
 
+#if defined(CONFIG_CPE_FAST_PATH)
+int original_dev_queue_xmit(struct sk_buff *skb);
+typedef int (*dpaa_wifi_xmit_local_hook_t)(struct sk_buff *skb);
+int dpa_register_wifi_xmit_local_hook(dpaa_wifi_xmit_local_hook_t hookfn);
+void dpa_unregister_wifi_xmit_local_hook(void);
+int dpa_add_dummy_eth_hdr(struct sk_buff** skb_in, int priv_headroom, unsigned char *hdroom_realloc);
+extern dpaa_wifi_xmit_local_hook_t dpaa_wifi_xmit_local_ipsec_handler;
+
+static inline int dev_queue_xmit(struct sk_buff *skb)
+{
+	if (dpaa_wifi_xmit_local_ipsec_handler && skb->ipsec_offload &&
+	    skb->dev->wifi_offload_dev)
+		return dpaa_wifi_xmit_local_ipsec_handler(skb);
+	return original_dev_queue_xmit(skb);
+}
+#else
 static inline int dev_queue_xmit(struct sk_buff *skb)
 {
 	return __dev_queue_xmit(skb, NULL);
 }
+#endif
 
 static inline int dev_queue_xmit_accel(struct sk_buff *skb,
 				       struct net_device *sb_dev)
@@ -5271,6 +5292,14 @@ extern struct list_head ptype_base[PTYPE_HASH_SIZE] __read_mostly;
 
 extern struct net_device *blackhole_netdev;
 
+#if defined(CONFIG_CPE_FAST_PATH)
+/* hook function for getting statistics from offloaded interfaces */
+typedef void (*fp_iface_stats_get)(struct net_device *device, struct rtnl_link_stats64 *tot);
+
+void dev_fp_stats_get_register(fp_iface_stats_get func);
+void dev_fp_stats_get_deregister(void);
+#endif
+
 /* Note: Avoid these macros in fast path, prefer per-cpu or per-queue counters. */
 #define DEV_STATS_INC(DEV, FIELD) atomic_long_inc(&(DEV)->stats.__##FIELD)
 #define DEV_STATS_ADD(DEV, FIELD, VAL) 	\
diff --git a/include/linux/poll.h b/include/linux/poll.h
index fc641b50f129..2b1f63e79be8 100644
--- a/include/linux/poll.h
+++ b/include/linux/poll.h
@@ -126,7 +126,6 @@ extern int poll_select_set_timeout(struct timespec64 *to, time64_t sec,
 
 #define __MAP(v, from, to) \
 	(from < to ? (v & from) * (to/from) : (v & from) / (from/to))
-
 static inline __u16 mangle_poll(__poll_t val)
 {
 	__u16 v = (__force __u16)val;
diff --git a/include/linux/skbuff.h b/include/linux/skbuff.h
index 7cf21f8ce51b..a5aaed9677f5 100644
--- a/include/linux/skbuff.h
+++ b/include/linux/skbuff.h
@@ -1034,6 +1034,13 @@ struct sk_buff {
 	};
 	__u32			priority;
 	int			skb_iif;
+#ifdef CONFIG_CPE_FAST_PATH
+	unsigned char		abm_ff;
+	unsigned char		expt_pkt;
+	int			iif_index;
+	int			underlying_iif;
+	__u16			underlying_vlan_tci;
+#endif
 	__u32			hash;
 	union {
 		u32		vlan_all;
@@ -1057,6 +1064,14 @@ struct sk_buff {
 		__u32		reserved_tailroom;
 	};
 
+#ifdef CONFIG_CPE_FAST_PATH
+	__u64			qosmark;
+#endif
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	__u16			ipsec_offload;
+	__u16			ipsec_xfrm_dir;
+#endif
+
 	union {
 		__be16		inner_protocol;
 		__u8		inner_ipproto;
diff --git a/include/net/ip.h b/include/net/ip.h
index bd201278c55a..25c7870e2485 100644
--- a/include/net/ip.h
+++ b/include/net/ip.h
@@ -723,6 +723,9 @@ enum ip_defrag_users {
 	IP_DEFRAG_VS_FWD,
 	IP_DEFRAG_AF_PACKET,
 	IP_DEFRAG_MACVLAN,
+#ifdef CONFIG_CPE_TNL_4RD
+	IP_DEFRAG_IP6_TNL_4RD /* Used to support Post Fragmentation for 4o6 tunnels */
+#endif
 };
 
 /* Return true if the value of 'user' is between 'lower_bond'
diff --git a/include/net/ip6_tunnel.h b/include/net/ip6_tunnel.h
index 399592405c72..9835c0561cd0 100644
--- a/include/net/ip6_tunnel.h
+++ b/include/net/ip6_tunnel.h
@@ -52,7 +52,12 @@ struct ip6_tnl {
 	struct flowi fl;	/* flowi template for xmit */
 	struct dst_cache dst_cache;	/* cached dst */
 	struct gro_cells gro_cells;
-
+#if defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	u32 genid;
+#endif
+#ifdef CONFIG_CPE_4RD_TUNNEL
+	struct ip6_tnl_4rd_parm ip4rd; /* 4rd parameters for the tunnel */
+#endif
 	int err_count;
 	unsigned long err_time;
 
diff --git a/include/net/netfilter/nf_conntrack.h b/include/net/netfilter/nf_conntrack.h
index 8cb70e7485e2..846d19ff054f 100644
--- a/include/net/netfilter/nf_conntrack.h
+++ b/include/net/netfilter/nf_conntrack.h
@@ -24,6 +24,11 @@
 
 #include <net/netfilter/nf_conntrack_tuple.h>
 
+#ifdef CONFIG_CPE_FAST_PATH
+#define LAYERSCAPE_PERMANENT_TIMEOUT  1000
+#endif
+
+
 struct nf_ct_udp {
 	unsigned long	stream_ts;
 };
@@ -68,10 +73,31 @@ struct nf_conntrack_net {
 
 #include <linux/types.h>
 #include <linux/skbuff.h>
+#if defined(CONFIG_CPE_FAST_PATH)
+#ifndef IPSEC_FLOW_CACHE
+#include <net/xfrm.h>
+#endif
+#endif
 
 #include <net/netfilter/ipv4/nf_conntrack_ipv4.h>
 #include <net/netfilter/ipv6/nf_conntrack_ipv6.h>
 
+#if defined(CONFIG_CPE_FAST_PATH)
+#ifndef IPSEC_FLOW_CACHE
+#define MAX_SUPPORTED_XFRMS_PER_DIR 2
+#endif
+struct comcerto_fp_info {
+	int ifindex;
+	int iif;
+	int underlying_iif;
+	u32 mark;
+#ifndef IPSEC_FLOW_CACHE
+	u16 xfrm_handle[MAX_SUPPORTED_XFRMS_PER_DIR*2];
+#endif
+	u16 underlying_vlan_id;
+};
+#endif
+
 struct nf_conn {
 	/* Usage count in here is 1 for hash table, 1 per skb,
 	 * plus 1 for any connection(s) we are `master' for
@@ -118,6 +144,11 @@ struct nf_conn {
 	u_int32_t secmark;
 #endif
 
+#if defined(CONFIG_CPE_FAST_PATH)
+	u_int64_t qosconnmark;
+	struct comcerto_fp_info fp_info[IP_CT_DIR_MAX];
+#endif
+
 	/* Extensions */
 	struct nf_ct_ext *ext;
 
@@ -273,6 +304,12 @@ static inline int nf_ct_is_dying(const struct nf_conn *ct)
 {
 	return test_bit(IPS_DYING_BIT, &ct->status);
 }
+#ifdef CONFIG_CPE_FAST_PATH
+static inline int nf_ct_is_permanent(const struct nf_conn *ct)
+{
+	return test_bit(IPS_PERMANENT_BIT, &ct->status);
+}
+#endif
 
 /* Packet is received from loopback */
 static inline bool nf_is_loopback_packet(const struct sk_buff *skb)
@@ -296,11 +333,19 @@ static inline void nf_conntrack_alter_reply(struct nf_conn *ct,
 static inline unsigned long nf_ct_expires(const struct nf_conn *ct)
 {
 	s32 timeout = READ_ONCE(ct->timeout) - nfct_time_stamp;
-
+#ifdef CONFIG_CPE_FAST_PATH
+	return (nf_ct_is_permanent(ct))? LAYERSCAPE_PERMANENT_TIMEOUT : max(timeout, 0);
+#else
 	return max(timeout, 0);
+#endif
 }
 
+#ifdef CONFIG_CPE_FAST_PATH
+bool nf_ct_is_expired(const struct nf_conn *ct);
+static inline bool __nf_ct_is_expired(const struct nf_conn *ct)
+#else
 static inline bool nf_ct_is_expired(const struct nf_conn *ct)
+#endif
 {
 	return (__s32)(READ_ONCE(ct->timeout) - nfct_time_stamp) <= 0;
 }
@@ -337,6 +382,11 @@ static inline void nf_ct_offload_timeout(struct nf_conn *ct)
 
 struct kernel_param;
 
+#if defined(CONFIG_CPE_FAST_PATH)
+extern int nf_conntrack_set_dpi_allow_report(struct sk_buff *skb);
+extern int nf_conntrack_set_dpi_allow_and_mark(struct sk_buff *skb, int mark);
+#endif
+
 int nf_conntrack_set_hashsize(const char *val, const struct kernel_param *kp);
 int nf_conntrack_hash_resize(unsigned int hashsize);
 
diff --git a/include/net/netns/xfrm.h b/include/net/netns/xfrm.h
index 23dd647fe024..9c7c9758e5e1 100644
--- a/include/net/netns/xfrm.h
+++ b/include/net/netns/xfrm.h
@@ -42,6 +42,9 @@ struct netns_xfrm {
 	struct hlist_head	__rcu *state_bydst;
 	struct hlist_head	__rcu *state_bysrc;
 	struct hlist_head	__rcu *state_byspi;
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	struct hlist_head	__rcu *state_byh;
+#endif
 	struct hlist_head	__rcu *state_byseq;
 	struct hlist_head	 __percpu *state_cache_input;
 	unsigned int		state_hmask;
diff --git a/include/net/tcp.h b/include/net/tcp.h
index 3255a199ef60..ab98025206df 100644
--- a/include/net/tcp.h
+++ b/include/net/tcp.h
@@ -137,6 +137,10 @@ void tcp_time_wait(struct sock *sk, int state, int timeo);
 #define TCP_DELACK_MAX	((unsigned)(HZ/5))	/* maximal time to delay before sending an ACK */
 static_assert((1 << ATO_BITS) > TCP_DELACK_MAX);
 
+#ifdef CONFIG_COMCERTO_TCP_DELACK_MIN
+#define TCP_DELACK_MIN ((unsigned)(HZ/100))
+#define TCP_ATO_MIN    ((unsigned)(HZ/100))
+#else
 #if HZ >= 100
 #define TCP_DELACK_MIN	((unsigned)(HZ/25))	/* minimal time to delay before sending an ACK */
 #define TCP_ATO_MIN	((unsigned)(HZ/25))
@@ -144,6 +148,7 @@ static_assert((1 << ATO_BITS) > TCP_DELACK_MAX);
 #define TCP_DELACK_MIN	4U
 #define TCP_ATO_MIN	4U
 #endif
+#endif
 #define TCP_RTO_MAX	((unsigned)(120*HZ))
 #define TCP_RTO_MIN	((unsigned)(HZ/5))
 #define TCP_TIMEOUT_MIN	(2U) /* Min timeout for TCP timers in jiffies */
diff --git a/include/net/xfrm.h b/include/net/xfrm.h
index 1484dd15a369..6a0225dbaf4f 100644
--- a/include/net/xfrm.h
+++ b/include/net/xfrm.h
@@ -183,6 +183,12 @@ struct xfrm_state {
 		struct hlist_node	bysrc;
 	};
 	struct hlist_node	byspi;
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	struct hlist_node	byh;
+	u16			handle;
+	u16			in_byh_hash;
+	u16			parent_sa_handle; /*handle of the old SA from which this SA is created using rekey*/
+#endif
 	struct hlist_node	byseq;
 	struct hlist_node	state_cache;
 	struct hlist_node	state_cache_input;
@@ -300,6 +306,11 @@ struct xfrm_state {
 	/* Private data of this transformer, format is opaque,
 	 * interpreted by xfrm_type methods. */
 	void			*data;
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	/* Intended direction of this state, used for offloading */
+	int	offloaded;
+	u64	curr_time;
+#endif
 	u8			dir;
 };
 
@@ -320,6 +331,13 @@ enum {
 	XFRM_STATE_EXPIRED,
 	XFRM_STATE_DEAD
 };
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+enum {
+	 XFRM_STATE_DIR_UNKNOWN,
+	 XFRM_STATE_DIR_IN,
+	 XFRM_STATE_DIR_OUT,
+};
+#endif
 
 /* callback structure passed from either netlink or pfkey */
 struct km_event {
@@ -1114,6 +1132,35 @@ struct sec_path {
 
 struct sec_path *secpath_set(struct sk_buff *skb);
 
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+struct xfrm_input_shared
+{
+	struct sk_buff 		*skb;
+	int 			xfrm_nr, first, xfrm_encap;
+	struct xfrm_state 	*xfrm_vec[XFRM_MAX_DEPTH];
+	__u16 			encap_type;
+	int 			decaps;
+	u32			seq, spi;
+	unsigned int   nhoff;
+	int 			nexthdr;
+	int 			(*callback)(struct xfrm_input_shared *sh);
+	atomic_t		refcnt;
+};
+
+
+static inline void xfrm_shared_get(struct xfrm_input_shared *sh)
+{
+	atomic_inc(&sh->refcnt);
+}
+
+static inline void xfrm_shared_put(struct xfrm_input_shared *sh)
+{
+	if (atomic_dec_and_test(&sh->refcnt)) {
+		kfree(sh);
+	}
+}
+#endif
+
 static inline void
 secpath_reset(struct sk_buff *skb)
 {
diff --git a/include/uapi/linux/fmd/Peripherals/fm_ioctls.h b/include/uapi/linux/fmd/Peripherals/fm_ioctls.h
index 3cc27cafecba..e4838bd36562 100644
--- a/include/uapi/linux/fmd/Peripherals/fm_ioctls.h
+++ b/include/uapi/linux/fmd/Peripherals/fm_ioctls.h
@@ -606,6 +606,34 @@ typedef struct ioc_fm_ctrl_mon_counters_params_t {
 #endif
 #define FM_IOC_CTRL_MON_GET_COUNTERS                       _IOW(FM_IOC_TYPE_BASE, FM_IOC_NUM(17), ioc_fm_ctrl_mon_counters_params_t)
 
+/**************************************************************************//**
+ @Function      FM_ReadTimeStamp
+
+ @Description   Reads the FMan engine's timestamp.
+
+ @Param[out]    uint32_t                   The indicated engine's timestamp
+
+ @Return        E_OK on success; Error code otherwise.
+
+ @Cautions      Allowed only following FM_Init().
+*//***************************************************************************/
+#define FM_IOC_READ_TIMESTAMP                              _IOWR(FM_IOC_TYPE_BASE, FM_IOC_NUM(18), uint32_t)
+
+/**************************************************************************//**
+ @Function      FM_GetTimeStampIncrementPerUsec
+
+ @Description   Provides the value of the FMan engine's timestamp increment
+                per microsecond.
+
+ @Param[out]    uint32_t                   The value the timestamp is
+                                           incremented with each microsecond
+
+ @Return        E_OK on success; Error code otherwise.
+
+ @Cautions      Allowed only following FM_Init().
+*//***************************************************************************/
+#define FM_IOC_GET_TIMESTAMP_INCREMENT                     _IOWR(FM_IOC_TYPE_BASE, FM_IOC_NUM(19), uint32_t)
+
 /** @} */ /* end of lnx_ioctl_FM_runtime_control_grp group */
 /** @} */ /* end of lnx_ioctl_FM_lib_grp group */
 /** @} */ /* end of lnx_ioctl_FM_grp */
diff --git a/include/uapi/linux/fmd/Peripherals/fm_pcd_ioctls.h b/include/uapi/linux/fmd/Peripherals/fm_pcd_ioctls.h
index c24f471bda76..5a9eda9a40b7 100644
--- a/include/uapi/linux/fmd/Peripherals/fm_pcd_ioctls.h
+++ b/include/uapi/linux/fmd/Peripherals/fm_pcd_ioctls.h
@@ -1359,6 +1359,14 @@ typedef struct ioc_fm_pcd_cc_key_params_t {
                                                  of the same size defined in the key_size */
     ioc_fm_pcd_cc_next_engine_params_t  cc_next_engine_params;
                                             /**< parameters for the next for the defined Key in p_key */
+#if 0 // following fields not defined in ioc_fm_pcd_cc_key_params_t 
+#if (DPAA_VERSION >= 11)
+	uint32_t					internal_tstamp:1; /* set to use internal FMAN time stamp */
+	uint32_t					reserved:29;
+	uint32_t					ext_timer_id:2; /* time stamp timer to use */
+	uintptr_t	monitor_addr;
+#endif /* (DPAA_VERSION >= 11) */
+#endif // 0
 
 } ioc_fm_pcd_cc_key_params_t;
 
@@ -1455,6 +1463,37 @@ typedef struct ioc_fm_pcd_hash_table_params_t {
 
     ioc_fm_pcd_cc_next_engine_params_t   cc_next_engine_params_for_miss;
                                                             /**< Parameters for defining the next engine when a key is not matched */
+
+	bool			aging_support;							/**< TRUE to enable aging support for all keys of this hash table;
+																Aging status of a key enables the application to monitor if the
+																key was accessed for a certain period of time, meaning if a
+																packet that matches this key was received since this bit was last
+																set by the application */
+
+#if (DPAA_VERSION >= 11)
+	bool			external_hash;
+#ifndef EXCLUDE_FMAN_IPR_OFFLOAD
+	uint32_t    table_type;    /* ip reassembly table */
+	//valid for reassembly tables only
+	struct {
+		uint32_t timeout_val;   //reassembly timeout
+		uint32_t timeout_fqid;  //fqid for reassmebly failures
+		uint32_t max_frags;     //max allowed fragments
+		uint32_t min_frag_size; //min allowed frag size except last frag
+		uint32_t max_sessions;  //max conn reassembly sessions
+	};
+#endif
+
+	struct {
+		uint8_t		data_mem_id;							/**< Memory partition ID for the external hash table buckets and contexts;
+    	 	 	 	 	 	 	 	 	 	 	 	 	 	 	 Must not cross the 4GB boundaries*/
+
+		uint16_t	data_liodn_offs;						/**< LIODN offset for access the external hash table buckets and contexts */
+
+		uintptr_t	miss_monitor_addr;						/**< user allocated miss monitor address */
+	} external_hash_params;
+#endif /* (DPAA_VERSION >= 11) */
+
     void                        *id;
 } ioc_fm_pcd_hash_table_params_t;
 
diff --git a/include/uapi/linux/if.h b/include/uapi/linux/if.h
index 797ba2c1562a..a8f014702f42 100644
--- a/include/uapi/linux/if.h
+++ b/include/uapi/linux/if.h
@@ -104,6 +104,9 @@ enum net_device_flags {
 	IFF_DORMANT			= 1<<17, /* volatile */
 	IFF_ECHO			= 1<<18, /* volatile */
 #endif /* __UAPI_DEF_IF_NET_DEVICE_FLAGS_LOWER_UP_DORMANT_ECHO */
+#if defined(CONFIG_CPE_FAST_PATH)
+	IFF_WIFI_OFLD		= 1<<19, /*Offload interface */
+#endif
 };
 #endif /* __UAPI_DEF_IF_NET_DEVICE_FLAGS_LOWER_UP_DORMANT_ECHO != 0 || __UAPI_DEF_IF_NET_DEVICE_FLAGS != 0 */
 
@@ -133,6 +136,10 @@ enum net_device_flags {
 #define IFF_ECHO			IFF_ECHO
 #endif /* __UAPI_DEF_IF_NET_DEVICE_FLAGS_LOWER_UP_DORMANT_ECHO */
 
+#if defined(CONFIG_CPE_FAST_PATH)
+#define IFF_WIFI_OFLD		IFF_WIFI_OFLD
+#endif
+
 #define IFF_VOLATILE	(IFF_LOOPBACK|IFF_POINTOPOINT|IFF_BROADCAST|IFF_ECHO|\
 		IFF_MASTER|IFF_SLAVE|IFF_RUNNING|IFF_LOWER_UP|IFF_DORMANT)
 
diff --git a/include/uapi/linux/if_arp.h b/include/uapi/linux/if_arp.h
index 4783af9fe520..a876f01dff07 100644
--- a/include/uapi/linux/if_arp.h
+++ b/include/uapi/linux/if_arp.h
@@ -29,6 +29,9 @@
 /* ARP protocol HARDWARE identifiers. */
 #define ARPHRD_NETROM	0		/* from KA9Q: NET/ROM pseudo	*/
 #define ARPHRD_ETHER 	1		/* Ethernet 10Mbps		*/
+#if defined(CONFIG_CPE_FAST_PATH)
+#define ARPHRD_IPV6_IPV6_TUNNEL		ARPHRD_ETHER
+#endif
 #define	ARPHRD_EETHER	2		/* Experimental Ethernet	*/
 #define	ARPHRD_AX25	3		/* AX.25 Level 2		*/
 #define	ARPHRD_PRONET	4		/* PROnet token ring		*/
diff --git a/include/uapi/linux/if_tunnel.h b/include/uapi/linux/if_tunnel.h
index e1a246dd8c62..69656f018bbb 100644
--- a/include/uapi/linux/if_tunnel.h
+++ b/include/uapi/linux/if_tunnel.h
@@ -21,6 +21,18 @@
 #define SIOCADD6RD      (SIOCDEVPRIVATE + 9)
 #define SIOCDEL6RD      (SIOCDEVPRIVATE + 10)
 #define SIOCCHG6RD      (SIOCDEVPRIVATE + 11)
+#ifdef CONFIG_CPE_4RD_TUNNEL
+#define SIOCGET4RD		(SIOCDEVPRIVATE + 12)
+#define SIOCADD4RD		(SIOCDEVPRIVATE + 13)
+#define SIOCDEL4RD		(SIOCDEVPRIVATE + 14)
+#define SIOCCHG4RD		(SIOCDEVPRIVATE + 15)
+#endif
+//#define COMCERTO_ETHERIPV4
+#ifdef CONFIG_CPE_ETHERIP
+/* SIOCCHG4RD is currently not used and even if it were, these two tunnels would never co-inside*/
+/* MSPD Added */
+#define SIOCISETHIPV4TUNNEL  (SIOCDEVPRIVATE + 15)
+#endif
 
 #define GRE_CSUM	__cpu_to_be16(0x8000)
 #define GRE_ROUTING	__cpu_to_be16(0x4000)
@@ -114,6 +126,22 @@ struct ip_tunnel_6rd {
 	__u16			relay_prefixlen;
 };
 
+#ifdef CONFIG_CPE_4RD_TUNNEL
+/* ip6 tnl 4rd parm -start  */
+struct ip6_tnl_4rd {
+	__be32                  prefix;
+	struct in6_addr         relay_prefix;
+	struct in6_addr         relay_suffix;
+	__u16                   prefixlen;
+	__u16                   relay_prefixlen;
+	__u16                   relay_suffixlen;
+	__u16                   psid_offsetlen;
+	__u16                   eabit_len;
+	__u16                   entry_num;
+};
+/* ip6 tnl 4rd parm -end  */
+#endif
+
 enum {
 	IFLA_GRE_UNSPEC,
 	IFLA_GRE_LINK,
diff --git a/include/uapi/linux/ip6_tunnel.h b/include/uapi/linux/ip6_tunnel.h
index 0245269b037c..a8e5aaa50313 100644
--- a/include/uapi/linux/ip6_tunnel.h
+++ b/include/uapi/linux/ip6_tunnel.h
@@ -53,4 +53,52 @@ struct ip6_tnl_parm2 {
 	__be32			o_key;
 };
 
+#ifdef CONFIG_CPE_4RD_TUNNEL
+struct ip6_4rd_map_msg {
+	__u32 reset;
+	__u32 ifindex;
+	__be32 prefix;
+	__u16 prefixlen;
+	struct in6_addr relay_prefix;
+	struct in6_addr relay_suffix;
+	__u16 relay_prefixlen;
+	__u16 relay_suffixlen;
+	__u16 psid_offsetlen;
+	__u16 eabit_len;
+	__u16 entry_num;
+};
+
+struct ip6_tnl_4rd_map_rule {
+	__be32 prefix;
+	__u16 prefixlen;
+	struct in6_addr relay_prefix;
+	struct in6_addr relay_suffix;
+	__u16 relay_prefixlen;
+	__u16 relay_suffixlen;
+	__u16 psid_offsetlen;
+	__u16 eabit_len;
+	__u16 entry_num;
+	struct list_head mr_list;
+};
+
+#ifdef __KERNEL__
+struct ip6_tnl_4rd_parm {
+	__be32 prefix;
+	struct in6_addr relay_prefix;
+	struct in6_addr relay_suffix;
+	__u16 prefixlen;
+	__u16 relay_prefixlen;
+	__u16 relay_suffixlen;
+	__be32 laddr4;
+	__u16 port_set_id;
+	__u16 port_set_id_len;
+	__u16 psid_offsetlen;
+	__u16 eabit_len;
+
+	struct list_head map_list;
+	rwlock_t map_lock;
+};
+#endif
+#endif
+
 #endif
diff --git a/include/uapi/linux/netfilter/nf_conntrack_common.h b/include/uapi/linux/netfilter/nf_conntrack_common.h
index 26071021e986..8960c093dc8e 100644
--- a/include/uapi/linux/netfilter/nf_conntrack_common.h
+++ b/include/uapi/linux/netfilter/nf_conntrack_common.h
@@ -118,6 +118,16 @@ enum ip_conntrack_status {
 	IPS_HW_OFFLOAD_BIT = 15,
 	IPS_HW_OFFLOAD = (1 << IPS_HW_OFFLOAD_BIT),
 
+#ifdef CONFIG_CPE_FAST_PATH
+	/* Connection cannot expire */
+	IPS_PERMANENT_BIT = 16,
+	IPS_PERMANENT = (1 << IPS_PERMANENT_BIT),
+
+	/* Connection is assured by DPI application */
+	IPS_DPI_ALLOWED_BIT = 17,
+	IPS_DPI_ALLOWED = (1 << IPS_DPI_ALLOWED_BIT),
+#endif
+
 	/* Be careful here, modifying these bits can make things messy,
 	 * so don't let users modify them directly.
 	 */
@@ -126,7 +136,11 @@ enum ip_conntrack_status {
 				 IPS_SEQ_ADJUST | IPS_TEMPLATE | IPS_UNTRACKED |
 				 IPS_OFFLOAD | IPS_HW_OFFLOAD),
 
+#ifdef CONFIG_CPE_FAST_PATH
+	__IPS_MAX_BIT = 18,
+#else
 	__IPS_MAX_BIT = 16,
+#endif
 };
 
 /* Connection tracking event types */
@@ -143,6 +157,7 @@ enum ip_conntrack_events {
 	IPCT_NATSEQADJ = IPCT_SEQADJ,
 	IPCT_SECMARK,		/* new security mark has been set */
 	IPCT_LABEL,		/* new connlabel has been set */
+	IPCT_QOSCONNMARK,   /* new qosconnmark has been set */
 	IPCT_SYNPROXY,		/* synproxy has been set */
 #ifdef __KERNEL__
 	__IPCT_MAX
diff --git a/include/uapi/linux/netfilter/nf_conntrack_tuple_common.h b/include/uapi/linux/netfilter/nf_conntrack_tuple_common.h
index 64390fac6f7e..88ad3a41c2c5 100644
--- a/include/uapi/linux/netfilter/nf_conntrack_tuple_common.h
+++ b/include/uapi/linux/netfilter/nf_conntrack_tuple_common.h
@@ -14,6 +14,9 @@ enum ip_conntrack_dir {
 	IP_CT_DIR_MAX
 };
 
+#ifdef CONFIG_CPE_4RD_TUNNEL
+#define IP_NAT_RANGE_4RD_NAPT 16
+#endif
 /* The protocol-specific manipulable parts of the tuple: always in
  * network order
  */
diff --git a/include/uapi/linux/netfilter/nfnetlink_conntrack.h b/include/uapi/linux/netfilter/nfnetlink_conntrack.h
index c2ac7269acf7..49f0dc31c1d8 100644
--- a/include/uapi/linux/netfilter/nfnetlink_conntrack.h
+++ b/include/uapi/linux/netfilter/nfnetlink_conntrack.h
@@ -57,6 +57,12 @@ enum ctattr_type {
 	CTA_SYNPROXY,
 	CTA_FILTER,
 	CTA_STATUS_MASK,
+#if defined(CONFIG_CPE_FAST_PATH)
+	CTA_LAYERSCAPE_FP_ORIG,
+	CTA_LAYERSCAPE_FP_REPLY,
+	CTA_QOSCONNMARK,
+	CTA_QOSCONNMARK_PAD,
+#endif
 	__CTA_MAX
 };
 #define CTA_MAX (__CTA_MAX - 1)
@@ -242,6 +248,22 @@ enum ctattr_secctx {
 };
 #define CTA_SECCTX_MAX (__CTA_SECCTX_MAX - 1)
 
+#if defined(CONFIG_CPE_FAST_PATH)
+enum ctattr_comcerto_fp {
+	CTA_COMCERTO_FP_UNSPEC,
+	CTA_COMCERTO_FP_MARK,
+	CTA_COMCERTO_FP_IFINDEX,
+	CTA_COMCERTO_FP_IIF,
+	CTA_COMCERTO_FP_UNDERLYING_IIF,
+	CTA_COMCERTO_FP_UNDERLYING_VID,
+#ifndef IPSEC_FLOW_CACHE
+	CTA_COMCERTO_FP_XFRM_HANDLE,
+#endif
+	__CTA_COMCERTO_FP_MAX
+};
+#define CTA_COMCERTO_FP_MAX (__CTA_COMCERTO_FP_MAX - 1)
+#endif
+
 enum ctattr_stats_cpu {
 	CTA_STATS_UNSPEC,
 	CTA_STATS_SEARCHED,	/* no longer used */
diff --git a/include/uapi/linux/netfilter/xt_QOSCONNMARK.h b/include/uapi/linux/netfilter/xt_QOSCONNMARK.h
new file mode 100644
index 000000000000..8a0821856c32
--- /dev/null
+++ b/include/uapi/linux/netfilter/xt_QOSCONNMARK.h
@@ -0,0 +1,10 @@
+#ifndef _XT_QOSCONNMARK_H_target
+#define _XT_QOSCONNMARK_H_target
+
+#include <linux/netfilter/xt_qosconnmark.h>
+
+#endif /*_XT_QOSCONNMARK_H_target*/
+
+
+
+
diff --git a/include/uapi/linux/netfilter/xt_QOSMARK.h b/include/uapi/linux/netfilter/xt_QOSMARK.h
new file mode 100644
index 000000000000..45c4795aac12
--- /dev/null
+++ b/include/uapi/linux/netfilter/xt_QOSMARK.h
@@ -0,0 +1,6 @@
+#ifndef _XT_QOSMARK_H_target
+#define _XT_QOSMARK_H_target
+
+#include <linux/netfilter/xt_qosmark.h>
+
+#endif /*_XT_QOSMARK_H_target */
diff --git a/include/uapi/linux/netfilter/xt_qosconnmark.h b/include/uapi/linux/netfilter/xt_qosconnmark.h
new file mode 100644
index 000000000000..d9901a9bd4fd
--- /dev/null
+++ b/include/uapi/linux/netfilter/xt_qosconnmark.h
@@ -0,0 +1,35 @@
+#ifndef _XT_QOSCONNMARK_H
+#define _XT_QOSCONNMARK_H
+
+#include <linux/types.h>
+
+/* Copyright (C) 2002,2004 MARA Systems AB <http://www.marasystems.com>
+    + * by Henrik Nordstrom <hno@marasystems.com>
+    + *
+    + * This program is free software; you can redistribute it and/or modify
+    + * it under the terms of the GNU General Public License as published by
+    + * the Free Software Foundation; either version 2 of the License, or
+    + * (at your option) any later version.
+    + */
+
+enum {
+    XT_QOSCONNMARK_SET = 0,
+    XT_QOSCONNMARK_SAVE_QOSMARK,
+    XT_QOSCONNMARK_RESTORE_QOSMARK
+};
+
+struct xt_qosconnmark_tginfo1 {
+    __u64 mark, ctmask, nfmask;
+    __u8 mode;
+};
+
+struct xt_qosconnmark_mtinfo1 {
+    __u64 mark, mask;
+     __u8 invert;
+};
+
+#endif /*_XT_QOSCONNMARK_H*/
+
+
+
+
diff --git a/include/uapi/linux/netfilter/xt_qosmark.h b/include/uapi/linux/netfilter/xt_qosmark.h
new file mode 100644
index 000000000000..6f80bd016c40
--- /dev/null
+++ b/include/uapi/linux/netfilter/xt_qosmark.h
@@ -0,0 +1,19 @@
+#ifndef _XT_QOSMARK_H
+#define _XT_QOSMARK_H
+
+#include <linux/types.h>
+
+struct xt_qosmark_tginfo2 {
+    __u64 mark, mask;
+};
+
+struct xt_qosmark_mtinfo1 {
+    __u64 mark, mask;
+    __u8 invert;
+};
+
+#endif /*_XT_QOSMARK_H*/
+
+
+
+
diff --git a/include/uapi/linux/netlink.h b/include/uapi/linux/netlink.h
index f87aaf28a649..75b0b7099cce 100644
--- a/include/uapi/linux/netlink.h
+++ b/include/uapi/linux/netlink.h
@@ -30,9 +30,17 @@
 #define NETLINK_CRYPTO		21	/* Crypto layer */
 #define NETLINK_SMC		22	/* SMC monitoring */
 
+#ifdef CONFIG_CPE_FAST_PATH
+#define NETLINK_FF              30
+#define NETLINK_KEY             32
+#define NETLINK_L2FLOW          33
+#define MAX_LINKS 64
+#else
+#define MAX_LINKS 32       
+#endif
+
 #define NETLINK_INET_DIAG	NETLINK_SOCK_DIAG
 
-#define MAX_LINKS 32		
 
 struct sockaddr_nl {
 	__kernel_sa_family_t	nl_family;	/* AF_NETLINK	*/
diff --git a/include/uapi/linux/pfkeyv2.h b/include/uapi/linux/pfkeyv2.h
index 8abae1f6749c..6472850001cd 100644
--- a/include/uapi/linux/pfkeyv2.h
+++ b/include/uapi/linux/pfkeyv2.h
@@ -281,6 +281,9 @@ struct sadb_x_filter {
 #define SADB_SAFLAGS_NOPMTUDISC	0x20000000
 #define SADB_SAFLAGS_DECAP_DSCP	0x40000000
 #define SADB_SAFLAGS_NOECN	0x80000000
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+#define SADB_SAFLAGS_ESN	0x01000000
+#endif
 
 /* Security Association states */
 #define SADB_SASTATE_LARVAL	0
diff --git a/include/uapi/linux/ppp-ioctl.h b/include/uapi/linux/ppp-ioctl.h
index 1cc5ce0ae062..debf115544d9 100644
--- a/include/uapi/linux/ppp-ioctl.h
+++ b/include/uapi/linux/ppp-ioctl.h
@@ -117,6 +117,9 @@ struct pppol2tp_ioc_stats {
 #define PPPIOCGL2TPSTATS _IOR('t', 54, struct pppol2tp_ioc_stats)
 #define PPPIOCBRIDGECHAN _IOW('t', 53, int)	/* bridge one channel to another */
 #define PPPIOCUNBRIDGECHAN _IO('t', 52)	/* unbridge channel */
+#if defined(CONFIG_CPE_FAST_PATH)
+#define PPPIOCSFPPIDLE	_IOW('t', 51, struct ppp_idle)	/* Set the FPP stats */
+#endif
 
 #define SIOCGPPPSTATS   (SIOCDEVPRIVATE + 0)
 #define SIOCGPPPVER     (SIOCDEVPRIVATE + 1)	/* NEVER change this!! */
diff --git a/include/uapi/linux/rtnetlink.h b/include/uapi/linux/rtnetlink.h
index db7254d52d93..729d6ac8b11f 100644
--- a/include/uapi/linux/rtnetlink.h
+++ b/include/uapi/linux/rtnetlink.h
@@ -151,6 +151,16 @@ enum {
 
 	RTM_NEWCACHEREPORT = 96,
 #define RTM_NEWCACHEREPORT RTM_NEWCACHEREPORT
+/*#ifdef CONFIG_CPE_4RD_TUNNEL
+	These defines should be enabled irrespective of CONFIG_CPE_4RD_TUNNEL is defined or not
+	this is to enable CMM build to pass*/
+	RTM_NEW4RD = 97,
+#define RTM_NEW4RD		RTM_NEW4RD
+	RTM_DEL4RD,
+#define RTM_DEL4RD		RTM_DEL4RD
+	RTM_GET4RD,
+#define RTM_GET4RD		RTM_GET4RD
+/*#endif*/
 
 	RTM_NEWCHAIN = 100,
 #define RTM_NEWCHAIN RTM_NEWCHAIN
diff --git a/net/Kconfig b/net/Kconfig
index 5b3c54974d06..f41e7658b445 100644
--- a/net/Kconfig
+++ b/net/Kconfig
@@ -125,6 +125,15 @@ config INET
 	  Short answer: say Y.
 
 if INET
+
+config CPE_FAST_PATH
+	bool "Fast Path Processing offload"
+	depends on ARCH_LAYERSCAPE
+	depends on NETFILTER
+	select NF_CONNTRACK
+	help
+	  Support for Fast Path offload.
+
 source "net/ipv4/Kconfig"
 source "net/ipv6/Kconfig"
 source "net/netlabel/Kconfig"
diff --git a/net/bridge/br.c b/net/bridge/br.c
index ed08717541fe..346524427218 100644
--- a/net/bridge/br.c
+++ b/net/bridge/br.c
@@ -474,6 +474,60 @@ static void __exit br_deinit(void)
 	br_fdb_fini();
 }
 
+#if defined(CONFIG_CPE_FAST_PATH)
+static ATOMIC_NOTIFIER_HEAD(brevent_notif_chain);
+
+/**
+ * register_brevent_notifier - register a netevent notifier block
+ * @nb: notifier
+ *
+ * Register a notifier to be called when a bridge event occurs.
+ * The notifier passed is linked into the kernel structures and must
+ * not be reused until it has been unregistered. A negative errno code
+ * is returned on a failure.
+ */
+int register_brevent_notifier(struct notifier_block *nb)
+{
+	int err;
+
+	err = atomic_notifier_chain_register(&brevent_notif_chain, nb);
+	return err;
+}
+
+/**
+ * unregister_brevent_notifier - unregister a netevent notifier block
+ * @nb: notifier
+ *
+ * Unregister a notifier previously registered by
+ * register_neigh_notifier(). The notifier is unlinked into the
+ * kernel structures and may then be reused. A negative errno code
+ * is returned on a failure.
+ */
+
+int unregister_brevent_notifier(struct notifier_block *nb)
+{
+	return atomic_notifier_chain_unregister(&brevent_notif_chain, nb);
+}
+
+/**
+ * call_brevent_notifiers - call all netevent notifier blocks
+ *		@val: value passed unmodified to notifier function
+ *		@v:   pointer passed unmodified to notifier function
+ *
+ * Call all neighbour notifier blocks.  Parameters and return value
+ * are as for notifier_call_chain().
+ */
+
+int call_brevent_notifiers(unsigned long val, void *v)
+{
+	return atomic_notifier_call_chain(&brevent_notif_chain, val, v);
+}
+
+EXPORT_SYMBOL_GPL(register_brevent_notifier);
+EXPORT_SYMBOL_GPL(unregister_brevent_notifier);
+EXPORT_SYMBOL_GPL(call_brevent_notifiers);
+#endif
+
 module_init(br_init)
 module_exit(br_deinit)
 MODULE_LICENSE("GPL");
diff --git a/net/bridge/br_fdb.c b/net/bridge/br_fdb.c
index 642b8ccaae8e..f140ac15f68b 100644
--- a/net/bridge/br_fdb.c
+++ b/net/bridge/br_fdb.c
@@ -14,6 +14,10 @@
 #include <linux/times.h>
 #include <linux/netdevice.h>
 #include <linux/etherdevice.h>
+#if defined(CONFIG_CPE_FAST_PATH)
+#include <linux/rtnetlink.h>
+#include <linux/module.h>
+#endif
 #include <linux/jhash.h>
 #include <linux/random.h>
 #include <linux/slab.h>
@@ -33,6 +37,11 @@ static const struct rhashtable_params br_fdb_rht_params = {
 
 static struct kmem_cache *br_fdb_cache __read_mostly;
 
+#if defined(CONFIG_CPE_FAST_PATH)
+int(*br_fdb_can_expire)(unsigned char *mac_addr, struct net_device *dev) = NULL;
+DEFINE_SPINLOCK(br_fdb_cb_lock);
+#endif
+
 int __init br_fdb_init(void)
 {
 	br_fdb_cache = KMEM_CACHE(net_bridge_fdb_entry, SLAB_HWCACHE_ALIGN);
@@ -455,6 +464,20 @@ static int fdb_add_local(struct net_bridge *br, struct net_bridge_port *source,
 	if (!fdb)
 		return -ENOMEM;
 
+//#if defined(CONFIG_CPE_FAST_PATH)
+/*
+ * Below commented code is specific to LS1024 device unicast list.
+ * It is not applicable to other architectures.
+ */
+#if 0
+	list_for_each_entry(p, &br->port_list, list) {
+		if (source == p)
+			continue;
+
+		dev_uc_add(source->dev, p->dev->dev_addr);
+		dev_uc_add(p->dev, addr);
+	}
+#endif
 	fdb_add_hw_addr(br, addr);
 	fdb_notify(br, fdb, RTM_NEWNEIGH, true);
 	return 0;
@@ -567,6 +590,16 @@ void br_fdb_cleanup(struct work_struct *work)
 			continue;
 		}
 
+#if defined(CONFIG_CPE_FAST_PATH)
+		spin_lock(&br_fdb_cb_lock);
+		if(br_fdb_can_expire && !(*br_fdb_can_expire)(f->key.addr.addr, READ_ONCE(f->dst)->dev)){
+			f->updated = jiffies;
+			spin_unlock(&br_fdb_cb_lock);
+			continue;
+		}
+		spin_unlock(&br_fdb_cb_lock);
+#endif
+
 		if (time_after(this_timer, now)) {
 			work_delay = min(work_delay, this_timer - now);
 		} else {
@@ -915,6 +948,14 @@ void br_fdb_update(struct net_bridge *br, struct net_bridge_port *source,
 			/* fastpath: update of existing entry */
 			if (unlikely(source != READ_ONCE(fdb->dst) &&
 				     !test_bit(BR_FDB_STICKY, &fdb->flags))) {
+#if defined(CONFIG_CPE_FAST_PATH)
+				struct brevent_fdb_update fdb_update;
+
+				fdb_update.dev = source->dev;
+				fdb_update.mac_addr = fdb->key.addr.addr;
+				fdb_update.brdev = br->dev;
+				call_brevent_notifiers(BREVENT_FDB_UPDATE, &fdb_update);
+#endif
 				br_switchdev_fdb_notify(br, fdb, RTM_DELNEIGH);
 				WRITE_ONCE(fdb->dst, source);
 				fdb_modified = true;
@@ -1554,3 +1595,21 @@ void br_fdb_clear_offload(const struct net_device *dev, u16 vid)
 	spin_unlock_bh(&p->br->hash_lock);
 }
 EXPORT_SYMBOL_GPL(br_fdb_clear_offload);
+
+#if defined(CONFIG_CPE_FAST_PATH)
+void br_fdb_register_can_expire_cb(int(*cb)(unsigned char *mac_addr, struct net_device *dev))
+{
+	spin_lock_bh(&br_fdb_cb_lock);
+	br_fdb_can_expire = cb;
+	spin_unlock_bh(&br_fdb_cb_lock);
+}
+EXPORT_SYMBOL(br_fdb_register_can_expire_cb);
+
+void br_fdb_deregister_can_expire_cb(void)
+{
+	spin_lock_bh(&br_fdb_cb_lock);
+	br_fdb_can_expire = NULL;
+	spin_unlock_bh(&br_fdb_cb_lock);
+}
+EXPORT_SYMBOL(br_fdb_deregister_can_expire_cb);
+#endif
diff --git a/net/bridge/br_forward.c b/net/bridge/br_forward.c
index e19b583ff2c6..52de8201979d 100644
--- a/net/bridge/br_forward.c
+++ b/net/bridge/br_forward.c
@@ -33,7 +33,11 @@ static inline int should_deliver(const struct net_bridge_port *p,
 int br_dev_queue_push_xmit(struct net *net, struct sock *sk, struct sk_buff *skb)
 {
 	skb_push(skb, ETH_HLEN);
-	if (!is_skb_forwardable(skb->dev, skb))
+	if (
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+		(!skb->ipsec_offload) && 
+#endif
+		!is_skb_forwardable(skb->dev, skb))
 		goto drop;
 
 	br_drop_fake_rtable(skb);
diff --git a/net/bridge/br_input.c b/net/bridge/br_input.c
index ceaa5a89b947..9d9e3b229b61 100644
--- a/net/bridge/br_input.c
+++ b/net/bridge/br_input.c
@@ -65,6 +65,10 @@ static int br_pass_frame_up(struct sk_buff *skb, bool promisc)
 	br_multicast_count(br, NULL, skb, br_multicast_igmp_type(skb),
 			   BR_MCAST_DIR_TX);
 
+#if defined(CONFIG_CPE_FAST_PATH)
+	skb->underlying_iif = indev->ifindex;
+#endif
+
 	BR_INPUT_SKB_CB(skb)->promisc = promisc;
 
 	return NF_HOOK(NFPROTO_BRIDGE, NF_BR_LOCAL_IN,
@@ -161,6 +165,10 @@ int br_handle_frame_finish(struct net *net, struct sock *sk, struct sk_buff *skb
 	BR_INPUT_SKB_CB(skb)->brdev = br->dev;
 	BR_INPUT_SKB_CB(skb)->src_port_isolated = !!(p->flags & BR_ISOLATED);
 
+#if defined(CONFIG_CPE_FAST_PATH)
+	skb->abm_ff = 0;
+#endif
+
 	if (IS_ENABLED(CONFIG_INET) &&
 	    (skb->protocol == htons(ETH_P_ARP) ||
 	     skb->protocol == htons(ETH_P_RARP))) {
@@ -209,6 +217,10 @@ int br_handle_frame_finish(struct net *net, struct sock *sk, struct sk_buff *skb
 
 		if (now != dst->used)
 			dst->used = now;
+#if defined(CONFIG_CPE_FAST_PATH)
+			/* Used by ABM module */
+			skb->abm_ff = 1;
+#endif
 		br_forward(dst->dst, skb, local_rcv, false);
 	} else {
 		if (!mcast_hit)
diff --git a/net/bridge/br_private.h b/net/bridge/br_private.h
index 5026a256bf92..2b66abe5e104 100644
--- a/net/bridge/br_private.h
+++ b/net/bridge/br_private.h
@@ -618,6 +618,11 @@ struct br_input_skb_cb {
 #endif
 
 	u32 backup_nhid;
+
+#ifdef CONFIG_CPE_FAST_PATH
+	u16 vid;
+	u8 untagged:1;
+#endif
 };
 
 #define BR_INPUT_SKB_CB(__skb)	((struct br_input_skb_cb *)(__skb)->cb)
@@ -854,6 +859,11 @@ int br_fdb_add_local(struct net_bridge *br, struct net_bridge_port *source,
 void br_fdb_update(struct net_bridge *br, struct net_bridge_port *source,
 		   const unsigned char *addr, u16 vid, unsigned long flags);
 
+#if defined(CONFIG_CPE_FAST_PATH)
+extern void br_fdb_register_can_expire_cb(int(*cb)(unsigned char *mac_addr, struct net_device *dev));
+extern void br_fdb_deregister_can_expire_cb(void);
+#endif
+
 int br_fdb_delete(struct ndmsg *ndm, struct nlattr *tb[],
 		  struct net_device *dev, const unsigned char *addr, u16 vid,
 		  struct netlink_ext_ack *extack);
diff --git a/net/bridge/br_stp_if.c b/net/bridge/br_stp_if.c
index 75204d36d7f9..0ee39d723422 100644
--- a/net/bridge/br_stp_if.c
+++ b/net/bridge/br_stp_if.c
@@ -123,6 +123,10 @@ void br_stp_disable_port(struct net_bridge_port *p)
 
 	if (br_is_root_bridge(br) && !wasroot)
 		br_become_root_bridge(br);
+
+#if defined(CONFIG_CPE_FAST_PATH)
+	call_brevent_notifiers(BREVENT_PORT_DOWN, p->dev);
+#endif
 }
 
 static int br_stp_call_user(struct net_bridge *br, char *arg)
diff --git a/net/bridge/br_vlan.c b/net/bridge/br_vlan.c
index dae576a6d026..fa750c257dd6 100644
--- a/net/bridge/br_vlan.c
+++ b/net/bridge/br_vlan.c
@@ -520,9 +520,21 @@ struct sk_buff *br_handle_vlan(struct net_bridge *br,
 	 * hardware on each egress port as appropriate. So only strip the VLAN
 	 * header if forwarding offload is not being used.
 	 */
+#ifdef CONFIG_CPE_FAST_PATH
+	BR_INPUT_SKB_CB(skb)->vid = vid;
+#endif
 	if (v->flags & BRIDGE_VLAN_INFO_UNTAGGED &&
-	    !br_switchdev_frame_uses_tx_fwd_offload(skb))
+	    !br_switchdev_frame_uses_tx_fwd_offload(skb)) {
+#ifdef CONFIG_CPE_FAST_PATH
+		BR_INPUT_SKB_CB(skb)->untagged = true;
+#endif
 		__vlan_hwaccel_clear_tag(skb);
+	}
+#ifdef CONFIG_CPE_FAST_PATH
+	else {
+		BR_INPUT_SKB_CB(skb)->untagged = false;
+	}
+#endif
 
 	if (p && (p->flags & BR_VLAN_TUNNEL) &&
 	    br_handle_egress_vlan_tunnel(skb, v)) {
@@ -603,6 +615,9 @@ static bool __allowed_ingress(const struct net_bridge *br,
 			 */
 			skb->vlan_tci |= pvid;
 
+		if(!skb->underlying_vlan_tci)
+			skb->underlying_vlan_tci = skb_vlan_tag_get(skb);
+
 		/* if snooping and stats are disabled we can avoid the lookup */
 		if (!br_opt_get(br, BROPT_MCAST_VLAN_SNOOPING_ENABLED) &&
 		    !br_opt_get(br, BROPT_VLAN_STATS_ENABLED)) {
@@ -632,6 +647,9 @@ static bool __allowed_ingress(const struct net_bridge *br,
 		u64_stats_update_end(&stats->syncp);
 	}
 
+	if(!skb->underlying_vlan_tci)
+		skb->underlying_vlan_tci = skb_vlan_tag_get(skb);
+
 	*vlan = v;
 
 	return true;
diff --git a/net/core/dev.c b/net/core/dev.c
index cfd32bd02a69..7f01d99fffd6 100644
--- a/net/core/dev.c
+++ b/net/core/dev.c
@@ -172,6 +172,10 @@ static int call_netdevice_notifiers_extack(unsigned long val,
 					   struct net_device *dev,
 					   struct netlink_ext_ack *extack);
 
+#if defined(CONFIG_CPE_FAST_PATH)
+static fp_iface_stats_get fast_path_stats_get;
+#endif
+
 static DEFINE_MUTEX(ifalias_mutex);
 
 /* protects napi_hash addition/deletion and napi_gen_id */
@@ -3758,10 +3762,17 @@ static struct sk_buff *validate_xmit_skb(struct sk_buff *skb, struct net_device
 			skb = segs;
 		}
 	} else {
-		if (skb_needs_linearize(skb, features) &&
-		    __skb_linearize(skb))
-			goto out_kfree_skb;
-
+		// linearise only if ipsec policy is not selected
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+		if(!(skb->ipsec_offload))
+#endif // defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+		{
+			if (skb_needs_linearize(skb, features))
+			{
+				if (__skb_linearize(skb))
+					goto out_kfree_skb;
+			}
+		}
 		/* If packet is not checksummed and device does not
 		 * support checksumming for this protocol, complete
 		 * checksumming here.
@@ -4544,6 +4555,40 @@ int __dev_queue_xmit(struct sk_buff *skb, struct net_device *sb_dev)
 }
 EXPORT_SYMBOL(__dev_queue_xmit);
 
+#if defined(CONFIG_CPE_FAST_PATH)
+/* WiFi IPSEC offload hook - allows cdx to intercept packets for IPSEC
+ * processing when the packet is transmitted on a wifi interface.
+ */
+dpaa_wifi_xmit_local_hook_t dpaa_wifi_xmit_local_ipsec_handler;
+EXPORT_SYMBOL(dpaa_wifi_xmit_local_ipsec_handler);
+
+/* Register a hook function for IPSEC offload on wifi interfaces */
+int dpa_register_wifi_xmit_local_hook(dpaa_wifi_xmit_local_hook_t hookfn)
+{
+	if (dpaa_wifi_xmit_local_ipsec_handler) {
+		pr_warn("%s: hook already registered\n", __func__);
+		return -1;
+	}
+	dpaa_wifi_xmit_local_ipsec_handler = hookfn;
+	return 0;
+}
+EXPORT_SYMBOL(dpa_register_wifi_xmit_local_hook);
+
+/* Unregister the IPSEC offload hook */
+void dpa_unregister_wifi_xmit_local_hook(void)
+{
+	dpaa_wifi_xmit_local_ipsec_handler = NULL;
+}
+EXPORT_SYMBOL(dpa_unregister_wifi_xmit_local_hook);
+
+/* Original dev_queue_xmit - called when wifi hook is not applicable */
+int original_dev_queue_xmit(struct sk_buff *skb)
+{
+	return __dev_queue_xmit(skb, NULL);
+}
+EXPORT_SYMBOL(original_dev_queue_xmit);
+#endif
+
 int __dev_direct_xmit(struct sk_buff *skb, u16 queue_id)
 {
 	struct net_device *dev = skb->dev;
@@ -5552,6 +5597,14 @@ static int __netif_receive_skb_core(struct sk_buff **pskb, bool pfmemalloc,
 
 	trace_netif_receive_skb(skb);
 
+#ifdef CONFIG_CPE_FAST_PATH
+	/* ifindex of device we arrived on,now skb->skb_iif
+	always tracks skb->dev */
+	if (!skb->iif_index)
+		skb->iif_index = skb->dev->ifindex;
+	if(!skb->underlying_iif)
+		skb->underlying_iif = skb->dev->ifindex;
+#endif
 	orig_dev = skb->dev;
 
 	skb_reset_network_header(skb);
@@ -6893,8 +6946,6 @@ static int __napi_poll(struct napi_struct *n, bool *repoll)
 		napi_gro_flush(n, HZ >= 1000);
 	}
 
-	gro_normal_list(n);
-
 	/* Some drivers may have called napi_schedule
 	 * prior to exhausting their budget.
 	 */
@@ -11045,10 +11096,28 @@ struct rtnl_link_stats64 *dev_get_stats(struct net_device *dev,
 			storage->rx_otherhost_dropped += READ_ONCE(core_stats->rx_otherhost_dropped);
 		}
 	}
+#if defined(CONFIG_CPE_FAST_PATH)
+	if (fast_path_stats_get)
+		fast_path_stats_get(dev, storage);
+#endif
 	return storage;
 }
 EXPORT_SYMBOL(dev_get_stats);
 
+#if defined(CONFIG_CPE_FAST_PATH)
+void dev_fp_stats_get_register(fp_iface_stats_get func)
+{
+	fast_path_stats_get = func;
+}
+EXPORT_SYMBOL(dev_fp_stats_get_register);
+
+void dev_fp_stats_get_deregister(void)
+{
+	fast_path_stats_get = NULL;
+}
+EXPORT_SYMBOL(dev_fp_stats_get_deregister);
+#endif
+
 /**
  *	dev_fetch_sw_netstats - get per-cpu network device statistics
  *	@s: place to store stats
diff --git a/net/core/gro.c b/net/core/gro.c
index 0ad549b07e03..6e1c5724b7f5 100644
--- a/net/core/gro.c
+++ b/net/core/gro.c
@@ -648,6 +648,11 @@ static void napi_reuse_skb(struct napi_struct *napi, struct sk_buff *skb)
 	__vlan_hwaccel_clear_tag(skb);
 	skb->dev = napi->dev;
 	skb->skb_iif = 0;
+#ifdef CONFIG_CPE_FAST_PATH
+	skb->iif_index = 0;
+	skb->underlying_iif = 0;
+	skb->underlying_vlan_tci = 0;
+#endif
 
 	/* eth_type_trans() assumes pkt_type is PACKET_HOST */
 	skb->pkt_type = PACKET_HOST;
diff --git a/net/core/rtnetlink.c b/net/core/rtnetlink.c
index 28ef506b10b0..b1ecabf41944 100644
--- a/net/core/rtnetlink.c
+++ b/net/core/rtnetlink.c
@@ -800,9 +800,17 @@ int rtnetlink_put_metrics(struct sk_buff *skb, u32 *metrics)
 	struct nlattr *mx;
 	int i, valid = 0;
 
+#ifndef CONFIG_CPE_FAST_PATH
+	/*By default this metric is zero for all routes unless mtu is 
+		included while adding route.Due to this mtu is coming as zero 
+		when cmm gets the route through netlink messge.So Added condtion 
+		to bypass this code so that cmm gets right mtu value even if route
+		is added without including mtu
+					*/
 	/* nothing is dumped for dst_default_metrics, so just skip the loop */
 	if (metrics == dst_default_metrics.metrics)
 		return 0;
+#endif
 
 	mx = nla_nest_start_noflag(skb, RTA_METRICS);
 	if (mx == NULL)
@@ -832,6 +840,17 @@ int rtnetlink_put_metrics(struct sk_buff *skb, u32 *metrics)
 			}
 			valid++;
 		}
+#ifdef CONFIG_CPE_FAST_PATH
+		else if (i  == RTAX_MTU - 1){
+			struct dst_entry *dst = skb_dst(skb);
+			if(dst)
+			{
+				if (nla_put_u32(skb, i + 1, dst_mtu(dst)))
+					goto nla_put_failure;
+					valid++;
+			}
+		}
+#endif	
 	}
 
 	if (!valid) {
diff --git a/net/core/skbuff.c b/net/core/skbuff.c
index 578513eb738e..e23b58bf4499 100644
--- a/net/core/skbuff.c
+++ b/net/core/skbuff.c
@@ -1552,18 +1552,32 @@ static void __copy_skb_header(struct sk_buff *new, const struct sk_buff *old)
 	skb_dst_copy(new, old);
 	__skb_ext_copy(new, old);
 	__nf_copy(new, old, false);
+#if defined(CONFIG_CPE_FAST_PATH)
+	new->qosmark    = old->qosmark;
+#endif
 
 	/* Note : this field could be in the headers group.
 	 * It is not yet because we do not want to have a 16 bit hole
 	 */
 	new->queue_mapping = old->queue_mapping;
 
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	new->ipsec_offload       = old->ipsec_offload;
+	new->ipsec_xfrm_dir      = old->ipsec_xfrm_dir;
+#endif
 	memcpy(&new->headers, &old->headers, sizeof(new->headers));
 	CHECK_SKB_FIELD(protocol);
 	CHECK_SKB_FIELD(csum);
 	CHECK_SKB_FIELD(hash);
 	CHECK_SKB_FIELD(priority);
 	CHECK_SKB_FIELD(skb_iif);
+#ifdef CONFIG_CPE_FAST_PATH
+	CHECK_SKB_FIELD(abm_ff);
+	CHECK_SKB_FIELD(expt_pkt);
+	CHECK_SKB_FIELD(iif_index);
+	CHECK_SKB_FIELD(underlying_iif);
+	CHECK_SKB_FIELD(underlying_vlan_tci);
+#endif
 	CHECK_SKB_FIELD(vlan_proto);
 	CHECK_SKB_FIELD(vlan_tci);
 	CHECK_SKB_FIELD(transport_header);
@@ -1598,6 +1612,24 @@ static struct sk_buff *__skb_clone(struct sk_buff *n, struct sk_buff *skb)
 {
 #define C(x) n->x = skb->x
 
+#if defined(CONFIG_COMCERTO_CUSTOM_SKB_LAYOUT)
+	if (skb->mspd_data) {
+		if (skb->mspd_len) {
+			int ofst = skb->len - skb->mspd_len;
+
+			memcpy(skb->data + ofst, skb->mspd_data + skb->mspd_ofst, skb->mspd_len);
+			skb->mspd_len = 0;
+		}
+
+		WARN_ON(skb_shared(skb));
+
+		if (!skb_shared(skb)) {
+			kfree(skb->mspd_data);
+			skb->mspd_data = NULL;
+		}
+	}
+#endif
+
 	n->next = n->prev = NULL;
 	n->sk = NULL;
 	__copy_skb_header(n, skb);
@@ -1620,6 +1652,13 @@ static struct sk_buff *__skb_clone(struct sk_buff *n, struct sk_buff *skb)
 	C(truesize);
 	refcount_set(&n->users, 1);
 
+#if defined(CONFIG_COMCERTO_CUSTOM_SKB_LAYOUT)
+	WARN_ON(skb->mspd_data);
+	C(mspd_data);
+	C(mspd_len);
+	C(mspd_ofst);
+#endif
+
 	atomic_inc(&(skb_shinfo(skb)->dataref));
 	skb->cloned = 1;
 
@@ -2215,6 +2254,9 @@ struct sk_buff *__pskb_copy_fclone(struct sk_buff *skb, int headroom,
 	int flags = skb_alloc_rx_flag(skb) | (fclone ? SKB_ALLOC_FCLONE : 0);
 	struct sk_buff *n = __alloc_skb(size, gfp_mask, flags, NUMA_NO_NODE);
 
+#if defined(CONFIG_COMCERTO_CUSTOM_SKB_LAYOUT)
+	WARN_ON(skb->mspd_len);
+#endif
 	if (!n)
 		goto out;
 
@@ -6133,7 +6175,15 @@ void skb_scrub_packet(struct sk_buff *skb, bool xnet)
 	skb->skb_iif = 0;
 	skb->ignore_df = 0;
 	skb_dst_drop(skb);
-	skb_ext_reset(skb);
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	/* TODO ***
+	skb->sp is getting initialized to NULL, which is getting used in ethernet driver
+	for ipsec_offload cases. 
+	Need to revisit for a proper fix.
+	*/
+	if (!skb->ipsec_offload)
+#endif
+		skb_ext_reset(skb);
 	nf_reset_ct(skb);
 	nf_reset_trace(skb);
 
diff --git a/net/ipv4/Kconfig b/net/ipv4/Kconfig
index 6d2c97f8e9ef..eebe4c9c6dd4 100644
--- a/net/ipv4/Kconfig
+++ b/net/ipv4/Kconfig
@@ -392,6 +392,12 @@ config INET_ESPINTCP
 
 	  If unsure, say N.
 
+config INET_IPSEC_OFFLOAD
+	bool "IPsec Fast Path Processing offload"
+	depends on (INET_ESP || INET_AH) && CPE_FAST_PATH
+	help
+	  Support for IPsec Fast Path offload.
+
 config INET_IPCOMP
 	tristate "IP: IPComp transformation"
 	select INET_XFRM_TUNNEL
diff --git a/net/ipv4/ip_output.c b/net/ipv4/ip_output.c
index 49811c9281d4..87b2653bb951 100644
--- a/net/ipv4/ip_output.c
+++ b/net/ipv4/ip_output.c
@@ -102,6 +102,17 @@ int __ip_local_out(struct net *net, struct sock *sk, struct sk_buff *skb)
 {
 	struct iphdr *iph = ip_hdr(skb);
 
+#if defined(CONFIG_INET_IPSEC_OFFLOAD)
+	/*
+	 * The tunnel header is not added in slow path and packet may be ipv6
+	 * (IPv6 traffic and IPv4 IPSec tunnel) in case IPv6 over IPv4 IPsec
+	 * tunnel. When it assumes as IPv4 and accessing IP header from SKB
+	 * causing invalid accesses it leading to kernel panic.
+	 * Avoiding ip header checks.
+	 */
+	if((skb->ipsec_offload) && (iph->version == 6))
+		goto sendout;
+#endif /* endif for CONFIG_INET_IPSEC_OFFLOAD */
 	IP_INC_STATS(net, IPSTATS_MIB_OUTREQUESTS);
 
 	iph_set_totlen(iph, skb->len);
@@ -114,8 +125,19 @@ int __ip_local_out(struct net *net, struct sock *sk, struct sk_buff *skb)
 	if (unlikely(!skb))
 		return 0;
 
+#if defined(CONFIG_INET_IPSEC_OFFLOAD)
+sendout:
+#endif
 	skb->protocol = htons(ETH_P_IP);
 
+#if defined(CONFIG_INET_IPSEC_OFFLOAD)
+	if(skb->ipsec_offload)
+	{
+		dst_output(net, sk, skb);
+		return 0;
+	}
+	else
+#endif /* endif for CONFIG_INET_IPSEC_OFFLOAD */
 	return nf_hook(NFPROTO_IPV4, NF_INET_LOCAL_OUT,
 		       net, sk, skb, NULL, skb_dst(skb)->dev,
 		       dst_output);
@@ -308,7 +330,11 @@ static int __ip_finish_output(struct net *net, struct sock *sk, struct sk_buff *
 	if (skb_is_gso(skb))
 		return ip_finish_output_gso(net, sk, skb, mtu);
 
-	if (skb->len > mtu || IPCB(skb)->frag_max_size)
+	if (
+#if defined(CONFIG_INET_IPSEC_OFFLOAD)
+		(skb->ipsec_offload == 0) &&
+#endif
+		(skb->len > mtu || IPCB(skb)->frag_max_size))
 		return ip_fragment(net, sk, skb, mtu, ip_finish_output2);
 
 	return ip_finish_output2(net, sk, skb);
@@ -431,6 +457,13 @@ int ip_output(struct net *net, struct sock *sk, struct sk_buff *skb)
 	skb->dev = dev;
 	skb->protocol = htons(ETH_P_IP);
 
+#if defined(CONFIG_INET_IPSEC_OFFLOAD)
+	/* Bypass invoking post routing hooks since the tunnel header and ESP
+	 * processing is not done in slow path for IPSec offloaded cases
+	 */
+	if (skb->ipsec_offload)
+		return ip_finish_output(net, sk, skb);
+#endif
 	return NF_HOOK_COND(NFPROTO_IPV4, NF_INET_POST_ROUTING,
 			    net, sk, skb, indev, dev,
 			    ip_finish_output,
@@ -561,6 +594,9 @@ static void ip_copy_metadata(struct sk_buff *to, struct sk_buff *from)
 	skb_dst_copy(to, from);
 	to->dev = from->dev;
 	to->mark = from->mark;
+#if defined(CONFIG_CPE_FAST_PATH)
+	to->qosmark = from->qosmark;
+#endif
 
 	skb_copy_hash(to, from);
 
diff --git a/net/ipv4/ip_tunnel.c b/net/ipv4/ip_tunnel.c
index 09b73acf037a..1083fe44416d 100644
--- a/net/ipv4/ip_tunnel.c
+++ b/net/ipv4/ip_tunnel.c
@@ -438,6 +438,9 @@ int ip_tunnel_rcv(struct ip_tunnel *tunnel, struct sk_buff *skb,
 		skb->protocol = eth_type_trans(skb, tunnel->dev);
 		skb_postpull_rcsum(skb, eth_hdr(skb), ETH_HLEN);
 	} else {
+#ifdef CONFIG_CPE_FAST_PATH
+		skb->underlying_iif = skb->dev->ifindex;
+#endif
 		skb->dev = tunnel->dev;
 	}
 
diff --git a/net/ipv4/xfrm4_policy.c b/net/ipv4/xfrm4_policy.c
index 7e1c2faed1ff..985934c2e331 100644
--- a/net/ipv4/xfrm4_policy.c
+++ b/net/ipv4/xfrm4_policy.c
@@ -33,6 +33,19 @@ static struct dst_entry *__xfrm4_dst_lookup(struct flowi4 *fl4,
 	fl4->flowi4_proto = params->ipproto;
 	fl4->uli = params->uli;
 
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	/*
+	 * For IPsec packets with directly connected IPv4 tunnel end points,
+	 * neighbor resolution is done for inner destination since we do not
+	 * add tunnel headers in slow path to IPsec packets. To fix this issue,
+	 * flag "FLOWI_FLAG_KNOWN_NH" is passed during tunnel route lookup.
+	 * This flag will ensure that if the src and dst are directly connected
+	 * then a new route entry is created with "rt_gateway" set to dst
+	 * address (tunnel dst address).
+	 */
+	fl4->flowi4_flags |= FLOWI_FLAG_KNOWN_NH;
+#endif
+
 	rt = __ip_route_output_key(params->net, fl4);
 	if (!IS_ERR(rt))
 		return &rt->dst;
diff --git a/net/ipv6/Kconfig b/net/ipv6/Kconfig
index 1c9c686d9522..396a081a12b9 100644
--- a/net/ipv6/Kconfig
+++ b/net/ipv6/Kconfig
@@ -103,6 +103,12 @@ config INET6_ESPINTCP
 
 	  If unsure, say N.
 
+config INET6_IPSEC_OFFLOAD
+	bool "IPsec IPv6 Fast Path Processing offload"
+	depends on (INET6_ESP && CPE_FAST_PATH)
+	help
+	  Support for IPsec IPv6 Fast Path offload.
+
 config INET6_IPCOMP
 	tristate "IPv6: IPComp transformation"
 	select INET6_XFRM_TUNNEL
diff --git a/net/ipv6/ip6_output.c b/net/ipv6/ip6_output.c
index f0e5431c2d46..87fe154cd7ea 100644
--- a/net/ipv6/ip6_output.c
+++ b/net/ipv6/ip6_output.c
@@ -83,6 +83,13 @@ static int ip6_finish_output2(struct net *net, struct sock *sk, struct sk_buff *
 
 	hdr = ipv6_hdr(skb);
 	daddr = &hdr->daddr;
+#if defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	/* For IPv4 over IPv6 IPsec tunnel cases, just send the packet out
+	 * since the packet is IPv4
+	 */
+	if((skb->ipsec_offload) && (hdr->version == 4))
+		goto sendout;
+#endif /* endif for CONFIG_INET6_IPSEC_OFFLOAD */
 	if (ipv6_addr_is_multicast(daddr)) {
 		if (!(dev->flags & IFF_LOOPBACK) && sk_mc_loop(sk) &&
 		    ((mroute6_is_socket(net, skb) &&
@@ -114,6 +121,9 @@ static int ip6_finish_output2(struct net *net, struct sock *sk, struct sk_buff *
 		}
 	}
 
+#if defined(CONFIG_INET6_IPSEC_OFFLOAD)
+sendout:
+#endif /* endif for CONFIG_INET6_IPSEC_OFFLOAD */
 	if (lwtunnel_xmit_redirect(dst->lwtstate)) {
 		int res = lwtunnel_xmit(skb);
 
@@ -208,8 +218,15 @@ static int __ip6_finish_output(struct net *net, struct sock *sk, struct sk_buff
 	if (skb_is_gso(skb))
 		return ip6_finish_output_gso(net, sk, skb, mtu);
 
-	if (skb->len > mtu ||
-	    (IP6CB(skb)->frag_max_size && skb->len > IP6CB(skb)->frag_max_size))
+	if (
+#if defined(CONFIG_INET6_IPSEC_OFFLOAD)
+		/* If ipsec offload is there, do not do fragment. So, when IPSec
+		 * offload is enabled it directly calls ip6_finish_output2
+		 */
+		(skb->ipsec_offload == 0) &&
+#endif
+		((skb->len > mtu) ||
+		(IP6CB(skb)->frag_max_size && skb->len > IP6CB(skb)->frag_max_size)))
 		return ip6_fragment(net, sk, skb, ip6_finish_output2);
 
 	return ip6_finish_output2(net, sk, skb);
@@ -244,6 +261,13 @@ int ip6_output(struct net *net, struct sock *sk, struct sk_buff *skb)
 		return 0;
 	}
 
+#if defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	/* Bypass invoking post routing hooks since the tunnel header and ESP
+	 * processing is not done in slow path for IPSec offloaded cases
+	 */
+	if (skb->ipsec_offload)
+		return ip6_finish_output(net, sk, skb);
+#endif
 	return NF_HOOK_COND(NFPROTO_IPV6, NF_INET_POST_ROUTING,
 			    net, sk, skb, indev, dev,
 			    ip6_finish_output,
@@ -686,6 +710,9 @@ static void ip6_copy_metadata(struct sk_buff *to, struct sk_buff *from)
 	skb_dst_set(to, dst_clone(skb_dst(from)));
 	to->dev = from->dev;
 	to->mark = from->mark;
+#if defined(CONFIG_CPE_FAST_PATH)
+	to->qosmark = from->qosmark;
+#endif
 
 	skb_copy_hash(to, from);
 
diff --git a/net/ipv6/ip6_tunnel.c b/net/ipv6/ip6_tunnel.c
index 5350c9bb2319..a377c01624d8 100644
--- a/net/ipv6/ip6_tunnel.c
+++ b/net/ipv6/ip6_tunnel.c
@@ -19,6 +19,7 @@
 #include <linux/capability.h>
 #include <linux/errno.h>
 #include <linux/types.h>
+#include <linux/version.h>
 #include <linux/sockios.h>
 #include <linux/icmp.h>
 #include <linux/if.h>
@@ -75,6 +76,505 @@ static u32 HASH(const struct in6_addr *addr1, const struct in6_addr *addr2)
 	return hash_32(hash, IP6_TUNNEL_HASH_SIZE_SHIFT);
 }
 
+#ifdef CONFIG_CPE_4RD_TUNNEL
+#define for_each_ip6_tunnel_rcu(start) \
+	for (t = rcu_dereference(start); t; t = rcu_dereference(t->next))
+
+/*
+ * 4RD Tunnel Support Functions
+ * Locking: hash tables are protected by RCU and RTNL
+ */
+static struct kmem_cache *mr_kmem __read_mostly;
+int mr_kmem_alloced = 0;
+
+static inline size_t ip6_4rd_nlmsg_size(void)
+{
+	return NLMSG_ALIGN(sizeof(struct ip6_4rd_map_msg));
+}
+
+static int ip6_4rd_fill_node(struct sk_buff *skb, struct ip6_tnl_4rd_map_rule *mr,
+		u32 pid, u32 seq, int type, unsigned int flags, int reset,
+		unsigned int ifindex)
+{
+	struct ip6_4rd_map_msg *mr_msg;
+	struct nlmsghdr *nlh;
+
+	nlh = nlmsg_put(skb, pid, seq, type, sizeof(*mr_msg), flags);
+	if (nlh == NULL)
+		return -EMSGSIZE;
+
+	mr_msg = nlmsg_data(nlh);
+	if (reset) {
+		memset(mr_msg, 0, sizeof(*mr_msg));
+		mr_msg->reset = 1;
+		mr_msg->ifindex = ifindex;
+	} else {
+		memset(mr_msg, 0, sizeof(*mr_msg));
+		mr_msg->prefix = mr->prefix;
+		mr_msg->prefixlen = mr->prefixlen;
+		mr_msg->relay_prefix = mr->relay_prefix;
+		mr_msg->relay_suffix = mr->relay_suffix;
+		mr_msg->relay_prefixlen = mr->relay_prefixlen;
+		mr_msg->relay_suffixlen = mr->relay_suffixlen;
+		mr_msg->psid_offsetlen = mr->psid_offsetlen;
+		mr_msg->eabit_len = mr->eabit_len;
+		mr_msg->entry_num = mr->entry_num;
+		mr_msg->ifindex = ifindex;
+	}
+	nlmsg_end(skb, nlh);
+	return nlh->nlmsg_len;
+}
+
+static void ip6_4rd_notify(int event, struct ip6_tnl_4rd_map_rule *mr,
+		struct net_device *dev, int reset)
+{
+	struct sk_buff *skb;
+	struct net *net = dev_net(dev);
+	int err;
+
+	err = -ENOBUFS;
+	skb = nlmsg_new(ip6_4rd_nlmsg_size(), gfp_any());
+	if (skb == NULL)
+		goto errout;
+
+	err = ip6_4rd_fill_node(skb, mr, 0, 0, event, 0, reset, dev->ifindex);
+	if (err < 0) {
+		WARN_ON(err == -EMSGSIZE);
+		kfree_skb(skb);
+		goto errout;
+	}
+	rtnl_notify(skb, net, 0, RTNLGRP_IPV6_IFADDR, NULL, gfp_any());
+	return;
+errout:
+	if (err < 0)
+		rtnl_set_sk_err(net, RTNLGRP_IPV6_IFADDR, err);
+}
+
+static inline void
+ip6_tnl_4rd_mr_destroy(char *f, struct ip6_tnl_4rd_map_rule *mr)
+{
+	list_del(&mr->mr_list);
+	kmem_cache_free(mr_kmem, mr);
+	--mr_kmem_alloced;
+}
+
+static int
+ip6_tnl_4rd_mr_create(struct ip6_tnl_4rd *ip4rd, struct ip6_tnl_4rd_parm *parm,
+		struct net_device *dev)
+{
+	struct ip6_tnl_4rd_map_rule *mr;
+	int err = 0;
+
+	write_lock_bh(&parm->map_lock);
+	list_for_each_entry(mr, &parm->map_list, mr_list) {
+		if (mr->entry_num == ip4rd->entry_num) {
+			pr_debug("ip6_tnl_4rd_mr_create: map rule found update\n");
+			mr->prefix = ip4rd->prefix;
+			mr->relay_prefix = ip4rd->relay_prefix;
+			mr->relay_suffix = ip4rd->relay_suffix;
+			mr->prefixlen = ip4rd->prefixlen;
+			mr->relay_prefixlen = ip4rd->relay_prefixlen;
+			mr->relay_suffixlen = ip4rd->relay_suffixlen;
+			mr->psid_offsetlen = ip4rd->psid_offsetlen;
+			mr->eabit_len = ip4rd->eabit_len;
+			mr->entry_num = ip4rd->entry_num;
+			goto out;
+		}
+	}
+
+	mr = kmem_cache_alloc(mr_kmem, GFP_KERNEL);
+	if (!mr) {
+		pr_info("ip6_tnl_4rd_mr_create: kmem_cache_alloc fail\n");
+		err = -1;
+		goto out;
+	}
+
+	mr->prefix = ip4rd->prefix;
+	mr->relay_prefix = ip4rd->relay_prefix;
+	mr->relay_suffix = ip4rd->relay_suffix;
+	mr->prefixlen = ip4rd->prefixlen;
+	mr->relay_prefixlen = ip4rd->relay_prefixlen;
+	mr->relay_suffixlen = ip4rd->relay_suffixlen;
+	mr->psid_offsetlen = ip4rd->psid_offsetlen;
+	mr->eabit_len = ip4rd->eabit_len;
+	mr->entry_num = ip4rd->entry_num;
+
+	++mr_kmem_alloced;
+	list_add_tail(&mr->mr_list, &parm->map_list);
+
+out:
+	ip6_4rd_notify(RTM_NEW4RD, mr, dev, 0);
+	write_unlock_bh(&parm->map_lock);
+	return err;
+}
+
+static void
+ip6_tnl_4rd_mr_delete_all(struct ip6_tnl_4rd_parm *parm, struct net_device *dev)
+{
+	struct ip6_tnl_4rd_map_rule *mr, *mr_rule;
+
+	write_lock_bh(&parm->map_lock);
+	list_for_each_entry_safe(mr, mr_rule, &parm->map_list, mr_list) {
+		ip6_tnl_4rd_mr_destroy("all", mr);
+	}
+	ip6_4rd_notify(RTM_DEL4RD, mr, dev, 1);
+	write_unlock_bh(&parm->map_lock);
+}
+
+static int
+ip6_tnl_4rd_mr_delete(__u16 entry_num, struct ip6_tnl_4rd_parm *parm,
+		struct net_device *dev)
+{
+	struct ip6_tnl_4rd_map_rule *mr, *mr_rule;
+	int err = -1;
+
+	write_lock_bh(&parm->map_lock);
+	list_for_each_entry_safe(mr, mr_rule, &parm->map_list, mr_list) {
+		if (mr->entry_num == entry_num) {
+			pr_debug("ip6_tnl_4rd_mr_delete: map rule found delete\n");
+			ip6_tnl_4rd_mr_destroy("one", mr);
+			err = 0;
+			break;
+		}
+	}
+	ip6_4rd_notify(RTM_DEL4RD, mr, dev, 0);
+	write_unlock_bh(&parm->map_lock);
+	return err;
+}
+
+static void
+ip6_tnl_4rd_mr_show(struct ip6_tnl_4rd_parm *parm)
+{
+	struct ip6_tnl_4rd_map_rule *mr;
+
+	pr_debug("-- 4rd mapping rule list\n");
+	pr_debug("-- entry num = %d\n", mr_kmem_alloced);
+
+	read_lock(&parm->map_lock);
+	list_for_each_entry(mr, &parm->map_list, mr_list) {
+		pr_debug("%03d : %pI4/%02d %pI6c/%03d %pI6c/%03d eabit:%03d offset:%03d\n",
+			mr->entry_num,
+			&mr->prefix,
+			mr->prefixlen,
+			&mr->relay_prefix,
+			mr->relay_prefixlen,
+			&mr->relay_suffix,
+			mr->relay_suffixlen,
+			mr->eabit_len,
+			mr->psid_offsetlen);
+	}
+	read_unlock(&parm->map_lock);
+}
+
+static int
+ip6_tnl_4rd_modify_daddr(struct in6_addr *daddr6, __be32 daddr4, __be16 dport4,
+		struct ip6_tnl_4rd_map_rule *mr)
+{
+	int i, pbw0, pbi0, pbi1;
+	__u32 daddr[4];
+	__u32 port_set_id = 0;
+	__u32 mask;
+	__u32 da = ntohl(daddr4);
+	__u16 dp = ntohs(dport4);
+	__u32 diaddr[4];
+	int port_set_id_len = (mr->eabit_len) - (32 - mr->prefixlen);
+
+	if (port_set_id_len < 0) {
+		pr_debug("ip6_tnl_4rd_modify_daddr: PSID length ERROR %d\n",
+			port_set_id_len);
+		return -1;
+	}
+
+	if (port_set_id_len > 0) {
+		mask = 0xffffffff >> (32 - port_set_id_len);
+		port_set_id = (dp >> (16 - mr->psid_offsetlen - port_set_id_len) & mask);
+	}
+
+	for (i = 0; i < 4; ++i)
+		daddr[i] = ntohl(mr->relay_prefix.s6_addr32[i])
+			| ntohl(mr->relay_suffix.s6_addr32[i]);
+
+	if (mr->prefixlen < 32) {
+		pbw0 = mr->relay_prefixlen >> 5;
+		pbi0 = mr->relay_prefixlen & 0x1f;
+		daddr[pbw0] |= (da << mr->prefixlen) >> pbi0;
+		pbi1 = pbi0 - mr->prefixlen;
+		if (pbi1 > 0)
+			daddr[pbw0+1] |= da << (32 - pbi1);
+	}
+	if (port_set_id_len > 0) {
+		pbw0 = (mr->relay_prefixlen + 32 - mr->prefixlen) >> 5;
+		pbi0 = (mr->relay_prefixlen + 32 - mr->prefixlen) & 0x1f;
+		daddr[pbw0] |= (port_set_id << (32 - port_set_id_len)) >> pbi0;
+		pbi1 = pbi0 - (32 - port_set_id_len);
+		if (pbi1 > 0)
+			daddr[pbw0+1] |= port_set_id << (32 - pbi1);
+	}
+
+	memset(diaddr, 0, sizeof(diaddr));
+	diaddr[2] = (da >> 8);
+	diaddr[3] = (da << 24);
+	diaddr[3] |= (port_set_id << 8);
+
+	for (i = 0; i < 4; ++i)
+		daddr[i] = daddr[i] | diaddr[i];
+
+	for (i = 0; i < 4; ++i)
+		daddr6->s6_addr32[i] = htonl(daddr[i]);
+
+	pr_debug("ip6_tnl_4rd_modify_daddr: %08x %08x %08x %08x  PSID:%04x\n",
+		daddr[0], daddr[1], daddr[2], daddr[3], port_set_id);
+
+	return 0;
+}
+
+/**
+ * ip6_tnl_4rd_rcv_helper - validate received 4RD packet
+ *   @skb: received socket buffer
+ *   @t: tunnel device
+ **/
+static int
+ip6_tnl_4rd_rcv_helper(struct sk_buff *skb, struct ip6_tnl *t)
+{
+	int err = 0;
+	struct iphdr *iph;
+
+	iph = ip_hdr(skb);
+
+	switch (iph->protocol) {
+	case IPPROTO_TCP:
+	case IPPROTO_UDP:
+	case IPPROTO_ICMP:
+	case IPPROTO_GRE:
+		break;
+	default:
+		err = -1;
+		break;
+	}
+
+	return err;
+}
+
+static int
+ip6_tnl_4rd_xmit_helper(struct sk_buff *skb, struct flowi6 *fl6,
+		struct ip6_tnl *t)
+{
+	int err = 0;
+	struct iphdr *iph, *icmpiph;
+	__be16 *idp;
+	struct tcphdr *tcph, *icmptcph;
+	struct udphdr *udph, *icmpudph;
+	struct icmphdr *icmph;
+	__u32 mask;
+	__be16 *sportp = NULL;
+	__be32 daddr;
+	__be16 dport;
+	u8 *ptr;
+	int no_dst_chg = 0;
+	struct ip6_tnl_4rd_map_rule *mr, *mr_tmp;
+	int mr_prefixlen;
+	int count;
+
+	iph = ip_hdr(skb);
+
+	daddr = iph->daddr;
+	idp = &iph->id;
+
+	ptr = (u8 *)iph;
+	ptr += iph->ihl * 4;
+	switch (iph->protocol) {
+	case IPPROTO_TCP:
+		tcph = (struct tcphdr *)ptr;
+		sportp = &tcph->source;
+		dport = tcph->dest;
+		break;
+	case IPPROTO_UDP:
+		udph = (struct udphdr *)ptr;
+		sportp = &udph->source;
+		dport = udph->dest;
+		break;
+	case IPPROTO_ICMP:
+		icmph = (struct icmphdr *)ptr;
+		switch (icmph->type) {
+		case ICMP_DEST_UNREACH:
+		case ICMP_SOURCE_QUENCH:
+		case ICMP_REDIRECT:
+		case ICMP_TIME_EXCEEDED:
+		case ICMP_PARAMETERPROB:
+			ptr = (u8 *)icmph;
+			ptr += sizeof(struct icmphdr);
+			icmpiph = (struct iphdr *)ptr;
+			if (ntohs(iph->tot_len) < icmpiph->ihl * 4 + 12) {
+				err = -1;
+				goto out;
+			}
+			daddr = icmpiph->saddr;
+			ptr += icmpiph->ihl * 4;
+			switch (icmpiph->protocol) {
+			case IPPROTO_TCP:
+				icmptcph = (struct tcphdr *)ptr;
+				sportp = &icmptcph->dest;
+				dport = icmptcph->source;
+				break;
+			case IPPROTO_UDP:
+				icmpudph = (struct udphdr *)ptr;
+				sportp = &icmpudph->dest;
+				dport = icmpudph->source;
+				break;
+			default:
+				err = -1;
+				goto out;
+			}
+			break;
+		default:
+			no_dst_chg = 1;
+			break;
+		}
+		break;
+	default:
+		err = -1;
+		goto out;
+	}
+
+	if (no_dst_chg == 0) {
+		count = 0;
+		mr_prefixlen = 0;
+
+		read_lock(&t->ip4rd.map_lock);
+		list_for_each_entry(mr, &t->ip4rd.map_list, mr_list) {
+			mask = 0xffffffff << (32 - mr->prefixlen);
+			if ((htonl(daddr) & mask) == htonl(mr->prefix)) {
+				if (mr->prefixlen >= mr_prefixlen) {
+					mr_prefixlen = mr->prefixlen;
+					mr_tmp = mr;
+					count++;
+				}
+			}
+		}
+
+		if (count) {
+			err = ip6_tnl_4rd_modify_daddr(&fl6->daddr, daddr, dport, mr_tmp);
+			if (err) {
+				read_unlock(&t->ip4rd.map_lock);
+				goto out;
+			}
+		}
+		read_unlock(&t->ip4rd.map_lock);
+
+		if (sportp && idp)
+			*idp = *sportp;
+	}
+
+	iph->check = 0;
+	iph->check = ip_fast_csum((unsigned char *)iph, iph->ihl);
+
+out:
+	return err;
+}
+
+/**
+ * ip6_tnl_4rd_update_parms - update 4rd parameters
+ *   @t: tunnel to be updated
+ *
+ * Description:
+ *   ip6_tnl_4rd_update_parms() updates 4rd parameters
+ **/
+static void
+ip6_tnl_4rd_update_parms(struct ip6_tnl *t)
+{
+	int pbw0, pbi0, pbi1;
+	__u32 d;
+
+	t->ip4rd.port_set_id_len = t->ip4rd.relay_suffixlen
+		- t->ip4rd.relay_prefixlen
+		- (32 - t->ip4rd.prefixlen);
+	pbw0 = (t->ip4rd.relay_suffixlen - t->ip4rd.port_set_id_len) >> 5;
+	pbi0 = (t->ip4rd.relay_suffixlen - t->ip4rd.port_set_id_len) & 0x1f;
+	d = (ntohl(t->parms.laddr.s6_addr32[pbw0]) << pbi0)
+		>> (32 - t->ip4rd.port_set_id_len);
+	pbi1 = pbi0 - (32 - t->ip4rd.port_set_id_len);
+
+	if (pbi1 > 0)
+		d |= ntohl(t->parms.laddr.s6_addr32[pbw0+1]) >> (32 - pbi1);
+	t->ip4rd.port_set_id = d;
+
+	/* local v4 address */
+	t->ip4rd.laddr4 = t->ip4rd.prefix;
+	pbw0 = t->ip4rd.relay_prefixlen >> 5;
+	pbi0 = t->ip4rd.relay_prefixlen & 0x1f;
+	d = (ntohl(t->parms.laddr.s6_addr32[pbw0]) << pbi0)
+		>> t->ip4rd.prefixlen;
+	pbi1 = pbi0 - t->ip4rd.prefixlen;
+	if (pbi1 > 0)
+		d |= ntohl(t->parms.laddr.s6_addr32[pbw0+1]) >> (32 - pbi1);
+	t->ip4rd.laddr4 |= htonl(d);
+	if (t->ip4rd.port_set_id_len < 0) {
+		d = ntohl(t->ip4rd.laddr4);
+		d &= 0xffffffff << -t->ip4rd.port_set_id_len;
+		t->ip4rd.laddr4 = htonl(d);
+	}
+}
+
+static int inet6_dump4rd_mrule(struct sk_buff *skb, struct netlink_callback *cb)
+{
+	struct net *net = sock_net(skb->sk);
+	unsigned int h, s_h;
+	int s_idx, s_ip_idx;
+	int idx, ip_idx;
+	struct ip6_tnl_4rd_map_rule *mr;
+	int err = 0;
+	struct ip6_tnl *t;
+	struct ip6_tnl_net *ip6n = net_generic(net, ip6_tnl_net_id);
+
+	s_h = cb->args[0];
+	s_idx = idx = cb->args[1];
+	s_ip_idx = ip_idx = cb->args[2];
+
+	rcu_read_lock();
+
+	for (h = s_h; h < IP6_TUNNEL_HASH_SIZE; h++, s_idx = 0) {
+		idx = 0;
+		for_each_ip6_tunnel_rcu(ip6n->tnls_r_l[h]) {
+			if (idx < s_idx)
+				goto cont_tunnel;
+			if (idx > s_idx)
+				s_ip_idx = 0;
+			ip_idx = 0;
+			read_lock(&t->ip4rd.map_lock);
+			list_for_each_entry(mr, &t->ip4rd.map_list, mr_list) {
+				if (ip_idx < s_ip_idx)
+					goto cont_mr;
+
+				err = ip6_4rd_fill_node(skb, mr,
+					NETLINK_CB(cb->skb).portid,
+					cb->nlh->nlmsg_seq, RTM_NEW4RD,
+					NLM_F_MULTI, 0, t->dev->ifindex);
+				if (err < 0) {
+					WARN_ON(err == -EMSGSIZE);
+					kfree_skb(skb);
+					read_unlock(&t->ip4rd.map_lock);
+					goto out;
+				}
+cont_mr:
+				ip_idx++;
+			}
+			read_unlock(&t->ip4rd.map_lock);
+cont_tunnel:
+			idx++;
+		}
+	}
+out:
+	rcu_read_unlock();
+
+	cb->args[0] = h;
+	cb->args[1] = idx;
+	cb->args[2] = ip_idx;
+
+	return skb->len;
+}
+
+#endif /* CONFIG_CPE_4RD_TUNNEL */
+
 static int ip6_tnl_dev_init(struct net_device *dev);
 static void ip6_tnl_dev_setup(struct net_device *dev);
 static struct rtnl_link_ops ip6_link_ops __read_mostly;
@@ -95,8 +595,10 @@ static inline int ip6_tnl_mpls_supported(void)
 	return IS_ENABLED(CONFIG_MPLS);
 }
 
+#ifndef CONFIG_CPE_4RD_TUNNEL
 #define for_each_ip6_tunnel_rcu(start) \
 	for (t = rcu_dereference(start); t; t = rcu_dereference(t->next))
+#endif
 
 /**
  * ip6_tnl_lookup - fetch tunnel matching the end-point addresses
@@ -870,6 +1372,11 @@ static int __ip6_tnl_rcv(struct ip6_tnl *tunnel, struct sk_buff *skb,
 		}
 	}
 
+#ifdef CONFIG_CPE_4RD_TUNNEL
+	if (ip6_tnl_4rd_rcv_helper(skb, tunnel))
+		goto drop;
+#endif
+
 	dev_sw_netstats_rx_add(tunnel->dev, skb->len);
 
 	skb_scrub_packet(skb, !net_eq(tunnel->net, dev_net(tunnel->dev)));
@@ -1196,10 +1703,27 @@ int ip6_tnl_xmit(struct sk_buff *skb, struct net_device *dev, __u8 dsfield,
 		       IPV6_MIN_MTU : IPV4_MIN_MTU);
 
 	skb_dst_update_pmtu_no_confirm(skb, mtu);
-	if (skb->len - t->tun_hlen - eth_hlen > mtu && !skb_is_gso(skb)) {
-		*pmtu = mtu;
-		err = -EMSGSIZE;
-		goto tx_err_dst_release;
+
+#ifdef CONFIG_CPE_4RD_TUNNEL
+		if (!t->ip4rd.prefix) {   /* 4rd support requires Post Fragmentation, so skb->len could be greater than MTU */ 
+#endif
+			if (skb->len - t->tun_hlen - eth_hlen > mtu && !skb_is_gso(skb)) {
+				*pmtu = mtu;
+				err = -EMSGSIZE;
+				goto tx_err_dst_release;
+			}
+#ifdef CONFIG_CPE_4RD_TUNNEL
+		}                         
+
+	if (t->ip4rd.prefix) {
+		struct iphdr *iph;
+		iph = ip_hdr(skb);
+		hop_limit = iph->ttl;
+	}
+	else
+#endif
+	{
+		hop_limit = t->parms.hop_limit;
 	}
 
 	if (t->err_count > 0) {
@@ -1398,6 +1922,12 @@ ipxip6_tnl_xmit(struct sk_buff *skb, struct net_device *dev,
 
 	skb_set_inner_ipproto(skb, protocol);
 
+#ifdef CONFIG_CPE_4RD_TUNNEL
+	if (protocol == IPPROTO_IPIP &&
+	    t->ip4rd.prefix && ip6_tnl_4rd_xmit_helper(skb, &fl6, t))
+		return -1;
+#endif
+
 	err = ip6_tnl_xmit(skb, dev, dsfield, &fl6, encap_limit, &mtu,
 			   protocol);
 	if (err != 0) {
@@ -1432,6 +1962,10 @@ ip6_tnl_start_xmit(struct sk_buff *skb, struct net_device *dev)
 
 	switch (skb->protocol) {
 	case htons(ETH_P_IP):
+#ifdef CONFIG_CPE_4RD_TUNNEL
+		if (t->ip4rd.prefix && ip_defrag(skb, IP_DEFRAG_IP6_TNL_4RD))
+			return NETDEV_TX_OK;
+#endif
 		ipproto = IPPROTO_IPIP;
 		break;
 	case htons(ETH_P_IPV6):
@@ -1636,6 +2170,10 @@ ip6_tnl_siocdevprivate(struct net_device *dev, struct ifreq *ifr,
 	struct ip6_tnl *t = netdev_priv(dev);
 	struct net *net = t->net;
 	struct ip6_tnl_net *ip6n = net_generic(net, ip6_tnl_net_id);
+#ifdef CONFIG_CPE_4RD_TUNNEL
+	struct ip6_tnl_4rd ip4rd, *ip4rdp;  
+	struct ip6_tnl_4rd_map_rule *mr;   
+#endif
 
 	memset(&p1, 0, sizeof(p1));
 
@@ -1716,9 +2254,120 @@ ip6_tnl_siocdevprivate(struct net_device *dev, struct ifreq *ifr,
 		err = 0;
 		unregister_netdevice(dev);
 		break;
+#ifdef CONFIG_CPE_4RD_TUNNEL
+	case SIOCADD4RD:
+	case SIOCDEL4RD:
+		err = -EPERM;
+		if (!capable(CAP_NET_ADMIN))
+			goto done;
+
+		err = -EFAULT;
+		if (copy_from_user(&ip4rd, ifr->ifr_ifru.ifru_data, sizeof(ip4rd)))
+			goto done;
+
+		t = netdev_priv(dev);
+
+		if (cmd == SIOCADD4RD) {
+
+			__be32 prefix;
+			struct in6_addr relay_prefix, relay_suffix;
+
+			err = -EINVAL;
+
+			if (ip4rd.relay_suffixlen > 64)
+				goto done;
+
+			if (ip4rd.relay_suffixlen <= ip4rd.relay_prefixlen)
+				goto done;
+
+			prefix = ip4rd.prefix & htonl(0xffffffffUL << (32 - ip4rd.prefixlen));
+			if (prefix != ip4rd.prefix)
+				goto done;
+
+			ipv6_addr_prefix(&relay_prefix, &ip4rd.relay_prefix, ip4rd.relay_prefixlen);
+			if (!ipv6_addr_equal(&relay_prefix, &ip4rd.relay_prefix))
+				goto done;
+
+			ipv6_addr_prefix(&relay_suffix, &ip4rd.relay_suffix, ip4rd.relay_suffixlen);
+			if (!ipv6_addr_equal(&relay_suffix, &ip4rd.relay_suffix))
+				goto done;
+
+
+			err = ip6_tnl_4rd_mr_create(&ip4rd, &t->ip4rd, t->dev); /* modified by MSPD */
+
+			if ( ip4rd.entry_num == 0 ){
+
+				t->ip4rd.prefix = prefix;
+				t->ip4rd.relay_prefix = relay_prefix;
+				t->ip4rd.relay_suffix = relay_suffix;
+				t->ip4rd.prefixlen = ip4rd.prefixlen;
+				t->ip4rd.relay_prefixlen = ip4rd.relay_prefixlen;
+				t->ip4rd.relay_suffixlen = ip4rd.relay_suffixlen;
+				t->ip4rd.psid_offsetlen = ip4rd.psid_offsetlen;
+
+				ip6_tnl_4rd_update_parms(t);
+				ip6_tnl_dst_reset(t);
+				ip6_tnl_link_config(t);
+			}
+			/* DBG */
+			ip6_tnl_4rd_mr_show(&t->ip4rd);
+		}else if(cmd == SIOCDEL4RD){
+			if ( ip4rd.entry_num == 0 ){
+				ip6_tnl_4rd_mr_delete_all(&t->ip4rd, t->dev);
+				t->ip4rd.prefix = 0;
+				memset(&t->ip4rd.relay_prefix, 0, sizeof(t->ip4rd.relay_prefix));
+				memset(&t->ip4rd.relay_suffix, 0, sizeof(t->ip4rd.relay_suffix));
+				t->ip4rd.prefixlen = 0;
+				t->ip4rd.relay_prefixlen = 0;
+				t->ip4rd.relay_suffixlen = 0;
+				t->ip4rd.psid_offsetlen = 0;
+				t->ip4rd.laddr4 = 0;
+				t->ip4rd.port_set_id = t->ip4rd.port_set_id_len = 0;
+
+				ip6_tnl_dst_reset(t);
+				ip6_tnl_link_config(t);
+			}else{
+				err = ip6_tnl_4rd_mr_delete( ip4rd.entry_num , &t->ip4rd, t->dev);  /* modified by MSPD */
+			}
+			/* DBG */
+			ip6_tnl_4rd_mr_show(&t->ip4rd);
+		}else{
+			printk(KERN_ERR "=== ioctl_cmd 0x%x \n",cmd );
+		}
+		err = 0;
+		break;
+	case SIOCGET4RD:
+		t = netdev_priv(dev);
+		ip4rdp = (struct ip6_tnl_4rd *)ifr->ifr_ifru.ifru_data;
+
+		read_lock(&t->ip4rd.map_lock);
+		list_for_each_entry (mr, &t->ip4rd.map_list, mr_list){
+			ip4rd.relay_prefix = mr->relay_prefix;
+			ip4rd.relay_suffix = mr->relay_suffix;
+			ip4rd.prefix = mr->prefix;
+			ip4rd.relay_prefixlen = mr->relay_prefixlen;
+			ip4rd.relay_suffixlen = mr->relay_suffixlen;
+			ip4rd.prefixlen = mr->prefixlen;
+			ip4rd.eabit_len = mr->eabit_len;
+			ip4rd.psid_offsetlen = mr->psid_offsetlen;
+			ip4rd.entry_num = mr->entry_num;
+
+			if (copy_to_user(ip4rdp, &ip4rd, sizeof(ip4rd))) {
+				read_unlock(&t->ip4rd.map_lock);
+				err = -EFAULT;
+			}
+			ip4rdp++;
+		}
+		read_unlock(&t->ip4rd.map_lock);
+		break;
+#endif
+
 	default:
 		err = -EINVAL;
 	}
+#ifdef CONFIG_CPE_4RD_TUNNEL
+done:
+#endif
 	return err;
 }
 
@@ -2313,9 +2962,24 @@ static int __init ip6_tunnel_init(void)
 	if (!ipv6_mod_enabled())
 		return -EOPNOTSUPP;
 
+#ifdef CONFIG_CPE_4RD_TUNNEL
+	mr_kmem = kmem_cache_create("ip6_tnl_4rd_map_rule",
+				sizeof(struct ip6_tnl_4rd_map_rule), 0, SLAB_HWCACHE_ALIGN,
+				NULL);
+	if (!mr_kmem)
+	{
+		err= -ENOMEM; 
+		goto out_pernet;
+	}
+#endif
+
 	err = register_pernet_device(&ip6_tnl_net_ops);
 	if (err < 0)
+#ifdef CONFIG_CPE_4RD_TUNNEL
+		goto out_kmem;
+#else
 		goto out_pernet;
+#endif
 
 	err = xfrm6_tunnel_register(&ip4ip6_handler, AF_INET);
 	if (err < 0) {
@@ -2352,6 +3016,10 @@ static int __init ip6_tunnel_init(void)
 	xfrm6_tunnel_deregister(&ip4ip6_handler, AF_INET);
 out_ip4ip6:
 	unregister_pernet_device(&ip6_tnl_net_ops);
+#ifdef CONFIG_CPE_4RD_TUNNEL
+out_kmem:
+	kmem_cache_destroy(mr_kmem);
+#endif
 out_pernet:
 	return err;
 }
diff --git a/net/ipv6/netfilter/ip6t_NPT.c b/net/ipv6/netfilter/ip6t_NPT.c
index 787c74aa85e3..f523f471722a 100644
--- a/net/ipv6/netfilter/ip6t_NPT.c
+++ b/net/ipv6/netfilter/ip6t_NPT.c
@@ -11,6 +11,9 @@
 #include <linux/netfilter_ipv6.h>
 #include <linux/netfilter_ipv6/ip6t_NPT.h>
 #include <linux/netfilter/x_tables.h>
+#ifdef CONFIG_CPE_FAST_PATH
+#include <net/netfilter/nf_conntrack.h>
+#endif
 
 static int ip6t_npt_checkentry(const struct xt_tgchk_param *par)
 {
@@ -114,6 +117,19 @@ ip6t_snpt_tg(struct sk_buff *skb, const struct xt_action_param *par)
 			ip6t_npt_map_pfx(npt, &bounced_hdr->daddr);
 	}
 
+#ifdef CONFIG_CPE_FAST_PATH
+	{
+		struct nf_conn *ct;
+		enum ip_conntrack_info ctinfo;
+		rcu_read_lock();
+		ct = nf_ct_get(skb, &ctinfo);
+		if (ct && ((ctinfo == IP_CT_NEW) || (ctinfo == IP_CT_RELATED))) {
+			memcpy(&ct->tuplehash[IP_CT_DIR_REPLY].tuple.dst.u3.in6,
+			       &ipv6_hdr(skb)->saddr, sizeof(struct in6_addr));
+		}
+		rcu_read_unlock();
+	}
+#endif
 	return XT_CONTINUE;
 }
 
@@ -139,6 +155,19 @@ ip6t_dnpt_tg(struct sk_buff *skb, const struct xt_action_param *par)
 			ip6t_npt_map_pfx(npt, &bounced_hdr->saddr);
 	}
 
+#ifdef CONFIG_CPE_FAST_PATH
+	{
+		struct nf_conn *ct;
+		enum ip_conntrack_info ctinfo;
+		rcu_read_lock();
+		ct = nf_ct_get(skb, &ctinfo);
+		if (ct && ((ctinfo == IP_CT_NEW) || (ctinfo == IP_CT_RELATED))) {
+			memcpy(&ct->tuplehash[IP_CT_DIR_REPLY].tuple.src.u3.in6,
+			       &ipv6_hdr(skb)->daddr, sizeof(struct in6_addr));
+		}
+		rcu_read_unlock();
+	}
+#endif
 	return XT_CONTINUE;
 }
 
diff --git a/net/ipv6/output_core.c b/net/ipv6/output_core.c
index 806d4b5dd1e6..f27467e8e51d 100644
--- a/net/ipv6/output_core.c
+++ b/net/ipv6/output_core.c
@@ -128,7 +128,18 @@ int __ip6_local_out(struct net *net, struct sock *sk, struct sk_buff *skb)
 	len = skb->len - sizeof(struct ipv6hdr);
 	if (len > IPV6_MAXPLEN)
 		len = 0;
+
+#if defined(CONFIG_INET6_IPSEC_OFFLOAD)
+/* Since tunnel header is not added in slow path and route cache entry lookup is changed to perform
+   lookup on tunnel header, for Ipv4 over Ipv6 IPsec tunnel cases,dst_output will be ip6 output 
+   but packet will be IPv4 type. So,this check is introduced to update ipv6 pay_load for the following cases
+   1.IPv6 over Ipv6 IPsec tunnel.
+   2.IPv4 over Ipv6 Ipsec tunnel when software encryption come into play(i.e for packets > 1782 bytes) */
+        if((ipv6_hdr(skb)->version) == 6)
+                ipv6_hdr(skb)->payload_len = htons(len);
+#else
 	ipv6_hdr(skb)->payload_len = htons(len);
+#endif
 	IP6CB(skb)->nhoff = offsetof(struct ipv6hdr, nexthdr);
 
 	/* if egress device is enslaved to an L3 master device pass the
@@ -140,6 +151,14 @@ int __ip6_local_out(struct net *net, struct sock *sk, struct sk_buff *skb)
 
 	skb->protocol = htons(ETH_P_IPV6);
 
+#if defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	if(skb->ipsec_offload)
+	{
+		dst_output(net, sk, skb);
+		return 0;
+	}
+	else
+#endif
 	return nf_hook(NFPROTO_IPV6, NF_INET_LOCAL_OUT,
 		       net, sk, skb, NULL, skb_dst(skb)->dev,
 		       dst_output);
diff --git a/net/ipv6/sit.c b/net/ipv6/sit.c
index 3c15a0ae228e..338f3d6674c3 100644
--- a/net/ipv6/sit.c
+++ b/net/ipv6/sit.c
@@ -694,6 +694,9 @@ static int ipip6_rcv(struct sk_buff *skb)
 		skb->mac_header = skb->network_header;
 		skb_reset_network_header(skb);
 		IPCB(skb)->flags = 0;
+#ifdef CONFIG_CPE_FAST_PATH
+		skb->underlying_iif = skb->dev->ifindex;
+#endif
 		skb->dev = tunnel->dev;
 
 		if (packet_is_spoofed(skb, iph, tunnel)) {
diff --git a/net/ipv6/udp.c b/net/ipv6/udp.c
index 57e38e5e4be9..7d0137e59362 100644
--- a/net/ipv6/udp.c
+++ b/net/ipv6/udp.c
@@ -784,7 +784,6 @@ static int udpv6_queue_rcv_one_skb(struct sock *sk, struct sk_buff *skb)
 
 		/* FALLTHROUGH -- it's a UDP Packet */
 	}
-
 	/*
 	 * UDP-Lite specific tests, ignored on UDP sockets (see net/ipv4/udp.c).
 	 */
diff --git a/net/ipv6/xfrm6_policy.c b/net/ipv6/xfrm6_policy.c
index 1f19b6f14484..090c1456274f 100644
--- a/net/ipv6/xfrm6_policy.c
+++ b/net/ipv6/xfrm6_policy.c
@@ -40,6 +40,16 @@ static struct dst_entry *xfrm6_dst_lookup(const struct xfrm_dst_lookup_params *p
 	fl6.flowi4_proto = params->ipproto;
 	fl6.uli = params->uli;
 
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	/*
+	 * For IPsec packets with directly connected tunnel end points,
+	 * neighbor resolution is done for inner destination since we do not
+	 * add tunnel headers in slow path to IPsec packets. To fix this issue,
+	 * flag "FLOWI_FLAG_KNOWN_NH" is passed during tunnel route lookup.
+	 */
+	fl6.flowi6_flags |= FLOWI_FLAG_KNOWN_NH;
+#endif
+
 	dst = ip6_route_output(params->net, NULL, &fl6);
 
 	err = dst->error;
diff --git a/net/key/af_key.c b/net/key/af_key.c
index c56bb4f451e6..0e0177ce90bf 100644
--- a/net/key/af_key.c
+++ b/net/key/af_key.c
@@ -26,8 +26,183 @@
 #include <net/net_namespace.h>
 #include <net/netns/generic.h>
 #include <net/xfrm.h>
+#if defined(CONFIG_INET_IPSEC_OFFLOAD)|| defined(CONFIG_INET6_IPSEC_OFFLOAD)
+#include <net/netlink.h>
+#endif
 
 #include <net/sock.h>
+#if defined(CONFIG_INET_IPSEC_OFFLOAD)|| defined(CONFIG_INET6_IPSEC_OFFLOAD)
+#include <net/ip6_route.h>
+#define NLKEY_SUPPORT 1
+#else 
+#undef NLKEY_SUPPORT
+#endif 
+
+#ifdef NLKEY_SUPPORT
+#include <net/dsfield.h>
+#include <net/inet_ecn.h>
+#include <net/ipv6.h>
+
+
+extern int xfrm_get_tos(struct flowi *fl, int family);
+
+
+#define	NLKEY_SA_CREATE		0x0A01
+#define NLKEY_SA_DELETE		0x0A02
+#define NLKEY_SA_FLUSH 		0x0A03
+#define NLKEY_SA_SET_KEYS	0x0A04
+#define NLKEY_SA_SET_TUNNEL	0x0A05
+#define NLKEY_SA_SET_NATT	0x0A06
+#define	NLKEY_SA_SET_STATE	0x0A07
+#define	NLKEY_SA_SET_LIFETIME	0x0A08
+#define	NLKEY_SA_NOTIFY		0x0A09
+#define NLKEY_SA_INFO_UPDATE	0x0A0C
+#define NLKEY_SA_SET_OFFLOAD	0x0A0D
+#define	NLKEY_FLOW_ADD		0x0A11
+#define NLKEY_FLOW_REMOVE	0x0A12
+#define NLKEY_FLOW_NOTIFY	0x0A13
+#define NLKEY_NULL_MSG		0x0000
+
+#define NLKEY_HDR_LEN		4
+#define NLKEY_MSG_LEN 		256
+
+#define NLKEY_MAX_NUM_KEYS	2
+#define NLKEY_MAX_KEY_LEN	(512 / 8)
+
+struct nlkey_msg {
+	/* message data */
+	unsigned short fcode;
+	unsigned short length;
+	unsigned short payload[(NLKEY_MSG_LEN /sizeof(unsigned short))];
+};
+/* sizeof(nlkey_msg) = 4 + 256 */
+
+struct nlkey_sa_id {
+	unsigned int spi;
+	unsigned char sa_type;
+	unsigned char proto_family;
+	unsigned char replay_window;
+#define NLKEY_SAFLAGS_ESN	0x1
+#define NLKEY_SAFLAGS_INBOUND	0x2
+	unsigned char flags;
+	unsigned int dst_ip[4];
+	unsigned int src_ip[4];
+	unsigned short mtu;
+	unsigned short dev_mtu;
+
+};
+/* sizeof(nlkey_sa_id) = 24 */
+
+struct nlkey_sa_create {
+	unsigned short sagd;
+	unsigned short parent_sa_sagd; /*sagd value of old SA from which this SA is rekeyed.*/
+	struct nlkey_sa_id said;
+};
+/* sizeof(nlkey_sa_delete) = 28 */
+
+struct nlkey_sa_delete {
+	unsigned short sagd;
+	unsigned short rsvd;
+};
+/* sizeof(nlkey_sa_delete) = 4 */
+
+struct nlkey_sa_set_tunnel {
+	unsigned short sagd;
+	unsigned char rsvd;
+	unsigned char proto_family;
+	union {
+		struct iphdr 	 ipv4h;
+		struct ipv6hdr ipv6h;
+	} h;
+};
+/* sizeof(nlkey_sa_set_tunnel) = 36 */
+
+struct nlkey_sa_set_natt {
+	unsigned short sagd;
+	unsigned short sport;
+	unsigned short dport;
+	unsigned short rsvd;
+};
+/* sizeof(nlkey_sa_set_natt) = 4 */
+
+struct nlkey_sa_set_state {
+	unsigned short sagd;
+	unsigned short parent_sa_sagd;
+	unsigned short state;
+	unsigned short rsvd2;
+};
+/* sizeof(nlkey_sa_set_natt) = 8 */
+
+struct nlkey_key_desc {
+	unsigned short key_bits;
+	unsigned char key_alg;
+	unsigned char  key_type;
+	unsigned char key[NLKEY_MAX_KEY_LEN]; 
+};
+/* sizeof(nlkey_key_desc) =  36 */
+
+struct nlkey_sa_set_keys {
+	unsigned short sagd;
+	unsigned short rsvd;	
+	unsigned short num_keys;
+	unsigned short rsvd2;
+	struct nlkey_key_desc keys[NLKEY_MAX_NUM_KEYS];
+};
+/* sizeof(nlkey_sa_set_keys) =  80 */
+
+struct nlkey_lifetime_desc {
+	unsigned int allocations;
+	unsigned int bytes[2];
+};
+/* sizeof(nlkey_sa_set_lifetime) =  12 */
+
+struct nlkey_sa_set_lifetime {
+	unsigned short sagd;
+	unsigned short rsvd;
+	struct nlkey_lifetime_desc hard_time;
+	struct nlkey_lifetime_desc soft_time;
+	struct nlkey_lifetime_desc current_time;
+};
+/* sizeof(nlkey_sa_set_lifetime) =  40 */
+
+/* SA notifications */
+#define IPSEC_SOFT_EXPIRE 0
+#define IPSEC_HARD_EXPIRE 1
+
+struct nlkey_sa_notify {
+	unsigned short sagd;
+	unsigned short rsvd;
+	unsigned int  action;
+};
+/* sizeof(nlkey_sa_notify) = 8 */
+
+/* SA Info update */
+
+struct nlkey_sa_info {
+        unsigned short sagd;
+        unsigned short rsvd;
+        unsigned long long bytes;
+        unsigned long long packets;
+};
+/* sizeof(nlkey_sa_info) =  */
+
+
+static int ipsec_nlkey_send(struct net *net, struct xfrm_state *x, const struct km_event *c);
+static void ipsec_nlkey_rcv(struct sk_buff *skb);
+static void ipsec_nlkey_init(void);
+static unsigned short ipsec_sacode_to_nlkeycode(unsigned short sa_code);
+static struct sk_buff * ipsec_xfrm2nlkey (struct net *net, struct xfrm_state *x, 
+					const struct km_event *c, unsigned short *msg_id);
+static int ipsec_nlkey_set_said(struct net *net, struct xfrm_state *x, const struct km_event *c, struct nlkey_sa_id *said);
+
+void flow_cache_remove(const struct flowi *fl, unsigned short family,
+		unsigned short dir);
+/* netlink NETLINK_KEY socket */
+struct sock *nlkey_socket = NULL;
+
+#endif
+/************************************************************************************/
+
 
 #define _X2KEY(x) ((x) == XFRM_INF ? 0 : (x))
 #define _KEY2X(x) ((x) == 0 ? XFRM_INF : (x))
@@ -876,6 +1051,10 @@ static struct sk_buff *__pfkey_xfrm_state2msg(const struct xfrm_state *x,
 		sa->sadb_sa_flags |= SADB_SAFLAGS_DECAP_DSCP;
 	if (x->props.flags & XFRM_STATE_NOPMTUDISC)
 		sa->sadb_sa_flags |= SADB_SAFLAGS_NOPMTUDISC;
+#ifdef NLKEY_SUPPORT
+	if (x->props.flags & XFRM_STATE_ESN)
+		sa->sadb_sa_flags |= SADB_SAFLAGS_ESN;
+#endif
 
 	/* hard time */
 	if (hsc & 2) {
@@ -908,6 +1087,11 @@ static struct sk_buff *__pfkey_xfrm_state2msg(const struct xfrm_state *x,
 	lifetime->sadb_lifetime_bytes = x->curlft.bytes;
 	lifetime->sadb_lifetime_addtime = x->curlft.add_time;
 	lifetime->sadb_lifetime_usetime = x->curlft.use_time;
+
+#if defined(CONFIG_INET_IPSEC_OFFLOAD)|| defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	lifetime->sadb_lifetime_usetime = x->curr_time;
+#endif
+
 	/* src address */
 	addr = skb_put(skb, sizeof(struct sadb_address) + sockaddr_size);
 	addr->sadb_address_len =
@@ -1133,6 +1317,10 @@ static struct xfrm_state * pfkey_msg2xfrm_state(struct net *net,
 		x->props.flags |= XFRM_STATE_DECAP_DSCP;
 	if (sa->sadb_sa_flags & SADB_SAFLAGS_NOPMTUDISC)
 		x->props.flags |= XFRM_STATE_NOPMTUDISC;
+#ifdef NLKEY_SUPPORT
+	if (sa->sadb_sa_flags & SADB_SAFLAGS_ESN)
+		x->props.flags |= XFRM_STATE_ESN;
+#endif
 
 	lifetime = ext_hdrs[SADB_EXT_LIFETIME_HARD - 1];
 	if (lifetime != NULL) {
@@ -3076,6 +3264,12 @@ static int pfkey_send_notify(struct xfrm_state *x, const struct km_event *c)
 	struct net *net = x ? xs_net(x) : c->net;
 	struct netns_pfkey *net_pfkey = net_generic(net, pfkey_net_id);
 
+
+#ifdef NLKEY_SUPPORT
+	/* send message to the user space through NETLINK_KEY socket*/
+	ipsec_nlkey_send(net, x, c);
+#endif
+
 	if (atomic_read(&net_pfkey->socks_nr) == 0)
 		return 0;
 
@@ -3863,6 +4057,687 @@ static struct xfrm_mgr pfkeyv2_mgr =
 	.is_alive	= pfkey_is_alive,
 };
 
+
+#ifdef NLKEY_SUPPORT
+extern struct xfrm_state *xfrm_state_lookup_byhandle(struct net *net, u16 handle);
+
+static unsigned short ipsec_sacode_to_nlkeycode(unsigned short sa_code)
+{
+	unsigned nlkey_code;
+
+	switch (sa_code) 
+	{
+		case XFRM_MSG_DELSA:
+			nlkey_code = NLKEY_SA_DELETE;
+			break;
+		case XFRM_MSG_NEWSA:
+		case XFRM_MSG_UPDSA:
+			nlkey_code = NLKEY_SA_CREATE;
+			break;
+		case XFRM_MSG_FLUSHSA:
+			nlkey_code = NLKEY_SA_FLUSH;
+			break;
+		case XFRM_MSG_EXPIRE:
+			nlkey_code = NLKEY_SA_SET_STATE;
+			break;
+		default:
+			nlkey_code = NLKEY_NULL_MSG;
+			break;
+	}
+
+	return nlkey_code;
+}
+
+static void ipsec_nlkey_rcv(struct sk_buff *skb)
+{
+	struct nlmsghdr *nlh = NULL;
+	struct nlkey_msg *msg = NULL;
+	struct flowi flow;
+	unsigned short *p;
+	unsigned short family, dir;
+	struct xfrm_state *x;
+	struct nlkey_sa_notify sa_notify_msg;
+	struct nlkey_sa_info sa_info_msg;
+
+	/* extract message from skb */
+	nlh = (struct nlmsghdr *)skb->data;
+
+	msg = (struct nlkey_msg *)NLMSG_DATA(nlh);
+
+	//printk(KERN_INFO "ipsec_nlkey_rcv fcode: 0x%x length: %d bytes\n",msg->fcode,msg->length);
+
+	/* process command received from user space */
+	switch(msg->fcode)
+	{
+		case NLKEY_FLOW_REMOVE:
+			//printk(KERN_INFO "ipsec_nlkey_rcv NLKEY_FLOW_REMOVE\n");
+			p = msg->payload;
+			memcpy(&flow, p, sizeof(struct flowi)); p += sizeof(struct flowi)/2;
+			family = *p; p++;
+			dir = *p; p++;
+			flow_cache_remove(&flow, family, dir);
+			break;
+
+		case NLKEY_SA_NOTIFY:
+			//printk(KERN_INFO "ipsec_nlkey_rcv NLKEY_SA_NOTIFY\n");
+			memcpy(&sa_notify_msg, msg->payload, sizeof(struct nlkey_sa_notify));
+			x = xfrm_state_lookup_byhandle(&init_net, sa_notify_msg.sagd);
+			if (x) {
+				spin_lock(&x->lock);
+
+				if (sa_notify_msg.action) { 
+					// hard expired
+					x->km.state = XFRM_STATE_EXPIRED;
+					hrtimer_start(&x->mtimer, ktime_set(0,0), HRTIMER_MODE_REL_SOFT);
+				}
+				else if (!x->km.dying) {
+					 x->km.dying = 1;
+					 km_state_expired(x, 0, 0);
+				}
+
+				spin_unlock(&x->lock);
+				xfrm_state_put(x);
+			}
+			break;
+
+		case NLKEY_SA_INFO_UPDATE:
+			memcpy(&sa_info_msg, msg->payload, sizeof(struct nlkey_sa_info));
+
+			x = xfrm_state_lookup_byhandle(&init_net,sa_info_msg.sagd);
+			if (x) {
+				spin_lock(&x->lock);
+
+				if (x->curlft.bytes != sa_info_msg.bytes)
+					x->curr_time = ktime_get_real_seconds();
+
+				x->curlft.bytes = sa_info_msg.bytes;
+				x->curlft.packets = sa_info_msg.packets;
+
+				spin_unlock(&x->lock);
+				xfrm_state_put(x);
+			}
+			break;
+
+		case NLKEY_SA_SET_OFFLOAD:
+			memcpy(&sa_notify_msg, msg->payload, sizeof(struct nlkey_sa_notify));
+			x = xfrm_state_lookup_byhandle(&init_net,sa_notify_msg.sagd);
+			if (x) {
+				spin_lock(&x->lock);
+				if(sa_notify_msg.action)
+					x->offloaded = 	1;
+				else
+					x->offloaded = 	0;
+				spin_unlock(&x->lock);
+				xfrm_state_put(x);
+			}
+			break;
+		default:
+			//printk(KERN_INFO "ipsec_nlkey_rcv fcode 0x%x not supported\n", msg->fcode);
+			break;
+	}
+
+}
+static int ipsec_nlkey_set_said(struct net *net, struct xfrm_state *x, 
+				const struct km_event *c, struct nlkey_sa_id *said)
+{
+
+	struct flowi fl;
+	int tos;
+	xfrm_address_t saddr, daddr;
+	struct dst_entry *dst;
+	struct rt6_info  *rt;
+	int rc = 0;
+	int oif = 0;
+
+	memset(&fl, 0, sizeof(struct flowi));
+
+	/* SPI */
+	said->spi = x->id.spi;
+	/* SA Type (AH or ESP) */
+	said->sa_type = x->id.proto;
+	/* Protocol Family (IPv4 or IPv6) */
+	said->proto_family = x->props.family;
+	/* Replay window */
+	said->replay_window = x->props.replay_window;
+	/* Destination IP Address */
+	if(x->props.family == AF_INET6) {
+		memcpy(&said->dst_ip, x->id.daddr.a6, sizeof(struct in6_addr));
+		fl.u.ip6.daddr = *(struct in6_addr *)x->id.daddr.a6;
+		memcpy(&said->src_ip, x->props.saddr.a6, sizeof(struct in6_addr));
+	}
+	else {
+		said->dst_ip[0] = x->id.daddr.a4;
+		fl.u.ip4.daddr = x->id.daddr.a4;
+		said->src_ip[0] = x->props.saddr.a4;
+	}
+	said->mtu = 0;
+
+	if(x->props.flags & XFRM_STATE_ESN)
+		said->flags = NLKEY_SAFLAGS_ESN;
+	xfrm_flowi_addr_get(&fl, &saddr, &daddr, x->props.family);
+
+	tos = xfrm_get_tos(&fl, x->props.family);
+	if (tos < 0) {
+		printk(KERN_ERR "%s:%d: FIXME\n",__FUNCTION__,__LINE__);	
+		rc = -1;
+		goto error;
+	}
+	
+	switch (x->props.family)
+	{
+		case AF_INET:
+			if (!__ip_route_output_key(net, &(fl.u.ip4)))
+			{
+				printk(KERN_ERR "%s:%d:  FIXME\n",__FUNCTION__,__LINE__);
+				rc = -1;
+				goto error;
+			}
+			oif = fl.u.ip4.flowi4_oif;
+			break;
+
+		case AF_INET6:
+			rt = rt6_lookup(net, &fl.u.ip6.daddr, NULL, 0, NULL, 0);
+			if ((!rt) || (!rt->dst.dev))
+			{
+				printk(KERN_ERR "%s:%d: FIXME\n",__FUNCTION__,__LINE__);
+				rc = -1;
+				goto error;
+			}
+			oif = rt->dst.dev->ifindex;
+			break;
+	}
+
+	{
+		struct xfrm_dst_lookup_params params = {
+			.net = net,
+			.tos = tos,
+			.oif = oif,
+			.saddr = NULL,
+			.daddr = &daddr,
+			.mark = xfrm_smark_get(0, x),
+		};
+		dst = __xfrm_dst_lookup(x->props.family, &params);
+	}
+	if (IS_ERR(dst)) {
+		printk(KERN_ERR "%s:%d: FIXME\n",__FUNCTION__,__LINE__);
+		rc = -1;
+		goto error;
+	}
+
+	if (strcmp(dst->dev->name, "lo") == 0)
+		said->flags |= NLKEY_SAFLAGS_INBOUND;
+
+	said->dev_mtu = dst_mtu(dst);
+	said->mtu = xfrm_state_mtu(x,dst_mtu(dst));	
+
+	dst_release(dst);
+error:
+	return rc;
+}
+
+static struct sk_buff * ipsec_xfrm2nlkey (struct net *net, struct xfrm_state *x, 
+					const struct km_event *c, unsigned short *msg_id)
+{
+	struct nlkey_sa_id sa_id_msg;
+	struct nlkey_sa_create sa_create_msg;
+	struct nlkey_sa_delete sa_delete_msg;
+	struct nlkey_sa_set_keys sa_set_keys_msg;
+	struct nlkey_sa_set_tunnel sa_set_tunnel_msg;
+	struct nlkey_sa_set_natt sa_set_natt_msg;
+	struct nlkey_sa_set_state sa_set_state_msg;
+	struct nlkey_sa_set_lifetime sa_set_lifetime_msg;
+	struct nlkey_msg msg;
+	struct sk_buff *skb = NULL;
+	struct nlmsghdr *nlh = NULL;
+	gfp_t allocation = GFP_ATOMIC; //This may called from atomic context
+	unsigned char tunnel, keys, natt, state, lifetime;
+
+	/* supported SA informations */
+	keys = 1; state = 1; tunnel = 1; lifetime = 1; natt = 1; 
+
+	/* next message to build */
+	memset(&msg, 0, sizeof(struct nlkey_msg));
+	msg.fcode = *msg_id;
+	
+	//printk(KERN_INFO "\n\nipsec_xfrm2nlkey: processing event 0x%x\n", msg.fcode);
+
+	switch (msg.fcode)
+	{
+		case NLKEY_SA_CREATE:
+			//printk(KERN_INFO "ipsec_xfrm2nlkey: NLKEY_SA_CREATE\n");
+			if(x) {
+				/* some check before builing message */
+				if(x->id.proto != IPPROTO_ESP) {
+					printk(KERN_ERR "protocol %d not supported in fast path.\n", x->id.proto);
+					*msg_id = NLKEY_NULL_MSG;
+					goto exit;
+				}	
+
+				memset(&sa_create_msg, 0, sizeof(struct nlkey_sa_create));
+
+				/* SA global handler */
+				sa_create_msg.sagd = x->handle;
+
+				sa_create_msg.parent_sa_sagd = x->parent_sa_handle;
+
+				/* SA identifier */
+				if(ipsec_nlkey_set_said(net, x, c, &sa_create_msg.said) < 0)
+				{
+					printk(KERN_ERR "%s: set sa ID failed\n", __func__);
+					*msg_id = NLKEY_NULL_MSG; /* next message */
+					goto exit;
+				}
+				memcpy(msg.payload, &sa_create_msg, sizeof(struct nlkey_sa_create));
+				msg.length = sizeof(struct nlkey_sa_create);
+				*msg_id = NLKEY_SA_SET_KEYS; /* next message */
+			} else {
+				*msg_id = NLKEY_NULL_MSG; /* next message */
+				goto exit;
+			}
+			
+			break;
+
+		case NLKEY_SA_SET_KEYS:
+			//printk(KERN_INFO "ipsec_xfrm2nlkey: NLKEY_SA_SET_KEYS\n");
+			if(keys) {
+				memset(&sa_set_keys_msg, 0, sizeof(struct nlkey_sa_set_keys));
+
+				/* SA global handler */
+				sa_set_keys_msg.sagd = x->handle; 
+				
+				/* auth key */
+				if(x->aalg) {
+					if (x->aalg->alg_key_len) {
+						sa_set_keys_msg.keys[sa_set_keys_msg.num_keys].key_bits = x->aalg->alg_key_len;
+						sa_set_keys_msg.keys[sa_set_keys_msg.num_keys].key_alg = x->props.aalgo;
+						sa_set_keys_msg.keys[sa_set_keys_msg.num_keys].key_type = 0;
+						memcpy(sa_set_keys_msg.keys[sa_set_keys_msg.num_keys].key, x->aalg->alg_key,(sa_set_keys_msg.keys[sa_set_keys_msg.num_keys].key_bits / 8));
+						//printk(KERN_INFO "ipsec_xfrm2nlkey: AUTH - algo %d key %d bits\n", sa_set_keys_msg.keys[sa_set_keys_msg.num_keys].key_alg, sa_set_keys_msg.keys[sa_set_keys_msg.num_keys].key_bits);
+						sa_set_keys_msg.num_keys++;
+					}
+				}
+				/* encrypt key */
+				if(x->ealg) {
+					if (x->ealg->alg_key_len) {
+
+						sa_set_keys_msg.keys[sa_set_keys_msg.num_keys].key_bits = x->ealg->alg_key_len;
+						sa_set_keys_msg.keys[sa_set_keys_msg.num_keys].key_alg = x->props.ealgo;
+						sa_set_keys_msg.keys[sa_set_keys_msg.num_keys].key_type = 1;
+						memcpy(sa_set_keys_msg.keys[sa_set_keys_msg.num_keys].key, x->ealg->alg_key,(sa_set_keys_msg.keys[sa_set_keys_msg.num_keys].key_bits / 8));
+						//printk(KERN_INFO "ipsec_xfrm2nlkey: ENCRYPT - algo %d key %d bits\n", sa_set_keys_msg.keys[sa_set_keys_msg.num_keys].key_alg, sa_set_keys_msg.keys[sa_set_keys_msg.num_keys].key_bits);
+						sa_set_keys_msg.num_keys++;
+					}
+				}
+				/* combined key */
+				if (x->aead) {
+					if (x->aead->alg_key_len) {
+						sa_set_keys_msg.keys[sa_set_keys_msg.num_keys].key_bits = x->aead->alg_key_len;
+						if (strstr(x->aead->alg_name, "rfc4106(gcm"))	/* AES GCM support */
+						{
+							if (x->aead->alg_icv_len == 64)
+								sa_set_keys_msg.keys[sa_set_keys_msg.num_keys].key_alg = SADB_X_EALG_AES_GCM_ICV8;
+							else if (x->aead->alg_icv_len == 96)
+								sa_set_keys_msg.keys[sa_set_keys_msg.num_keys].key_alg = SADB_X_EALG_AES_GCM_ICV12;
+							else if (x->aead->alg_icv_len == 128)
+								sa_set_keys_msg.keys[sa_set_keys_msg.num_keys].key_alg = SADB_X_EALG_AES_GCM_ICV16;
+						}
+						else if (strstr(x->aead->alg_name, "ccm")) /* AES CCM */
+						{
+							if (x->aead->alg_icv_len == 64)
+								sa_set_keys_msg.keys[sa_set_keys_msg.num_keys].key_alg = SADB_X_EALG_AES_CCM_ICV8;
+							else if (x->aead->alg_icv_len == 96)
+								sa_set_keys_msg.keys[sa_set_keys_msg.num_keys].key_alg = SADB_X_EALG_AES_CCM_ICV12;
+							else if (x->aead->alg_icv_len == 128)
+								sa_set_keys_msg.keys[sa_set_keys_msg.num_keys].key_alg = SADB_X_EALG_AES_CCM_ICV16;
+						}
+						else if (strstr(x->aead->alg_name, "rfc4543(gcm"))	/* AES GMAC defined in RFC 4543 derived from AES GCM */
+						{
+							sa_set_keys_msg.keys[sa_set_keys_msg.num_keys].key_alg = SADB_X_EALG_NULL_AES_GMAC;
+						}
+						
+						sa_set_keys_msg.keys[sa_set_keys_msg.num_keys].key_type = 1;
+						memcpy(sa_set_keys_msg.keys[sa_set_keys_msg.num_keys].key, x->aead->alg_key,(sa_set_keys_msg.keys[sa_set_keys_msg.num_keys].key_bits/ 8));
+						/*
+						printk(KERN_INFO "ipsec_xfrm2nlkey: ENCRYPT -alg name %s algo %d key %d bits\n",
+							x->aead->alg_name, sa_set_keys_msg.keys[sa_set_keys_msg.num_keys].key_alg, sa_set_keys_msg.keys[sa_set_keys_msg.num_keys].key_bits); 
+						*/
+						sa_set_keys_msg.num_keys++;
+					}
+				}
+	
+				memcpy(msg.payload, &sa_set_keys_msg, sizeof(struct nlkey_sa_set_keys));
+				msg.length = sizeof(struct nlkey_sa_set_keys);
+				*msg_id = NLKEY_SA_SET_TUNNEL; /* next message */
+			} else {
+				*msg_id = NLKEY_SA_SET_TUNNEL; /* next message */
+				goto exit;
+			}
+			break;
+
+		case NLKEY_SA_SET_TUNNEL:
+			//printk(KERN_INFO "ipsec_xfrm2nlkey: NLKEY_SA_SET_TUNNEL\n");
+			if(tunnel && (x->props.mode == XFRM_MODE_TUNNEL)) {
+				memset(&sa_set_tunnel_msg, 0, sizeof(struct nlkey_sa_set_tunnel));
+
+				/* SA global handler */
+				sa_set_tunnel_msg.sagd = x->handle; 
+
+				/* Tunnel */
+				sa_set_tunnel_msg.proto_family = x->props.family;
+				if(x->props.family == AF_INET6) {
+					struct ipv6hdr *top_iph = &sa_set_tunnel_msg.h.ipv6h;
+					int dsfield;
+					top_iph->version = 6;
+					top_iph->priority = 0;
+					top_iph->flow_lbl[0] = 0;
+					top_iph->flow_lbl[1] = 0;
+					top_iph->flow_lbl[2] = 0;
+					top_iph->nexthdr = IPPROTO_IPIP;	
+					dsfield = ipv6_get_dsfield(top_iph);
+					dsfield = INET_ECN_encapsulate(dsfield, dsfield);
+					if (x->props.flags & XFRM_STATE_NOECN)
+						dsfield &= ~INET_ECN_MASK;
+					ipv6_change_dsfield(top_iph, 0, dsfield);
+					top_iph->hop_limit = 64;
+					memcpy(&top_iph->daddr, x->id.daddr.a6, sizeof(struct in6_addr));
+					memcpy(&top_iph->saddr, x->props.saddr.a6, sizeof(struct in6_addr));
+					//printk(KERN_INFO "ipsec_xfrm2nlkey: IPv6 tunnel\n");
+					//printk(KERN_INFO "dst: %x %x %x %x\n", x->id.daddr.a6[0], x->id.daddr.a6[1], x->id.daddr.a6[2], x->id.daddr.a6[3]);
+					//(KERN_INFO "src: %x %x %x %x\n", x->props.saddr.a6[0], x->props.saddr.a6[1], x->props.saddr.a6[2], x->props.saddr.a6[3]);
+				}
+				else {
+					struct iphdr *top_iph = &sa_set_tunnel_msg.h.ipv4h;
+					top_iph->ihl = 5;
+					top_iph->version = 4;
+					top_iph->tos = 0;
+					top_iph->frag_off = 0; 
+					top_iph->ttl = 64;
+					top_iph->saddr = x->props.saddr.a4;
+					top_iph->daddr = x->id.daddr.a4;
+					//printk(KERN_INFO "ipsec_xfrm2nlkey: IPv4 tunnel dst:%x - src:%x \n", x->id.daddr.a4, x->props.saddr.a4);
+				}
+				memcpy(msg.payload, &sa_set_tunnel_msg, sizeof(struct nlkey_sa_set_tunnel));
+				msg.length = sizeof(struct nlkey_sa_set_tunnel);
+				*msg_id = NLKEY_SA_SET_NATT; /* next message */
+			} else {
+				*msg_id = NLKEY_SA_SET_NATT; /* next message */
+				goto exit;	
+			} 
+			break;
+
+		case NLKEY_SA_SET_NATT:
+			//printk(KERN_INFO "ipsec_xfrm2nlkey: NLKEY_SA_SET_NATT\n");
+			if((natt) && (x->encap)){
+				memset(&sa_set_natt_msg, 0, sizeof(struct nlkey_sa_set_natt));
+
+				/* SA global handler */
+				sa_set_natt_msg.sagd = x->handle; 
+				sa_set_natt_msg.sport = x->encap->encap_sport;
+				sa_set_natt_msg.dport = x->encap->encap_dport;
+				//printk(KERN_INFO "src port: %d  dst port: %d \n", ntohs(sa_set_natt_msg.sport), ntohs( sa_set_natt_msg.dport));
+				memcpy(msg.payload, &sa_set_natt_msg, sizeof(struct nlkey_sa_set_natt));
+				msg.length = sizeof(struct nlkey_sa_set_natt);
+				*msg_id = NLKEY_SA_SET_LIFETIME; /* next message */
+			} else {
+				*msg_id = NLKEY_SA_SET_LIFETIME; /* next message */
+				goto exit;	
+			}
+			break;
+
+		case NLKEY_SA_SET_LIFETIME:
+			//printk(KERN_INFO "ipsec_xfrm2nlkey: NLKEY_SA_SET_LIFETIME\n");
+			if(lifetime) {
+				memset(&sa_set_lifetime_msg, 0, sizeof(struct nlkey_sa_set_lifetime));
+
+				/* SA global handler */
+				sa_set_lifetime_msg.sagd = x->handle;
+
+				/* hard time */
+				sa_set_lifetime_msg.hard_time.allocations =  _X2KEY(x->lft.hard_packet_limit);
+				if(_X2KEY(x->lft.hard_byte_limit))
+					memcpy(sa_set_lifetime_msg.hard_time.bytes, &x->lft.hard_byte_limit, sizeof(uint64_t));
+
+				/* soft time */
+				sa_set_lifetime_msg.soft_time.allocations =  _X2KEY(x->lft.soft_packet_limit);
+				if(_X2KEY(x->lft.soft_byte_limit))
+					memcpy(sa_set_lifetime_msg.soft_time.bytes, &x->lft.soft_byte_limit, sizeof(uint64_t));
+
+				/* current time */
+				sa_set_lifetime_msg.current_time.allocations = x->curlft.packets;
+				memcpy(sa_set_lifetime_msg.current_time.bytes, &x->curlft.bytes, sizeof(uint64_t));
+
+				memcpy(msg.payload, &sa_set_lifetime_msg, sizeof(struct nlkey_sa_set_lifetime));
+				msg.length = sizeof(struct nlkey_sa_set_lifetime);
+				*msg_id = NLKEY_SA_SET_STATE; /* next message */
+			} else {
+				*msg_id = NLKEY_SA_SET_STATE; /* next message */
+				goto exit;	
+			}
+			break;
+
+		case NLKEY_SA_SET_STATE:
+			//printk(KERN_INFO "ipsec_xfrm2nlkey: NLKEY_SET_STATE\n");
+			if(state) {
+				memset(&sa_set_state_msg, 0, sizeof(struct nlkey_sa_set_state));
+				memset(&sa_id_msg, 0, sizeof(struct nlkey_sa_id));
+
+				/* SA global handler */
+				sa_set_state_msg.sagd = x->handle; 
+				sa_set_state_msg.parent_sa_sagd = x->parent_sa_handle;
+				/* State */
+				sa_set_state_msg.state = x->km.state;
+				// TODO: set the offloaded state once ack received !
+
+				memcpy(msg.payload, &sa_set_state_msg, sizeof(struct nlkey_sa_set_state));
+				msg.length = sizeof(struct nlkey_sa_set_state);
+				*msg_id = NLKEY_NULL_MSG; /* next message */
+			} else {
+				*msg_id = NLKEY_NULL_MSG; /* next message */
+				goto exit;
+			}
+			break;
+		
+		case NLKEY_SA_DELETE:
+			//printk(KERN_INFO "ipsec_xfrm2nlkey: NLKEY_SA_DELETE\n");
+			memset(&sa_delete_msg, 0, sizeof(struct nlkey_sa_delete));
+			
+			/* SA global handler */
+			sa_delete_msg.sagd = x->handle;
+			memcpy(msg.payload, &sa_delete_msg, sizeof(struct nlkey_sa_delete));
+			msg.length = sizeof(struct nlkey_sa_delete);
+
+
+			*msg_id = NLKEY_NULL_MSG; /* next message */
+			break;
+
+		case NLKEY_SA_FLUSH:
+			//printk(KERN_INFO "ipsec_xfrm2nlkey: NLKEY_SA_FLUSH\n");
+			/* No data required for flush SA command */
+
+			*msg_id = NLKEY_NULL_MSG; /* next message */
+			break;
+
+		default:
+			printk(KERN_ERR "ipsec_xfrm2nlkey: event 0x%x not supported\n", c->event);
+			*msg_id = NLKEY_NULL_MSG; /* next message */
+			break;
+	}
+
+	/* prepare netlink message for kernel to user space direction */
+	if(msg.length > NLKEY_MSG_LEN)
+	{
+		printk(KERN_ERR "ipsec_xfrm2nlkey: maximum message size reached (%d bytes)\n", msg.length);
+		goto exit;
+	}
+
+	skb = alloc_skb(NLMSG_SPACE(NLKEY_MSG_LEN + NLKEY_HDR_LEN), allocation);
+	if (skb == NULL)
+		goto exit;
+		
+	nlh = (struct nlmsghdr *)skb_put(skb, NLMSG_SPACE(NLKEY_HDR_LEN + msg.length));
+	memcpy(NLMSG_DATA(nlh), (unsigned char *)&msg, (NLKEY_HDR_LEN + msg.length));
+	
+	/* whole length of the message i.e. header + payload */
+	nlh->nlmsg_len = NLMSG_SPACE(NLKEY_HDR_LEN + msg.length);
+
+	/* from kernel */
+	nlh->nlmsg_pid = 0;
+	nlh->nlmsg_flags = 0;
+        nlh->nlmsg_type = 0;
+	NETLINK_CB(skb).portid = 0;
+	NETLINK_CB(skb).dst_group = 1;
+exit:
+	return skb;
+}
+
+static int ipsec_nlkey_send(struct net *net, struct xfrm_state *x, const struct km_event *c)
+{
+	struct sk_buff *skb;
+	unsigned short msg_type;
+	int rc = 0;
+
+	/* We may generate more than one message when adding new SA (sa_create + sa_set_state + sa_set_tunnel...) */
+	msg_type = ipsec_sacode_to_nlkeycode((unsigned short)c->event);
+
+	while(msg_type != NLKEY_NULL_MSG)
+	{
+		/* build nlkey message */
+		skb = ipsec_xfrm2nlkey(net, x, c, &msg_type);
+
+		if(skb != NULL)
+			if((rc = netlink_broadcast(nlkey_socket, skb, 0, 1, GFP_ATOMIC)) < 0)
+				return rc;
+	}
+
+	return rc;
+}
+
+
+int ipsec_nlkey_flow(u16 xfrm_nr, u16 *xfrm_handle, const struct flowi *fl, u16 family, u16 dir, u16 ignore_neigh)
+{
+	struct sk_buff *skb;
+	struct nlkey_msg msg;
+	struct nlmsghdr *nlh = NULL;
+	unsigned short *p;
+	gfp_t allocation = GFP_ATOMIC; //This may called from atomic context
+
+	//printk(KERN_INFO "ipsec_nlkey_flow \n");
+
+	/* next message to build */
+	memset(&msg, 0, sizeof(struct nlkey_msg));
+	msg.fcode = NLKEY_FLOW_ADD;
+
+	// Number of SA for this flow
+	p = msg.payload;
+	*p++ = xfrm_nr;
+	msg.length += sizeof(unsigned short);
+	// SA handles list
+	memcpy(p, xfrm_handle, xfrm_nr*sizeof(unsigned short));
+	msg.length += xfrm_nr*sizeof(unsigned short);
+	p+=xfrm_nr;
+	// flow family
+	*p++ = family;
+	msg.length += sizeof(unsigned short);
+	// flow family
+	*p++ = dir;
+	msg.length += sizeof(unsigned short);
+	// flow mode
+	*p++ = ignore_neigh;
+	msg.length += sizeof(unsigned short);
+	// flow descriptor
+	memcpy(p, fl, sizeof(struct flowi));
+	msg.length +=sizeof(struct flowi);
+	p+=sizeof(struct flowi) / sizeof(u16);
+
+	skb = alloc_skb(NLMSG_SPACE(NLKEY_MSG_LEN + NLKEY_HDR_LEN), allocation);
+	if (skb == NULL)
+		return -ENOMEM;
+
+	/* prepare netlink message for kernel to user space direction */
+	nlh = (struct nlmsghdr *)skb_put(skb, NLMSG_SPACE(NLKEY_HDR_LEN + msg.length));
+	memcpy(NLMSG_DATA(nlh), (unsigned char *)&msg, (NLKEY_HDR_LEN + msg.length));
+
+	/* whole length of the message i.e. header + payload */
+	nlh->nlmsg_len = NLMSG_SPACE(NLKEY_HDR_LEN + msg.length);
+
+	/* from kernel */
+	nlh->nlmsg_pid = 0; 
+	nlh->nlmsg_flags = 0;
+        nlh->nlmsg_type = 0;
+	NETLINK_CB(skb).portid = 0;
+	NETLINK_CB(skb).dst_group = 1;
+
+	return(netlink_broadcast(nlkey_socket, skb, 0, 1, allocation));
+}
+EXPORT_SYMBOL(ipsec_nlkey_flow);
+
+
+int ipsec_nlkey_flow_remove(struct flowi *fl, u16 family, u16 dir)
+{
+	struct sk_buff *skb;
+	struct nlkey_msg msg;
+	struct nlmsghdr *nlh = NULL;
+	unsigned short *p;
+	gfp_t allocation = GFP_ATOMIC; //This may called from atomic context
+
+	
+	//printk(KERN_INFO "ipsec_nlkey_flow_remove\n");
+
+	/* next message to build */
+	memset(&msg, 0, sizeof(struct nlkey_msg));
+	msg.fcode = NLKEY_FLOW_REMOVE;
+
+	p = msg.payload;
+	// flow family
+	*p++ = family;
+	msg.length += sizeof(unsigned short);
+	// flow family
+	*p++ = dir;
+	msg.length += sizeof(unsigned short);
+	// flow descriptor
+	memcpy(p, fl, sizeof(struct flowi));
+	msg.length +=sizeof(struct flowi);
+	p+=sizeof(struct flowi) / sizeof(u16);
+
+	skb = alloc_skb(NLMSG_SPACE(NLKEY_MSG_LEN + NLKEY_HDR_LEN), allocation);
+	if (skb == NULL)
+		return -ENOMEM;
+
+	/* prepare netlink message for kernel to user space direction */
+	nlh = (struct nlmsghdr *)skb_put(skb, NLMSG_SPACE(NLKEY_HDR_LEN + msg.length));
+	memcpy(NLMSG_DATA(nlh), (unsigned char *)&msg, (NLKEY_HDR_LEN + msg.length));
+	
+	/* whole length of the message i.e. header + payload */
+	nlh->nlmsg_len = NLMSG_SPACE(NLKEY_HDR_LEN + msg.length);
+
+	/* from kernel */
+	nlh->nlmsg_pid = 0; 
+	nlh->nlmsg_flags = 0;
+        nlh->nlmsg_type = 0;
+	NETLINK_CB(skb).portid = 0;
+	NETLINK_CB(skb).dst_group = 1;	
+
+		
+        return(netlink_broadcast(nlkey_socket, skb, 0, 1, allocation));
+
+	
+}
+EXPORT_SYMBOL(ipsec_nlkey_flow_remove);
+
+
+
+static void ipsec_nlkey_init(void)
+{
+	struct netlink_kernel_cfg cfg = {
+		.groups	  = 1,
+		.input	  = ipsec_nlkey_rcv,
+	};
+	printk(KERN_INFO "Initializing NETLINK_KEY socket\n");
+	nlkey_socket = netlink_kernel_create(&init_net, NETLINK_KEY, &cfg);
+}
+#endif
+
+
 static int __net_init pfkey_net_init(struct net *net)
 {
 	struct netns_pfkey *net_pfkey = net_generic(net, pfkey_net_id);
@@ -3897,6 +4772,11 @@ static void __exit ipsec_pfkey_exit(void)
 	sock_unregister(PF_KEY);
 	unregister_pernet_subsys(&pfkey_net_ops);
 	proto_unregister(&key_proto);
+
+#ifdef NLKEY_SUPPORT
+	/* release NETLINK_KEY socket */
+	sock_release(nlkey_socket->sk_socket);
+#endif
 }
 
 static int __init ipsec_pfkey_init(void)
@@ -3913,6 +4793,12 @@ static int __init ipsec_pfkey_init(void)
 	if (err != 0)
 		goto out_unregister_pernet;
 	xfrm_register_km(&pfkeyv2_mgr);
+
+#ifdef NLKEY_SUPPORT
+	/* create NETLINK_KEY socket for IPSec offload on Comcerto */
+	ipsec_nlkey_init();
+#endif
+
 out:
 	return err;
 
diff --git a/net/netfilter/Kconfig b/net/netfilter/Kconfig
index df2dc21304ef..f00d3404c098 100644
--- a/net/netfilter/Kconfig
+++ b/net/netfilter/Kconfig
@@ -790,6 +790,30 @@ config NETFILTER_XT_CONNMARK
 	ctmark), similarly to the packet mark (nfmark). Using this
 	target and match, you can set and match on this mark.
 
+config NETFILTER_XT_QOSMARK
+	tristate 'qosmark target and match support'
+	default m if NETFILTER_ADVANCED=n
+	help
+	  This option adds the "QOSMARK" target and "qosmark" match.
+
+	  Netfilter qosmark matching allows you to match packets based on the
+	  "qosmark" value in the packet.
+	  The target allows you to create rules in the "mangle" table which alter
+	  the netfilter qosmark field associated with the packet.
+
+config NETFILTER_XT_QOSCONNMARK
+	tristate 'qosconnmark target and match support'
+	depends on NF_CONNTRACK
+	depends on NETFILTER_ADVANCED
+	select NF_CONNTRACK_MARK
+	help
+	  This option adds the "QOSCONNMARK" target and "qosconnmark" match.
+
+	  Netfilter allows you to store a qosmark value per connection (a.k.a.
+	  qosconnmark), similarly to the qos mark (qosmark). Using this
+	  target and match, you can set and match on this mark.
+
+
 config NETFILTER_XT_SET
 	tristate 'set target and match support'
 	depends on IP_SET
diff --git a/net/netfilter/Makefile b/net/netfilter/Makefile
index f0aa4d7ef499..6af83a10050b 100644
--- a/net/netfilter/Makefile
+++ b/net/netfilter/Makefile
@@ -22,6 +22,7 @@ nf_conntrack-$(CONFIG_DEBUG_INFO_BTF) += nf_conntrack_bpf.o
 endif
 
 obj-$(CONFIG_NETFILTER) = netfilter.o
+obj-$(CONFIG_CPE_FAST_PATH) += comcerto_fp_netfilter.o
 obj-$(CONFIG_NETFILTER_BPF_LINK) += nf_bpf_link.o
 
 obj-$(CONFIG_NETFILTER_NETLINK) += nfnetlink.o
@@ -158,6 +159,8 @@ obj-$(CONFIG_NETFILTER_XTABLES) += x_tables.o xt_tcpudp.o
 # combos
 obj-$(CONFIG_NETFILTER_XT_MARK) += xt_mark.o
 obj-$(CONFIG_NETFILTER_XT_CONNMARK) += xt_connmark.o
+obj-$(CONFIG_NETFILTER_XT_QOSMARK) += xt_qosmark.o
+obj-$(CONFIG_NETFILTER_XT_QOSCONNMARK) += xt_qosconnmark.o
 obj-$(CONFIG_NETFILTER_XT_SET) += xt_set.o
 obj-$(CONFIG_NETFILTER_XT_NAT) += xt_nat.o
 
diff --git a/net/netfilter/comcerto_fp_netfilter.c b/net/netfilter/comcerto_fp_netfilter.c
new file mode 100644
index 000000000000..726261cad986
--- /dev/null
+++ b/net/netfilter/comcerto_fp_netfilter.c
@@ -0,0 +1,494 @@
+/* Copyright (C) 2015 Freescale Semiconductor, Inc.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are met:
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above copyright
+ *       notice, this list of conditions and the following disclaimer in the
+ *       documentation and/or other materials provided with the distribution.
+ *     * Neither the name of Freescale Semiconductor nor the
+ *       names of its contributors may be used to endorse or promote products
+ *       derived from this software without specific prior written permission.
+ *
+ *
+ * ALTERNATIVELY, this software may be distributed under the terms of the
+ * GNU General Public License ("GPL") as published by the Free Software
+ * Foundation, either version 2 of that License or (at your option) any
+ * later version.
+ *
+ * THIS SOFTWARE IS PROVIDED BY Freescale Semiconductor ``AS IS'' AND ANY
+ * EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
+ * WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
+ * DISCLAIMED. IN NO EVENT SHALL Freescale Semiconductor BE LIABLE FOR ANY
+ * DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
+ * (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+ * LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
+ * ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
+ * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include <linux/module.h>
+#include <linux/version.h>
+#include <linux/kernel.h>
+#include <linux/skbuff.h>
+#include <linux/netfilter.h>
+#include <net/netfilter/nf_conntrack.h>
+#include <net/netfilter/nf_conntrack_ecache.h>
+
+
+#ifndef IPSEC_FLOW_CACHE
+/* this function is used to fill the xfrm info in conntrack structure */
+static void nf_ct_set_xfrm_in_fp(struct sk_buff *skb, struct xfrm_state *xfrm[MAX_SUPPORTED_XFRMS_PER_DIR],
+						  int num_xfrm, int xfrm_dir, int *rekey)
+{
+	struct nf_conn *ct;
+	enum ip_conntrack_info ctinfo;
+	struct comcerto_fp_info *fp_info;
+	int dir, xfrm_ind, ii;
+
+	if (num_xfrm > MAX_SUPPORTED_XFRMS_PER_DIR)
+	{
+		printk(KERN_ERR "%s(%d) num_xfrm %d > %d(MAX supported)\n",
+			__FUNCTION__,__LINE__,num_xfrm,MAX_SUPPORTED_XFRMS_PER_DIR);
+		return;
+	}	
+	/* get ct info */
+	ct = nf_ct_get(skb, &ctinfo);
+	if (!ct)
+	{
+		return;
+	}
+	
+	dir = CTINFO2DIR(ctinfo);
+	if (dir == IP_CT_DIR_ORIGINAL) {
+		fp_info = &ct->fp_info[IP_CT_DIR_ORIGINAL];
+	} else {
+		fp_info = &ct->fp_info[IP_CT_DIR_REPLY];
+	}
+
+	if (xfrm_dir == XFRM_POLICY_FWD)
+		xfrm_dir = 0;
+	/* xfrm_dir can be XFRM_POLICY_IN, XFRM_POLICY_OUT, XFRM_POLICY_FWD */
+	/* fp_info->xfrm_id[4] has 4 instances , first 2 instances reserved for direction IN/FWD
+	   next 2 instances for OUT direction */
+	xfrm_ind =  xfrm_dir << 1;
+	
+	for (ii=0; ii<num_xfrm; ii++)
+	{
+		if (fp_info->xfrm_handle[xfrm_ind+ii]  && 
+			fp_info->xfrm_handle[xfrm_ind+ii] != xfrm[ii]->handle)
+		{
+			*rekey = 1;
+		}
+		/* filling SA info and xfrm handle */
+		fp_info->xfrm_handle[xfrm_ind+ii] = xfrm[ii]->handle;
+		/*printk("%s(%d)ii %d, index %d ct %p,  dir %d, SPI %x, proto %d xfrmdir %d, sgid %x\n",
+		__FUNCTION__,__LINE__,ii, xfrm_ind+ii, ct,  dir, xfrm[ii]->id.spi, xfrm[ii]->id.proto,
+		xfrm_dir, fp_info->xfrm_handle[xfrm_ind+ii]); */
+	}
+	return;
+}
+
+/* this function is used to get the inbound and outbound xfrm info corresponding to
+ * skb , if exist fill in conntrack structure */
+static unsigned int fp_netfilter_get_xfrm_info(struct sk_buff *skb)
+{
+	struct nf_conn *ct;
+	enum ip_conntrack_info ctinfo;
+	struct sec_path *sp ;
+	struct xfrm_state *x[2]={}, *tmp;
+	int num_xfrms = 0, i, dir, rekey = 0;
+	struct dst_entry *dst1 = skb_dst(skb);
+
+	/* get ct info */
+	ct = nf_ct_get(skb, &ctinfo);
+	if (!ct)
+	{
+		return NF_ACCEPT;
+	}
+	/* ctinfo direction [originator/replier] */
+	dir = CTINFO2DIR(ctinfo);
+
+	/* extract the inbound IPSec information if exist */
+	if ((sp = skb_sec_path(skb)))
+	{
+		for (i=sp->len-1; (i>=0) && (num_xfrms < MAX_SUPPORTED_XFRMS_PER_DIR); i--)
+		{
+			x[num_xfrms] = sp->xvec[i];
+	
+			/* printk("%s(%d) num_xfrm %d , xfrm %p , SPI %x dir XFRM_POLICY_FWD, handle %x\n",
+				__FUNCTION__,__LINE__,num_xfrms, x[num_xfrms], 
+				x[num_xfrms]->id.spi, x[num_xfrms]->handle);*/
+			num_xfrms++;
+		}
+		if (num_xfrms)
+			nf_ct_set_xfrm_in_fp(skb, x, num_xfrms, XFRM_POLICY_FWD, &rekey);
+	}
+
+	/* extract the outbound IPSec information if exist */
+	if (dst1 && dst1->xfrm)
+	{
+		for (i=0; i<MAX_SUPPORTED_XFRMS_PER_DIR; i++)
+			x[i]  = 0;
+		num_xfrms = 0;
+	
+		while(((tmp = dst1->xfrm) != NULL) && (num_xfrms<MAX_SUPPORTED_XFRMS_PER_DIR))  {
+			/*printk("%s(%d) num_xfrm %d , xfrm %p , SPI %x, handle %x XFRM_POLICY_OUT\n",
+				__FUNCTION__,__LINE__, num_xfrms, tmp, tmp->id.spi, tmp->handle);*/
+			x[num_xfrms] = tmp;			
+			dst1 = xfrm_dst_child(dst1);
+			num_xfrms++;
+			if (dst1 == NULL) {
+				printk("%s(%d) DST is null \n",__FUNCTION__,__LINE__);
+				break;
+			}
+		}
+		if (num_xfrms)
+			nf_ct_set_xfrm_in_fp(skb, x, num_xfrms, XFRM_POLICY_OUT, &rekey);
+	}
+
+	/* if there is a change in ipsec info, send rekey conntrack event */
+	if (rekey)
+	{
+		/*printk("%s(%d) sending rekey event\n",__FUNCTION__,__LINE__); */
+		nf_conntrack_event_cache(IPCT_PROTOINFO, ct);
+	}
+	return NF_ACCEPT;
+}
+#endif /* IPSEC_FLOW_CACHE */
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,4,0)
+static unsigned int fp_netfilter_pre_routing(int family, const struct nf_hook_state *state, struct sk_buff *skb)
+#else
+static unsigned int fp_netfilter_pre_routing(int family, const struct nf_hook_ops *ops, struct sk_buff *skb)
+#endif
+{
+	struct nf_conn *ct;
+	u_int8_t protonum;
+	enum ip_conntrack_info ctinfo;
+	struct comcerto_fp_info *fp_info;
+	int dir;
+
+	ct = nf_ct_get(skb, &ctinfo);
+	if (!ct)
+		goto done;
+
+	protonum = nf_ct_protonum(ct);
+	if ((protonum != IPPROTO_TCP) && (protonum != IPPROTO_UDP) && (protonum != IPPROTO_IPIP) && (protonum != IPPROTO_IPV6) && 
+#ifdef CONFIG_CPE_ETHERIP
+	(protonum != IPPROTO_ETHERIP) &&
+#endif
+	(protonum != IPPROTO_GRE) && (protonum != IPPROTO_ESP) && (protonum != IPPROTO_AH))
+		goto done;
+
+	dir = CTINFO2DIR(ctinfo);
+
+	//  if (printk_ratelimit())
+	//      printk(KERN_INFO "ct: %lx, dir: %x, mark: %x, ifindex: %d iif: %d iif_index:%d\n", (unsigned long)ct, dir, skb->mark, skb->dev->ifindex, skb->skb_iif,skb->iif_index);
+
+	/* We could also check for changes and notify userspace (or print message) */
+	if (dir == IP_CT_DIR_ORIGINAL) {
+		fp_info = &ct->fp_info[IP_CT_DIR_ORIGINAL];
+	} else {
+		fp_info = &ct->fp_info[IP_CT_DIR_REPLY];
+	}
+
+	if (fp_info->mark && (fp_info->mark != skb->mark))
+		if (printk_ratelimit())
+			printk(KERN_INFO "ct: mark changed %x, %x\n", fp_info->mark, skb->mark);
+
+
+	if (fp_info->ifindex && (fp_info->ifindex != skb->dev->ifindex))
+		if (printk_ratelimit())
+			printk(KERN_INFO "ct: ifindex changed %d, %d\n", fp_info->ifindex, skb->dev->ifindex);
+
+	if (fp_info->iif && (fp_info->iif != skb->iif_index))
+		if (printk_ratelimit())
+			printk(KERN_INFO "ct: iif changed %d, %d\n", fp_info->iif, skb->iif_index);
+	/*      // commenting it out as a duplicate print. In most cases iif and underlying iif are the same.
+			if (fp_info->underlying_iif && (fp_info->underlying_iif != skb->underlying_iif))
+			if (printk_ratelimit())
+			printk(KERN_INFO "ct: underlying_iif changed %d, %d\n", fp_info->underlying_iif, skb->underlying_iif);
+	 */
+
+	fp_info->mark = skb->mark;
+	fp_info->ifindex = skb->dev->ifindex;
+	/* now skb_iif always tracks dev,so iif_index stores incoming interface */
+	fp_info->iif = skb->iif_index;
+	fp_info->underlying_iif = skb->underlying_iif;
+	/*omit priority bits in vlan tag*/
+	fp_info->underlying_vlan_id = skb->underlying_vlan_tci & VLAN_VID_MASK;
+
+done:
+	return NF_ACCEPT;
+}
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,4,0)
+static unsigned int fp_netfilter_local_out(int family, const struct nf_hook_state *state, struct sk_buff *skb)
+#else
+static unsigned int fp_netfilter_local_out(int family, const struct nf_hook_ops *ops, struct sk_buff *skb)
+#endif
+{
+	struct nf_conn *ct;
+	u_int8_t protonum;
+	enum ip_conntrack_info ctinfo;
+	struct comcerto_fp_info *fp_info;
+	int dir,update_event=0;
+
+	ct = nf_ct_get(skb, &ctinfo);
+	if (!ct)
+		goto done;
+
+
+	protonum = nf_ct_protonum(ct);
+#ifdef CONFIG_CPE_ETHERIP
+	if ((protonum != IPPROTO_ETHERIP) && (protonum != IPPROTO_IPIP) && (protonum != IPPROTO_IPV6) && (protonum != IPPROTO_GRE))
+#else
+		if ((protonum != IPPROTO_IPIP) && (protonum != IPPROTO_IPV6) && (protonum != IPPROTO_GRE))
+			goto done;
+#endif
+
+	dir = CTINFO2DIR(ctinfo);
+
+	/* We could also check for changes and notify userspace (or print message) */
+	if (dir == IP_CT_DIR_ORIGINAL) {
+		fp_info = &ct->fp_info[IP_CT_DIR_ORIGINAL];
+	} else {
+		fp_info = &ct->fp_info[IP_CT_DIR_REPLY];
+	}
+
+	if (fp_info->mark && (fp_info->mark != skb->mark))
+		if (printk_ratelimit())
+			printk(KERN_INFO "ct: mark changed %x, %x\n", fp_info->mark, skb->mark);
+
+	if ((fp_info->ifindex) && (skb->dev) &&(fp_info->ifindex != skb->dev->ifindex))
+		if (printk_ratelimit()) {
+			printk(KERN_INFO "ct: ifindex changed %d, %d\n", fp_info->ifindex, skb->dev->ifindex);
+			update_event=1;
+		}
+#if 0
+	if (fp_info->iif && (fp_info->iif != skb->skb_iif))
+		if (printk_ratelimit())
+			printk(KERN_INFO "ct: iif changed %d, %d\n", fp_info->iif, skb->skb_iif);
+#endif
+
+	fp_info->mark = skb->mark;
+	if (skb->dev)
+		fp_info->ifindex = skb->dev->ifindex;
+
+	if (update_event == 1) {
+		nf_conntrack_event_cache(IPCT_PROTOINFO, ct);
+	}
+
+	//printk(KERN_INFO "%s:(DIR-%d, CT-%x):%x:%s:%x\n",__func__,dir, (unsigned int)ct, fp_info->mark,  skb->dev->name, skb->skb_iif);
+	fp_info->iif = 0; /* To identify the connection as local connection */
+
+#ifndef IPSEC_FLOW_CACHE
+	/* fill xfrm info in conntrack structure */
+	return (fp_netfilter_get_xfrm_info(skb));
+#endif /* IPSEC_FLOW_CACHE */
+done:
+	return NF_ACCEPT;
+}
+
+
+#ifndef IPSEC_FLOW_CACHE
+/* this post routing hook is introduced to gather the xfrm information
+ * corresponding to ctinfo of skb and fill it in conntrack structure.
+ * This is required to take the xfrm info of ctinfo part of conntrack message
+ * to user space
+ */
+static unsigned int fp_ip_netfilter_post_routing(void *priv,
+						struct sk_buff *skb,
+						const struct nf_hook_state *state)
+{
+	return (fp_netfilter_get_xfrm_info(skb));
+}
+#endif /* IPSEC_FLOW_CACHE */
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,4,0)
+static unsigned int fp_ipv4_netfilter_pre_routing(void *priv,
+		struct sk_buff *skb,
+		const struct nf_hook_state *state)
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(4,0,0)
+static unsigned int fp_ipv4_netfilter_pre_routing(const struct nf_hook_ops *ops,
+		struct sk_buff *skb,
+		const struct nf_hook_state *state)
+#else
+static unsigned int fp_ipv4_netfilter_pre_routing(const struct nf_hook_ops *ops,
+		struct sk_buff *skb,
+		const struct net_device *in,
+		const struct net_device *out,
+		int (*okfn)(struct sk_buff *))
+#endif
+
+{
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,4,0)
+	return fp_netfilter_pre_routing(PF_INET, state, skb);
+#else
+	return fp_netfilter_pre_routing(PF_INET, ops, skb);
+#endif
+}
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,4,0)
+static unsigned int fp_ipv6_netfilter_pre_routing(void *priv,
+		struct sk_buff *skb,
+		const struct nf_hook_state *state)
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(4,0,0)
+static unsigned int fp_ipv6_netfilter_pre_routing(const struct nf_hook_ops *ops,
+		struct sk_buff *skb,
+		const struct nf_hook_state *state)
+#else
+static unsigned int fp_ipv6_netfilter_pre_routing(const struct nf_hook_ops *ops,
+		struct sk_buff *skb,
+		const struct net_device *in,
+		const struct net_device *out,
+		int (*okfn)(struct sk_buff *))
+#endif
+{
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,4,0)
+	return fp_netfilter_pre_routing(PF_INET6, state, skb);
+#else
+	return fp_netfilter_pre_routing(PF_INET6, ops, skb);
+#endif
+}
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,4,0)
+static unsigned int fp_ipv4_netfilter_local_out(void *priv,
+		struct sk_buff *skb,
+		const struct nf_hook_state *state)
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(4,0,0)
+static unsigned int fp_ipv4_netfilter_local_out(const struct nf_hook_ops *ops,
+		struct sk_buff *skb,
+		const struct nf_hook_state *state)
+#else
+static unsigned int fp_ipv4_netfilter_local_out(const struct nf_hook_ops *ops,
+		struct sk_buff *skb,
+		const struct net_device *in,
+		const struct net_device *out,
+		int (*okfn)(struct sk_buff *))
+#endif
+{
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,4,0)
+	return fp_netfilter_local_out(PF_INET, state, skb);
+#else
+	return fp_netfilter_local_out(PF_INET, ops, skb);
+#endif
+}
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,4,0)
+static unsigned int fp_ipv6_netfilter_local_out(void *priv,
+		struct sk_buff *skb,
+		const struct nf_hook_state *state)
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(4,0,0)
+static unsigned int fp_ipv6_netfilter_local_out(const struct nf_hook_ops *ops,
+		struct sk_buff *skb,
+		const struct nf_hook_state *state)
+#else
+static unsigned int fp_ipv6_netfilter_local_out(const struct nf_hook_ops *ops,
+		struct sk_buff *skb,
+		const struct net_device *in,
+		const struct net_device *out,
+		int (*okfn)(struct sk_buff *))
+#endif
+{
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4,4,0)
+	return fp_netfilter_local_out(PF_INET6, state, skb);
+#else
+	return fp_netfilter_local_out(PF_INET6, ops, skb);
+#endif
+}
+
+
+static struct nf_hook_ops fp_netfilter_ops[] __read_mostly = {
+	{
+		.hook       = fp_ipv4_netfilter_pre_routing,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4,4,0)
+		.owner      = THIS_MODULE,
+#endif
+		.pf     = NFPROTO_IPV4,
+		.hooknum    = NF_INET_PRE_ROUTING,
+		.priority   = NF_IP_PRI_LAST,
+	},
+	{
+		.hook       = fp_ipv6_netfilter_pre_routing,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4,4,0)
+		.owner      = THIS_MODULE,
+#endif
+		.pf     = NFPROTO_IPV6,
+		.hooknum    = NF_INET_PRE_ROUTING,
+		.priority   = NF_IP_PRI_LAST,
+	},
+	/* For local_out packets, routing will be done
+	   1. before entering the LOCAL_OUT hook
+	   2. and at the completion of all mangle rules,
+	   if there are changes to the packet like mark etc
+
+	   So NF_IP_PRI_LAST priority is used here to receive
+	   the mark value of the packet, at the end of all changes.
+	 */
+	{
+		.hook           = fp_ipv4_netfilter_local_out,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4,4,0)
+		.owner          = THIS_MODULE,
+#endif
+		.pf             = NFPROTO_IPV4,
+		.hooknum        = NF_INET_LOCAL_OUT,
+		.priority       = NF_IP_PRI_LAST - 1,
+	},
+	{
+		.hook           = fp_ipv6_netfilter_local_out,
+#if LINUX_VERSION_CODE < KERNEL_VERSION(4,4,0)
+		.owner          = THIS_MODULE,
+#endif
+		.pf             = NFPROTO_IPV6,
+		.hooknum        = NF_INET_LOCAL_OUT,
+		.priority       = NF_IP_PRI_LAST - 1,
+	},
+
+#ifndef IPSEC_FLOW_CACHE
+	{
+		.hook			= fp_ip_netfilter_post_routing,
+		.pf 			= NFPROTO_IPV4,
+		.hooknum		= NF_INET_POST_ROUTING,
+		.priority		= NF_IP_PRI_LAST - 1, /* this priority should be less than INT_MAX */
+	},
+	{
+		.hook			= fp_ip_netfilter_post_routing,
+		.pf 			= NFPROTO_IPV6,
+		.hooknum		= NF_INET_POST_ROUTING,
+		.priority		= NF_IP_PRI_LAST - 1, /* this priority should be less than INT_MAX, */
+	},
+#endif
+};
+
+static int __init fp_netfilter_init(void)
+{
+	int rc;
+
+	rc = nf_register_net_hooks(&init_net, fp_netfilter_ops, ARRAY_SIZE(fp_netfilter_ops));
+	if (rc < 0) {
+		printk(KERN_ERR "fp_netfilter_ops: can't register hooks.\n");
+		goto err0;
+	}
+
+	return 0;
+
+err0:
+	return rc;
+}
+
+
+static void __exit fp_netfilter_exit(void)
+{
+	nf_unregister_net_hooks(&init_net, fp_netfilter_ops, ARRAY_SIZE(fp_netfilter_ops));
+}
+
+module_init(fp_netfilter_init);
+module_exit(fp_netfilter_exit);
diff --git a/net/netfilter/nf_conntrack_core.c b/net/netfilter/nf_conntrack_core.c
index f5bde4f13958..cfb67c09add4 100644
--- a/net/netfilter/nf_conntrack_core.c
+++ b/net/netfilter/nf_conntrack_core.c
@@ -10,7 +10,7 @@
  */
 
 #define pr_fmt(fmt) KBUILD_MODNAME ": " fmt
-
+#include <linux/version.h>
 #include <linux/types.h>
 #include <linux/netfilter.h>
 #include <linux/module.h>
@@ -1696,6 +1696,14 @@ __nf_conntrack_alloc(struct net *net,
 	ct->tuplehash[IP_CT_DIR_ORIGINAL].tuple = *orig;
 	ct->tuplehash[IP_CT_DIR_ORIGINAL].hnnode.pprev = NULL;
 	ct->tuplehash[IP_CT_DIR_REPLY].tuple = *repl;
+#if defined(CONFIG_CPE_FAST_PATH)
+#ifndef IPSEC_FLOW_CACHE
+	memset(ct->fp_info[IP_CT_DIR_ORIGINAL].xfrm_handle, 0,
+		 	sizeof(ct->fp_info[IP_CT_DIR_ORIGINAL].xfrm_handle));
+	memset(ct->fp_info[IP_CT_DIR_REPLY].xfrm_handle, 0,
+		 	sizeof(ct->fp_info[IP_CT_DIR_REPLY].xfrm_handle));
+#endif
+#endif
 	/* save hash for reusing when confirming */
 	*(unsigned long *)(&ct->tuplehash[IP_CT_DIR_REPLY].hnnode.pprev) = hash;
 	ct->status = 0;
@@ -1829,6 +1837,9 @@ init_conntrack(struct net *net, struct nf_conn *tmpl,
 #ifdef CONFIG_NF_CONNTRACK_MARK
 			ct->mark = READ_ONCE(exp->master->mark);
 #endif
+#if defined(CONFIG_CPE_FAST_PATH)
+			ct->qosconnmark = exp->master->qosconnmark;
+#endif
 #ifdef CONFIG_NF_CONNTRACK_SECMARK
 			ct->secmark = exp->master->secmark;
 #endif
@@ -2550,6 +2561,52 @@ void *nf_ct_alloc_hashtable(unsigned int *sizep, int nulls)
 }
 EXPORT_SYMBOL_GPL(nf_ct_alloc_hashtable);
 
+#ifdef CONFIG_CPE_FAST_PATH
+int nf_conntrack_set_dpi_allow_report(struct sk_buff *skb)
+{
+	int err = 0;
+	struct nf_conn *ct;
+	enum ip_conntrack_info ctinfo;
+
+	ct = nf_ct_get(skb, &ctinfo);
+	/*TODO: Dow we need to add any checks here? */
+
+	nf_conntrack_get(skb_nfct(skb));
+
+	set_bit(IPS_DPI_ALLOWED_BIT, &ct->status);
+
+	nf_conntrack_event_cache(IPCT_PROTOINFO, ct);
+
+	nf_conntrack_put(skb_nfct(skb));
+
+	return err;
+}
+EXPORT_SYMBOL(nf_conntrack_set_dpi_allow_report);
+
+int nf_conntrack_set_dpi_allow_and_mark(struct sk_buff *skb, int mark)
+{
+	int err = 0;
+	struct nf_conn *ct;
+	enum ip_conntrack_info ctinfo;
+
+	ct = nf_ct_get(skb, &ctinfo);
+	nf_conntrack_get(skb_nfct(skb));
+
+	set_bit(IPS_DPI_ALLOWED_BIT, &ct->status);
+
+#ifdef CONFIG_NF_CONNTRACK_MARK
+	ct->mark = mark;
+#endif
+
+	nf_conntrack_event_cache(IPCT_PROTOINFO, ct);
+
+	nf_conntrack_put(skb_nfct(skb));
+
+	return err;
+}
+EXPORT_SYMBOL(nf_conntrack_set_dpi_allow_and_mark);
+#endif
+
 int nf_conntrack_hash_resize(unsigned int hashsize)
 {
 	int i, bucket;
@@ -2829,3 +2886,19 @@ int nf_ct_change_status_common(struct nf_conn *ct, unsigned int status)
 	return 0;
 }
 EXPORT_SYMBOL_GPL(nf_ct_change_status_common);
+
+#ifdef CONFIG_CPE_FAST_PATH
+bool nf_ct_is_expired(const struct nf_conn *ct)
+{
+	const struct nf_conntrack_l4proto *l4proto;
+
+	l4proto = nf_ct_l4proto_find(nf_ct_protonum(ct));
+	if ((!nf_ct_is_permanent(ct)) ||
+	    ((l4proto->l4proto == IPPROTO_TCP) &&
+	     (ct->proto.tcp.state != TCP_CONNTRACK_ESTABLISHED)))
+		return (__nf_ct_is_expired(ct));
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(nf_ct_is_expired);
+#endif
diff --git a/net/netfilter/nf_conntrack_netlink.c b/net/netfilter/nf_conntrack_netlink.c
index 18a91c031554..96731d50534a 100644
--- a/net/netfilter/nf_conntrack_netlink.c
+++ b/net/netfilter/nf_conntrack_netlink.c
@@ -28,6 +28,11 @@
 #include <linux/netlink.h>
 #include <linux/spinlock.h>
 #include <linux/interrupt.h>
+#if defined(CONFIG_CPE_FAST_PATH)
+#ifndef IPSEC_FLOW_CACHE
+#include <net/xfrm.h>
+#endif
+#endif
 #include <linux/slab.h>
 #include <linux/siphash.h>
 
@@ -202,9 +207,16 @@ static int ctnetlink_dump_protoinfo(struct sk_buff *skb, struct nf_conn *ct,
 	struct nlattr *nest_proto;
 	int ret;
 
+#ifdef CONFIG_CPE_FAST_PATH
+	rcu_read_lock();
+#endif
 	l4proto = nf_ct_l4proto_find(nf_ct_protonum(ct));
-	if (!l4proto->to_nlattr)
+	if (!l4proto->to_nlattr) {
+#ifdef CONFIG_CPE_FAST_PATH
+		rcu_read_unlock();
+#endif
 		return 0;
+	}
 
 	nest_proto = nla_nest_start(skb, CTA_PROTOINFO);
 	if (!nest_proto)
@@ -214,9 +226,15 @@ static int ctnetlink_dump_protoinfo(struct sk_buff *skb, struct nf_conn *ct,
 
 	nla_nest_end(skb, nest_proto);
 
+#ifdef CONFIG_CPE_FAST_PATH
+	rcu_read_unlock();
+#endif
 	return ret;
 
 nla_put_failure:
+#ifdef CONFIG_CPE_FAST_PATH
+	rcu_read_unlock();
+#endif
 	return -1;
 }
 
@@ -353,6 +371,18 @@ static int ctnetlink_dump_mark(struct sk_buff *skb, const struct nf_conn *ct,
 #define ctnetlink_dump_mark(a, b, c) (0)
 #endif
 
+#if defined(CONFIG_CPE_FAST_PATH)
+static inline int
+ctnetlink_dump_qosconnmark(struct sk_buff *skb, const struct nf_conn *ct)
+{
+	nla_put_be64(skb, CTA_QOSCONNMARK, cpu_to_be64(ct->qosconnmark),
+		     CTA_QOSCONNMARK_PAD);
+	return 0;
+}
+#else
+#define ctnetlink_dump_qosconnmark(a, b) (0)
+#endif
+
 #ifdef CONFIG_NF_CONNTRACK_SECMARK
 static int ctnetlink_dump_secctx(struct sk_buff *skb, const struct nf_conn *ct)
 {
@@ -413,6 +443,59 @@ ctnetlink_dump_labels(struct sk_buff *skb, const struct nf_conn *ct)
 	return 0;
 }
 
+#if defined(CONFIG_CPE_FAST_PATH)
+static int
+ctnetlink_dump_comcerto_fp(struct sk_buff *skb, const struct nf_conn *ct)
+{
+	struct nlattr *nest_count;
+
+	nest_count = nla_nest_start(skb, CTA_LAYERSCAPE_FP_ORIG | NLA_F_NESTED);
+	if (!nest_count)
+		goto nla_put_failure;
+
+	nla_put_u32(skb, CTA_COMCERTO_FP_MARK, ct->fp_info[IP_CT_DIR_ORIGINAL].mark);
+	nla_put_u32(skb, CTA_COMCERTO_FP_IFINDEX, ct->fp_info[IP_CT_DIR_ORIGINAL].ifindex);
+	nla_put_u32(skb, CTA_COMCERTO_FP_IIF, ct->fp_info[IP_CT_DIR_ORIGINAL].iif);
+	nla_put_u32(skb, CTA_COMCERTO_FP_UNDERLYING_IIF, ct->fp_info[IP_CT_DIR_ORIGINAL].underlying_iif);
+	nla_put_u16(skb, CTA_COMCERTO_FP_UNDERLYING_VID, ct->fp_info[IP_CT_DIR_ORIGINAL].underlying_vlan_id);
+#ifndef IPSEC_FLOW_CACHE
+	if ((ct->fp_info[IP_CT_DIR_ORIGINAL].xfrm_handle[0]) ||
+	    (ct->fp_info[IP_CT_DIR_ORIGINAL].xfrm_handle[MAX_SUPPORTED_XFRMS_PER_DIR]))
+	{
+		nla_put(skb, CTA_COMCERTO_FP_XFRM_HANDLE, sizeof(ct->fp_info[IP_CT_DIR_ORIGINAL].xfrm_handle),
+				ct->fp_info[IP_CT_DIR_ORIGINAL].xfrm_handle);
+	}
+#endif /* IPSEC_FLOW_CACHE */
+	nla_nest_end(skb, nest_count);
+
+	nest_count = nla_nest_start(skb, CTA_LAYERSCAPE_FP_REPLY | NLA_F_NESTED);
+	if (!nest_count)
+		goto nla_put_failure;
+
+	nla_put_u32(skb, CTA_COMCERTO_FP_MARK, ct->fp_info[IP_CT_DIR_REPLY].mark);
+	nla_put_u32(skb, CTA_COMCERTO_FP_IFINDEX, ct->fp_info[IP_CT_DIR_REPLY].ifindex);
+	nla_put_u32(skb, CTA_COMCERTO_FP_IIF, ct->fp_info[IP_CT_DIR_REPLY].iif);
+	nla_put_u32(skb, CTA_COMCERTO_FP_UNDERLYING_IIF, ct->fp_info[IP_CT_DIR_REPLY].underlying_iif);
+	nla_put_u16(skb, CTA_COMCERTO_FP_UNDERLYING_VID, ct->fp_info[IP_CT_DIR_REPLY].underlying_vlan_id);
+#ifndef IPSEC_FLOW_CACHE
+	if ((ct->fp_info[IP_CT_DIR_REPLY].xfrm_handle[0]) ||
+	    (ct->fp_info[IP_CT_DIR_REPLY].xfrm_handle[MAX_SUPPORTED_XFRMS_PER_DIR]))
+	{
+		nla_put(skb, CTA_COMCERTO_FP_XFRM_HANDLE, sizeof(ct->fp_info[IP_CT_DIR_REPLY].xfrm_handle),
+			ct->fp_info[IP_CT_DIR_REPLY].xfrm_handle);
+	}
+#endif /* IPSEC_FLOW_CACHE */
+	nla_nest_end(skb, nest_count);
+
+	return 0;
+
+nla_put_failure:
+	return -1;
+}
+#else
+#define ctnetlink_dump_comcerto_fp(a, b) (0)
+#endif
+
 #define master_tuple(ct) &(ct->master->tuplehash[IP_CT_DIR_ORIGINAL].tuple)
 
 static int ctnetlink_dump_master(struct sk_buff *skb, const struct nf_conn *ct)
@@ -553,7 +636,11 @@ static int ctnetlink_dump_info(struct sk_buff *skb, struct nf_conn *ct)
 {
 	if (ctnetlink_dump_status(skb, ct) < 0 ||
 	    ctnetlink_dump_mark(skb, ct, true) < 0 ||
+	    ctnetlink_dump_qosconnmark(skb, ct) < 0 ||
 	    ctnetlink_dump_secctx(skb, ct) < 0 ||
+#ifdef CONFIG_CPE_FAST_PATH
+	    ctnetlink_dump_comcerto_fp(skb, ct) < 0 ||
+#endif
 	    ctnetlink_dump_id(skb, ct) < 0 ||
 	    ctnetlink_dump_use(skb, ct) < 0 ||
 	    ctnetlink_dump_master(skb, ct) < 0)
@@ -705,6 +792,13 @@ static size_t ctnetlink_nlmsg_size(const struct nf_conn *ct)
 	       + nla_total_size(0) /* CTA_HELP */
 	       + nla_total_size(NF_CT_HELPER_NAME_LEN) /* CTA_HELP_NAME */
 	       + ctnetlink_secctx_size(ct)
+#ifdef CONFIG_CPE_FAST_PATH
+			+ 2 * nla_total_size(0) /* CTA_LAYERSCAPE_FP_ORIG|REPL */
+			+ 2 * nla_total_size(sizeof(uint32_t)) /* CTA_COMCERTO_FP_MARK */
+			+ 2 * nla_total_size(sizeof(uint32_t)) /* CTA_COMCERTO_FP_IFINDEX */
+			+ 2 * nla_total_size(sizeof(uint32_t)) /* CTA_COMCERTO_FP_IIF */
+			+ 2 * nla_total_size(sizeof(uint32_t)) /* CTA_COMCERTO_FP_UNDERLYING_IIF */
+#endif
 #if IS_ENABLED(CONFIG_NF_NAT)
 	       + 2 * nla_total_size(0) /* CTA_NAT_SEQ_ADJ_ORIG|REPL */
 	       + 6 * nla_total_size(sizeof(u_int32_t)) /* CTA_NAT_SEQ_OFFSET */
@@ -712,6 +806,9 @@ static size_t ctnetlink_nlmsg_size(const struct nf_conn *ct)
 #ifdef CONFIG_NF_CONNTRACK_MARK
 	       + nla_total_size(sizeof(u_int32_t)) /* CTA_MARK */
 #endif
+#if defined(CONFIG_CPE_FAST_PATH)
+			+ nla_total_size(sizeof(u_int64_t)) /* CTA_QOSCONNMARK */
+#endif
 #ifdef CONFIG_NF_CONNTRACK_ZONES
 	       + nla_total_size(sizeof(u_int16_t)) /* CTA_ZONE|CTA_TUPLE_ZONE */
 #endif
@@ -786,6 +883,11 @@ ctnetlink_conntrack_event(unsigned int events, const struct nf_ct_event *item)
 				   NF_CT_DEFAULT_ZONE_DIR) < 0)
 		goto nla_put_failure;
 
+#if defined(CONFIG_CPE_FAST_PATH)
+	if (ctnetlink_dump_comcerto_fp(skb, ct) < 0)
+		goto nla_put_failure;
+#endif
+
 	if (ctnetlink_dump_id(skb, ct) < 0)
 		goto nla_put_failure;
 
@@ -837,6 +939,11 @@ ctnetlink_conntrack_event(unsigned int events, const struct nf_ct_event *item)
 #ifdef CONFIG_NF_CONNTRACK_MARK
 	if (ctnetlink_dump_mark(skb, ct, events & (1 << IPCT_MARK)))
 		goto nla_put_failure;
+#endif
+#if defined(CONFIG_CPE_FAST_PATH)
+	if ((events & (1 << IPCT_QOSCONNMARK) || ct->qosconnmark)
+		&& ctnetlink_dump_qosconnmark(skb, ct) < 0)
+		goto nla_put_failure;
 #endif
 	nlmsg_end(skb, nlh);
 	err = nfnetlink_send(skb, net, item->portid, group, item->report,
@@ -1546,6 +1653,9 @@ static const struct nla_policy ct_nla_policy[CTA_MAX+1] = {
 	[CTA_NAT_SRC]		= { .type = NLA_NESTED },
 	[CTA_TIMEOUT] 		= { .type = NLA_U32 },
 	[CTA_MARK]		= { .type = NLA_U32 },
+#if defined(CONFIG_CPE_FAST_PATH)
+	[CTA_QOSCONNMARK]		= { .type = NLA_U64 },
+#endif
 	[CTA_ID]		= { .type = NLA_U32 },
 	[CTA_NAT_DST]		= { .type = NLA_NESTED },
 	[CTA_TUPLE_MASTER]	= { .type = NLA_NESTED },
@@ -1900,6 +2010,48 @@ ctnetlink_change_status(struct nf_conn *ct, const struct nlattr * const cda[])
 	return nf_ct_change_status_common(ct, ntohl(nla_get_be32(cda[CTA_STATUS])));
 }
 
+#if defined(CONFIG_CPE_FAST_PATH)
+/*
+ * This function detects ctnetlink messages that require
+ * to set the conntrack status to IPS_PERMANENT.
+ * It updates only this bit regardless of other possible
+ * changes.
+ * Return 0 if succesfull
+ */
+static int
+ctnetlink_change_permanent(struct nf_conn *ct, const struct nlattr * const cda[])
+{
+	unsigned int status;
+	u_int32_t id;
+	__be32 conntrack_id = ntohl((__force __be32)nf_ct_get_id(ct));
+
+	if (cda[CTA_STATUS] && cda[CTA_ID]) {
+		status = ntohl(nla_get_be32(cda[CTA_STATUS]));
+		id = ntohl(nla_get_be32(cda[CTA_ID]));
+
+		if (status & IPS_PERMANENT) {
+			if (conntrack_id == id) {
+				ct->status |= IPS_PERMANENT;
+				return 0;
+			}
+			else
+				return -ENOENT;
+		}
+		else if (nf_ct_is_permanent(ct))
+		{
+			/* Clear the PERMANENT bit. */
+			if (conntrack_id == id) {
+				clear_bit(IPS_PERMANENT_BIT, &ct->status);
+				return 0;
+			}
+			else
+				return -ENOENT;
+		}
+	}
+	return -1;
+}
+#endif
+
 static int
 ctnetlink_setup_nat(struct nf_conn *ct, const struct nlattr * const cda[])
 {
@@ -2204,6 +2356,11 @@ ctnetlink_change_conntrack(struct nf_conn *ct,
 			return err;
 	}
 
+#if defined(CONFIG_CPE_FAST_PATH)
+	if (cda[CTA_QOSCONNMARK])
+		ct->qosconnmark = be64_to_cpu(nla_get_be64(cda[CTA_QOSCONNMARK]));
+#endif
+
 #if defined(CONFIG_NF_CONNTRACK_MARK)
 	if (cda[CTA_MARK])
 		ctnetlink_change_mark(ct, cda);
@@ -2342,6 +2499,11 @@ ctnetlink_create_conntrack(struct net *net,
 			goto err2;
 	}
 
+#if defined(CONFIG_CPE_FAST_PATH)
+	if (cda[CTA_QOSCONNMARK])
+		ct->qosconnmark = be64_to_cpu(nla_get_be64(cda[CTA_QOSCONNMARK]));
+#endif
+
 #if defined(CONFIG_NF_CONNTRACK_MARK)
 	if (cda[CTA_MARK])
 		ctnetlink_change_mark(ct, cda);
@@ -2468,6 +2630,15 @@ static int ctnetlink_new_conntrack(struct sk_buff *skb,
 	err = -EEXIST;
 	ct = nf_ct_tuplehash_to_ctrack(h);
 	if (!(info->nlh->nlmsg_flags & NLM_F_EXCL)) {
+#if defined(CONFIG_CPE_FAST_PATH)
+		/* If the permanent status has been set, this is a specific
+		 * message. Don't broadcast the event and don't update the ct */
+		err = ctnetlink_change_permanent(ct, cda);
+		if ((err == 0) || (err == -ENOENT)) {
+			nf_ct_put(ct);
+			return err;
+		}
+#endif
 		err = ctnetlink_change_conntrack(ct, cda);
 		if (err == 0) {
 			nf_conntrack_eventmask_report((1 << IPCT_REPLY) |
diff --git a/net/netfilter/nf_conntrack_proto_tcp.c b/net/netfilter/nf_conntrack_proto_tcp.c
index 0c1d086e96cb..d95187c90d7e 100644
--- a/net/netfilter/nf_conntrack_proto_tcp.c
+++ b/net/netfilter/nf_conntrack_proto_tcp.c
@@ -1330,6 +1330,10 @@ int nf_conntrack_tcp_packet(struct nf_conn *ct,
 		   connection. */
 		set_bit(IPS_ASSURED_BIT, &ct->status);
 		nf_conntrack_event_cache(IPCT_ASSURED, ct);
+#ifdef CONFIG_CPE_FAST_PATH
+		if (old_state == TCP_CONNTRACK_ESTABLISHED && new_state == TCP_CONNTRACK_ESTABLISHED)
+			nf_conntrack_event_cache(IPCT_PROTOINFO, ct);
+#endif
 	}
 	nf_ct_refresh_acct(ct, ctinfo, skb, timeout);
 
diff --git a/net/netfilter/nf_conntrack_standalone.c b/net/netfilter/nf_conntrack_standalone.c
index 3ea60ff7a6a4..f1aab3a1066a 100644
--- a/net/netfilter/nf_conntrack_standalone.c
+++ b/net/netfilter/nf_conntrack_standalone.c
@@ -336,6 +336,13 @@ static int ct_seq_show(struct seq_file *s, void *v)
 
 	if (seq_has_overflowed(s))
 		goto release;
+#ifdef CONFIG_CPE_FAST_PATH
+	if (test_bit(IPS_PERMANENT_BIT, &ct->status))
+		seq_printf(s, "[PERMANENT] ");
+
+	if (seq_has_overflowed(s))
+		goto release;
+#endif
 
 	seq_print_acct(s, ct, IP_CT_DIR_ORIGINAL);
 
@@ -361,6 +368,12 @@ static int ct_seq_show(struct seq_file *s, void *v)
 #if defined(CONFIG_NF_CONNTRACK_MARK)
 	seq_printf(s, "mark=%u ", READ_ONCE(ct->mark));
 #endif
+#if defined(CONFIG_CPE_FAST_PATH)
+	if (ct->qosconnmark != 0)
+		seq_printf(s, "qosconnmark=0x%llx ", (unsigned long long)ct->qosconnmark);
+	if (seq_has_overflowed(s))
+		goto release;
+#endif
 
 	ct_show_secctx(s, ct);
 	ct_show_zone(s, ct, NF_CT_DEFAULT_ZONE_DIR);
diff --git a/net/netfilter/xt_qosconnmark.c b/net/netfilter/xt_qosconnmark.c
new file mode 100644
index 000000000000..a47f1ad05168
--- /dev/null
+++ b/net/netfilter/xt_qosconnmark.c
@@ -0,0 +1,171 @@
+/* xt_connmark - Netfilter module to operate on connection marks
+ *
+ * Copyright (C) 2002,2004 MARA Systems AB <http://www.marasystems.com>
+ * by Henrik Nordstrom <hno@marasystems.com>
+ * Copyright  CC Computer Consultants GmbH, 2007 - 2008
+ * Jan Engelhardt <jengelh@medozas.de>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ */
+
+#include <linux/module.h>
+#include <linux/skbuff.h>
+#include <net/netfilter/nf_conntrack.h>
+#include <net/netfilter/nf_conntrack_ecache.h>
+#include <linux/netfilter/x_tables.h>
+#include <linux/netfilter/xt_qosconnmark.h>
+
+MODULE_AUTHOR("Henrik Nordstrom <hno@marasystems.com>");
+MODULE_DESCRIPTION("Xtables: QOS connection mark operations");
+MODULE_LICENSE("GPL");
+MODULE_ALIAS("ipt_QOSCONNMARK");
+MODULE_ALIAS("ip6t_QOSCONNMARK");
+MODULE_ALIAS("ipt_qosconnmark");
+MODULE_ALIAS("ip6t_qosconnmark");
+
+static unsigned int
+qosconnmark_tg(struct sk_buff *skb, const struct xt_action_param *par)
+{
+	const struct xt_qosconnmark_tginfo1 *info = par->targinfo;
+	enum ip_conntrack_info ctinfo;
+	struct nf_conn *ct;
+	u_int64_t newmark;
+
+	ct = nf_ct_get(skb, &ctinfo);
+	if (ct == NULL)
+		return XT_CONTINUE;
+
+	switch (info->mode) {
+		case XT_QOSCONNMARK_SET:
+			newmark = (ct->qosconnmark & ~info->ctmask) ^ info->mark;
+			if (ct->qosconnmark != newmark) {
+				ct->qosconnmark = newmark;
+				nf_conntrack_event_cache(IPCT_QOSCONNMARK, ct);
+			}
+			break;
+		case XT_QOSCONNMARK_SAVE_QOSMARK:
+			newmark = (ct->qosconnmark & ~info->ctmask) ^
+				(skb->qosmark & info->nfmask);
+			if (ct->qosconnmark != newmark) {
+				ct->qosconnmark = newmark;
+				nf_conntrack_event_cache(IPCT_QOSCONNMARK, ct);
+			}
+			break;
+		case XT_QOSCONNMARK_RESTORE_QOSMARK:
+			newmark = (skb->qosmark & ~info->nfmask) ^
+				(ct->qosconnmark & info->ctmask);
+			skb->qosmark = newmark;
+			break;
+	}
+
+	return XT_CONTINUE;
+}
+
+static int qosconnmark_tg_check(const struct xt_tgchk_param *par)
+{
+	int ret;
+
+	ret = nf_ct_netns_get(par->net, par->family);
+	if (ret < 0)
+		pr_info("cannot load conntrack support for proto=%u\n",
+			par->family);
+	return ret;
+}
+
+ 
+static void qosconnmark_tg_destroy(const struct xt_tgdtor_param *par)
+{
+	nf_ct_netns_put(par->net, par->family);
+}
+
+static bool
+qosconnmark_mt(const struct sk_buff *skb, struct xt_action_param *par)
+{
+	const struct xt_qosconnmark_mtinfo1 *info = par->matchinfo;
+	enum ip_conntrack_info ctinfo;
+	const struct nf_conn *ct;
+
+	ct = nf_ct_get(skb, &ctinfo);
+	if (ct == NULL)
+		return false;
+
+	return ((ct->qosconnmark & info->mask) == info->mark) ^ info->invert;
+}
+
+static int qosconnmark_mt_check(const struct xt_mtchk_param *par)
+{
+	int ret;
+
+	ret = nf_ct_netns_get(par->net, par->family);
+	if (ret < 0)
+		pr_info("cannot load conntrack support for proto=%u\n",
+			par->family);
+	return ret;
+}
+
+static void qosconnmark_mt_destroy(const struct xt_mtdtor_param *par)
+{
+	nf_ct_netns_put(par->net, par->family);
+}
+
+static struct xt_target qosconnmark_tg_reg __read_mostly = {
+	.name           = "QOSCONNMARK",
+	.revision       = 1,
+	.family         = NFPROTO_UNSPEC,
+	.checkentry     = qosconnmark_tg_check,
+	.target         = qosconnmark_tg,
+	.targetsize     = sizeof(struct xt_qosconnmark_tginfo1),
+	.destroy        = qosconnmark_tg_destroy,
+	.me             = THIS_MODULE,
+};
+
+static struct xt_match qosconnmark_mt_reg __read_mostly = {
+	.name           = "qosconnmark",
+	.revision       = 1,
+	.family         = NFPROTO_UNSPEC,
+	.checkentry     = qosconnmark_mt_check,
+	.match          = qosconnmark_mt,
+	.matchsize      = sizeof(struct xt_qosconnmark_mtinfo1),
+	.destroy        = qosconnmark_mt_destroy,
+	.me             = THIS_MODULE,
+};
+
+static int __init qosconnmark_mt_init(void)
+{
+	int ret;
+
+	ret = xt_register_target(&qosconnmark_tg_reg);
+	if (ret < 0)
+		return ret;
+	ret = xt_register_match(&qosconnmark_mt_reg);
+	if (ret < 0) {
+		xt_unregister_target(&qosconnmark_tg_reg);
+		return ret;
+	}
+	return 0;
+}
+
+static void __exit qosconnmark_mt_exit(void)
+{
+	xt_unregister_match(&qosconnmark_mt_reg);
+	xt_unregister_target(&qosconnmark_tg_reg);
+}
+
+module_init(qosconnmark_mt_init);
+module_exit(qosconnmark_mt_exit);
+
+             
+
+
diff --git a/net/netfilter/xt_qosmark.c b/net/netfilter/xt_qosmark.c
new file mode 100644
index 000000000000..771edb1f812f
--- /dev/null
+++ b/net/netfilter/xt_qosmark.c
@@ -0,0 +1,85 @@
+/*
+ * xt_mark - Netfilter module to match NFMARK value
+ *
+ * (C) 1999-2001 Marc Boucher <marc@mbsi.ca>
+ * Copyright  CC Computer Consultants GmbH, 2007 - 2008
+ * Jan Engelhardt <jengelh@medozas.de>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+
+#include <linux/module.h>
+#include <linux/skbuff.h>
+
+#include <linux/netfilter/xt_qosmark.h>
+#include <linux/netfilter/x_tables.h>
+
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Marc Boucher <marc@mbsi.ca>");
+MODULE_DESCRIPTION("Xtables: packet qosmark operations");
+MODULE_ALIAS("ipt_qosmark");
+MODULE_ALIAS("ip6t_qosmark");
+MODULE_ALIAS("ipt_QOSMARK");
+MODULE_ALIAS("ip6t_QOSMARK");
+
+static unsigned int
+qosmark_tg(struct sk_buff *skb, const struct xt_action_param *par)
+{
+	const struct xt_qosmark_tginfo2 *info = par->targinfo;
+
+	skb->qosmark = (skb->qosmark & ~info->mask) ^ info->mark;
+	return XT_CONTINUE;
+}
+
+static bool
+qosmark_mt(const struct sk_buff *skb, struct xt_action_param *par)
+{
+	const struct xt_qosmark_mtinfo1 *info = par->matchinfo;
+
+	return ((skb->qosmark & info->mask) == info->mark) ^ info->invert;
+}
+static struct xt_target qosmark_tg_reg __read_mostly = {
+	.name           = "QOSMARK",
+	.revision       = 2,
+	.family         = NFPROTO_UNSPEC,
+	.target         = qosmark_tg,
+	.targetsize     = sizeof(struct xt_qosmark_tginfo2),
+	.me             = THIS_MODULE,
+};
+
+static struct xt_match qosmark_mt_reg __read_mostly = {
+	.name           = "qosmark",
+	.revision       = 1,
+	.family         = NFPROTO_UNSPEC,
+	.match          = qosmark_mt,
+	.matchsize      = sizeof(struct xt_qosmark_mtinfo1),
+	.me             = THIS_MODULE,
+};
+
+static int __init qosmark_mt_init(void)
+{
+	int ret;
+
+	ret = xt_register_target(&qosmark_tg_reg);
+	if (ret < 0)
+		return ret;
+	ret = xt_register_match(&qosmark_mt_reg);
+	if (ret < 0) {
+		xt_unregister_target(&qosmark_tg_reg);
+		return ret;
+	}
+	return 0;
+}
+
+static void __exit qosmark_mt_exit(void)
+{
+	xt_unregister_match(&qosmark_mt_reg);
+	xt_unregister_target(&qosmark_tg_reg);
+}
+
+module_init(qosmark_mt_init);
+module_exit(qosmark_mt_exit);
+
+
diff --git a/net/wireless/Kconfig b/net/wireless/Kconfig
index 10345388ad13..722332d6dcc9 100644
--- a/net/wireless/Kconfig
+++ b/net/wireless/Kconfig
@@ -1,6 +1,6 @@
 # SPDX-License-Identifier: GPL-2.0-only
 config WIRELESS_EXT
-	bool
+	def_bool y
 
 config WEXT_CORE
 	def_bool y
@@ -12,10 +12,10 @@ config WEXT_PROC
 	depends on WEXT_CORE
 
 config WEXT_SPY
-	bool
+	def_bool y
 
 config WEXT_PRIV
-	bool
+	def_bool y
 
 config CFG80211
 	tristate "cfg80211 - wireless configuration API"
diff --git a/net/wireless/wext-core.c b/net/wireless/wext-core.c
index 838ad6541a17..862c47191b46 100644
--- a/net/wireless/wext-core.c
+++ b/net/wireless/wext-core.c
@@ -984,6 +984,9 @@ static int wireless_process_ioctl(struct net *net, struct iwreq *iwr,
 		else if (private)
 			return private(dev, iwr, cmd, info, handler);
 	}
+	/* Old driver API : call driver ioctl handler */
+	if (dev->netdev_ops->ndo_do_ioctl)
+		return dev->netdev_ops->ndo_do_ioctl(dev, (struct ifreq *)iwr, cmd);
 	return -EOPNOTSUPP;
 }
 
diff --git a/net/xfrm/Makefile b/net/xfrm/Makefile
index 512e0b2f8514..e8e13e0fd593 100644
--- a/net/xfrm/Makefile
+++ b/net/xfrm/Makefile
@@ -23,3 +23,4 @@ obj-$(CONFIG_XFRM_IPCOMP) += xfrm_ipcomp.o
 obj-$(CONFIG_XFRM_INTERFACE) += xfrm_interface.o
 obj-$(CONFIG_XFRM_ESPINTCP) += espintcp.o
 obj-$(CONFIG_DEBUG_INFO_BTF) += xfrm_state_bpf.o
+obj-$(CONFIG_INET_IPSEC_OFFLOAD) += ipsec_flow.o
diff --git a/net/xfrm/ipsec_flow.c b/net/xfrm/ipsec_flow.c
new file mode 100644
index 000000000000..55f5a3856888
--- /dev/null
+++ b/net/xfrm/ipsec_flow.c
@@ -0,0 +1,221 @@
+// SPDX-License-Identifier: GPL-2.0+
+/* Maintain IPSec flow table for ASK fast path
+ *
+ * Copyright 2019 NXP
+ */
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/list.h>
+#include <linux/jhash.h>
+#include <linux/interrupt.h>
+#include <linux/mm.h>
+#include <linux/random.h>
+#include <linux/init.h>
+#include <linux/slab.h>
+#include <linux/smp.h>
+#include <linux/completion.h>
+#include <linux/percpu.h>
+#include <linux/bitops.h>
+#include <linux/notifier.h>
+#include <linux/cpu.h>
+#include <linux/cpumask.h>
+#include <linux/mutex.h>
+#include <net/xfrm.h>
+#include <linux/atomic.h>
+#include <linux/security.h>
+#include <net/net_namespace.h>
+#include "ipsec_flow.h"
+
+/* Type for flow comparison (from removed flow cache) */
+typedef unsigned long flow_compare_t;
+
+/* Return the flow key size in units of flow_compare_t for a given address family */
+static inline size_t flow_key_size(unsigned short family)
+{
+	switch (family) {
+	case AF_INET:
+		return sizeof(struct flowi4) / sizeof(flow_compare_t);
+	case AF_INET6:
+		return sizeof(struct flowi6) / sizeof(flow_compare_t);
+	}
+	return 0;
+}
+
+#define IPSEC_FLOW_TABLE_SIZE  1024
+static struct kmem_cache *ipsec_flow_cachep __read_mostly;
+struct flow_table ipsec_flow_table_global;
+
+static u32 flow_hash_code(const struct flowi *flow, size_t keysize)
+{
+	const u32 *k = (const u32 *)flow;
+	const u32 length = keysize * sizeof(flow_compare_t) / sizeof(u32);
+	const u32 hash_random = 0; /*FIXME */
+
+
+	return jhash2(k, length, hash_random);
+}
+
+static int ipsec_flow_compare(const struct flowi *key1, const struct flowi *key2,
+       size_t keysize)
+{
+	const flow_compare_t *k1, *k1_lim, *k2;
+
+	k1 = (const flow_compare_t *) key1;
+	k1_lim = k1 + keysize;
+
+	k2 = (const flow_compare_t *) key2;
+
+	do {
+		if (*k1++ != *k2++)
+			return 1;
+	} while (k1 < k1_lim);
+
+	return 0;
+}
+
+/*
++* return 1 for new flow 0 for existing flow
++*/
+int ipsec_flow_add(struct net *net, const struct flowi *flow, u16 family, u8 dir, u16 *xfrm_handle)
+{
+	size_t keysize;
+	struct flow_entry *tfle, *fle;
+	struct flow_table *ft;
+	u32 hash;
+	u16 index, update = 0;
+
+	ft = &ipsec_flow_table_global;
+
+
+	keysize = flow_key_size(family);
+	if(!keysize)
+		return 0;
+
+	hash = (flow_hash_code(flow, keysize) &  (IPSEC_FLOW_TABLE_SIZE - 1));
+
+	spin_lock_bh(&ft->ipsec_flow_lock);
+	hlist_for_each_entry(tfle, &ft->hash_table[hash], hlist) {
+		if(tfle->net ==  net &&
+				tfle->family == family &&
+				tfle->dir == dir &&
+				(ipsec_flow_compare(flow, &tfle->flow, keysize) == 0)) {
+			/*Flow found */
+			for (index = 0; index < XFRM_POLICY_TYPE_MAX; index++) {
+				if (tfle->xfrm_handle[index] != xfrm_handle[index]) {
+					/*pr_info("%s()::%d flow handle updating from 0x%x to 0x%x\n",
+					  __func__, __LINE__, tfle->xfrm_handle[index], xfrm_handle[index]);*/
+					tfle->xfrm_handle[index] = xfrm_handle[index];
+					update = 1;
+				}
+			}
+			spin_unlock_bh(&ft->ipsec_flow_lock);
+			if (update) {
+				return 1;
+			}
+			else
+				return 0;
+
+		}
+	}
+	spin_unlock_bh(&ft->ipsec_flow_lock);
+	/* Insert flow into flow table */
+	fle = kmem_cache_alloc(ipsec_flow_cachep, GFP_ATOMIC);
+	if(fle) {
+		fle->net = net;
+		fle->family = family;
+		fle->dir = dir;
+		memcpy(&fle->flow, flow, keysize * sizeof(flow_compare_t));
+		memcpy(fle->xfrm_handle, xfrm_handle, XFRM_POLICY_TYPE_MAX*sizeof(u16));
+		spin_lock_bh(&ft->ipsec_flow_lock);
+		hlist_add_head(&fle->hlist, &ft->hash_table[hash]);
+		ft->flow_cnt++;
+		spin_unlock_bh(&ft->ipsec_flow_lock);
+		/*pr_info("%s flow added, xfrm_handle <0x%x 0x%x> fle->xfrm_handle <0x%x 0x%x>\n",
+		  __func__, xfrm_handle[0], xfrm_handle[1], fle->xfrm_handle[0], fle->xfrm_handle[1]);*/
+
+	}else {
+		pr_err("%s:  Failed to alloc memory, flow is not pushed\n", __func__);
+		return 0;
+	}
+
+	return 1;
+}
+EXPORT_SYMBOL(ipsec_flow_add);
+
+static int ipsec_flow_remove(const struct flowi *flow, u16 family, u8 dir)
+{
+	size_t keysize;
+	struct flow_entry *tfle;
+	struct flow_table *ft;
+	u32 hash;
+
+	ft = &ipsec_flow_table_global;
+
+
+	keysize = flow_key_size(family);
+	if(!keysize)
+		goto ignore_flow;
+
+	hash = (flow_hash_code(flow, keysize) &  (IPSEC_FLOW_TABLE_SIZE - 1));
+
+	spin_lock_bh(&ft->ipsec_flow_lock);
+	hlist_for_each_entry(tfle, &ft->hash_table[hash], hlist) {
+		if(tfle->family == family &&
+				tfle->dir == dir &&
+				(ipsec_flow_compare(flow, &tfle->flow, keysize) == 0)) {
+			/*Flow found */
+			hlist_del(&tfle->hlist);
+			kmem_cache_free(ipsec_flow_cachep, tfle);
+			ft->flow_cnt--;
+			spin_unlock_bh(&ft->ipsec_flow_lock);
+			return 1;
+		}
+	}
+
+	spin_unlock_bh(&ft->ipsec_flow_lock);
+ignore_flow:
+	pr_err("%s: Failed to remove flow\n", __func__);
+	return 0;
+}
+
+void flow_cache_remove(const struct flowi *key,    unsigned short family,
+       unsigned short dir)
+{
+
+	ipsec_flow_remove(key, family, dir);
+}
+
+int ipsec_flow_init(struct net *net)
+{
+	struct flow_table *ft;
+
+	pr_info("%s \n",__func__);
+	ft = &ipsec_flow_table_global;
+
+	if (!ipsec_flow_cachep)
+		ipsec_flow_cachep = kmem_cache_create("ipsec_flow_cache",
+				sizeof(struct flow_entry),
+				0, SLAB_PANIC, NULL);
+	ft->hash_table = kzalloc(sizeof(struct hlist_head) * IPSEC_FLOW_TABLE_SIZE, GFP_KERNEL);
+	if(!ft->hash_table) {
+		pr_err("%s: failed to allocate memory\n", __func__);
+		return -ENOMEM;
+	}
+	ft->flow_cnt = 0;
+	spin_lock_init(&ft->ipsec_flow_lock);
+	return 0;
+}
+EXPORT_SYMBOL(ipsec_flow_init);
+
+void ipsec_flow_fini(struct net *net)
+{
+	struct flow_table *ft;
+
+	pr_info("%s \n",__func__);
+	ft = &ipsec_flow_table_global;
+	kfree(ft->hash_table);
+}
+EXPORT_SYMBOL(ipsec_flow_fini);
+#endif
+
diff --git a/net/xfrm/ipsec_flow.h b/net/xfrm/ipsec_flow.h
new file mode 100644
index 000000000000..ee8a7fa571b8
--- /dev/null
+++ b/net/xfrm/ipsec_flow.h
@@ -0,0 +1,31 @@
+// SPDX-License-Identifier: GPL-2.0+
+/* Maintain IPSec flow table for ASK fast path
+ *
+ * Copyright 2019 NXP
+ */
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+#include <linux/kernel.h>
+#include <linux/list.h>
+#include <linux/mutex.h>
+#include <net/xfrm.h>
+#include <net/net_namespace.h>
+
+struct flow_table {
+	struct hlist_head   *hash_table;
+	spinlock_t      ipsec_flow_lock;
+	int             flow_cnt;
+};
+
+struct flow_entry {
+	struct hlist_node   hlist;
+	struct flowi        flow;
+	struct net      *net;
+	u16         family;
+	u16             xfrm_handle[XFRM_POLICY_TYPE_MAX];
+	u8          dir;
+
+};
+
+int ipsec_flow_add(struct net *net, const struct flowi *flow, u16 family, u8 dir, u16 *xfrm_handle);
+#endif
+
diff --git a/net/xfrm/xfrm_input.c b/net/xfrm/xfrm_input.c
index 841a60a6fbfe..6be170bf0f80 100644
--- a/net/xfrm/xfrm_input.c
+++ b/net/xfrm/xfrm_input.c
@@ -44,6 +44,10 @@ struct xfrm_trans_cb {
 
 #define XFRM_TRANS_SKB_CB(__skb) ((struct xfrm_trans_cb *)&((__skb)->cb[0]))
 
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+extern int dpaa_submit_inb_pkt_to_SEC(struct sk_buff *skb, uint16_t sagd);
+#endif /* IPSEC */
+
 static DEFINE_SPINLOCK(xfrm_input_afinfo_lock);
 static struct xfrm_input_afinfo const __rcu *xfrm_input_afinfo[2][AF_INET6 + 1];
 
@@ -599,6 +603,16 @@ int xfrm_input(struct sk_buff *skb, int nexthdr, __be32 spi, int encap_type)
 			goto drop;
 		}
 
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+		/*net_crit_ratelimited("%s(%d) x->handle %d, mac hdr %p, data %p\n",
+			__FUNCTION__,__LINE__, x->handle, skb_mac_header(skb), skb->data);  */
+		/* check if the corresponding SA is offloaded,
+		   then submit the packet to SEC engine */
+
+		if ((x->offloaded) && 
+		    !(dpaa_submit_inb_pkt_to_SEC(skb, x->handle)))
+			return 0;
+#endif /* IPSEC offload end */
 lock:
 		spin_lock(&x->lock);
 
diff --git a/net/xfrm/xfrm_output.c b/net/xfrm/xfrm_output.c
index a30538a980cc..06a66b6aae92 100644
--- a/net/xfrm/xfrm_output.c
+++ b/net/xfrm/xfrm_output.c
@@ -67,6 +67,10 @@ static int xfrm4_transport_output(struct xfrm_state *x, struct sk_buff *skb)
 	struct iphdr *iph = ip_hdr(skb);
 	int ihl = iph->ihl * 4;
 
+#if defined(CONFIG_INET_IPSEC_OFFLOAD)
+	if(skb->ipsec_offload)
+		return 0;
+#endif
 	skb_set_inner_transport_header(skb, skb_transport_offset(skb));
 
 	skb_set_network_header(skb, -x->props.header_len);
@@ -167,6 +171,10 @@ static int xfrm6_transport_output(struct xfrm_state *x, struct sk_buff *skb)
 	u8 *prevhdr;
 	int hdr_len;
 
+#if defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	if(skb->ipsec_offload)
+		return 0;
+#endif
 	iph = ipv6_hdr(skb);
 	skb_set_inner_transport_header(skb, skb_transport_offset(skb));
 
@@ -413,6 +421,10 @@ static int xfrm4_prepare_output(struct xfrm_state *x, struct sk_buff *skb)
 	IPCB(skb)->flags |= IPSKB_XFRM_TUNNEL_SIZE;
 	skb->protocol = htons(ETH_P_IP);
 
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	if (skb->ipsec_offload)
+		return 0;
+#endif
 	switch (x->props.mode) {
 	case XFRM_MODE_BEET:
 		return xfrm4_beet_encap_add(x, skb);
@@ -436,6 +448,10 @@ static int xfrm6_prepare_output(struct xfrm_state *x, struct sk_buff *skb)
 	skb->ignore_df = 1;
 	skb->protocol = htons(ETH_P_IPV6);
 
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	if (skb->ipsec_offload)
+		return 0;
+#endif
 	switch (x->props.mode) {
 	case XFRM_MODE_BEET:
 		return xfrm6_beet_encap_add(x, skb);
@@ -492,11 +508,40 @@ static int xfrm_output_one(struct sk_buff *skb, int err)
 	struct dst_entry *dst = skb_dst(skb);
 	struct xfrm_state *x = dst->xfrm;
 	struct net *net = xs_net(x);
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	struct xfrm_state *xfrm_vec[XFRM_MAX_DEPTH];
+	int xfrm_nr = 0;
+	int i;
+	struct sec_path *sp;
+#endif
 
 	if (err <= 0 || x->xso.type == XFRM_DEV_OFFLOAD_PACKET)
 		goto resume;
 
 	do {
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+		if (x->offloaded) {
+			if (xfrm_nr == XFRM_MAX_DEPTH) {
+				err = -ENOBUFS;
+				goto out;
+			}
+
+			if (!x->curlft.use_time)
+				x->curlft.use_time = ktime_get_real_seconds();
+
+			xfrm_state_hold(x);
+			xfrm_vec[xfrm_nr++] = x;
+			skb->ipsec_offload = 1;
+
+			err = xfrm_outer_mode_output(x, skb);
+			if (err) {
+				XFRM_INC_STATS(net, LINUX_MIB_XFRMOUTSTATEMODEERROR);
+				goto error_nolock;
+			}
+			goto next_dst;
+		}
+#endif
+
 		err = xfrm_skb_check_space(skb);
 		if (err) {
 			XFRM_INC_STATS(net, LINUX_MIB_XFRMOUTERROR);
@@ -561,6 +606,9 @@ static int xfrm_output_one(struct sk_buff *skb, int err)
 			goto error_nolock;
 		}
 
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+next_dst:
+#endif
 		dst = skb_dst_pop(skb);
 		if (!dst) {
 			XFRM_INC_STATS(net, LINUX_MIB_XFRMOUTERROR);
@@ -571,11 +619,40 @@ static int xfrm_output_one(struct sk_buff *skb, int err)
 		x = dst->xfrm;
 	} while (x && !(x->outer_mode.flags & XFRM_MODE_FLAG_TUNNEL));
 
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	if (!(sp = skb_sec_path(skb))) {
+
+		sp = secpath_set(skb);
+		if (!sp)
+			goto error_nolock;
+	}
+
+	/* Hub and spoke changes: Resetting the POLICY_IN SA and setting only the 
+	   POLICY_OUT SA */
+	if (skb->ipsec_xfrm_dir & ( 1 << XFRM_POLICY_IN))
+	{
+		sp->len = 0;
+		skb->ipsec_xfrm_dir &= ~ ( 1 << XFRM_POLICY_IN);
+	}
+
+	if (xfrm_nr + sp->len > XFRM_MAX_DEPTH)
+		goto error_nolock;
+
+	memcpy(sp->xvec + sp->len, xfrm_vec,
+			xfrm_nr * sizeof(xfrm_vec[0]));
+	sp->len += xfrm_nr;
+#endif
+
+
 	return 0;
 
 error:
 	spin_unlock_bh(&x->lock);
 error_nolock:
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	for (i = 0; i < xfrm_nr; i++)
+		xfrm_state_put(xfrm_vec[i]);
+#endif
 	kfree_skb(skb);
 out:
 	return err;
@@ -862,10 +939,20 @@ static int xfrm4_extract_output(struct xfrm_state *x, struct sk_buff *skb)
 	if (err)
 		return err;
 
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	if (skb->ipsec_offload == 0) {
+		XFRM_MODE_SKB_CB(skb)->protocol = ip_hdr(skb)->protocol;
+		xfrm4_extract_header(skb);
+		return 0;
+	} else {
+		return 0;
+	}
+#else
 	XFRM_MODE_SKB_CB(skb)->protocol = ip_hdr(skb)->protocol;
 
 	xfrm4_extract_header(skb);
 	return 0;
+#endif
 }
 
 #if IS_ENABLED(CONFIG_IPV6)
@@ -909,10 +996,18 @@ static int xfrm6_extract_output(struct xfrm_state *x, struct sk_buff *skb)
 	if (err)
 		return err;
 
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	if (skb->ipsec_offload == 0) {
+		XFRM_MODE_SKB_CB(skb)->protocol = ipv6_hdr(skb)->nexthdr;
+		xfrm6_extract_header(skb);
+	}
+	return 0;
+#else
 	XFRM_MODE_SKB_CB(skb)->protocol = ipv6_hdr(skb)->nexthdr;
 
 	xfrm6_extract_header(skb);
 	return 0;
+#endif
 #else
 	WARN_ON_ONCE(1);
 	return -EAFNOSUPPORT;
diff --git a/net/xfrm/xfrm_policy.c b/net/xfrm/xfrm_policy.c
index 2c42d83fbaa2..6e59a2b10409 100644
--- a/net/xfrm/xfrm_policy.c
+++ b/net/xfrm/xfrm_policy.c
@@ -48,6 +48,11 @@
 #include <net/inet_dscp.h>
 
 #include "xfrm_hash.h"
+#ifdef IPSEC_FLOW_CACHE
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+#include "ipsec_flow.h"
+#endif
+#endif
 
 #define XFRM_QUEUE_TMO_MIN ((unsigned)(HZ/10))
 #define XFRM_QUEUE_TMO_MAX ((unsigned)(60*HZ))
@@ -179,6 +184,15 @@ static struct xfrm_policy_afinfo const __rcu *xfrm_policy_afinfo[AF_INET6 + 1]
 
 static struct kmem_cache *xfrm_dst_cache __ro_after_init;
 
+#ifdef IPSEC_FLOW_CACHE
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+extern int ipsec_nlkey_flow(u16 xfrm_nr, u16 *xfrm_handle,
+		const struct flowi *fl, u16 family, u16 dir, u16 ignore_neigh);
+int ipsec_flow_init(struct net *net);
+void ipsec_flow_fini(struct net *net);
+#endif
+#endif
+
 static struct rhashtable xfrm_policy_inexact_table;
 static const struct rhashtable_params xfrm_pol_inexact_params;
 
@@ -2590,7 +2604,11 @@ xfrm_tmpl_resolve(struct xfrm_policy **pols, int npols, const struct flowi *fl,
 
 }
 
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+int xfrm_get_tos(const struct flowi *fl, int family)
+#else
 static int xfrm_get_tos(const struct flowi *fl, int family)
+#endif
 {
 	if (family == AF_INET)
 		return fl->u.ip4.flowi4_tos & INET_DSCP_MASK;
@@ -2656,6 +2674,9 @@ static inline int xfrm_fill_dst(struct xfrm_dst *xdst, struct net_device *dev,
 
 	return err;
 }
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+EXPORT_SYMBOL(xfrm_get_tos);
+#endif
 
 
 /* Allocate chain of dst_entry's, attach known xfrm's, calculate
@@ -3290,6 +3311,35 @@ struct dst_entry *xfrm_lookup_with_ifid(struct net *net,
 		dst = dst_orig;
 	}
 
+#ifdef IPSEC_FLOW_CACHE
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	{
+		struct dst_entry *dst1 = dst;
+		struct xfrm_state *x;
+		u16 xfrm_handle[XFRM_POLICY_TYPE_MAX];
+		u16 ignore_neigh = 0;
+
+		num_xfrms = 0;
+		memset(xfrm_handle, 0, XFRM_POLICY_TYPE_MAX * sizeof(u16));
+		while (((x = dst1->xfrm) != NULL) && (num_xfrms < XFRM_POLICY_TYPE_MAX)) {
+			xfrm_handle[num_xfrms++] = x->handle;
+			if (x->props.mode == XFRM_MODE_TUNNEL)
+				ignore_neigh = 1;
+			dst1 = xfrm_dst_child(dst1);
+
+			if (dst1 == NULL) {
+				err = -EHOSTUNREACH;
+				goto error;
+			}
+		}
+		if (ipsec_flow_add(net, fl, family, dir, xfrm_handle)) {
+			/* sent flow notification to cmm with sa_handle */
+			ipsec_nlkey_flow(num_xfrms, xfrm_handle, fl, family, (unsigned short)dir, ignore_neigh);
+		}
+	}
+#endif
+#endif
+
 ok:
 	xfrm_pols_put(pols, drop_pols);
 	if (dst && dst->xfrm &&
@@ -3847,6 +3897,31 @@ int __xfrm_policy_check(struct sock *sk, int dir, struct sk_buff *skb,
 			goto reject;
 		}
 
+#ifdef IPSEC_FLOW_CACHE
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+		{
+			struct xfrm_state *x;
+			u16 xfrm_handle[XFRM_POLICY_TYPE_MAX];
+
+			xfrm_nr = 0;
+			memset(xfrm_handle, 0, XFRM_POLICY_TYPE_MAX * sizeof(u16));
+			for (i = sp->len - 1; (i >= 0) && (xfrm_nr < XFRM_POLICY_TYPE_MAX); i--) {
+				x = sp->xvec[i];
+				xfrm_handle[xfrm_nr++] = x->handle;
+			}
+			if (ipsec_flow_add(net, (const struct flowi *)&fl, family, dir, xfrm_handle)) {
+				/* sent flow notification to cmm with sa_handle */
+				ipsec_nlkey_flow(xfrm_nr, xfrm_handle, (const struct flowi *)&fl, family, dir, 0);
+			}
+		}
+
+		/* Hub and spoke changes: Setting the POLICY_IN direction in the packet */
+		skb->ipsec_xfrm_dir |= (1 << XFRM_POLICY_IN);
+
+std_path:
+#endif
+#endif
+
 		xfrm_pols_put(pols, npols);
 		sp->verified_cnt = k;
 
@@ -4316,6 +4391,14 @@ static int __net_init xfrm_net_init(struct net *net)
 	if (rv < 0)
 		goto out_sysctl;
 
+#ifdef IPSEC_FLOW_CACHE
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	rv = ipsec_flow_init(net);
+	if (rv < 0)
+		goto out_ipsec_flow;
+#endif
+#endif
+
 	rv = xfrm_nat_keepalive_net_init(net);
 	if (rv < 0)
 		goto out_nat_keepalive;
@@ -4323,6 +4406,12 @@ static int __net_init xfrm_net_init(struct net *net)
 	return 0;
 
 out_nat_keepalive:
+#ifdef IPSEC_FLOW_CACHE
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	ipsec_flow_fini(net);
+out_ipsec_flow:
+#endif
+#endif
 	xfrm_sysctl_fini(net);
 out_sysctl:
 	xfrm_policy_fini(net);
@@ -4337,6 +4426,11 @@ static int __net_init xfrm_net_init(struct net *net)
 static void __net_exit xfrm_net_exit(struct net *net)
 {
 	xfrm_nat_keepalive_net_fini(net);
+#ifdef IPSEC_FLOW_CACHE
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	ipsec_flow_fini(net);
+#endif
+#endif
 	xfrm_sysctl_fini(net);
 	xfrm_policy_fini(net);
 	xfrm_state_fini(net);
diff --git a/net/xfrm/xfrm_state.c b/net/xfrm/xfrm_state.c
index 6f99fd2d966c..38a0386a7162 100644
--- a/net/xfrm/xfrm_state.c
+++ b/net/xfrm/xfrm_state.c
@@ -58,6 +58,9 @@ static inline bool xfrm_state_hold_rcu(struct xfrm_state __rcu *x)
 	return refcount_inc_not_zero(&x->refcnt);
 }
 
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+static unsigned short xfrm_state_handle;
+#endif
 static inline unsigned int xfrm_dst_hash(struct net *net,
 					 const xfrm_address_t *daddr,
 					 const xfrm_address_t *saddr,
@@ -114,12 +117,22 @@ static unsigned int xfrm_seq_hash(struct net *net, u32 seq)
 			hlist_add_before_rcu(_n, &_x->by);                 \
 	}
 
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
 static void xfrm_hash_transfer(struct hlist_head *list,
 			       struct hlist_head *ndsttable,
 			       struct hlist_head *nsrctable,
 			       struct hlist_head *nspitable,
 			       struct hlist_head *nseqtable,
+			       struct hlist_head *nhtable,
 			       unsigned int nhashmask)
+#else
+static void xfrm_hash_transfer(struct hlist_head *list,
+			       struct hlist_head *ndsttable,
+			       struct hlist_head *nsrctable,
+			       struct hlist_head *nspitable,
+			       struct hlist_head *nseqtable,
+			       unsigned int nhashmask)
+#endif
 {
 	struct hlist_node *tmp;
 	struct xfrm_state *x;
@@ -150,6 +163,13 @@ static void xfrm_hash_transfer(struct hlist_head *list,
 			XFRM_STATE_INSERT(byseq, &x->byseq, nseqtable + h,
 					  x->xso.type);
 		}
+
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+		if (x->handle && x->in_byh_hash) {
+			h = (x->handle & nhashmask);
+			hlist_add_head_rcu(&x->byh, nhtable + h);
+		}
+#endif
 	}
 }
 
@@ -162,6 +182,9 @@ static void xfrm_hash_resize(struct work_struct *work)
 {
 	struct net *net = container_of(work, struct net, xfrm.state_hash_work);
 	struct hlist_head *ndst, *nsrc, *nspi, *nseq, *odst, *osrc, *ospi, *oseq;
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	struct hlist_head *nh, *oh;
+#endif
 	unsigned long nsize, osize;
 	unsigned int nhashmask, ohashmask;
 	int i;
@@ -188,6 +211,16 @@ static void xfrm_hash_resize(struct work_struct *work)
 		xfrm_hash_free(nspi, nsize);
 		return;
 	}
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	nh = xfrm_hash_alloc(nsize);
+	if (!nh) {
+		xfrm_hash_free(ndst, nsize);
+		xfrm_hash_free(nsrc, nsize);
+		xfrm_hash_free(nspi, nsize);
+		xfrm_hash_free(nseq, nsize);
+		return;
+	}
+#endif
 
 	spin_lock_bh(&net->xfrm.xfrm_state_lock);
 	write_seqcount_begin(&net->xfrm.xfrm_state_hash_generation);
@@ -195,17 +228,27 @@ static void xfrm_hash_resize(struct work_struct *work)
 	nhashmask = (nsize / sizeof(struct hlist_head)) - 1U;
 	odst = xfrm_state_deref_prot(net->xfrm.state_bydst, net);
 	for (i = net->xfrm.state_hmask; i >= 0; i--)
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+		xfrm_hash_transfer(odst + i, ndst, nsrc, nspi, nseq, nh, nhashmask);
+#else
 		xfrm_hash_transfer(odst + i, ndst, nsrc, nspi, nseq, nhashmask);
+#endif
 
 	osrc = xfrm_state_deref_prot(net->xfrm.state_bysrc, net);
 	ospi = xfrm_state_deref_prot(net->xfrm.state_byspi, net);
 	oseq = xfrm_state_deref_prot(net->xfrm.state_byseq, net);
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	oh = xfrm_state_deref_prot(net->xfrm.state_byh, net);
+#endif
 	ohashmask = net->xfrm.state_hmask;
 
 	rcu_assign_pointer(net->xfrm.state_bydst, ndst);
 	rcu_assign_pointer(net->xfrm.state_bysrc, nsrc);
 	rcu_assign_pointer(net->xfrm.state_byspi, nspi);
 	rcu_assign_pointer(net->xfrm.state_byseq, nseq);
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	rcu_assign_pointer(net->xfrm.state_byh, nh);
+#endif
 	net->xfrm.state_hmask = nhashmask;
 
 	write_seqcount_end(&net->xfrm.xfrm_state_hash_generation);
@@ -219,6 +262,9 @@ static void xfrm_hash_resize(struct work_struct *work)
 	xfrm_hash_free(osrc, osize);
 	xfrm_hash_free(ospi, osize);
 	xfrm_hash_free(oseq, osize);
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	xfrm_hash_free(oh, osize);
+#endif
 }
 
 static DEFINE_SPINLOCK(xfrm_state_afinfo_lock);
@@ -680,6 +726,9 @@ struct xfrm_state *xfrm_state_alloc(struct net *net)
 		INIT_HLIST_NODE(&x->bysrc);
 		INIT_HLIST_NODE(&x->byspi);
 		INIT_HLIST_NODE(&x->byseq);
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+		INIT_HLIST_NODE(&x->byh);
+#endif
 		hrtimer_init(&x->mtimer, CLOCK_BOOTTIME, HRTIMER_MODE_ABS_SOFT);
 		x->mtimer.function = xfrm_timer_handler;
 		timer_setup(&x->rtimer, xfrm_replay_timer_handler, 0);
@@ -690,6 +739,12 @@ struct xfrm_state *xfrm_state_alloc(struct net *net)
 		x->lft.hard_packet_limit = XFRM_INF;
 		x->replay_maxage = 0;
 		x->replay_maxdiff = 0;
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+		do {
+			x->handle = xfrm_state_handle++;
+		} while (x->handle == 0);
+		x->in_byh_hash = 0;
+#endif
 		x->pcpu_num = UINT_MAX;
 		spin_lock_init(&x->lock);
 	}
@@ -769,6 +824,17 @@ int __xfrm_state_delete(struct xfrm_state *x)
 
 		if (x->id.spi)
 			hlist_del_rcu(&x->byspi);
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+		/*
+		 * if 'handle' value is assigned and xfrm_state is inserted
+		 * into 'byh' hash table, remove it now and reset 'in_byh_hash'
+		 * to zero.
+		 */
+		if (x->handle && x->in_byh_hash) {
+			hlist_del_rcu(&x->byh);
+			x->in_byh_hash = 0;
+		}
+#endif
 		net->xfrm.state_num--;
 		xfrm_nat_keepalive_state_updated(x);
 		spin_unlock(&net->xfrm.xfrm_state_lock);
@@ -1521,6 +1587,19 @@ xfrm_state_find(const xfrm_address_t *daddr, const xfrm_address_t *saddr,
 						  net->xfrm.state_byseq + h,
 						  x->xso.type);
 			}
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+			/*
+			 * at this point, xfrm_state is activated because it
+			 * has been inserted into other linux original hash
+			 * tables.  it must be inserted into 'byh' hash table
+			 * too if it is not yet inserted.
+			 */
+			if (x->handle && !x->in_byh_hash) {
+				h = (x->handle & net->xfrm.state_hmask);
+				hlist_add_head_rcu(&x->byh, net->xfrm.state_byh + h);
+				x->in_byh_hash = 1;
+			}
+#endif
 			x->lft.hard_add_expires_seconds = net->xfrm.sysctl_acq_expires;
 			hrtimer_start(&x->mtimer,
 				      ktime_set(net->xfrm.sysctl_acq_expires, 0),
@@ -1691,6 +1770,19 @@ static void __xfrm_state_insert(struct xfrm_state *x)
 				  x->xso.type);
 	}
 
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	/*
+	 * at this point, xfrm_state is activated because it has been inserted
+	 * into other linux original hash tables.  it must also be inserted
+	 * into 'byh' hash table if it is not yet inserted.
+	 */
+	if (x->handle && !x->in_byh_hash) {
+		h = (x->handle & net->xfrm.state_hmask);
+		hlist_add_head_rcu(&x->byh, net->xfrm.state_byh + h);
+		x->in_byh_hash = 1;
+	}
+#endif
+
 	hrtimer_start(&x->mtimer, ktime_set(1, 0), HRTIMER_MODE_REL_SOFT);
 	if (x->replay_maxage)
 		mod_timer(&x->rtimer, jiffies + x->replay_maxage);
@@ -1712,6 +1804,9 @@ static void __xfrm_state_bump_genids(struct xfrm_state *xnew)
 	u32 mark = xnew->mark.v & xnew->mark.m;
 	u32 if_id = xnew->if_id;
 	u32 cpu_id = xnew->pcpu_num;
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	u16 parent_sa_handle = 0;
+#endif
 
 	h = xfrm_dst_hash(net, &xnew->id.daddr, &xnew->props.saddr, reqid, family);
 	hlist_for_each_entry(x, net->xfrm.state_bydst+h, bydst) {
@@ -1722,8 +1817,19 @@ static void __xfrm_state_bump_genids(struct xfrm_state *xnew)
 		    (mark & x->mark.m) == x->mark.v &&
 		    xfrm_addr_equal(&x->id.daddr, &xnew->id.daddr, family) &&
 		    xfrm_addr_equal(&x->props.saddr, &xnew->props.saddr, family))
+		{
 			x->genid++;
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+			if (!parent_sa_handle)
+			{
+				parent_sa_handle = x->handle;
+			}
+#endif
+		}
 	}
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	xnew->parent_sa_handle = parent_sa_handle;
+#endif
 }
 
 void xfrm_state_insert(struct xfrm_state *x)
@@ -2263,6 +2369,36 @@ xfrm_state_lookup_byaddr(struct net *net, u32 mark,
 }
 EXPORT_SYMBOL(xfrm_state_lookup_byaddr);
 
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+struct xfrm_state *__xfrm_state_lookup_byhandle(struct net *net, u16 handle)
+{
+	unsigned int h = (handle & net->xfrm.state_hmask);
+	struct xfrm_state *x;
+
+	hlist_for_each_entry(x, net->xfrm.state_byh + h, byh) {
+		if (x->handle != handle)
+			continue;
+
+		xfrm_state_hold(x);
+		return x;
+	}
+
+	return NULL;
+}
+
+struct xfrm_state *
+xfrm_state_lookup_byhandle(struct net *net, u16 handle)
+{
+	struct xfrm_state *x;
+
+	spin_lock_bh(&net->xfrm.xfrm_state_lock);
+	x = __xfrm_state_lookup_byhandle(net, handle);
+	spin_unlock_bh(&net->xfrm.xfrm_state_lock);
+	return x;
+}
+EXPORT_SYMBOL(xfrm_state_lookup_byhandle);
+#endif
+
 struct xfrm_state *
 xfrm_find_acq(struct net *net, const struct xfrm_mark *mark, u8 mode, u32 reqid,
 	      u32 if_id, u32 pcpu_num, u8 proto, const xfrm_address_t *daddr,
@@ -2510,6 +2646,20 @@ int xfrm_alloc_spi(struct xfrm_state *x, u32 low, u32 high,
 			x->id.spi = newspi;
 			h = xfrm_spi_hash(net, &x->id.daddr, newspi, x->id.proto, x->props.family);
 			XFRM_STATE_INSERT(byspi, &x->byspi, net->xfrm.state_byspi + h, x->xso.type);
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+			/*
+			 * at this point, xfrm_state is inserted into 'byspi' hash
+			 * table.  this may be an additional step to make the entry
+			 * searchable by SPI.  however, it is a time to consider
+			 * whether the entry is also inserted into 'byh' hash table
+			 * or not.  if it still not be inserted, insert it now.
+			 */
+			if (x->handle && !x->in_byh_hash) {
+				h = (x->handle & net->xfrm.state_hmask);
+				hlist_add_head_rcu(&x->byh, net->xfrm.state_byh + h);
+				x->in_byh_hash = 1;
+			}
+#endif
 			spin_unlock_bh(&net->xfrm.xfrm_state_lock);
 			err = 0;
 			goto unlock;
@@ -3184,6 +3334,13 @@ int __net_init xfrm_state_init(struct net *net)
 	if (!net->xfrm.state_byseq)
 		goto out_byseq;
 
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	net->xfrm.state_byh = xfrm_hash_alloc(sz);
+	if (!net->xfrm.state_byh)
+		goto out_byh;
+	get_random_bytes(&xfrm_state_handle, sizeof(xfrm_state_handle));
+#endif
+
 	net->xfrm.state_cache_input = alloc_percpu(struct hlist_head);
 	if (!net->xfrm.state_cache_input)
 		goto out_state_cache_input;
@@ -3198,6 +3355,10 @@ int __net_init xfrm_state_init(struct net *net)
 	return 0;
 
 out_state_cache_input:
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	xfrm_hash_free(net->xfrm.state_byh, sz);
+out_byh:
+#endif
 	xfrm_hash_free(net->xfrm.state_byseq, sz);
 out_byseq:
 	xfrm_hash_free(net->xfrm.state_byspi, sz);
@@ -3228,6 +3389,10 @@ void xfrm_state_fini(struct net *net)
 	xfrm_hash_free(net->xfrm.state_bysrc, sz);
 	WARN_ON(!hlist_empty(net->xfrm.state_bydst));
 	xfrm_hash_free(net->xfrm.state_bydst, sz);
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	WARN_ON(!hlist_empty(net->xfrm.state_byh));
+	xfrm_hash_free(net->xfrm.state_byh, sz);
+#endif
 	free_percpu(net->xfrm.state_cache_input);
 }
 
diff --git a/net/xfrm/xfrm_user.c b/net/xfrm/xfrm_user.c
index d41e5642625e..0f8543738ab2 100644
--- a/net/xfrm/xfrm_user.c
+++ b/net/xfrm/xfrm_user.c
@@ -1067,6 +1067,10 @@ static void copy_to_user_state(struct xfrm_state *x, struct xfrm_usersa_info *p)
 	if (x->xso.dev)
 		xfrm_dev_state_update_stats(x);
 	memcpy(&p->curlft, &x->curlft, sizeof(p->curlft));
+#if defined(CONFIG_INET_IPSEC_OFFLOAD) || defined(CONFIG_INET6_IPSEC_OFFLOAD)
+	if (x->curr_time)
+		p->curlft.use_time = x->curr_time;
+#endif
 	put_unaligned(x->stats.replay_window, &p->stats.replay_window);
 	put_unaligned(x->stats.replay, &p->stats.replay);
 	put_unaligned(x->stats.integrity_failed, &p->stats.integrity_failed);
diff --git a/tools/perf/.gitignore b/tools/perf/.gitignore
index 1ef45d803024..ac39fdc4b77a 100644
--- a/tools/perf/.gitignore
+++ b/tools/perf/.gitignore
@@ -3,7 +3,6 @@ PERF-CFLAGS
 PERF-GUI-VARS
 PERF-VERSION-FILE
 FEATURE-DUMP
-perf
 !include/perf/
 perf-read-vdso32
 perf-read-vdsox32
-- 
2.47.3

